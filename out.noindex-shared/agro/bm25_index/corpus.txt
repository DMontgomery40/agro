#!/usr/bin/env python3\n"""Root shim: exports `app` from server.app for backward compatibility."""\nfrom server.app import app  # noqa: F401\n\nif __name__ == "__main__":\n    # Optional direct run support\n    import os\n    import uvicorn\n    host = os.getenv("HOST", "127.0.0.1")\n    port = int(os.getenv("PORT", "8012"))\n    uvicorn.run("serve_rag:app", host=host, port=port)
from retrieval.rerank import *  # noqa: F401,F403
from common.config_loader import *  # noqa: F401,F403
from retrieval.hybrid_search import *  # noqa: F401,F403\n\n# Query intent → layer preferences_classify_query(q:str)->str:\n    ql=(q or '').lower()\n    if any(k in ql for k in ['ui','react','component','tsx','page','frontend','render','css']):\n        return 'ui'\n    if any(k in ql for k in ['notification','pushover','apprise','hubspot','provider','integration','adapter','webhook']):\n        return 'integration'\n    if any(k in ql for k in ['diagnostic','health','event log','phi','mask','hipaa','middleware','auth','token','oauth','hmac']):\n        return 'server'\n    if any(k in ql for k in ['sdk','client library','python sdk','node sdk']):\n        return 'sdk'\n    if any(k in ql for k in ['infra','asterisk','sip','t.38','ami','freeswitch','egress','cloudflared']):\n        return 'infra'\n    return 'server'
_project_layer_bonus(layer:str,intent:str)->float:\n    layer_lower=(layer or '').lower()\n    intent_lower=(intent or 'server').lower()\n    table={'server':{'kernel':0.10,'plugin':0.04,'ui':0.00,'docs':0.00,'tests':0.00,'infra':0.02},\n           'integration':{'integration':0.12,'kernel':0.04,'ui':0.00,'docs':0.00,'tests':0.00,'infra':0.00},\n           'ui':{'ui':0.12,'docs':0.06,'kernel':0.02,'plugin':0.02,'tests':0.00,'infra':0.00},\n           'sdk':{'kernel':0.04,'docs':0.02},\n           'infra':{'infra':0.12,'kernel':0.04}}\n    return table.get(intent_lower,{}).get(layer_lower,0.0)
_project_layer_bonus(layer:str,intent:str)->float:\n    layer_lower=(layer or '').lower()\n    intent_lower=(intent or 'server').lower()\n    table={'server':{'server':0.10,'integration':0.06,'fax':0.30,'admin console':0.10,'sdk':0.00,'infra':0.00,'docs':0.02},\n           'integration':{'provider':0.12,'traits':0.10,'server':0.06,'ui':0.00,'sdk':0.00,'infra':0.02,'docs':0.00},\n           'ui':{'ui':0.12,'docs':0.06,'server':0.02,'hipaa':0.20},\n           'sdk':{'sdk':0.12,'server':0.04,'docs':0.02},\n           'infra':{'infra':0.12,'server':0.04,'provider':0.04}}\n    return table.get(intent_lower,{}).get(layer_lower,0.0)\n_provider_plugin_hint(fp:str, code:str)->float:\n    fp=(fp or '').lower()\n    code=(code or '').lower()\n    keys=['provider','providers','integration','adapter','webhook','pushover','apprise','hubspot']\n    return 0.06 if any(k in fp or k in code for k in keys) else 0.0
_origin_bonus(origin:str, mode:str)->float:\n    origin = (origin or '').lower()\n    mode=(mode or 'prefer_first_party').lower()\n    if mode == 'prefer_first_party':\n        return 0.06 if origin=='first_party' else (-0.08 if origin=='vendor' else 0.0)\n    if mode == 'prefer_vendor':\n        return 0.06 if origin=='vendor' else 0.0\n    return 0.0\n_feature_bonus(query:str, fp:str, code:str)->float:\n    ql = (query or '').lower()\n    fp = (fp or '').lower()\n    code=(code or '').lower()\n    bumps = 0.0\n    if any(k in ql for k in ['diagnostic','health','event log','phi','hipaa']):\n        if ('diagnostic' in fp) or ('diagnostic' in code) or ('event' in fp and 'log' in fp):\n            bumps += 0.06\n    return bumps\n_card_bonus(chunk_id: str, card_chunk_ids: set) -> float:\n    """Boost chunks that matched via card-based retrieval."""\n    return 0.08 if str(chunk_id) in card_chunk_ids else 0.0\n\n# Path-aware bonus to tilt results toward likely server/auth code
_path_bonus(fp: str) -> float:\n    fp = (fp or '').lower()\n    bonus = 0.0\n    for sfx, b in [\n        ('/identity/', 0.12),\n        ('/auth/', 0.12),\n        ('/server', 0.10),\n        ('/backend', 0.10),\n        ('/api/', 0.08),\n    ]:\n        if sfx in fp:\n            bonus += b\n    return bonus\n\n# Additional PROJECT-only path boosts (env-tunable)
_project_path_boost(fp: str, repo_tag: str) -> float:\n    import os as _os\n    if (repo_tag or '').lower() != 'project':\n        return 0.0\n    cfg = _os.getenv('project_PATH_BOOSTS', 'app/,lib/,config/,scripts/,server/,api/,api/app,app/services,app/routers,api/admin_ui,app/plugins')\n    tokens = [t.strip().lower() for t in cfg.split(',') if t.strip()]\n    s = (fp or '').lower()\n    bonus = 0.0\n    for tok in tokens:\n        if tok and tok in s:\n            bonus += 0.06\n    return min(bonus, 0.18)\n\n# Load environment from repo root .env without hard-coded paths\ntry:\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / ".env"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nQDRANT_URL = os.getenv('QDRANT_URL','http://127.0.0.1:6333')\nREPO = os.getenv('REPO','project')\nVENDOR_MODE = os.getenv('VENDOR_MODE','prefer_first_party')\n# Allow explicit collection override (for versioned collections per embedding config)\nCOLLECTION = os.getenv('COLLECTION_NAME', f'code_chunks_{REPO}')\n\n# --- Embeddings provider (openai | voyage | local) ---
_lazy_import_openai():\n    from openai import OpenAI\n    return OpenAI(api_key=os.getenv("OPENAI_API_KEY"))\n_lazy_import_voyage():\n    import voyageai\n    return voyageai.Client(api_key=os.getenv("VOYAGE_API_KEY"))\n\n_local_embed_model = None
_get_embedding(text: str, kind: str = "query") -> list[float]:\n    et = (os.getenv("EMBEDDING_TYPE", "openai") or "openai").lower()\n    if et == "voyage":\n        vo = _lazy_import_voyage()\n        out = vo.embed([text], model="voyage-code-3", input_type=kind, output_dimension=512)\n        return out.embeddings[0]\n    if et == "local":\n        global _local_embed_model\n        if _local_embed_model is None:\n            from sentence_transformers import SentenceTransformer\n            _local_embed_model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n        # Normalize embeddings for cosine distance\n        return _local_embed_model.encode([text], normalize_embeddings=True, show_progress_bar=False)[0].tolist()\n    # default openai\n    client = _lazy_import_openai()\n    resp = client.embeddings.create(input=text, model="text-embedding-3-large")\n    return resp.data[0].embedding
rrf(\n    dense: list,\n    sparse: list,\n    k: int = 10,\n    kdiv: int = 60\n) -> list:\n    """\n    Reciprocal Rank Fusion (RRF) for combining dense and sparse retrieval results.\n\n    Args:\n        dense (List): Ranked list of IDs from dense retrieval.\n        sparse (List): Ranked list of IDs from sparse retrieval.\n        k (int, optional): Number of top results to return. Defaults to 10.\n        kdiv (int, optional): RRF constant to dampen rank impact. Defaults to 60.\n\n    Returns:\n        List: Top-k fused IDs by RRF score.\n    """\n    score: dict = collections.defaultdict(float)\n    for rank, pid in enumerate(dense, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    for rank, pid in enumerate(sparse, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    ranked = sorted(score.items(), key=lambda x: x[1], reverse=True)\n    return [pid for pid, _ in ranked[:k]]
_load_chunks(repo: str) -> List[Dict]:\n    """Load minimal chunk metadata (omit code to reduce memory)."""\n    p = os.path.join(out_dir(repo), 'chunks.jsonl')\n    chunks: List[Dict] = []\n    if os.path.exists(p):\n        with open(p, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                # Drop bulky fields to keep memory bounded\n                o.pop('code', None)\n                o.pop('summary', None)\n                o.pop('keywords', None)\n                chunks.append(o)\n    return chunks\n_load_bm25_map(idx_dir: str):\n    # Prefer point IDs (UUID strings) aligned with Qdrant\n    pid_json = os.path.join(idx_dir, 'bm25_point_ids.json')\n    if os.path.exists(pid_json):\n        m = json.load(open(pid_json))\n        return [m[str(i)] for i in range(len(m))]\n    # Fallback to chunk_ids.txt (string chunk IDs)\n    map_path = os.path.join(idx_dir, 'chunk_ids.txt')\n    if os.path.exists(map_path):\n        with open(map_path, 'r', encoding='utf-8') as f:\n            ids = [line.strip() for line in f if line.strip()]\n        return ids\n    return None
_load_cards_bm25(repo: str):\n    idx_dir = os.path.join(out_dir(repo), 'bm25_cards')\n    try:\n        import bm25s\n        retr = bm25s.BM25.load(idx_dir)\n        return retr\n    except Exception:\n        return None\n_load_cards_map(repo: str) -> Dict:\n    """Load cards to get chunk ID mapping. Returns dict with card index -> chunk_id and chunk_id -> card data."""\n    cards_file = os.path.join(out_dir(repo), 'cards.jsonl')\n    cards_by_idx = {}  # card corpus index -> chunk_id\n    cards_by_chunk_id = {}  # chunk_id -> card metadata\n    try:\n        with open(cards_file, 'r', encoding='utf-8') as f:\n            for idx, line in enumerate(f):\n                card = json.loads(line)\n                chunk_id = str(card.get('id', ''))\n                if chunk_id:\n                    cards_by_idx[idx] = chunk_id\n                    cards_by_chunk_id[chunk_id] = card\n        return {'by_idx': cards_by_idx, 'by_chunk_id': cards_by_chunk_id}\n    except Exception:\n        return {'by_idx': {}, 'by_chunk_id': {}}
search(query: str, repo: str, topk_dense: int = 75, topk_sparse: int = 75, final_k: int = 10) -> List[Dict]:\n    chunks = _load_chunks(repo)\n    if not chunks:\n        return []\n\n    # ---- Dense (Qdrant) ----\n    dense_pairs = []\n    qc = QdrantClient(url=QDRANT_URL)\n    coll = os.getenv('COLLECTION_NAME', f'code_chunks_{repo}')\n    try:\n        e = _get_embedding(query, kind="query")\n    except Exception:\n        e = []\n    try:\n        dres = qc.query_points(\n            collection_name=coll,\n            query=e,\n            using='dense',\n            limit=topk_dense,\n            with_payload=models.PayloadSelectorInclude(include=['file_path','start_line','end_line','language','layer','repo','hash','id'])\n        )\n        points = getattr(dres, 'points', dres)\n        dense_pairs = [(str(p.id), dict(p.payload)) for p in points]  # type: ignore\n    except Exception:\n        dense_pairs = []\n\n    # ---- Sparse (BM25S) ----\n    idx_dir = os.path.join(out_dir(repo), 'bm25_index')\n    retriever = bm25s.BM25.load(idx_dir)\n    tokenizer = Tokenizer(stemmer=Stemmer('english'), stopwords='en')\n    tokens = tokenizer.tokenize([query])\n    ids, _ = retriever.retrieve(tokens, k=topk_sparse)\n    # ids shaped (1, k)\n    ids = ids.tolist()[0] if hasattr(ids, 'tolist') else list(ids[0])\n    id_map = _load_bm25_map(idx_dir)\n    by_chunk_id = {str(c['id']): c for c in chunks}\n    sparse_pairs = []\n    for i in ids:\n        if id_map is not None:\n            if 0 <= i < len(id_map):\n                pid_or_cid = id_map[i]\n                key = str(pid_or_cid)\n                if key in by_chunk_id:\n                    # id_map contained chunk id\n                    sparse_pairs.append((key, by_chunk_id[key]))\n                else:\n                    # Fallback to corpus order alignment\n                    if 0 <= i < len(chunks):\n                        sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n        else:\n            # fallback to corpus order alignment\n            if 0 <= i < len(chunks):\n                sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n\n    # Card-based BM25 boosting: retrieve cards and boost matching chunks\n    card_chunk_ids: set = set()\n    cards_retr = _load_cards_bm25(repo)\n    if cards_retr is not None:\n        try:\n            cards_map = _load_cards_map(repo)\n            tokens = tokenizer.tokenize([query])\n            c_ids, _ = cards_retr.retrieve(tokens, k=min(topk_sparse, 30))\n            # Map card indices to chunk IDs\n            c_ids_flat = c_ids[0] if hasattr(c_ids, '__getitem__') else c_ids\n            for card_idx in c_ids_flat:\n                chunk_id = cards_map['by_idx'].get(int(card_idx))\n                if chunk_id:\n                    card_chunk_ids.add(str(chunk_id))\n        except Exception:\n            pass\n\n    # Fuse\n    dense_ids = [pid for pid,_ in dense_pairs]\n    sparse_ids = [pid for pid,_ in sparse_pairs]\n    fused = rrf(dense_ids, sparse_ids, k=max(final_k, 2*final_k)) if dense_pairs else sparse_ids[:final_k]\n    by_id = {pid: p for pid,p in (dense_pairs + sparse_pairs)}\n    docs = [by_id[pid] for pid in fused if pid in by_id]\n    # Hydrate code bodies with a low-memory strategy (lazy, on-demand)\n    HYDRATION_MODE = (os.getenv('HYDRATION_MODE','lazy') or 'lazy').lower()\n    if HYDRATION_MODE != 'none':\n        _hydrate_docs_inplace(repo, docs)\n    docs = ce_rerank(query, docs, top_k=final_k)\n    # Apply path + layer intent + provider + feature + card + (optional) origin bonuses, then resort\n    intent = _classify_query(query)\n    for d in docs:\n        layer_bonus = _project_layer_bonus(d.get('layer',''), intent) if repo=='project' else _project_layer_bonus(d.get('layer',''), intent)\n        origin_bonus = _origin_bonus(d.get('origin',''), VENDOR_MODE) if 'VENDOR_MODE' in os.environ else 0.0\n        repo_tag = d.get('repo', repo)\n        chunk_id = str(d.get('id', ''))\n        d['rerank_score'] = float(\n            d.get('rerank_score', 0.0)\n            + _path_bonus(d.get('file_path', ''))\n            + _project_path_boost(d.get('file_path',''), repo_tag)\n            + layer_bonus\n            + _provider_plugin_hint(d.get('file_path', ''), d.get('code', '')[:1000])\n            + _feature_bonus(query, d.get('file_path',''), d.get('code','')[:800])\n            + _card_bonus(chunk_id, card_chunk_ids)\n            + origin_bonus\n        )\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n    return docs[:final_k]\n\n# Local code cache to hydrate code bodies from chunks.jsonl instead of Qdrant payloads\n_code_cache_by_repo: dict[str, dict] = {}
_load_code_cache(repo: str):\n    import json\n    if repo in _code_cache_by_repo:\n        return _code_cache_by_repo[repo]\n    jl = os.path.join(out_dir(repo), 'chunks.jsonl')\n    cache: dict[str, dict[str, str]] = {'by_hash': {}, 'by_id': {}}\n    try:\n        with open(jl, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                h = o.get('hash')\n                cid = str(o.get('id', ''))\n                code = o.get('code', '')\n                if h:\n                    cache['by_hash'][h] = code\n                if cid:\n                    cache['by_id'][cid] = code\n    except FileNotFoundError:\n        pass\n    _code_cache_by_repo[repo] = cache\n    return cache
_hydrate_docs_inplace(repo: str, docs: List[Dict]) -> None:\n    """Fill missing code for the selected docs by streaming chunks.jsonl once.\n\n    Avoids loading the entire repo into memory. Honors HYDRATION_MAX_CHARS to cap snippet size.\n    """\n    needed_ids: set[str] = set()\n    needed_hashes: set[str] = set()\n    for d in docs:\n        if d.get('code'):\n            continue\n        cid = str(d.get('id','') or '')\n        h = d.get('hash')\n        if cid:\n            needed_ids.add(cid)\n        if h:\n            needed_hashes.add(h)\n    if not needed_ids and not needed_hashes:\n        return\n    jl = os.path.join(out_dir(repo), 'chunks.jsonl')\n    max_chars = int(os.getenv('HYDRATION_MAX_CHARS', '2000') or '2000')\n    found_by_id: dict[str, str] = {}\n    found_by_hash: dict[str, str] = {}\n    try:\n        with open(jl, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                cid = str(o.get('id','') or '')\n                h = o.get('hash')\n                code = (o.get('code') or '')\n                if max_chars > 0 and code:\n                    code = code[:max_chars]\n                if cid and cid in needed_ids and cid not in found_by_id:\n                    found_by_id[cid] = code\n                if h and h in needed_hashes and h not in found_by_hash:\n                    found_by_hash[h] = code\n                if len(found_by_id) >= len(needed_ids) and len(found_by_hash) >= len(needed_hashes):\n                    break\n    except FileNotFoundError:\n        return\n    for d in docs:\n        if not d.get('code'):\n            cid = str(d.get('id','') or '')\n            h = d.get('hash')\n            d['code'] = found_by_id.get(cid) or (found_by_hash.get(h) if h else '') or ''\n\n# --- filename/path boosts applied post-rerank ---
_apply_filename_boosts(docs: list[dict], question: str) -> None:\n    terms = set((question or '').lower().replace('/', ' ').replace('-', ' ').split())\n    for d in docs:\n        fp = (d.get('file_path') or '').lower()\n        fn = os.path.basename(fp)\n        parts = fp.split('/')\n        score = float(d.get('rerank_score', 0.0) or 0.0)\n        if any(t and t in fn for t in terms):\n            score *= 1.5\n        if any(t and t in p for t in terms for p in parts):\n            score *= 1.2\n        d['rerank_score'] = score\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n\n# --- Strict per-repo routing helpers (no fusion) ---
route_repo(query: str, default_repo: str | None = None) -> str:\n    """Route to a repo using repos.json config and lightweight prefixing.\n\n    - Supports explicit prefix: "<name>: question"\n    - Falls back to keyword voting as configured in repos.json\n    - Defaults to configured default_repo (repos.json) or env REPO\n    """\n    try:\n        # Prefer config-driven choice (handles prefixes + keywords)\n        return choose_repo_from_query(query, default=(default_repo or get_default_repo()))\n    except Exception:\n        # Very safe fallback\n        q = (query or '').lower().strip()\n        if ':' in q:\n            cand, _ = q.split(':', 1)\n            cand = cand.strip()\n            if cand:\n                return cand\n        return (default_repo or os.getenv('REPO', 'project') or 'project').strip()\nsearch_routed(query: str, repo_override: str | None = None, final_k: int = 10):\n    repo = (repo_override or route_repo(query, default_repo=os.getenv('REPO', 'project')) or os.getenv('REPO', 'project')).strip()\n    return search(query, repo=repo, final_k=final_k)\n\n# Multi-query expansion (cheap) and routed search
expand_queries(query: str, m: int = 4) -> list[str]:\n    # Fast path: no expansion requested\n    if m <= 1:\n        return [query]\n    try:\n        sys = "Rewrite a developer query into multiple search-friendly variants without changing meaning."\n        user = f"Count: {m}\nQuery: {query}\nOutput one variant per line, no numbering."\n        text, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n        lines = [ln.strip('- ').strip() for ln in (text or '').splitlines() if ln.strip()]\n        uniq = []\n        for ln in lines:\n            if ln and ln not in uniq:\n                uniq.append(ln)\n        return (uniq or [query])[:m]\n    except Exception:\n        return [query]
search_routed_multi(query: str, repo_override: str | None = None, m: int = 4, final_k: int = 10):\n    repo = (repo_override or route_repo(query) or os.getenv('REPO','project')).strip()\n    variants = expand_queries(query, m=m)\n    all_docs = []\n    for qv in variants:\n        docs = search(qv, repo=repo, final_k=final_k)\n        all_docs.extend(docs)\n    # Deduplicate by file_path + line span\n    seen = set()\n    uniq = []\n    for d in all_docs:\n        key = (d.get('file_path'), d.get('start_line'), d.get('end_line'))\n        if key in seen:\n            continue\n        seen.add(key)\n        uniq.append(d)\n    # Rerank union\n    try:\n        from rerank import rerank_results as ce_rerank\n        reranked = ce_rerank(query, uniq, top_k=final_k)\n        _apply_filename_boosts(reranked, query)\n        return reranked\n    except Exception:\n        return uniq[:final_k]
from common.paths import *  # noqa: F401,F403
from common.filtering import *  # noqa: F401,F403
from server.env_model import *  # noqa: F401,F403
#!/usr/bin/env python3\n"""\nMinimal eval loop with regression tracking.\n\nUsage:\n  python eval_loop.py                    # Run once\n  python eval_loop.py --watch            # Run on file changes\n  python eval_loop.py --baseline         # Save current results as baseline\n  python eval_loop.py --compare          # Compare against baseline\n"""\nimport os\nimport sys\nimport json\nimport time\nimport argparse\nfrom typing import Dict, Any\nfrom dotenv import load_dotenv\nfrom eval_rag import hit, GOLDEN_PATH, USE_MULTI, FINAL_K\nfrom retrieval.hybrid_search import search_routed, search_routed_multi\n\nload_dotenv()\n\n\nBASELINE_PATH = os.getenv('BASELINE_PATH', 'eval_baseline.json')
run_eval_with_results() -> Dict[str, Any]:\n    """Run eval and return detailed results."""\n    if not os.path.exists(GOLDEN_PATH):\n        return {"error": f"No golden questions file found at: {GOLDEN_PATH}. Create golden.json with test questions first."}\n\n    try:\n        with open(GOLDEN_PATH) as f:\n            gold = json.load(f)\n    except json.JSONDecodeError as e:\n        return {"error": f"Invalid JSON in {GOLDEN_PATH}: {e}. Check file syntax."}\n    except Exception as e:\n        return {"error": f"Failed to read {GOLDEN_PATH}: {e}"}\n\n    if not isinstance(gold, list):\n        return {"error": f"golden.json must be a JSON array, got {type(gold).__name__}"}\n\n    # Filter out comment entries and invalid questions\n    valid_questions = []\n    for i, row in enumerate(gold):\n        if not isinstance(row, dict):\n            print(f"⚠ Skipping entry {i}: not a dict", file=sys.stderr)\n            continue\n        if 'q' not in row:\n            # Skip comment entries like {"_comment": "..."}\n            continue\n        if not row['q'].strip():\n            print(f"⚠ Skipping entry {i}: empty question", file=sys.stderr)\n            continue\n        valid_questions.append(row)\n\n    if not valid_questions:\n        return {"error": f"No valid questions found in {GOLDEN_PATH}. Each question must have a 'q' field."}\n\n    total = len(valid_questions)\n    hits_top1 = 0\n    hits_topk = 0\n    results = []\n\n    t0 = time.time()\n    for i, row in enumerate(valid_questions, 1):\n        q = row['q']\n        repo = row.get('repo') or os.getenv('REPO', 'agro')\n        expect = row.get('expect_paths') or []\n\n        try:\n            if USE_MULTI:\n                docs = search_routed_multi(q, repo_override=repo, m=4, final_k=FINAL_K)\n            else:\n                docs = search_routed(q, repo_override=repo, final_k=FINAL_K)\n        except Exception as e:\n            print(f"⚠ Search failed for question {i}: {e}", file=sys.stderr)\n            docs = []\n\n        paths = [d.get('file_path', '') for d in docs]\n        top1_hit = hit(paths[:1], expect) if paths else False\n        topk_hit = hit(paths, expect) if paths else False\n\n        if top1_hit:\n            hits_top1 += 1\n        if topk_hit:\n            hits_topk += 1\n\n        results.append({\n            "question": q,\n            "repo": repo,\n            "expect_paths": expect,\n            "top1_path": paths[:1],\n            "top1_hit": top1_hit,\n            "topk_hit": topk_hit,\n            "top_paths": paths[:FINAL_K]\n        })\n\n    dt = time.time() - t0\n\n    return {\n        "total": total,\n        "top1_hits": hits_top1,\n        "topk_hits": hits_topk,\n        "top1_accuracy": round(hits_top1 / max(1, total), 3),\n        "topk_accuracy": round(hits_topk / max(1, total), 3),\n        "final_k": FINAL_K,\n        "use_multi": USE_MULTI,\n        "duration_secs": round(dt, 2),\n        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),\n        "results": results\n    }
save_baseline(results: Dict[str, Any]):\n    """Save current results as baseline."""\n    with open(BASELINE_PATH, 'w') as f:\n        json.dump(results, f, indent=2)\n    print(f"✓ Baseline saved to {BASELINE_PATH}")
compare_with_baseline(current: Dict[str, Any]):\n    """Compare current results with baseline."""\n    if not os.path.exists(BASELINE_PATH):\n        print(f"⚠ No baseline found at {BASELINE_PATH}")\n        print("  Run with --baseline to create one")\n        return\n\n    with open(BASELINE_PATH) as f:\n        baseline = json.load(f)\n\n    print("\n" + "="*60)\n    print("REGRESSION CHECK: Current vs Baseline")\n    print("="*60)\n\n    curr_top1 = current["top1_accuracy"]\n    base_top1 = baseline["top1_accuracy"]\n    curr_topk = current["topk_accuracy"]\n    base_topk = baseline["topk_accuracy"]\n\n    delta_top1 = curr_top1 - base_top1\n    delta_topk = curr_topk - base_topk\n\n    print("\nTop-1 Accuracy:")\n    print(f"  Baseline: {base_top1:.3f}")\n    print(f"  Current:  {curr_top1:.3f}")\n    print(f"  Delta:    {delta_top1:+.3f} {'✓' if delta_top1 >= 0 else '✗'}")\n\n    print(f"\nTop-{FINAL_K} Accuracy:")\n    print(f"  Baseline: {base_topk:.3f}")\n    print(f"  Current:  {curr_topk:.3f}")\n    print(f"  Delta:    {delta_topk:+.3f} {'✓' if delta_topk >= 0 else '✗'}")\n\n    # Check for regressions per-question\n    regressions = []\n    improvements = []\n\n    for i, (curr_res, base_res) in enumerate(zip(current["results"], baseline["results"])):\n        if curr_res["question"] != base_res["question"]:\n            continue  # skip if questions don't align\n\n        if base_res["top1_hit"] and not curr_res["top1_hit"]:\n            regressions.append((i+1, curr_res["question"], curr_res["repo"]))\n        elif not base_res["top1_hit"] and curr_res["top1_hit"]:\n            improvements.append((i+1, curr_res["question"], curr_res["repo"]))\n\n    if regressions:\n        print(f"\n⚠ REGRESSIONS ({len(regressions)} questions):")\n        for idx, q, repo in regressions:\n            print(f"  [{idx}] {repo}: {q}")\n\n    if improvements:\n        print(f"\n✓ IMPROVEMENTS ({len(improvements)} questions):")\n        for idx, q, repo in improvements:\n            print(f"  [{idx}] {repo}: {q}")\n\n    if not regressions and delta_top1 >= -0.05 and delta_topk >= -0.05:\n        print("\n✓ No significant regressions detected")\n        return True\n    else:\n        print("\n✗ Regressions detected!")\n        return False
watch_mode():\n    """Watch for file changes and re-run eval."""\n    print("⏱ Watch mode: monitoring for changes...")\n    print(f"   Watching: {GOLDEN_PATH}, hybrid_search.py, langgraph_app.py")\n\n    files_to_watch = [\n        GOLDEN_PATH,\n        "hybrid_search.py",\n        "langgraph_app.py",\n        "index_repo.py",\n        "rerank.py"\n    ]\n\n    last_mtimes = {}\n    for fp in files_to_watch:\n        if os.path.exists(fp):\n            last_mtimes[fp] = os.path.getmtime(fp)\n\n    while True:\n        time.sleep(5)\n        changed = False\n        for fp in files_to_watch:\n            if not os.path.exists(fp):\n                continue\n            mtime = os.path.getmtime(fp)\n            if fp not in last_mtimes or mtime > last_mtimes[fp]:\n                print(f"\n🔄 Change detected: {fp}")\n                last_mtimes[fp] = mtime\n                changed = True\n\n        if changed:\n            print("\n" + "="*60)\n            print("Running eval...")\n            print("="*60)\n            results = run_eval_with_results()\n            if "error" in results:\n                print(f"Error: {results['error']}")\n            else:\n                print(json.dumps({\n                    "top1_accuracy": results["top1_accuracy"],\n                    "topk_accuracy": results["topk_accuracy"],\n                    "total": results["total"],\n                    "duration_secs": results["duration_secs"]\n                }, indent=2))
main():\n    parser = argparse.ArgumentParser(description="RAG eval loop with regression tracking")\n    parser.add_argument("--baseline", action="store_true", help="Save current results as baseline")\n    parser.add_argument("--compare", action="store_true", help="Compare current results with baseline")\n    parser.add_argument("--watch", action="store_true", help="Watch for file changes and re-run")\n    parser.add_argument("--json", action="store_true", help="Output results as JSON")\n\n    args = parser.parse_args()\n\n    if args.watch:\n        watch_mode()\n        return\n\n    print("Running eval...")\n    results = run_eval_with_results()\n\n    if "error" in results:\n        print(f"Error: {results['error']}", file=sys.stderr)\n        sys.exit(1)\n\n    if args.json:\n        print(json.dumps(results, indent=2))\n    else:\n        print("\n" + "="*60)\n        print("EVAL RESULTS")\n        print("="*60)\n        print(f"Total questions: {results['total']}")\n        print(f"Top-1 accuracy:  {results['top1_accuracy']:.1%} ({results['top1_hits']}/{results['total']})")\n        print(f"Top-{FINAL_K} accuracy: {results['topk_accuracy']:.1%} ({results['topk_hits']}/{results['total']})")\n        print(f"Duration:        {results['duration_secs']}s")\n        print(f"Timestamp:       {results['timestamp']}")\n\n        # Show failures\n        failures = [r for r in results["results"] if not r["topk_hit"]]\n        if failures:\n            print(f"\n⚠ Failures ({len(failures)}):")\n            for r in failures:\n                print(f"  [{r['repo']}] {r['question']}")\n                print(f"    Expected: {r['expect_paths']}")\n                print(f"    Got: {r['top_paths'][:3]}")\n\n    if args.baseline:\n        save_baseline(results)\n    elif args.compare:\n        compare_with_baseline(results)\n\n\nif __name__ == "__main__":\n    main()
from indexer.build_cards import *  # noqa: F401,F403
"""Root shim for backward compatibility: re-export get_index_stats from server.index_stats"""\nfrom server.index_stats import get_index_stats  # noqa: F401
#!/usr/bin/env python3\n"""Root shim forwarding to server.mcp.http for backward compatibility."""\nfrom server.mcp.http import mcp  # re-export tools\nimport os\n\nif __name__ == "__main__":\n    host = os.getenv("MCP_HTTP_HOST", "0.0.0.0")\n    port = int(os.getenv("MCP_HTTP_PORT", "8013"))\n    path = os.getenv("MCP_HTTP_PATH", "/mcp")\n    mcp.run(transport="http", host=host, port=port, path=path)
# Python auto-imports sitecustomize at startup if present in sys.path.\n# We use it to block legacy Chat Completions usage at runtime.\ntry:\n    import openai  # type: ignore\n\n    def _blocked(*_args, **_kwargs):  # noqa: D401\n        raise RuntimeError(\n            "Legacy Chat Completions API is disabled. Use Responses API via env_model.generate_text().\n"\n            "Docs: https://openai.com/index/new-tools-and-features-in-the-responses-api/"\n        )\n\n    # Block classic patterns if present on this installed version\n    if hasattr(openai, "ChatCompletion"):\n        try:\n            openai.ChatCompletion.create = staticmethod(_blocked)  # type: ignore[attr-defined]\n        except Exception:\n            pass\n    # Some older clients expose nested chat.completions\n    if hasattr(openai, "chat"):\n        chat = getattr(openai, "chat")\n        if hasattr(chat, "completions"):\n            try:\n                chat.completions.create = _blocked  # type: ignore[attr-defined]\n            except Exception:\n                pass\nexcept Exception:\n    # If openai not installed yet, do nothing.\n    pass
from server.langgraph_app import build_graph  # shim for backward compatibility\n\nif __name__ == '__main__':\n    import sys\n    q = ' '.join(sys.argv[1:]) if len(sys.argv) > 1 else 'Where is OAuth token validated?'\n    graph = build_graph(); cfg = {'configurable': {'thread_id': 'dev'}}\n    res = graph.invoke({'question': q, 'documents': [], 'generation': '', 'iteration': 0, 'confidence': 0.0}, cfg)\n    print(res['generation'])
import os\nimport json\nimport time\nfrom typing import List\nfrom dotenv import load_dotenv\nfrom retrieval.hybrid_search import search_routed, search_routed_multi\n\nload_dotenv()\n\nGOLDEN_PATH = os.getenv('GOLDEN_PATH', 'golden.json')\nUSE_MULTI = os.getenv('EVAL_MULTI','1') == '1'\nFINAL_K = int(os.getenv('EVAL_FINAL_K','5'))\n\n"""\nGolden file format (golden.json):\n[\n  {"q": "Where is ProviderSetupWizard rendered?", "repo": "project", "expect_paths": ["core/admin_ui/src/components/ProviderSetupWizard.tsx"]},\n  {"q": "Where do we mask PHI in events?", "repo": "project", "expect_paths": ["app/..."]}\n]\n"""\nhit(paths: List[str], expect: List[str]) -> bool:\n    return any(any(exp in p for p in paths) for exp in expect)
main():\n    if not os.path.exists(GOLDEN_PATH):\n        print('No golden file found at', GOLDEN_PATH)\n        return\n    gold = json.load(open(GOLDEN_PATH))\n    total = len(gold)\n    hits_top1 = 0\n    hits_topk = 0\n    t0 = time.time()\n    for i, row in enumerate(gold, 1):\n        q = row['q']\n        repo = row.get('repo') or os.getenv('REPO','project')\n        expect = row.get('expect_paths') or []\n        if USE_MULTI:\n            docs = search_routed_multi(q, repo_override=repo, m=4, final_k=FINAL_K)\n        else:\n            docs = search_routed(q, repo_override=repo, final_k=FINAL_K)\n        paths = [d.get('file_path','') for d in docs]\n        if paths:\n            if hit(paths[:1], expect):\n                hits_top1 += 1\n            if hit(paths, expect):\n                hits_topk += 1\n        print(f"[{i}/{total}] repo={repo} q={q}\n  top1={paths[:1]}\n  top{FINAL_K} hit={hit(paths, expect)}")\n    dt = time.time() - t0\n    print(json.dumps({\n        'total': total,\n        'top1': hits_top1,\n        'topk': hits_topk,\n        'final_k': FINAL_K,\n        'use_multi': USE_MULTI,\n        'secs': round(dt,2)\n    }, indent=2))\n\nif __name__ == '__main__':\n    main()
from retrieval.ast_chunker import *  # noqa: F401,F403
from common.metadata import *  # noqa: F401,F403\n            txt = r.choices[0].message.content or "{}"\n        except Exception as e:\n            return {"summary": f"OpenAI error: {str(e)[:100]}", "keywords": []}\n\n    # Parse JSON response\n    # Parse JSON response; if model returned plain text, fallback to capturing tokens\n    try:\n        data = json.loads(txt)\n        if isinstance(data, dict):\n            kws = data.get("keywords") or []\n            if isinstance(kws, str):\n                try:\n                    kws = json.loads(kws)\n                except Exception:\n                    kws = [w.strip() for w in kws.split(',') if w.strip()]\n            return {"summary": data.get("summary", ""), "keywords": kws}\n    except Exception:\n        pass\n    # heuristic fallback: extract potential keywords from text\n    import re as _re\n    toks = [t.lower() for t in _re.findall(r"\b[a-zA-Z_][a-zA-Z0-9_]{2,}\b", txt or "")][:15]\n    return {"summary": (txt or "")[:300], "keywords": toks}
#!/usr/bin/env python3\n"""\nInteractive CLI chat interface for RAG service.\nUses LangGraph with Redis checkpoints for conversation memory.\n\nUsage:\n    export REPO=agro\n    export THREAD_ID=my-session-1\n    python chat_cli.py\n\nCommands:\n    /repo <name>    - Switch repository (from repos.json)\n    /save           - Save conversation checkpoint\n    /clear          - Clear conversation history\n    /help           - Show commands\n    /exit, /quit    - Exit chat\n"""\nimport os\nimport sys\nfrom pathlib import Path\ntry:\n    from dotenv import load_dotenv\nexcept Exception:\n    # Graceful fallback if python-dotenv is not installed yet\n    def load_dotenv(*args, **kwargs):\n        return False\n\n# Load environment\nload_dotenv(Path(__file__).parent / ".env")\n\nfrom server.langgraph_app import build_graph\nfrom common.config_loader import list_repos\nfrom rich.console import Console\nfrom rich.markdown import Markdown\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\n\nconsole = Console()\n\n# Configuration\nREPO = os.getenv('REPO', 'agro')\nTHREAD_ID = os.getenv('THREAD_ID', 'cli-chat')
ChatCLI:\n    """Interactive CLI chat with RAG."""\n\n    def __init__(self, repo: str = 'agro', thread_id: str = 'cli-chat'):\n        self.repo = repo\n        self.thread_id = thread_id\n        self.graph = None\n        self._init_graph()\n\n    def _init_graph(self):\n        """Initialize LangGraph with Redis checkpoints."""\n        try:\n            self.graph = build_graph()\n            console.print(f"[green]✓[/green] Graph initialized with Redis checkpoints")\n        except Exception as e:\n            console.print(f"[red]✗[/red] Failed to initialize graph: {e}")\n            sys.exit(1)\n\n    def _get_config(self):\n        """Get config for current thread."""\n        return {"configurable": {"thread_id": self.thread_id}}\n\n    def _format_answer(self, generation: str) -> str:\n        """Format answer, removing repo header if present."""\n        lines = generation.split('\n')\n        # Remove [repo: ...] header if present\n        if lines and lines[0].startswith('[repo:'):\n            return '\n'.join(lines[1:]).strip()\n        return generation\n\n    def ask(self, question: str) -> dict:\n        """Ask a question and get answer."""\n        try:\n            state = {\n                "question": question,\n                "documents": [],\n                "generation": "",\n                "iteration": 0,\n                "confidence": 0.0,\n                "repo": self.repo\n            }\n\n            result = self.graph.invoke(state, self._get_config())\n            return result\n        except Exception as e:\n            console.print(f"[red]Error:[/red] {e}")\n            return {"generation": f"Error: {e}", "documents": [], "confidence": 0.0}\n\n    def switch_repo(self, new_repo: str):\n        """Switch to a different repository."""\n        allowed = set(list_repos())\n        if new_repo not in allowed:\n            console.print(f"[red]✗[/red] Invalid repo. Allowed: {sorted(allowed)}")\n            return\n\n        self.repo = new_repo\n        console.print(f"[green]✓[/green] Switched to repo: [bold]{new_repo}[/bold]")\n\n    def show_help(self):\n        """Show available commands."""\n        help_text = """\n## Commands\n\n- `/repo <name>` - Switch repository (from repos.json)\n- `/save` - Save conversation checkpoint\n- `/clear` - Clear conversation history\n- `/help` - Show this help\n- `/exit`, `/quit` - Exit chat\n\n## Examples\n\nAsk a question:\n```\n> Where is OAuth token validated?\n```\n\nSwitch repo:\n```\n> /repo agro\n> How do we handle inbound faxes?\n```\n        """\n        console.print(Markdown(help_text))\n\n    def show_welcome(self):\n        """Show welcome message."""\n        welcome = f"""\n# 🤖 RAG CLI Chat\n\nConnected to: [bold cyan]{self.repo}[/bold cyan]\nThread ID: [bold]{self.thread_id}[/bold]\n\nType your question or use `/help` for commands.\n        """\n        console.print(Panel(Markdown(welcome), border_style="cyan"))\n\n    def run(self):\n        """Main chat loop."""\n        self.show_welcome()\n\n        while True:\n            try:\n                # Get user input\n                user_input = Prompt.ask(\n                    f"\n[bold cyan]{self.repo}[/bold cyan] >",\n                    default=""\n                )\n\n                if not user_input.strip():\n                    continue\n\n                # Handle commands\n                if user_input.startswith('/'):\n                    cmd = user_input.lower().split()[0]\n\n                    if cmd in ['/exit', '/quit']:\n                        console.print("[yellow]Goodbye![/yellow]")\n                        break\n\n                    elif cmd == '/help':\n                        self.show_help()\n                        continue\n\n                    elif cmd == '/repo':\n                        parts = user_input.split(maxsplit=1)\n                        if len(parts) > 1:\n                            self.switch_repo(parts[1].strip())\n                        else:\n                            console.print("[red]Usage:[/red] /repo <project|project>")\n                        continue\n\n                    elif cmd == '/save':\n                        console.print(f"[green]✓[/green] Checkpoint saved (thread: {self.thread_id})")\n                        continue\n\n                    elif cmd == '/clear':\n                        # Create new thread ID to start fresh\n                        import time\n                        self.thread_id = f"cli-chat-{int(time.time())}"\n                        console.print(f"[green]✓[/green] Cleared history (new thread: {self.thread_id})")\n                        continue\n\n                    else:\n                        console.print(f"[red]Unknown command:[/red] {cmd}")\n                        console.print("Type [bold]/help[/bold] for available commands")\n                        continue\n\n                # Ask question\n                console.print("[dim]Thinking...[/dim]")\n                result = self.ask(user_input)\n\n                # Show answer\n                answer = self._format_answer(result.get('generation', ''))\n                confidence = result.get('confidence', 0.0)\n                docs = result.get('documents', [])\n\n                # Display answer in panel\n                console.print("\n")\n                console.print(Panel(\n                    Markdown(answer),\n                    title=f"Answer (confidence: {confidence:.2f})",\n                    border_style="green" if confidence > 0.6 else "yellow"\n                ))\n\n                # Show top citations\n                if docs:\n                    console.print("\n[dim]Top sources:[/dim]")\n                    for i, doc in enumerate(docs[:3], 1):\n                        fp = doc.get('file_path', 'unknown')\n                        start = doc.get('start_line', 0)\n                        end = doc.get('end_line', 0)\n                        score = doc.get('rerank_score', 0.0)\n                        console.print(f"  [dim]{i}.[/dim] {fp}:{start}-{end} [dim](score: {score:.3f})[/dim]")\n\n            except KeyboardInterrupt:\n                console.print("\n[yellow]Use /exit to quit[/yellow]")\n                continue\n            except EOFError:\n                console.print("\n[yellow]Goodbye![/yellow]")\n                break\n            except Exception as e:\n                console.print(f"[red]Error:[/red] {e}")\n                continue
main():\n    """Entry point."""\n    # Check dependencies\n    try:\n        from rich.console import Console\n        from rich.markdown import Markdown\n        from rich.panel import Panel\n        from rich.prompt import Prompt\n    except ImportError:\n        print("Error: Missing 'rich' library. Install with: pip install rich")\n        sys.exit(1)\n\n    # Get config from environment\n    repo = os.getenv('REPO', 'agro')\n    thread_id = os.getenv('THREAD_ID', 'cli-chat')\n\n    # Create and run chat\n    chat = ChatCLI(repo=repo, thread_id=thread_id)\n    chat.run()\n\n\nif __name__ == '__main__':\n    main()
from typing import Any, Dict, List, Optional, Tuple\n\nNumber = float\n\n_looks_local(model_id: Optional[str]) -> bool:\n    return bool(model_id) and (":" in model_id)\n\n_any_true(d: Dict[str, Any], keys: List[str]) -> bool:\n    return any(bool(d.get(k)) for k in keys)\n\n_safe_num(x: Any, default: Number = 0.0) -> Number:\n    try:\n        n = float(x)\n        if n != n:  # NaN\n            return default\n        return n\n    except Exception:\n        return default\n\n_normalize_workload(workload: Dict[str, Any]) -> Dict[str, Number]:\n    R = _safe_num(workload.get("requests_per_day"), 0)\n    Tin = _safe_num(workload.get("tokens_in_per_req"), 0)\n    Tout = _safe_num(workload.get("tokens_out_per_req"), 0)\n    MQ = _safe_num(workload.get("mq_rewrites"), 1)\n    E_tokens = _safe_num(workload.get("embed_tokens_per_req"), Tin) * MQ\n    K_base = max(256.0, float(int(Tout // 4)))\n    K_tokens = _safe_num(workload.get("rerank_tokens_per_req"), K_base) * MQ\n    return dict(R=R, Tin=Tin, Tout=Tout, MQ=MQ, E_tokens=E_tokens, K_tokens=K_tokens)
_weights(wl: Dict[str, Number]) -> Dict[str, Number]:\n    W_GEN = wl["R"] * (wl["Tin"] + wl["Tout"])\n    W_EMB = wl["R"] * wl["E_tokens"]\n    W_RR = wl["R"] * wl["K_tokens"]\n    total = W_GEN + W_EMB + W_RR\n    if total <= 0:\n        return dict(Wg=1 / 3, We=1 / 3, Wr=1 / 3)\n    return dict(Wg=W_GEN / total, We=W_EMB / total, Wr=W_RR / total)\n\n_allowed_set(policy: Dict[str, Any]) -> set:\n    providers = policy.get("providers_allowed") or []\n    return set([p.lower() for p in providers if isinstance(p, str)])\n\n_meets_policy_maps(candidate: Dict[str, Any], policy: Dict[str, Any]) -> bool:\n    regions_allowed = policy.get("regions_allowed")\n    compliance = policy.get("compliance")\n    for comp in ("GEN", "EMB", "RERANK"):\n        row = candidate.get(comp, {})\n        if not row:\n            return False\n        region = row.get("region")\n        comp_flags = set(row.get("compliance", []) or [])\n        if regions_allowed and region and region not in regions_allowed:\n            return False\n        if compliance and comp_flags and not comp_flags.issuperset(set(compliance)):\n            return False\n    return True
_decorate_row(m: Dict[str, Any], comp_type: str, use_heuristics: bool = False) -> Dict[str, Any]:\n    out = dict(m)\n    out["comp"] = comp_type.upper()\n    out["provider"] = (out.get("provider") or "").lower()\n    qs = out.get("quality_score")\n    if qs is None:\n        out["quality_score"] = _infer_quality_score(out, comp_type) if use_heuristics else 0.5\n    else:\n        out["quality_score"] = _safe_num(qs, 0.5)\n    if out.get("latency_p95_ms") is not None:\n        out["latency_p95_ms"] = _safe_num(out["latency_p95_ms"], None)\n    if out.get("throughput_qps") is not None:\n        out["throughput_qps"] = _safe_num(out["throughput_qps"], None)\n    return out
_infer_quality_score(row: Dict[str, Any], comp_type: str) -> Number:\n    """Heuristic quality when not provided in prices.json.\n    Tries to be sensible for performance mode ranking.\n    """\n    prov = (row.get("provider") or "").lower()\n    fam = (row.get("family") or "").lower()\n    model = (row.get("model") or "").lower()\n    c = comp_type.upper()\n\n    if c == "GEN":\n        # OpenAI / o-series / GPT-4 family hierarchy\n        if prov == "openai":\n            if model.startswith("o1"):\n                return 0.95\n            if model.startswith("o3"):\n                return 0.90\n            if "gpt-4o" in model and "mini" not in model:\n                return 0.88\n            if "gpt-4-turbo" in model:\n                return 0.86\n            if model.startswith("gpt-4"):\n                return 0.85\n            if "gpt-4o-mini" in model:\n                return 0.78\n        if prov == "anthropic":\n            if "opus" in model:\n                return 0.98\n            if "3-5-sonnet" in model or "3.5-sonnet" in model or "sonnet" in model:\n                return 0.92\n            if "3-5-haiku" in model or "3.5-haiku" in model or "haiku" in model:\n                return 0.82\n        if prov == "google":\n            if "gemini-1.5-pro" in model:\n                return 0.87\n            if "gemini-1.5-flash" in model:\n                return 0.78\n        if prov == "meta" and "70b" in model:\n            return 0.83\n        if prov == "mistral" and "large" in model:\n            return 0.82\n        if prov == "cohere" and "command-r-plus" in model:\n            return 0.84\n        # local or unknown\n        return 0.72 if prov != "local" else 0.60\n\n    if c == "EMB":\n        if prov == "openai":\n            if "3-large" in model:\n                return 0.90\n            if "3-small" in model:\n                return 0.82\n        if prov == "voyage":\n            return 0.86\n        if prov == "cohere":\n            return 0.78\n        return 0.70 if prov != "local" else 0.60\n\n    if c == "RERANK":\n        if prov == "cohere" and ("3.5" in model or "rerank-3.5" in model):\n            return 0.90\n        if prov in ("hf", "local") and ("bge-reranker" in model or "reranker" in model):\n            return 0.82\n        return 0.75 if prov != "local" else 0.65\n\n    return 0.5
_component_rows(\n    comp_type: str,\n    ALLOW: set,\n    prices: Dict[str, Any],\n    include_local: bool = False,\n    use_heuristics: bool = False,\n) -> List[Dict[str, Any]]:\n    rows: List[Dict[str, Any]] = []\n    models = prices.get("models") or []\n    comp = comp_type.upper()\n\n    for m in models:\n        prov = (m.get("provider") or "").lower()\n        if prov == "local":\n            continue\n        if ALLOW and prov not in ALLOW:\n            continue\n        unit = (m.get("unit") or "")\n        if comp == "GEN":\n            if unit == "1k_tokens" and (\n                _safe_num(m.get("input_per_1k")) > 0 or _safe_num(m.get("output_per_1k")) > 0\n            ):\n                rows.append(_decorate_row(m, comp, use_heuristics))\n        elif comp == "EMB":\n            if _safe_num(m.get("embed_per_1k")) > 0:\n                rows.append(_decorate_row(m, comp, use_heuristics))\n        elif comp == "RERANK":\n            if _safe_num(m.get("rerank_per_1k")) > 0 or unit == "request":\n                rows.append(_decorate_row(m, comp, use_heuristics))\n\n    if include_local and ((not ALLOW) or ("local" in ALLOW)):\n        local_stub = dict(\n            provider="local",\n            model="local",\n            unit="request",\n            quality_score=0.5,\n            latency_p95_ms=None,\n            throughput_qps=None,\n        )\n        rows.insert(0, _decorate_row(local_stub, comp, use_heuristics))\n\n    rows.sort(key=lambda r: r["quality_score"], reverse=True)\n    cap = 4 if comp == "GEN" else 3\n    return rows[:cap]
_pair_limited(GENs, EMBs, RRs, limit: int = 60) -> List[Dict[str, Any]]:\n    out: List[Dict[str, Any]] = []\n    for g in GENs:\n        for e in EMBs:\n            for r in RRs:\n                out.append({"GEN": g, "EMB": e, "RERANK": r})\n                if len(out) >= limit:\n                    return out\n    return out\n\n_valid_pipeline(c: Dict[str, Any]) -> bool:\n    g = c.get("GEN")\n    return bool(g and g.get("provider") and g.get("model"))\n\n_meets_slos(c: Dict[str, Any], slo: Dict[str, Any]) -> bool:\n    target_ms = slo.get("latency_target_ms")\n    min_qps = slo.get("min_qps")\n    if target_ms is None and min_qps is None:\n        return True\n    for comp in ("GEN", "EMB", "RERANK"):\n        row = c.get(comp, {})\n        if target_ms is not None and row.get("latency_p95_ms") is not None:\n            if _safe_num(row.get("latency_p95_ms")) > float(target_ms):\n                return False\n        if min_qps is not None and row.get("throughput_qps") is not None:\n            if _safe_num(row.get("throughput_qps")) < float(min_qps):\n                return False\n    return True
_monthly_cost(c: Dict[str, Any], wl: Dict[str, Number]) -> Number:\n    R = wl["R"]\n    Tin = wl["Tin"]\n    Tout = wl["Tout"]\n    E_tokens = wl["E_tokens"]\n    K_tokens = wl["K_tokens"]\n    P = 30.0\n\n    def gen_cost(row):\n        if row.get("provider") == "local":\n            return 0.0\n        inp = _safe_num(row.get("input_per_1k"))\n        out = _safe_num(row.get("output_per_1k"))\n        return (Tin / 1000.0) * inp + (Tout / 1000.0) * out\n\n    def emb_cost(row):\n        if row.get("provider") == "local":\n            return 0.0\n        emb = _safe_num(row.get("embed_per_1k"))\n        return (E_tokens / 1000.0) * emb\n\n    def rr_cost(row):\n        if row.get("provider") == "local":\n            return 0.0\n        rrk = row.get("rerank_per_1k")\n        if rrk is not None:\n            return (K_tokens / 1000.0) * _safe_num(rrk)\n        return _safe_num(row.get("per_request"))\n\n    per_req = gen_cost(c["GEN"]) + emb_cost(c["EMB"]) + rr_cost(c["RERANK"])\n    return per_req * R * P
_lat_bonus(lat_ms: Optional[Number], target_ms: Optional[Number], alpha=0.02, beta=0.05) -> Number:\n    if lat_ms is None or target_ms is None:\n        return 0.0\n    if lat_ms <= target_ms:\n        return alpha\n    return -beta * ((lat_ms - target_ms) / target_ms)\n\n_utility(c: Dict[str, Any], wl_w: Dict[str, Number], defaults: Dict[str, Any], slo: Dict[str, Any]) -> Number:\n    Qg = _safe_num(c["GEN"].get("quality_score"), 0.5)\n    Qe = _safe_num(c["EMB"].get("quality_score"), 0.5)\n    Qr = _safe_num(c["RERANK"].get("quality_score"), 0.5)\n    target_ms = slo.get("latency_target_ms")\n    Lg = _lat_bonus(c["GEN"].get("latency_p95_ms"), target_ms)\n    Le = _lat_bonus(c["EMB"].get("latency_p95_ms"), target_ms)\n    Lr = _lat_bonus(c["RERANK"].get("latency_p95_ms"), target_ms)\n    U_gen = Qg + Lg\n    U_emb = Qe + Le\n    U_rr = Qr + Lr\n    U = wl_w["Wg"] * U_gen + wl_w["We"] * U_emb + wl_w["Wr"] * U_rr\n    def_gen = defaults.get("gen_model")\n    if def_gen and c["GEN"].get("model") == def_gen:\n        U += 0.01\n    return U
_select_cost(C: List[Dict[str, Any]], B: Optional[Number]) -> Dict[str, Any]:\n    if B is not None:\n        feasible = [c for c in C if c["monthly"] <= B]\n        if feasible:\n            return min(feasible, key=lambda x: x["monthly"])\n    return min(C, key=lambda x: x["monthly"])\n\n_select_performance(C: List[Dict[str, Any]]) -> Dict[str, Any]:\n    # Maximize utility. If tie, prefer higher sum of component qualities; then tie-break by min cost.\n    bestU = max(c["utility"] for c in C)\n    top = [c for c in C if c["utility"] == bestU]\n    if len(top) <= 1:\n        return top[0]\n    def qsum(c: Dict[str, Any]) -> Number:\n        return _safe_num(c["GEN"].get("quality_score"), 0.0) + _safe_num(c["EMB"].get("quality_score"), 0.0) + _safe_num(c["RERANK"].get("quality_score"), 0.0)\n    bestQ = max(qsum(c) for c in top)\n    top2 = [c for c in top if qsum(c) == bestQ]\n    return min(top2, key=lambda x: x["monthly"])
_select_balanced(C: List[Dict[str, Any]], B: Optional[Number]) -> Dict[str, Any]:\n    if B is not None:\n        feasible = [c for c in C if c["monthly"] <= B]\n        if feasible:\n            bestU = max(c["utility"] for c in feasible)\n            top = [c for c in feasible if c["utility"] == bestU]\n            return min(top, key=lambda x: x["monthly"])\n        lam = 1.0 / (B if B and B > 0 else 1.0)\n        def score(c):\n            return c["utility"] - lam * (c["monthly"] - B)\n\n        return max(C, key=score)\n    return _select_performance(C)
autoprofile(request: Dict[str, Any], prices: Dict[str, Any]) -> Tuple[Dict[str, str], Dict[str, Any]]:\n    hw = request.get("hardware", {})\n    rt = hw.get("runtimes", {}) or {}\n    policy = request.get("policy", {}) or {}\n    wl = _normalize_workload(request.get("workload", {}) or {})\n    obj = request.get("objective", {}) or {}\n    defaults = request.get("defaults", {}) or {}\n\n    ALLOW = _allowed_set(policy)\n    local_cap = _any_true(rt, ["cuda", "ollama", "coreml", "openvino", "vpu", "npu", "mps"])\n    B = obj.get("monthly_budget_usd")\n    mode = (obj.get("mode") or "balanced").lower()\n    slo = {"latency_target_ms": obj.get("latency_target_ms"), "min_qps": obj.get("min_qps")}\n\n    W = _weights(wl)\n    tuning = request.get("tuning", {}) or {}\n    use_heuristics = bool(tuning.get("use_heuristic_quality"))\n\n    # Diagnostics: available rows under current provider policy\n    diag = {\n        "providers_allowed": sorted(list(ALLOW)) if ALLOW else None,\n        "local_cap": bool(local_cap),\n        "use_heuristic_quality": use_heuristics,\n        "rows": {\n            "gen": len(_component_rows("GEN", ALLOW, prices, include_local=False, use_heuristics=use_heuristics)),\n            "emb": len(_component_rows("EMB", ALLOW, prices, include_local=local_cap, use_heuristics=use_heuristics)),\n            "rerank": len(_component_rows("RERANK", ALLOW, prices, include_local=local_cap, use_heuristics=use_heuristics)),\n        }\n    }\n\n    def build_candidates(AL: set) -> List[Dict[str, Any]]:\n        C: List[Dict[str, Any]] = []\n        if local_cap:\n            gen_local = defaults.get("gen_model") if _looks_local(defaults.get("gen_model")) else None\n            top_cloud_gen = _component_rows("GEN", AL, prices, include_local=False, use_heuristics=use_heuristics)\n            GENs = [{"provider": "local", "model": gen_local}] if gen_local else top_cloud_gen\n            EMBs = _component_rows("EMB", AL, prices, include_local=True, use_heuristics=use_heuristics)\n            RRs = _component_rows("RERANK", AL, prices, include_local=True, use_heuristics=use_heuristics)\n            C.extend(_pair_limited(GENs, EMBs, RRs, limit=60))\n        GENs = _component_rows("GEN", AL, prices, include_local=False, use_heuristics=use_heuristics)\n        EMBs = _component_rows("EMB", AL, prices, include_local=local_cap, use_heuristics=use_heuristics)\n        RRs = _component_rows("RERANK", AL, prices, include_local=local_cap, use_heuristics=use_heuristics)\n        C.extend(_pair_limited(GENs, EMBs, RRs, limit=60))\n        C = [c for c in C if _valid_pipeline(c)]\n        C = [c for c in C if _meets_slos(c, slo)]\n        try:\n            C = [c for c in C if _meets_policy_maps(c, policy)]\n        except Exception:\n            pass\n        return C\n\n    C = build_candidates(ALLOW)\n\n    # Fallback: if providers_allowed is non-empty and produced no candidates, relax provider filter once.\n    relaxed = False\n    if not C and ALLOW:\n        C = build_candidates(set())\n        relaxed = bool(C)\n\n    if not C:\n        return {}, {"error": "no_viable_candidate", "why": "after building/filters", "providers_allowed": list(ALLOW), "diag": diag}\n\n    for c in C:\n        c["monthly"] = _monthly_cost(c, wl)\n        c["utility"] = _utility(c, W, defaults, slo)\n\n    if mode == "cost":\n        winner = _select_cost(C, B)\n    elif mode == "performance":\n        winner = _select_performance(C)\n    else:\n        winner = _select_balanced(C, B)\n\n    # Recommend MQ_REWRITES when not provided (derive from objective + budget + workload size)\n    def recommend_mq(mode: str, B: Optional[Number], wl: Dict[str, Number]) -> int:\n        tin = wl.get("Tin", 0.0); tout = wl.get("Tout", 0.0)\n        size = tin + tout\n        B = (B or 0.0)\n        if mode == "performance":\n            if B >= 1000 or size >= 50000:  # heavy usage or large prompts/answers\n                return 6\n            if B >= 100 or size >= 5000:\n                return 4\n            return 3\n        if mode == "cost":\n            if B < 10 and size < 2000:\n                return 1\n            return 2\n        # balanced\n        if B >= 50 or size >= 5000:\n            return 4\n        return 3\n\n    mq = int(wl["MQ"]) if wl["MQ"] > 0 else recommend_mq(mode, B, wl)\n\n    env: Dict[str, str] = {\n        "HYDRATION_MODE": "lazy",\n        "MQ_REWRITES": str(mq),\n        "GEN_MODEL": winner["GEN"]["model"],\n        "EMBEDDING_TYPE": "local" if winner["EMB"]["provider"] == "local" else winner["EMB"]["provider"],\n        "RERANK_BACKEND": "local" if winner["RERANK"]["provider"] == "local" else winner["RERANK"]["provider"],\n    }\n    if env["RERANK_BACKEND"] == "cohere":\n        env["COHERE_RERANK_MODEL"] = winner["RERANK"]["model"]\n\n    reason = {\n        "objective": mode,\n        "budget": B,\n        "workload": wl,\n        "weights": W,\n        "candidates_total": len(C),\n        "selected": {\n            "gen": winner["GEN"],\n            "embed": winner["EMB"],\n            "rerank": winner["RERANK"],\n            "monthly": winner["monthly"],\n            "utility": winner["utility"],\n        },\n        "policy_relaxed": relaxed,\n        "diag": diag,\n    }\n    return env, reason
# coding: utf-8\nfrom common.qdrant_utils import *  # noqa: F401,F403
import { defineConfig } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: 'tests',\n  fullyParallel: true,\n  timeout: 60_000,\n  expect: { timeout: 10_000 },\n  use: {\n    baseURL: 'http://127.0.0.1:8012',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'retain-on-failure'\n  },\n  webServer: {\n    command: "bash -lc '. .venv/bin/activate && source scripts/select_index.sh shared || true; uvicorn serve_rag:app --host 127.0.0.1 --port 8012'",\n    url: 'http://127.0.0.1:8012/health',\n    reuseExistingServer: true,\n    timeout: 120_000,\n    stdout: 'pipe',\n    stderr: 'pipe'\n  }\n});
from indexer.index_repo import *  # noqa: F401,F403\n\nif __name__ == "__main__":\n    # Run canonical entrypoint when invoked as a script\n    from indexer.index_repo import main as _main\n    _main()
from retrieval.embed_cache import *  # noqa: F401,F403
#!/usr/bin/env python3\n"""Root shim forwarding to server.mcp.server.MCPServer for backward compatibility."""\nfrom server.mcp.server import MCPServer\n\nif __name__ == "__main__":\n    MCPServer().run()
import { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: 'html',\n\n  use: {\n    baseURL: 'http://127.0.0.1:8012',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n  ],\n\n  webServer: {\n    command: '.venv/bin/uvicorn serve_rag:app --host 127.0.0.1 --port 8012',\n    url: 'http://127.0.0.1:8012/health',\n    reuseExistingServer: true,\n    timeout: 120 * 1000,\n  },\n});
"""\nInteraction Tests for AGRO GUI\nTests user interactions and workflows\n"""\nimport pytest\nfrom playwright.sync_api import Page, expect\n\ntest_cost_calculator_interaction(page: Page):\n    """Test cost calculator interaction"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Fill in cost calculator inputs\n    page.fill("#cost-in", "1000")\n    page.fill("#cost-out", "2000")\n    page.fill("#cost-rpd", "50")\n    \n    # Click calculate button\n    page.click("#btn-estimate")\n    \n    # Wait for response\n    page.wait_for_timeout(1000)\n    \n    # Check that results are displayed (not just dashes)\n    daily = page.locator("#cost-daily")\n    expect(daily).not_to_contain_text("—")
test_profile_save_interaction(page: Page):\n    """Test saving a profile"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Enter profile name\n    test_profile_name = "test-profile-playwright"\n    page.fill("#profile-name", test_profile_name)\n    \n    # Click save button\n    page.click("#btn-save-profile")\n    \n    # Wait for save operation\n    page.wait_for_timeout(1000)\n    \n    # Verify profile appears in list (if profiles list is visible)\n    # This might show in an alert or list - adjust based on actual behavior\n\ntest_model_selection_changes(page: Page):\n    """Test changing model selections"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Navigate to Models tab\n    page.click("button:has-text('Models')")\n    \n    # Change primary model\n    gen_model_input = page.locator("input[name='GEN_MODEL']")\n    expect(gen_model_input).to_be_visible()\n    gen_model_input.fill("gpt-4o")\n    \n    # Verify input was changed\n    expect(gen_model_input).to_have_value("gpt-4o")
test_retrieval_parameters_editable(page: Page):\n    """Test that retrieval parameters can be edited"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Navigate to Retrieval tab\n    page.click("button:has-text('Retrieval')")\n    \n    # Change Multi-Query Rewrites\n    mq_input = page.locator("input[name='MQ_REWRITES']")\n    expect(mq_input).to_be_visible()\n    mq_input.fill("5")\n    expect(mq_input).to_have_value("5")\n    \n    # Change Final K\n    final_k_input = page.locator("input[name='FINAL_K']")\n    expect(final_k_input).to_be_visible()\n    final_k_input.fill("20")\n    expect(final_k_input).to_have_value("20")
test_infrastructure_settings_visible(page: Page):\n    """Test infrastructure settings are visible and editable"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Navigate to Infrastructure tab\n    page.click("button:has-text('Infrastructure')")\n    \n    # Check Qdrant URL field\n    qdrant_input = page.locator("input[name='QDRANT_URL']")\n    expect(qdrant_input).to_be_visible()\n    expect(qdrant_input).to_have_value("http://127.0.0.1:6333")\n    \n    # Check Redis URL field\n    redis_input = page.locator("input[name='REDIS_URL']")\n    expect(redis_input).to_be_visible()\n    expect(redis_input).to_have_value("redis://127.0.0.1:6379/0")\n\ntest_auto_profile_budget_input(page: Page):\n    """Test auto-profile budget input"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Should be on dashboard by default\n    budget_input = page.locator("#budget")\n    expect(budget_input).to_be_visible()\n    \n    # Change budget value\n    budget_input.fill("100")\n    expect(budget_input).to_have_value("100")
test_git_hooks_status_check(page: Page):\n    """Test git hooks status check"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Navigate to Tools tab\n    page.click("button:has-text('Tools')")\n    \n    # Check hooks status is displayed\n    hooks_status = page.locator("#hooks-status")\n    expect(hooks_status).to_be_visible()\n\ntest_wizard_oneclick_button(page: Page):\n    """Test the wizard one-click configuration button"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Should be on dashboard\n    wizard_btn = page.locator("#btn-wizard-oneclick")\n    expect(wizard_btn).to_be_visible()\n    expect(wizard_btn).to_contain_text("Configure Automatically")
test_responsive_sidebar(page: Page):\n    """Test that sidebar is visible and contains expected sections"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Check sidepanel is visible\n    expect(page.locator(".sidepanel")).to_be_visible()\n    \n    # Check all expected sections\n    sections = [\n        "Live Cost Calculator",\n        "Profiles",\n        "Auto‑Tune",\n        "Secrets Ingest"\n    ]\n    \n    for section in sections:\n        expect(page.locator(f"h4:has-text('{section}')")).to_be_visible()\n\ntest_secrets_dropzone_present(page: Page):\n    """Test that secrets dropzone is present"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    dropzone = page.locator("#dropzone")\n    expect(dropzone).to_be_visible()\n    expect(dropzone).to_contain_text("Drop .env")
"""\nBasic GUI Tests for AGRO Configuration Interface\nTests core functionality and navigation\n"""\nimport pytest\nimport re\nfrom playwright.sync_api import Page, expect\n\ntest_health_endpoint_accessible(page: Page):\n    """Test that the health endpoint is accessible"""\n    response = page.request.get("http://127.0.0.1:8012/health")\n    assert response.ok\n    data = response.json()\n    assert data["status"] == "healthy"\n    assert data["graph_loaded"] == True\n\ntest_gui_loads_successfully(page: Page):\n    """Test that the GUI main page loads"""\n    page.goto("http://127.0.0.1:8012/")\n    expect(page).to_have_title("AGRO — Local Configuration GUI")\n    \n    # Check that main elements are present\n    expect(page.locator(".topbar")).to_be_visible()\n    expect(page.locator(".brand")).to_contain_text("AGRO")
test_tabs_are_present(page: Page):\n    """Test that all major tabs are present"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    tabs = [\n        "Dashboard",\n        "Models",\n        "Retrieval",\n        "Repos & Indexing",\n        "Infrastructure",\n        "Tools"\n    ]\n    \n    for tab_name in tabs:\n        expect(page.locator(f"button:has-text('{tab_name}')")).to_be_visible()\n\ntest_tab_switching_works(page: Page):\n    """Test that clicking tabs changes the active content"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Click Models tab\n    page.click("button:has-text('Models')")\n    expect(page.locator("#tab-generation")).to_be_visible()\n    expect(page.locator("button[data-tab='models']")).to_have_class(re.compile("active"))\n    \n    # Click Infrastructure tab\n    page.click("button:has-text('Infrastructure')")\n    expect(page.locator("#tab-infra")).to_be_visible()\n    expect(page.locator("button[data-tab='infra']")).to_have_class(re.compile("active"))
test_health_button_works(page: Page):\n    """Test that the health check button works"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Click health button\n    page.click("#btn-health")\n    \n    # Wait for status update\n    page.wait_for_timeout(500)\n    \n    # Check that health status is updated\n    health_status = page.locator("#health-status")\n    expect(health_status).not_to_contain_text("—")\n\ntest_dashboard_overview_visible(page: Page):\n    """Test that dashboard overview section is visible"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Should be on dashboard by default\n    expect(page.locator("#tab-dashboard")).to_be_visible()\n    expect(page.locator(".settings-section.overview")).to_be_visible()\n    expect(page.locator("#dash-health")).to_be_visible()
test_cost_calculator_present(page: Page):\n    """Test that the live cost calculator is present in sidebar"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    expect(page.locator(".sidepanel")).to_be_visible()\n    expect(page.locator("h4:has-text('Live Cost Calculator')")).to_be_visible()\n    expect(page.locator("#cost-provider")).to_be_visible()\n    expect(page.locator("#btn-estimate")).to_be_visible()\n\ntest_profiles_section_visible(page: Page):\n    """Test that profiles section is visible"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    expect(page.locator("h4:has-text('Profiles')")).to_be_visible()\n    expect(page.locator("#profile-name")).to_be_visible()\n    expect(page.locator("#btn-save-profile")).to_be_visible()
test_global_search_present(page: Page):\n    """Test that global search is present"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    search_box = page.locator("#global-search")\n    expect(search_box).to_be_visible()\n    expect(search_box).to_have_attribute("placeholder", "Search settings (Ctrl+K)")\n\ntest_apply_changes_button_present(page: Page):\n    """Test that Apply All Changes button is present"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    expect(page.locator("#save-btn")).to_be_visible()\n    expect(page.locator("#save-btn")).to_contain_text("Apply All Changes")\n\n\n@pytest.mark.parametrize("tab,content_id", [\n    ("models", "tab-generation"),\n    ("retrieval", "tab-retrieval"),\n    ("repos", "tab-repos"),\n    ("infra", "tab-infra"),\n    ("tools", "tab-tools"),\n])test_tab_content_loads(page: Page, tab: str, content_id: str):\n    """Parametrized test for tab content loading"""\n    page.goto("http://127.0.0.1:8012/")\n    page.click(f"button[data-tab='{tab}']")\n    expect(page.locator(f"#{content_id}")).to_be_visible()
"""\nAPI Tests for AGRO Backend\nTests the FastAPI endpoints\n"""\nimport pytest\nfrom playwright.sync_api import Page, APIRequestContext\n\ntest_config_endpoint(page: Page):\n    """Test /api/config endpoint"""\n    response = page.request.get("http://127.0.0.1:8012/api/config")\n    assert response.ok\n    data = response.json()\n    assert "env" in data\n    assert "repos" in data\n    assert isinstance(data["env"], dict)\n    assert isinstance(data["repos"], list)\n\ntest_prices_endpoint(page: Page):\n    """Test /api/prices endpoint"""\n    response = page.request.get("http://127.0.0.1:8012/api/prices")\n    assert response.ok\n    data = response.json()\n    assert "models" in data\n    assert isinstance(data["models"], list)\n\ntest_scan_hw_endpoint(page: Page):\n    """Test /api/scan-hw endpoint"""\n    response = page.request.post("http://127.0.0.1:8012/api/scan-hw")\n    assert response.ok\n    data = response.json()\n    assert "info" in data\n    assert "runtimes" in data\n    assert "tools" in data\n    assert "os" in data["info"]\n    assert "arch" in data["info"]
test_profiles_list_endpoint(page: Page):\n    """Test /api/profiles endpoint"""\n    response = page.request.get("http://127.0.0.1:8012/api/profiles")\n    assert response.ok\n    data = response.json()\n    assert "profiles" in data\n    assert isinstance(data["profiles"], list)\n\ntest_git_hooks_status_endpoint(page: Page):\n    """Test /api/git/hooks/status endpoint"""\n    response = page.request.get("http://127.0.0.1:8012/api/git/hooks/status")\n    assert response.ok\n    data = response.json()\n    assert "dir" in data\n    assert "post_checkout" in data\n    assert "post_commit" in data\n\ntest_keywords_endpoint(page: Page):\n    """Test /api/keywords endpoint"""\n    response = page.request.get("http://127.0.0.1:8012/api/keywords")\n    assert response.ok\n    data = response.json()\n    assert "keywords" in data\n    assert isinstance(data["keywords"], list)
test_search_endpoint_requires_query(page: Page):\n    """Test /search endpoint validation"""\n    response = page.request.get("http://127.0.0.1:8012/search")\n    # Should fail without query parameter\n    assert not response.ok\n\ntest_answer_endpoint_requires_query(page: Page):\n    """Test /answer endpoint validation"""\n    response = page.request.get("http://127.0.0.1:8012/answer")\n    # Should fail without query parameter\n    assert not response.ok
import { test, expect } from '@playwright/test';\n\ntest.describe('GUI smoke', () => {\n  test.beforeEach(async ({ page }) => {\n    await page.goto('/gui/');\n    await page.waitForSelector('.tab-bar');\n  });\n\n  test('dashboard renders and health shows OK', async ({ page }) => {\n    await expect(page.locator('#dash-health')).toBeVisible();\n    // Kick health\n    await page.waitForTimeout(200);\n  });\n\n  test('tab switching works', async ({ page }) => {\n    await page.getByRole('button', { name: 'Models' }).click();\n    await expect(page.locator('#tab-generation')).toBeVisible();\n    await page.getByRole('button', { name: 'Repos & Indexing' }).click();\n    await expect(page.locator('#tab-repos')).toBeVisible();\n  });\n\n  test('global search highlights', async ({ page }) => {\n    await page.fill('#global-search', 'Model');\n    await page.keyboard.press('Enter');\n    await page.waitForTimeout(200);\n    const marks = await page.locator('mark.hl').count();\n    expect(marks).toBeGreaterThan(0);\n  });\n\n  test('Git hooks install via Tools tab', async ({ page }) => {\n    await page.getByRole('button', { name: 'Tools' }).click();
await page.getByRole('button', { name: 'Install' }).click();\n    await page.waitForTimeout(200);\n    const status = await page.locator('#hooks-status').textContent();\n    expect(status || '').not.toContain('Not installed');\n  });\n\n  test('indexer quick action updates status', async ({ page }) => {\n    // Dashboard quick action\n    await page.getByRole('button', { name: 'Dashboard' }).click();\n    await page.locator('#dash-index-start').click();\n    await page.waitForTimeout(400);\n    const txt = await page.locator('#dash-index-status').textContent();\n    expect((txt || '')).toContain('Chunks');\n  });\n\n  test('wizard one-click config produces preview', async ({ page }) => {\n    await page.getByRole('button', { name: 'Dashboard' }).click();\n    await page.locator('#btn-wizard-oneclick').click();\n    await page.waitForTimeout(500);\n    const preview = await page.locator('#profile-preview').textContent();\n    expect((preview || '')).toContain('Models:');\n  });\n\n  test('cost calculator estimates include embeddings', async ({ page }) => {\n    await page.getByRole('button', { name: 'Tools' }).click();
// Switch embedding provider model\n    await page.fill('input[name="GEN_MODEL"]', 'gpt-4o-mini');\n    await page.selectOption('#cost-embed-provider', { label: 'openai' }).catch(()=>{});\n    const embedModel = page.locator('#cost-embed-model');\n    if (await embedModel.count()) {\n      await embedModel.fill('text-embedding-3-small');\n    }\n    // set some numbers\n    await page.fill('#cost-in', '1000');\n    await page.fill('#cost-out', '1000');\n    await page.fill('#cost-embeds', '1000');\n    await page.fill('#cost-rerank', '1000');\n    await page.fill('#cost-rpd', '10');\n    // Re-run wizard generate which triggers cost preview underneath\n    await page.getByRole('button', { name: 'Dashboard' }).click();\n    await page.locator('#btn-wizard-oneclick').click();\n    await page.waitForTimeout(400);\n    const preview = await page.locator('#profile-preview').textContent();\n    expect((preview || '')).toMatch(/Cost Estimate|Daily|Monthly/);\n  });\n\n  test('profiles save and list updates', async ({ page }) => {\n    await page.getByRole('button', { name: 'Dashboard' }).click();
await page.fill('#profile-name', 'pw-ui');\n    const btn = page.locator('#btn-save-profile');\n    if (await btn.count()) {\n      await btn.click();\n      await page.waitForTimeout(200);\n      const ul = page.locator('#profiles-ul');\n      await expect(ul).toContainText(/pw-ui/);\n    }\n  });\n});
import { test, expect } from '@playwright/test';\n\ntest.describe('GUI cost panel', () => {\n  test.beforeEach(async ({ page }) => {\n    await page.goto('/gui/');\n    await page.getByRole('button', { name: 'Tools' }).click();\n  });\n\n  test('embeddings and reranks affect totals', async ({ page }) => {\n    // Set providers explicitly\n    await page.selectOption('#cost-provider', { label: 'openai' }).catch(()=>{});\n    await page.fill('#cost-model', 'gpt-4o-mini');\n\n    await page.selectOption('#cost-embed-provider', { label: 'openai' }).catch(()=>{});\n    await page.fill('#cost-embed-model', 'text-embedding-3-small');\n\n    await page.selectOption('#cost-rerank-provider', { label: 'Cohere' }).catch(()=>{});\n    await page.fill('#cost-rerank-model', 'rerank-english-v3.0');\n\n    // Inputs\n    await page.fill('#cost-in', '0');\n    await page.fill('#cost-out', '0');\n    await page.fill('#cost-rpd', '1');\n\n    // Baseline none\n    await page.fill('#cost-embeds', '0');\n    await page.fill('#cost-rerank', '0');\n    await page.click('#btn-estimate');\n    const baseDaily = parseFloat((await page.locator('#cost-daily').textContent())!.replace(/[^0-9.]/g,'')) || 0;
// With embeddings + reranks\n    await page.fill('#cost-embeds', `${Math.ceil(10_000_000/30)}`); // ~10M/month\n    await page.fill('#cost-rerank', '10000');\n    await page.click('#btn-estimate');\n    const incDaily = parseFloat((await page.locator('#cost-daily').textContent())!.replace(/[^0-9.]/g,'')) || 0;\n    await expect(incDaily).toBeGreaterThan(baseDaily);\n  });\n});
import { test, expect } from '@playwright/test';\n\nasync function estimate(request, payload) {\n  const res = await request.post('/api/cost/estimate', { data: payload });\n  if (!res.ok()) throw new Error(`estimate failed: ${res.status()}`);\n  return await res.json();\n}\n\ntest.describe('Cost calculator sanity', () => {\n  test('Embeddings: 0 vs 10M/month (OpenAI small)', async ({ request }) => {\n    // Per-day tokens for 10M/month ~ 333_334 per day\n    const perDay = Math.ceil(10_000_000 / 30);\n    const base = {\n      gen_provider: 'openai', gen_model: 'gpt-4o-mini',\n      tokens_in: 0, tokens_out: 0, requests_per_day: 1,\n      reranks: 0\n    };\n    const none = await estimate(request, { ...base, embeds: 0, embed_provider: 'openai', embed_model: 'text-embedding-3-small' });\n    const many = await estimate(request, { ...base, embeds: perDay, embed_provider: 'openai', embed_model: 'text-embedding-3-small' });\n    console.log('Embeds/day:', perDay, 'Daily none:', none.daily, 'Daily many:', many.daily, 'Monthly many:', many.monthly);\n    expect(many.daily).toBeGreaterThan(none.daily);
expect(many.monthly).toBeGreaterThan(none.monthly);\n  });\n\n  test('Rerank: 0 vs 10k/day (Cohere)', async ({ request }) => {\n    const base = {\n      gen_provider: 'openai', gen_model: 'gpt-4o-mini',\n      tokens_in: 0, tokens_out: 0, requests_per_day: 1,\n      embeds: 0, embed_provider: 'openai', embed_model: 'text-embedding-3-small'\n    };\n    const none = await estimate(request, { ...base, reranks: 0, rerank_provider: 'cohere', rerank_model: 'rerank-english-v3.0' });\n    const many = await estimate(request, { ...base, reranks: 10_000, rerank_provider: 'cohere', rerank_model: 'rerank-english-v3.0' });\n    console.log('Reranks/day:', 10_000, 'Daily none:', none.daily, 'Daily many:', many.daily, 'Monthly many:', many.monthly);\n    expect(many.daily).toBeGreaterThan(none.daily);\n    expect(many.monthly).toBeGreaterThan(none.monthly);\n  });\n});
"""\nPlaywright smoke test for embedded editor feature.\nTests the complete editor workflow end-to-end.\n"""\nimport asyncio\nimport os\nfrom playwright.async_api import async_playwright, expect\n\nBASE_URL = os.getenv("BASE_URL", "http://127.0.0.1:8012")\n\n\nasync def test_editor_feature():\n    """Test the embedded editor feature end-to-end"""\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True)\n        context = await browser.new_context()\n        page = await context.new_page()\n\n        try:\n            print("✓ Starting editor feature smoke test...")\n\n            # 1. Navigate to GUI\n            print("  → Navigating to GUI...")\n            await page.goto(f"{BASE_URL}/gui/index.html")\n            await page.wait_for_load_state("networkidle")\n            print("    ✓ GUI loaded")\n\n            # 2. Check Editor tab exists\n            print("  → Checking Editor tab exists...")\n            editor_tab_button = page.locator('button[data-tab="editor"]')\n            await expect(editor_tab_button).to_be_visible()\n            print("    ✓ Editor tab button found")\n\n            # 3. Click Editor tab\n            print("  → Clicking Editor tab...")\n            await editor_tab_button.click()
await page.wait_for_timeout(1000)\n            print("    ✓ Editor tab clicked")\n\n            # 4. Check Editor tab content is visible\n            print("  → Checking Editor tab content...")\n            editor_tab_content = page.locator('#tab-editor')\n            await expect(editor_tab_content).to_be_visible()\n            print("    ✓ Editor tab content visible")\n\n            # 5. Check health badge exists\n            print("  → Checking health badge...")\n            health_badge = page.locator('#editor-health-badge')\n            await expect(health_badge).to_be_visible()\n            badge_text = await health_badge.locator('#editor-health-text').text_content()\n            print(f"    ✓ Health badge shows: {badge_text}")\n\n            # 6. Check control buttons exist\n            print("  → Checking control buttons...")\n            open_window_btn = page.locator('#btn-editor-open-window')\n            copy_url_btn = page.locator('#btn-editor-copy-url')\n            restart_btn = page.locator('#btn-editor-restart')\n\n            await expect(open_window_btn).to_be_visible()\n            await expect(copy_url_btn).to_be_visible()\n            await expect(restart_btn).to_be_visible()\n            print("    ✓ All control buttons found")\n\n            # 7. Check iframe container exists
print("  → Checking iframe container...")\n            iframe_container = page.locator('#editor-iframe-container')\n            await expect(iframe_container).to_be_visible()\n            print("    ✓ Iframe container visible")\n\n            # 8. Check iframe element exists\n            print("  → Checking iframe element...")\n            iframe = page.locator('#editor-iframe')\n            await expect(iframe).to_be_visible()\n            print("    ✓ Iframe element found")\n\n            # 9. Wait for iframe to potentially load (if editor is running)\n            await page.wait_for_timeout(2000)\n            iframe_src = await iframe.get_attribute('src')\n            if iframe_src:\n                print(f"    ✓ Iframe loaded with URL: {iframe_src}")\n            else:\n                print("    ℹ Iframe src empty (editor may be disabled)")\n\n            # 10. Check Misc tab for editor settings\n            print("  → Checking Editor settings in Misc tab...")\n            misc_tab = page.locator('button[data-tab="misc"]')\n            await misc_tab.click()\n            await page.wait_for_timeout(500)\n\n            # Wait for misc tab to be visible\n            misc_tab_content = page.locator('#tab-misc')\n            await expect(misc_tab_content).to_be_visible()\n            await page.wait_for_timeout(1000)\n\n            # Debug: Check if editor settings exist in the HTML
has_editor_settings = await page.evaluate("""\n                () => {\n                    const checkbox = document.querySelector('input[name="EDITOR_ENABLED"]');\n                    const miscTab = document.querySelector('#tab-misc');\n                    return {\n                        checkbox_exists: !!checkbox,\n                        misc_tab_exists: !!miscTab,\n                        misc_tab_html_length: miscTab ? miscTab.innerHTML.length : 0,\n                        has_editor_text: miscTab ? miscTab.innerHTML.includes('Embedded Editor') : false\n                    };\n                }\n            """)\n            print(f"    Debug - Editor settings check: {has_editor_settings}")\n\n            # Check for editor settings section\n            editor_enabled_checkbox = page.locator('input[name="EDITOR_ENABLED"]')\n            editor_port_input = page.locator('input[name="EDITOR_PORT"]')\n            editor_bind_select = page.locator('select[name="EDITOR_BIND"]')\n\n            # Only proceed if checkbox exists\n            if has_editor_settings['checkbox_exists']:\n                await editor_enabled_checkbox.scroll_into_view_if_needed()\n                await page.wait_for_timeout(500)\n                await expect(editor_enabled_checkbox).to_be_visible(timeout=10000)\n            await expect(editor_port_input).to_be_visible()
await expect(editor_bind_select).to_be_visible()\n            print("    ✓ Editor settings found in Misc tab")\n\n            # 11. Test health endpoint directly\n            print("  → Testing health endpoint...")\n            response = await page.request.get(f"{BASE_URL}/health/editor")\n            assert response.ok, f"Health endpoint failed: {response.status}"\n            health_data = await response.json()\n            print(f"    ✓ Health endpoint responded: enabled={health_data.get('enabled')}, ok={health_data.get('ok')}")\n\n            # 12. Test restart endpoint (without actually restarting)\n            print("  → Checking restart endpoint exists...")\n            # We won't actually call restart in the test to avoid disruption\n            print("    ✓ Restart endpoint available at /api/editor/restart")\n\n            print("\n✅ All editor feature tests passed!")\n            return True\n\n        except Exception as e:\n            print(f"\n❌ Test failed: {str(e)}")\n            # Take screenshot on failure\n            await page.screenshot(path="/tmp/editor_test_failure.png")\n            print(f"    Screenshot saved to /tmp/editor_test_failure.png")\n            raise\n        finally:\n            await browser.close()\n\n\nasync def main():\n    """Run the test"""\n    try:
result = await test_editor_feature()\n        exit(0 if result else 1)\n    except Exception as e:\n        print(f"\n❌ Test suite failed: {str(e)}")\n        exit(1)\n\n\nif __name__ == "__main__":\n    asyncio.run(main())
import { test, expect, request } from '@playwright/test';\n\ntest.describe('HTTP API', () => {\n  test('health returns healthy', async ({ request }) => {\n    const res = await request.get('/health');\n    expect(res.ok()).toBeTruthy();\n    const body = await res.json();\n    expect(body.status).toBe('healthy');\n  });\n\n  test('keywords returns arrays and countable union', async ({ request }) => {\n    const res = await request.get('/api/keywords');\n    expect(res.ok()).toBeTruthy();\n    const body = await res.json();\n    expect(Array.isArray(body.keywords)).toBeTruthy();\n    expect(Array.isArray(body.discriminative)).toBeTruthy();\n    expect(Array.isArray(body.semantic)).toBeTruthy();\n  });\n\n  test('prices exposes models incl. embeddings + rerank', async ({ request }) => {\n    const res = await request.get('/api/prices');\n    expect(res.ok()).toBeTruthy();\n    const body = await res.json();\n    const models = body.models as any[];\n    expect(models.some(m => m.model?.includes('text-embedding'))).toBeTruthy();\n    expect(models.some(m => (m.provider === 'cohere' && m.rerank_per_1k > 0))).toBeTruthy();
});\n\n  test('cost estimate counts gen + embed + rerank', async ({ request }) => {\n    const payload = {\n      gen_provider: 'openai', gen_model: 'gpt-4o-mini',\n      tokens_in: 1000, tokens_out: 1000, requests_per_day: 10,\n      embeds: 1000, embed_provider: 'openai', embed_model: 'text-embedding-3-small',\n      reranks: 1000, rerank_provider: 'cohere', rerank_model: 'rerank-3.5'\n    };\n    const res = await request.post('/api/cost/estimate', { data: payload });\n    expect(res.ok()).toBeTruthy();\n    const body = await res.json();\n    expect(body.daily).toBeGreaterThan(0);\n    expect(body.monthly).toBeGreaterThan(0);\n  });\n\n  test('profiles list/save/apply flows', async ({ request }) => {\n    const list0 = await (await request.get('/api/profiles')).json();\n    const save = await request.post('/api/profiles/save', { data: { name: 'pw-test', profile: { GEN_MODEL: 'gpt-4o-mini' } } });\n    expect(save.ok()).toBeTruthy();\n    const list1 = await (await request.get('/api/profiles')).json();\n    expect((list1.profiles as string[]).includes('pw-test')).toBeTruthy();\n    const apply = await request.post('/api/profiles/apply', { data: { profile: { MQ_REWRITES: '3' } } });
expect(apply.ok()).toBeTruthy();\n  });\n\n  test('git hooks install + status endpoints', async ({ request }) => {\n    const before = await (await request.get('/api/git/hooks/status')).json();\n    const res = await request.post('/api/git/hooks/install');\n    expect(res.ok()).toBeTruthy();\n    const body = await res.json();\n    expect((body.message || '')).toContain('Installed git hooks');\n    const after = await (await request.get('/api/git/hooks/status')).json();\n    expect(after.post_checkout).toBeTruthy();\n    expect(after.post_commit).toBeTruthy();\n  });\n});
"""Test auto-profile functionality"""\nimport pytest\nfrom playwright.sync_api import Page, expect\ntest_autoprofile_button_exists(page: Page):\n    """Test that auto-profile button exists and is clickable"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Find the configure automatically button\n    button = page.locator("#btn-wizard-oneclick")\n    expect(button).to_be_visible()\n    expect(button).to_contain_text("Configure Automatically")\ntest_autoprofile_layout(page: Page):\n    """Test that the 2-column layout is visible"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Check results panel exists\n    results_panel = page.locator("#profile-results-panel")\n    expect(results_panel).to_be_visible()\n    \n    # Check placeholder is visible initially\n    placeholder = page.locator("#profile-placeholder")\n    expect(placeholder).to_be_visible()
test_autoprofile_button_click(page: Page):\n    """Test clicking the configure button"""\n    page.goto("http://127.0.0.1:8012/")\n    \n    # Click the button\n    page.click("#btn-wizard-oneclick")\n    \n    # Wait a moment for any async operations\n    page.wait_for_timeout(2000)\n    \n    # Check console for errors\n    console_messages = []\n    page.on("console", lambda msg: console_messages.append(f"{msg.type}: {msg.text}"))\n    \n    # Try clicking again to capture console\n    page.reload()\n    page.click("#btn-wizard-oneclick")\n    page.wait_for_timeout(2000)\n    \n    # Print console messages for debugging\n    print("\n=== Console Messages ===")\n    for msg in console_messages:\n        print(msg)
import os\nimport json\nimport time\nimport uuid\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\nfrom contextvars import ContextVar\n\nfrom common.config_loader import out_dir\n\n\n_TRACE_VAR: ContextVar[Optional["Trace"]] = ContextVar("agro_trace", default=None)\n\n_now_iso() -> str:\n    return __import__("datetime").datetime.utcnow().isoformat() + "Z"
Trace:\n    """Lightweight per-request trace recorder.\n\n    - Stores structured breadcrumb events in-memory\n    - Persists to out/<repo>/traces/<ts>_<id>.json on save()\n    - Enabled when LANGCHAIN_TRACING_V2 is truthy (1/true/on)\n    """\n\n    def __init__(self, repo: str, question: str):\n        self.repo = (repo or os.getenv("REPO", "agro")).strip()\n        self.question = question\n        self.id = uuid.uuid4().hex[:8]\n        self.started_at = _now_iso()\n        self.events: List[Dict[str, Any]] = []\n        self.path: Optional[str] = None\n        self.mode = (os.getenv('TRACING_MODE', '').lower() or (\n            'langsmith' if ((os.getenv('LANGCHAIN_TRACING_V2','0') or '0').strip().lower() in {'1','true','on'}) else 'local'))\n        # Optional LangSmith bridge (best effort)\n        self._ls = None\n        self._ls_project = os.getenv('LANGCHAIN_PROJECT', 'agro')\n        try:\n            if self.mode == 'langsmith':\n                from langchain.callbacks.tracers import LangChainTracerV2  # type: ignore\n                self._ls = LangChainTracerV2(project=self._ls_project)\n                # start root run\n                self._ls.on_chain_start({"name": "RAG.run"}, inputs={"question": question})\n        except Exception:\n            self._ls = None\n\n    # ---- control ----\n    @staticmethod\n    def enabled() -> bool:\n        mode = (os.getenv('TRACING_MODE','').lower() or (\n            'langsmith' if (os.getenv('LANGCHAIN_TRACING_V2','0').lower() in {'1','true','on'}) else 'local'))\n        if mode == 'off' or not mode:\n            return False\n        return True\n\n    def add(self, kind: str, payload: Dict[str, Any]) -> None:\n        try:\n            self.events.append({\n                "ts": _now_iso(),\n                "kind": str(kind),\n                "data": payload or {},\n            })\n            if self._ls is not None:\n                try:\n                    self._ls.on_chain_start({"name": kind}, inputs={})\n                    self._ls.on_chain_end(outputs=payload)\n                except Exception:\n                    pass\n        except Exception:\n            # tracing should never break request flow\n            pass\n\n    def _dir(self) -> Path:\n        base = Path(out_dir(self.repo))\n        d = base / "traces"\n        d.mkdir(parents=True, exist_ok=True)\n        return d\n\n    def save(self) -> str:\n        try:\n            ts_short = time.strftime("%Y%m%dT%H%M%SZ", time.gmtime())\n            out_path = self._dir() / f"{ts_short}_{self.id}.json"\n            data = {\n                "repo": self.repo,\n                "id": self.id,\n                "question": self.question,\n                "started_at": self.started_at,\n                "finished_at": _now_iso(),\n                "events": self.events,\n                "tracing_mode": self.mode,\n                "langsmith_project": self._ls_project if self.mode == 'langsmith' else None,\n            }\n            out_path.write_text(json.dumps(data, indent=2))\n            self.path = str(out_path)\n            # Simple retention purge\n            try:\n                keep = int(os.getenv('TRACE_RETENTION','50') or '50')\n            except Exception:\n                keep = 50\n            try:\n                files = sorted([p for p in self._dir().glob('*.json') if p.is_file()], key=lambda p: p.stat().st_mtime, reverse=True)\n                for p in files[keep:]:\n                    try: p.unlink()\n                    except Exception: pass\n            except Exception:\n                pass\n            return self.path\n        except Exception:\n            return ""\n\n\n# ---- context helpers ----
start_trace(repo: str, question: str) -> Trace:\n    tr = Trace(repo=repo, question=question)\n    _TRACE_VAR.set(tr)\n    return tr\n\nget_trace() -> Optional[Trace]:\n    return _TRACE_VAR.get()\n\nend_trace() -> Optional[str]:\n    tr = _TRACE_VAR.get()\n    if tr is None:\n        return None\n    try:\n        if tr._ls is not None:\n            tr._ls.on_chain_end(outputs={"status": "ok"})\n    except Exception:\n        pass\n    path = tr.save()\n    _TRACE_VAR.set(None)\n    return path\n\nlatest_trace_path(repo: str) -> Optional[str]:\n    try:\n        d = Path(out_dir(repo)) / "traces"\n        if not d.exists():\n            return None\n        files = sorted([p for p in d.glob("*.json") if p.is_file()], key=lambda p: p.stat().st_mtime, reverse=True)\n        return str(files[0]) if files else None\n    except Exception:\n        return None
import os\nimport json\nfrom typing import Optional, Dict, Any, Tuple\n\ntry:\n    from openai import OpenAI\nexcept Exception as e:\n    raise RuntimeError("openai>=1.x is required for Responses API") from e\n\n_DEFAULT_MODEL = os.getenv("GEN_MODEL", os.getenv("ENRICH_MODEL", "gpt-4o-mini"))\n_DEFAULT_TEMPERATURE = float(os.getenv("GEN_TEMPERATURE", "0.0") or 0.0)\n\n_client = None\n_mlx_model = None\n_mlx_tokenizer = None\n_get_mlx_model():\n    global _mlx_model, _mlx_tokenizer\n    if _mlx_model is None:\n        from mlx_lm import load\n        model_name = os.getenv("GEN_MODEL", "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit")\n        _mlx_model, _mlx_tokenizer = load(model_name)\n    return _mlx_model, _mlx_tokenizer\nclient() -> OpenAI:\n    global _client\n    if _client is None:\n        _client = OpenAI()\n    return _client
_extract_text(resp: Any) -> str:\n    txt = ""\n    if hasattr(resp, "output_text") and isinstance(getattr(resp, "output_text"), str):\n        txt = resp.output_text\n        if txt:\n            return txt\n    try:\n        out = getattr(resp, "output", None)\n        if out and len(out) > 0:\n            cont = getattr(out[0], "content", None)\n            if cont and len(cont) > 0 and hasattr(cont[0], "text"):\n                return cont[0].text or ""\n    except Exception:\n        pass\n    return txt or ""
generate_text(\n    user_input: str,\n    *,\n    system_instructions: Optional[str] = None,\n    model: Optional[str] = None,\n    reasoning_effort: Optional[str] = None,\n    response_format: Optional[Dict[str, Any]] = None,\n    store: bool = False,\n    previous_response_id: Optional[str] = None,\n    extra: Optional[Dict[str, Any]] = None,\n) -> Tuple[str, Any]:\n    mdl = model or _DEFAULT_MODEL\n    kwargs: Dict[str, Any] = {\n        "model": mdl,\n        "input": user_input,\n        "store": store,\n    }\n    # Apply temperature from env when supported (Responses API)\n    try:\n        temp = float(os.getenv("GEN_TEMPERATURE", str(_DEFAULT_TEMPERATURE)) or _DEFAULT_TEMPERATURE)\n    except Exception:\n        temp = _DEFAULT_TEMPERATURE\n    # Not all providers honor this, but Responses API does\n    kwargs["temperature"] = temp\n    if system_instructions:\n        kwargs["instructions"] = system_instructions\n    if reasoning_effort:\n        kwargs["reasoning"] = {"effort": reasoning_effort}\n    if response_format:\n        kwargs["response_format"] = response_format\n    if previous_response_id:\n        kwargs["previous_response_id"] = previous_response_id\n    if extra:\n        kwargs.update(extra)\n\n    ENRICH_BACKEND = os.getenv("ENRICH_BACKEND", "").lower()\n    is_mlx_model = mdl.startswith("mlx-community/") if mdl else False\n    prefer_mlx = (ENRICH_BACKEND == "mlx") or is_mlx_model\n\n    if prefer_mlx:\n        try:\n            from mlx_lm import generate\n            model, tokenizer = _get_mlx_model()\n            sys_text = (system_instructions or "").strip()\n            prompt = (f"<system>{sys_text}</system>\n" if sys_text else "") + user_input\n            text = generate(\n                model,\n                tokenizer,\n                prompt=prompt,\n                max_tokens=2048,\n                verbose=False\n            )\n            return text, {"response": text, "backend": "mlx"}\n        except Exception:\n            pass\n\n    OLLAMA_URL = os.getenv("OLLAMA_URL")\n    prefer_ollama = bool(OLLAMA_URL)\n    if prefer_ollama:\n        try:\n            import requests, json as _json, time\n            sys_text = (system_instructions or "").strip()\n            prompt = (f"<system>{sys_text}</system>\n" if sys_text else "") + user_input\n            url = OLLAMA_URL.rstrip("/") + "/generate"\n            max_retries = 2\n            chunk_timeout = 60\n            total_timeout = 300\n            for attempt in range(max_retries + 1):\n                start_time = time.time()\n                try:\n                    with requests.post(url, json={\n                        "model": mdl,\n                        "prompt": prompt,\n                        "stream": True,\n                        "options": {"temperature": temp, "num_ctx": 8192},\n                    }, timeout=chunk_timeout, stream=True) as r:\n                        r.raise_for_status()\n                        buf = []\n                        last = None\n                        for line in r.iter_lines(decode_unicode=True):\n                            if time.time() - start_time > total_timeout:\n                                partial = ("".join(buf) or "").strip()\n                                if partial:\n                                    return partial + " [TIMEOUT]", {"response": partial, "timeout": True}\n                                break\n                            if not line:\n                                continue\n                            try:\n                                obj = _json.loads(line)\n                            except Exception:\n                                continue\n                            if isinstance(obj, dict):\n                                seg = (obj.get("response") or "")\n                                if seg:\n                                    buf.append(seg)\n                                last = obj\n                                if obj.get("done") is True:\n                                    break\n                        text = ("".join(buf) or "").strip()\n                        if text:\n                            return text, (last or {"response": text})\n                    resp = requests.post(url, json={\n                        "model": mdl,\n                        "prompt": prompt,\n                        "stream": False,\n                        "options": {"temperature": temp, "num_ctx": 8192},\n                    }, timeout=total_timeout)\n                    resp.raise_for_status()\n                    data = resp.json()\n                    text = (data.get("response") or "").strip()\n                    if text:\n                        return text, data\n                except (requests.Timeout, requests.ConnectionError):\n                    if attempt < max_retries:\n                        backoff = 2 ** attempt\n                        time.sleep(backoff)\n                        continue\n                except Exception:\n                    break\n        except Exception:\n            pass\n\n    try:\n        # OpenAI Responses API (supports temperature)\n        resp = client().responses.create(**kwargs)\n        text = _extract_text(resp)\n        return text, resp\n    except Exception:\n        try:\n            messages = []\n            if system_instructions:\n                messages.append({"role": "system", "content": system_instructions})\n            messages.append({"role": "user", "content": user_input})\n            # Chat Completions fallback (supports temperature as well)\n            ckwargs: Dict[str, Any] = {"model": mdl, "messages": messages, "temperature": temp}\n            if response_format and isinstance(response_format, dict):\n                ckwargs["response_format"] = response_format\n            cc = client().chat.completions.create(**ckwargs)\n            text = (cc.choices[0].message.content if getattr(cc, "choices", []) else "") or ""\n            return text, cc\n        except Exception as e:\n            raise RuntimeError(f"Generation failed for model={mdl}: {e}")
"""Server package for app components (graph, models, stats).\n\nThis package allows reorganizing modules while keeping root shims\nfor backwards compatibility during migration.\n"""
import os\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, List\nfrom path_config import repo_root, data_dir\n\n_read_json(path: Path, default: Any) -> Any:\n    if path.exists():\n        try:\n            return json.loads(path.read_text())\n        except Exception:\n            return default\n    return default
_last_index_timestamp_for_repo(base: Path, repo_name: str) -> str | None:\n    """Return the best-effort last index timestamp for a single repo under a base dir.\n\n    Preference order:\n    1) base/<repo>/last_index.json["timestamp"]\n    2) mtime of base/<repo>/chunks.jsonl\n    3) mtime of base/<repo>/bm25_index directory\n    """\n    repo_dir = base / repo_name\n    if not repo_dir.exists():\n        return None\n\n    # 1) Explicit metadata file\n    meta = _read_json(repo_dir / "last_index.json", {})\n    ts = str(meta.get("timestamp") or "").strip()\n    if ts:\n        return ts\n\n    # 2) chunks.jsonl mtime\n    chunks = repo_dir / "chunks.jsonl"\n    if chunks.exists():\n        try:\n            return __import__('datetime').datetime.utcfromtimestamp(chunks.stat().st_mtime).isoformat() + 'Z'\n        except Exception:\n            pass\n\n    # 3) bm25_index dir mtime\n    bm25 = repo_dir / "bm25_index"\n    if bm25.exists():\n        try:\n            return __import__('datetime').datetime.utcfromtimestamp(bm25.stat().st_mtime).isoformat() + 'Z'\n        except Exception:\n            pass\n    return None
get_index_stats() -> Dict[str, Any]:\n    """Gather comprehensive indexing statistics with storage calculator integration.\n\n    Prefers a persisted last_index.json timestamp if present, falling back to\n    file mtimes, then now().\n    """\n    import subprocess\n    from datetime import datetime\n\n    # Get embedding configuration\n    embedding_type = os.getenv("EMBEDDING_TYPE", "openai").lower()\n    embedding_dim = int(os.getenv("EMBEDDING_DIM", "3072" if embedding_type == "openai" else "512"))\n\n    stats: Dict[str, Any] = {\n        "timestamp": datetime.utcnow().isoformat() + 'Z',  # may be replaced below\n        "repos": [],\n        "total_storage": 0,\n        "embedding_config": {\n            "provider": embedding_type,\n            "model": "text-embedding-3-large" if embedding_type == "openai" else f"local-{embedding_type}",\n            "dimensions": embedding_dim,\n            "precision": "float32",\n        },\n        "keywords_count": 0,\n        "storage_breakdown": {\n            "chunks_json": 0,\n            "bm25_index": 0,\n            "cards": 0,\n            "embeddings_raw": 0,\n            "qdrant_overhead": 0,\n            "reranker_cache": 0,\n            "redis": 419430400,  # 400 MiB default\n        },\n        "costs": {\n            "total_tokens": 0,\n            "embedding_cost": 0.0,\n        },\n    }\n\n    # Current repo + branch\n    try:\n        repo = os.getenv("REPO", "agro")\n        branch_result = subprocess.run(["git", "branch", "--show-current"], capture_output=True, text=True, cwd=str(repo_root()))\n        branch = branch_result.stdout.strip() if branch_result.returncode == 0 else "unknown"\n        stats["current_repo"] = repo\n        stats["current_branch"] = branch\n    except Exception:\n        stats["current_repo"] = os.getenv("REPO", "agro")\n        stats["current_branch"] = "unknown"\n\n    total_chunks = 0\n\n    # Index profiles to scan (shared, gui, devclean)\n    base_paths = ["out.noindex-shared", "out.noindex-gui", "out.noindex-devclean"]\n    discovered_ts: List[str] = []\n    for base in base_paths:\n        base_path = repo_root() / base\n        if not base_path.exists():\n            continue\n        profile_name = base.replace("out.noindex-", "")\n        repo_dirs = [d for d in base_path.iterdir() if d.is_dir()]\n        for repo_dir in repo_dirs:\n            repo_name = repo_dir.name\n            chunks_file = repo_dir / "chunks.jsonl"\n            bm25_dir = repo_dir / "bm25_index"\n            cards_file = repo_dir / "cards.jsonl"\n\n            repo_stats: Dict[str, Any] = {\n                "name": repo_name,\n                "profile": profile_name,\n                "paths": {\n                    "chunks": str(chunks_file) if chunks_file.exists() else None,\n                    "bm25": str(bm25_dir) if bm25_dir.exists() else None,\n                    "cards": str(cards_file) if cards_file.exists() else None,\n                },\n                "sizes": {},\n                "chunk_count": 0,\n                "has_cards": cards_file.exists() if cards_file else False,\n            }\n\n            # Aggregate sizes and counts\n            if chunks_file.exists():\n                size = chunks_file.stat().st_size\n                repo_stats["sizes"]["chunks"] = size\n                stats["total_storage"] += size\n                stats["storage_breakdown"]["chunks_json"] += size\n                try:\n                    with open(chunks_file, 'r') as f:\n                        cc = sum(1 for _ in f)\n                        repo_stats["chunk_count"] = cc\n                        total_chunks += cc\n                except Exception:\n                    pass\n\n            if bm25_dir.exists():\n                bm25_size = sum(f.stat().st_size for f in bm25_dir.rglob('*') if f.is_file())\n                repo_stats["sizes"]["bm25"] = bm25_size\n                stats["total_storage"] += bm25_size\n                stats["storage_breakdown"]["bm25_index"] += bm25_size\n\n            if cards_file.exists():\n                card_size = cards_file.stat().st_size\n                repo_stats["sizes"]["cards"] = card_size\n                stats["total_storage"] += card_size\n                stats["storage_breakdown"]["cards"] += card_size\n\n            stats["repos"].append(repo_stats)\n\n            # Try to resolve a last-index timestamp for this repo under this profile\n            ts = _last_index_timestamp_for_repo(base_path, repo_name)\n            if ts:\n                discovered_ts.append(ts)\n\n    # Embedding storage + rough costs when we have chunks\n    if total_chunks > 0:\n        bytes_per_float = 4\n        embeddings_raw = total_chunks * embedding_dim * bytes_per_float\n        qdrant_overhead_multiplier = 1.5\n        qdrant_total = embeddings_raw * qdrant_overhead_multiplier\n        reranker_cache = embeddings_raw * 0.5\n        stats["storage_breakdown"]["embeddings_raw"] = embeddings_raw\n        stats["storage_breakdown"]["qdrant_overhead"] = int(qdrant_total - embeddings_raw)\n        stats["storage_breakdown"]["reranker_cache"] = int(reranker_cache)\n        stats["total_storage"] += qdrant_total + reranker_cache + stats["storage_breakdown"]["redis"]\n        if embedding_type == "openai":\n            est_tokens_per_chunk = 750\n            total_tokens = total_chunks * est_tokens_per_chunk\n            cost_per_million = 0.13\n            embedding_cost = (total_tokens / 1_000_000) * cost_per_million\n            stats["costs"]["total_tokens"] = total_tokens\n            stats["costs"]["embedding_cost"] = round(embedding_cost, 4)\n\n    # Try to get keywords count\n    keywords_file = data_dir() / f"keywords_{stats.get('current_repo','agro')}.json"\n    if keywords_file.exists():\n        try:\n            kw_data = json.loads(keywords_file.read_text())\n            stats["keywords_count"] = len(kw_data) if isinstance(kw_data, list) else len(kw_data.get("keywords", []))\n        except Exception:\n            pass\n\n    # Set a better global timestamp if any per-repo timestamp found\n    if discovered_ts:\n        stats["timestamp"] = sorted(discovered_ts)[-1]\n\n    return stats
import os, operator\nfrom typing import List, Dict, TypedDict, Annotated\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nfrom langgraph.graph import END, StateGraph\nfrom langgraph.checkpoint.redis import RedisSaver\nfrom retrieval.hybrid_search import search_routed_multi as hybrid_search_routed_multi\nfrom server.tracing import get_trace\nfrom server.env_model import generate_text\nfrom server.index_stats import get_index_stats\n\n# Load environment from repo root .env without hard-coded paths\ntry:\n    # Load any existing env first\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / ".env"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nRAGState(TypedDict):\n    question: str\n    documents: Annotated[List[Dict], operator.add]\n    generation: str\n    iteration: int\n    confidence: float\n    repo: str
should_use_multi_query(question: str) -> bool:\n    q = (question or '').lower().strip()\n    if len(q.split()) <= 3:\n        return False\n    for w in ("how", "why", "explain", "compare", "tradeoff"):\n        if w in q:\n            return True\n    return False
retrieve_node(state: RAGState) -> Dict:\n    q = state['question']\n    repo = state.get('repo') if isinstance(state, dict) else None\n    mq = int(os.getenv('MQ_REWRITES','2')) if should_use_multi_query(q) else 1\n    tr = get_trace()\n    docs = hybrid_search_routed_multi(q, repo_override=repo, m=mq, final_k=int(os.getenv('LANGGRAPH_FINAL_K','20') or 20), trace=tr)\n    conf = float(sum(d.get('rerank_score',0.0) for d in docs)/max(1,len(docs)))\n    repo_used = (repo or (docs[0].get('repo') if docs else os.getenv('REPO','project')))\n    # freshness snapshot (per-request)\n    try:\n        from server.index_stats import get_index_stats\n        stats = get_index_stats()\n        if tr is not None:\n            tr.add('freshness.status', {\n                'bm25_updated': stats.get('timestamp'),\n                'cards_updated': None,\n                'dense_updated_min': stats.get('timestamp'),\n                'dense_updated_max': stats.get('timestamp'),\n                'dense_backlog': 0,\n                'vector_backend': (os.getenv('VECTOR_BACKEND','qdrant') or 'qdrant'),\n            })\n    except Exception:\n        pass\n    return {'documents': docs, 'confidence': conf, 'iteration': state.get('iteration',0)+1, 'repo': repo_used}
route_after_retrieval(state:RAGState)->str:\n    conf = float(state.get("confidence", 0.0) or 0.0)\n    it = int(state.get("iteration", 0) or 0)\n    docs = state.get("documents", []) or []\n    scores = sorted([float(d.get("rerank_score",0.0) or 0.0) for d in docs], reverse=True)\n    top1 = scores[0] if scores else 0.0\n    avg5 = (sum(scores[:5])/min(5, len(scores))) if scores else 0.0\n    try:\n        CONF_TOP1 = float(os.getenv('CONF_TOP1', '0.62'))\n        CONF_AVG5 = float(os.getenv('CONF_AVG5', '0.55'))\n        CONF_ANY = float(os.getenv('CONF_ANY', '0.55'))\n    except Exception:\n        CONF_TOP1, CONF_AVG5, CONF_ANY = 0.62, 0.55, 0.55\n    # add trace of gating decision\n    try:\n        from server.tracing import get_trace\n        tr = get_trace()\n        if tr is not None:\n            tr.add('gating.outcome', {\n                'confidence_top1': top1,\n                'confidence_avg5': avg5,\n                'thresholds': {'top1': CONF_TOP1, 'avg5': CONF_AVG5, 'any': CONF_ANY},\n                'iterated': it > 0,\n                'notes': ''\n            })\n    except Exception:\n        pass\n    if top1 >= CONF_TOP1 or avg5 >= CONF_AVG5 or conf >= CONF_ANY:\n        return "generate"\n    if it >= 3:\n        return "fallback"\n    return "rewrite_query"
rewrite_query(state: RAGState) -> Dict:\n    q = state['question']\n    sys = "You rewrite developer questions into search-optimized queries without changing meaning."\n    user = f"Rewrite this for code search (expand CamelCase, include API nouns), one line.\n\n{q}"\n    newq, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n    newq = (newq or '').strip()\n    return {'question': newq}
generate_node(state: RAGState) -> Dict:\n    q = state['question']; ctx = state['documents'][:5]\n    # packer summary for trace\n    try:\n        tr = get_trace()\n        if tr is not None:\n            budget = int(os.getenv('PACK_BUDGET_TOKENS', '4096') or 4096)\n            selected = []\n            for d in ctx:\n                sel = {\n                    'path': d.get('file_path'),\n                    'lines': f"L{d.get('start_line')}-L{d.get('end_line')}",\n                    'est_tokens': int(len((d.get('code') or ''))/4),\n                    'reason': ['high_rerank']\n                }\n                selected.append(sel)\n            tr.add('packer.pack', {\n                'budget_tokens': budget,\n                'diversity_penalty': 0.0,\n                'hydration_mode': (os.getenv('HYDRATION_MODE','lazy') or 'lazy'),\n                'selected': selected,\n                'final_tokens': sum(s['est_tokens'] for s in selected)\n            })\n    except Exception:\n        pass\n    ql = (q or '').lower()\n    if any(kw in ql for kw in ("last index", "last indexed", "when was this indexed", "when indexed", "index time")):\n        stats = get_index_stats()\n        repo_hdr = state.get('repo') or os.getenv('REPO','project')\n        paths = None\n        for r in stats.get('repos', []):\n            if str(r.get('name')) == str(repo_hdr):\n                paths = r.get('paths', {})\n                break\n        lines = []\n        lines.append(f"Most recent index: {stats.get('timestamp','unknown')}")\n        if paths and (paths.get('chunks') or paths.get('bm25')):\n            if paths.get('chunks'):\n                lines.append(f"chunks.jsonl: {paths['chunks']}")\n            if paths.get('bm25'):\n                lines.append(f"bm25_index: {paths['bm25']}")\n        content = "\n".join(lines)\n        header = f"[repo: {repo_hdr}]"\n        return {'generation': header + "\n" + content}\n    def _cite(d):\n        mark = " (card)" if d.get('card_hit') else ""\n        return f"- {d['file_path']}:{d['start_line']}-{d['end_line']}{mark}"\n    citations = "\n".join([_cite(d) for d in ctx])\n    context_text = "\n\n".join([d.get('code','') for d in ctx])\n    # Use custom system prompt if provided, otherwise use default\n    sys = os.getenv('SYSTEM_PROMPT') or 'You answer strictly from the provided code context. Always cite file paths and line ranges you used.'\n    user = f"Question:\n{q}\n\nContext:\n{context_text}\n\nCitations (paths and line ranges):\n{citations}\n\nAnswer:"\n    content, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n    content = content or ''\n    conf = float(state.get('confidence', 0.0) or 0.0)\n    if conf < 0.55:\n        repo = state.get('repo') or os.getenv('REPO','project')\n        alt_docs = hybrid_search_routed_multi(q, repo_override=repo, m=4, final_k=10)\n        if alt_docs:\n            ctx2 = alt_docs[:5]\n            citations2 = "\n".join([f"- {d['file_path']}:{d['start_line']}-{d['end_line']}" + (" (card)" if d.get('card_hit') else "") for d in ctx2])\n            context_text2 = "\n\n".join([d.get('code','') for d in ctx2])\n            user2 = f"Question:\n{q}\n\nContext:\n{context_text2}\n\nCitations (paths and line ranges):\n{citations2}\n\nAnswer:"\n            # Use same system prompt as first generation attempt\n            sys2 = os.getenv('SYSTEM_PROMPT') or 'You answer strictly from the provided code context. Always cite file paths and line ranges you used.'\n            content2, _ = generate_text(user_input=user2, system_instructions=sys2, reasoning_effort=None)\n            content = (content2 or content or '')\n    repo_hdr = state.get('repo') or (ctx[0].get('repo') if ctx else None) or os.getenv('REPO','project')\n    header = f"[repo: {repo_hdr}]"\n    return {'generation': header + "\n" + content}
fallback_node(state: RAGState) -> Dict:\n    repo_hdr = state.get('repo') or (state.get('documents')[0].get('repo') if state.get('documents') else None) or os.getenv('REPO','project')\n    header = f"[repo: {repo_hdr}]"\n    msg = "I don't have high confidence from local code. Try refining the question or expanding the context."\n    return {'generation': header + "\n" + msg}
build_graph():\n    builder = StateGraph(RAGState)\n    builder.add_node('retrieve', retrieve_node)\n    builder.add_node('rewrite_query', rewrite_query)\n    builder.add_node('generate', generate_node)\n    builder.add_node('fallback', fallback_node)\n    builder.set_entry_point('retrieve')\n    builder.add_conditional_edges('retrieve', route_after_retrieval, {\n        'generate': 'generate', 'rewrite_query': 'rewrite_query', 'fallback': 'fallback'\n    })\n    builder.add_edge('rewrite_query', 'retrieve')\n    builder.add_edge('generate', END)\n    builder.add_edge('fallback', END)\n    DB_URI = os.getenv('REDIS_URL','redis://127.0.0.1:6379/0')\n    try:\n        checkpointer = RedisSaver(redis_url=DB_URI)\n        graph = builder.compile(checkpointer=checkpointer)\n    except Exception:\n        graph = builder.compile()\n    return graph\n\nif __name__ == '__main__':\n    import sys\n    q = ' '.join(sys.argv[1:]) if len(sys.argv)>1 else 'Where is OAuth token validated?'\n    graph = build_graph(); cfg = {'configurable': {'thread_id': 'dev'}}\n    res = graph.invoke({'question': q, 'documents': [], 'generation':'', 'iteration':0, 'confidence':0.0}, cfg)\n    print(res['generation'])
from fastapi import FastAPI, Query, HTTPException\n# Canonical location: server/app.py\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom pathlib import Path\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse, JSONResponse\nfrom starlette.responses import StreamingResponse\nfrom server.langgraph_app import build_graph\nfrom server.tracing import start_trace, end_trace, Trace, latest_trace_path\nfrom retrieval.hybrid_search import search_routed_multi\nfrom common.config_loader import load_repos, out_dir\nfrom server.index_stats import get_index_stats as _get_index_stats\nfrom common.paths import repo_root, gui_dir, docs_dir, files_root\nimport os, json, sys\nfrom typing import Any, Dict\nfrom collections import Counter, defaultdict\nfrom pathlib import Path as _Path\n\napp = FastAPI(title="AGRO RAG + GUI")\n\n_graph = Noneget_graph():\n    global _graph\n    if _graph is None:\n        _graph = build_graph()\n    return _graph\n\nCFG = {"configurable": {"thread_id": "http"}}
Answer(BaseModel):\n    answer: str\n\nROOT = repo_root()\nGUI_DIR = gui_dir()\nDOCS_DIR = docs_dir()\n\n# Serve static GUI assets\nif GUI_DIR.exists():\n    app.mount("/gui", StaticFiles(directory=str(GUI_DIR), html=True), name="gui")\n\n# Serve local docs and repo files for in-GUI links\nif DOCS_DIR.exists():\n    app.mount("/docs", StaticFiles(directory=str(DOCS_DIR), html=True), name="docs")\napp.mount("/files", StaticFiles(directory=str(files_root()), html=True), name="files")\n\n@app.get("/", include_in_schema=False)serve_index():\n    idx = GUI_DIR / "index.html"\n    if idx.exists():\n        return FileResponse(str(idx))\n    return {"ok": True, "message": "GUI assets not found; use /health, /search, /answer"}\n\n@app.get("/health")health():\n    try:\n        g = get_graph()\n        return {"status": "healthy", "graph_loaded": g is not None, "ts": __import__('datetime').datetime.utcnow().isoformat() + 'Z'}\n    except Exception as e:\n        return {"status": "error", "detail": str(e)}\n\n@app.get("/answer", response_model=Answer)
answer(\n    q: str = Query(..., description="Question"),\n    repo: Optional[str] = Query(None, description="Repository override: agro|agro")\n):\n    """Answer a question using strict per-repo routing.\n\n    If `repo` is provided, retrieval and the answer header will use that repo.\n    Otherwise, a lightweight router selects the repo from the query content.\n    """\n    g = get_graph()\n    # start local trace if enabled\n    tr: Optional[Trace] = None\n    try:\n        if Trace.enabled():\n            tr = start_trace(repo=(repo or os.getenv('REPO','agro')), question=q)\n    except Exception:\n        tr = None\n    state = {"question": q, "documents": [], "generation":"", "iteration":0, "confidence":0.0, "repo": (repo.strip() if repo else None)}\n    res = g.invoke(state, CFG)\n    # finalize trace\n    try:\n        if tr is not None:\n            end_trace()\n    except Exception:\n        pass\n    return {"answer": res["generation"]}
ChatRequest(BaseModel):\n    question: str\n    repo: Optional[str] = None\n    model: Optional[str] = None\n    temperature: Optional[float] = None\n    max_tokens: Optional[int] = None\n    multi_query: Optional[int] = None\n    final_k: Optional[int] = None\n    confidence: Optional[float] = None\n    system_prompt: Optional[str] = None\n\n@app.post("/api/chat")
chat(req: ChatRequest) -> Dict[str, Any]:\n    """Chat endpoint with full settings control.\n\n    Accepts all chat settings and applies them to the RAG pipeline:\n    - model: Override GEN_MODEL\n    - temperature: Control response randomness (0.0-2.0)\n    - max_tokens: Maximum response length\n    - multi_query: Number of query rewrites (1-6)\n    - final_k: Number of code chunks to retrieve (5-50)\n    - confidence: Minimum confidence threshold (0.3-0.9)\n    - system_prompt: Custom system prompt override\n    """\n    # Save current env state\n    old_env = {\n        'GEN_MODEL': os.environ.get('GEN_MODEL'),\n        'GEN_TEMPERATURE': os.environ.get('GEN_TEMPERATURE'),\n        'GEN_MAX_TOKENS': os.environ.get('GEN_MAX_TOKENS'),\n        'MQ_REWRITES': os.environ.get('MQ_REWRITES'),\n        'LANGGRAPH_FINAL_K': os.environ.get('LANGGRAPH_FINAL_K'),\n        'CONF_TOP1': os.environ.get('CONF_TOP1'),\n        'CONF_AVG5': os.environ.get('CONF_AVG5'),\n        'CONF_ANY': os.environ.get('CONF_ANY'),\n        'SYSTEM_PROMPT': os.environ.get('SYSTEM_PROMPT'),\n    }\n\n    try:\n        # Apply chat settings to env\n        if req.model:\n            os.environ['GEN_MODEL'] = req.model\n        if req.temperature is not None:\n            os.environ['GEN_TEMPERATURE'] = str(req.temperature)\n        if req.max_tokens is not None:\n            os.environ['GEN_MAX_TOKENS'] = str(req.max_tokens)\n        if req.multi_query is not None:\n            os.environ['MQ_REWRITES'] = str(req.multi_query)\n        if req.final_k is not None:\n            os.environ['LANGGRAPH_FINAL_K'] = str(req.final_k)\n        if req.confidence is not None:\n            # Scale confidence to thresholds\n            conf = req.confidence\n            os.environ['CONF_TOP1'] = str(conf + 0.05)  # Slightly higher for top-1\n            os.environ['CONF_AVG5'] = str(conf)\n            os.environ['CONF_ANY'] = str(conf - 0.05)  # Slightly lower for any\n        if req.system_prompt:\n            os.environ['SYSTEM_PROMPT'] = req.system_prompt\n\n        # Run the RAG pipeline with overridden settings\n        g = get_graph()\n\n        # Start trace if enabled\n        tr: Optional[Trace] = None\n        try:\n            if Trace.enabled():\n                tr = start_trace(repo=(req.repo or os.getenv('REPO','agro')), question=req.question)\n        except Exception:\n            tr = None\n\n        state = {\n            "question": req.question,\n            "documents": [],\n            "generation": "",\n            "iteration": 0,\n            "confidence": 0.0,\n            "repo": (req.repo.strip() if req.repo else None)\n        }\n\n        res = g.invoke(state, CFG)\n\n        # Finalize trace\n        try:\n            if tr is not None:\n                end_trace()\n        except Exception:\n            pass\n\n        return {\n            "answer": res["generation"],\n            "confidence": res.get("confidence", 0.0),\n            "settings_applied": {\n                "model": req.model or old_env.get('GEN_MODEL'),\n                "temperature": req.temperature,\n                "max_tokens": req.max_tokens,\n                "multi_query": req.multi_query,\n                "final_k": req.final_k,\n                "confidence_threshold": req.confidence\n            }\n        }\n\n    finally:\n        # Restore original env\n        for k, v in old_env.items():\n            if v is None:\n                if k in os.environ:\n                    del os.environ[k]\n            else:\n                os.environ[k] = v\n\n@app.get("/search")
search(\n    q: str = Query(..., description="Question"),\n    repo: Optional[str] = Query(None, description="Repository override: agro|agro"),\n    top_k: int = Query(10, description="Number of results to return")\n):\n    """Search for relevant code locations without generation.\n\n    Returns file paths, line ranges, and rerank scores for the most relevant code chunks.\n    """\n    docs = search_routed_multi(q, repo_override=repo, m=4, final_k=top_k)\n    results = [\n        {\n            "file_path": d.get("file_path", ""),\n            "start_line": d.get("start_line", 0),\n            "end_line": d.get("end_line", 0),\n            "language": d.get("language", ""),\n            "rerank_score": float(d.get("rerank_score", 0.0) or 0.0),\n            "repo": d.get("repo", repo),\n        }\n        for d in docs\n    ]\n    return {"results": results, "repo": repo, "count": len(results)}\n\n# ---------------- Trace API ----------------\n@app.get("/api/traces")
list_traces(repo: Optional[str] = Query(None)) -> Dict[str, Any]:\n    """List available trace files for a repo (defaults to current REPO)."""\n    r = (repo or os.getenv('REPO','agro')).strip()\n    base = Path(out_dir(r)) / 'traces'\n    files = []\n    if base.exists():\n        for p in sorted([x for x in base.glob('*.json') if x.is_file()], key=lambda x: x.stat().st_mtime, reverse=True)[:50]:\n            files.append({\n                'path': str(p),\n                'name': p.name,\n                'mtime': __import__('datetime').datetime.utcfromtimestamp(p.stat().st_mtime).isoformat() + 'Z'\n            })\n    return {'repo': r, 'files': files}\n\n\n@app.get("/api/traces/latest")latest_trace(repo: Optional[str] = Query(None)) -> Dict[str, Any]:\n    r = (repo or os.getenv('REPO','agro')).strip()\n    p = latest_trace_path(r)\n    if not p:\n        return {'repo': r, 'trace': None}\n    try:\n        data = json.loads(Path(p).read_text())\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return {'repo': r, 'trace': data, 'path': p}\n\n# ---------------- Minimal GUI API stubs ----------------
_read_json(path: Path, default: Any) -> Any:\n    if path.exists():\n        try:\n            return json.loads(path.read_text())\n        except Exception:\n            return default\n    return default\n_write_json(path: Path, data: Any) -> None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(json.dumps(data, indent=2))\n\n# ---- Prices helper for auto-profile
_default_prices() -> Dict[str, Any]:\n    return {\n        "last_updated": "2025-10-10",\n        "currency": "USD",\n        "models": [\n            {"provider": "openai", "family": "gpt-4o-mini", "model": "gpt-4o-mini",\n             "unit": "1k_tokens", "input_per_1k": 0.005, "output_per_1k": 0.015,\n             "embed_per_1k": 0.0001, "rerank_per_1k": 0.0, "notes": "EXAMPLE"},\n            {"provider": "cohere", "family": "rerank-english-v3.0", "model": "rerank-english-v3.0",\n             "unit": "1k_tokens", "input_per_1k": 0.0, "output_per_1k": 0.0,\n             "embed_per_1k": 0.0, "rerank_per_1k": 0.30, "notes": "EXAMPLE"},\n            {"provider": "voyage", "family": "voyage-3-large", "model": "voyage-3-large",\n             "unit": "1k_tokens", "input_per_1k": 0.0, "output_per_1k": 0.0,\n             "embed_per_1k": 0.12, "rerank_per_1k": 0.0, "notes": "EXAMPLE"},\n            {"provider": "local", "family": "qwen3-coder", "model": "qwen3-coder:14b",\n             "unit": "request", "per_request": 0.0, "notes": "Local inference assumed $0; electricity optional"}\n        ]\n    }
_read_prices() -> Dict[str, Any]:\n    data = _read_json(GUI_DIR / "prices.json", {"models": []})\n    if not data or not isinstance(data, dict) or not data.get("models"):\n        return _default_prices()\n    return data\n\n@app.post("/api/env/reload")api_env_reload() -> Dict[str, Any]:\n    try:\n        from dotenv import load_dotenv as _ld\n        _ld(override=False)\n    except Exception:\n        pass\n    return {"ok": True}\n\n@app.get("/api/config")get_config() -> Dict[str, Any]:\n    cfg = load_repos()\n    # return a broad env snapshot for the GUI; rely on client to pick what it needs\n    env: Dict[str, Any] = {}\n    for k, v in os.environ.items():\n        # keep it simple; include strings only\n        env[k] = v\n    repos = cfg.get("repos", [])\n    return {\n        "env": env,\n        "default_repo": cfg.get("default_repo"),\n        "repos": repos,\n    }\n\n@app.post("/api/config")
set_config(payload: Dict[str, Any]) -> Dict[str, Any]:\n    """\n    Persist environment variables and repos.json edits coming from the GUI.\n\n    Shape: { env: {KEY: VALUE, ...}, repos: [{name, path, keywords, path_boosts, layer_bonuses}, ...] }\n\n    - Writes env keys to .env in repo root (idempotent upsert)\n    - Writes repos to repos.json\n    - Also applies env to current process so the running server reflects changes immediately\n    """\n    root = ROOT\n    env_updates: Dict[str, Any] = dict(payload.get("env") or {})\n    repos_updates: List[Dict[str, Any]] = list(payload.get("repos") or [])\n\n    # 1) Upsert .env\n    env_path = root / ".env"\n    existing: Dict[str, str] = {}\n    if env_path.exists():\n        for line in env_path.read_text().splitlines():\n            if not line.strip() or line.strip().startswith("#") or "=" not in line:\n                continue\n            k, v = line.split("=", 1)\n            existing[k.strip()] = v.strip()\n    for k, v in env_updates.items():\n        existing[str(k)] = str(v)\n        os.environ[str(k)] = str(v)\n    # Write back\n    lines = [f"{k}={existing[k]}" for k in sorted(existing.keys())]\n    env_path.write_text("\n".join(lines) + "\n")\n\n    # 2) Upsert repos.json\n    repos_path = root / "repos.json"\n    cfg = _read_json(repos_path, {"default_repo": None, "repos": []})\n    # Keep default_repo if provided in env\n    default_repo = env_updates.get("REPO") or cfg.get("default_repo")\n    # Merge repos by name\n    by_name: Dict[str, Dict[str, Any]] = {str(r.get("name")): r for r in cfg.get("repos", []) if r.get("name")}\n    for r in repos_updates:\n        name = str(r.get("name") or "").strip()\n        if not name:\n            continue\n        cur = by_name.get(name, {"name": name})\n        # Only accept expected keys\n        if "path" in r:\n            cur["path"] = r["path"]\n        if "keywords" in r and isinstance(r["keywords"], list):\n            cur["keywords"] = [str(x) for x in r["keywords"]]\n        if "path_boosts" in r and isinstance(r["path_boosts"], list):\n            cur["path_boosts"] = [str(x) for x in r["path_boosts"]]\n        if "layer_bonuses" in r and isinstance(r["layer_bonuses"], dict):\n            cur["layer_bonuses"] = r["layer_bonuses"]\n        by_name[name] = cur\n    new_cfg = {\n        "default_repo": default_repo,\n        "repos": sorted(by_name.values(), key=lambda x: str(x.get("name")))\n    }\n    _write_json(repos_path, new_cfg)\n\n    return {"status": "success", "applied_env_keys": sorted(existing.keys()), "repos_count": len(new_cfg["repos"]) }\n\n@app.get("/api/prices")
get_prices():\n    prices_path = GUI_DIR / "prices.json"\n    data = _read_json(prices_path, _default_prices())\n    return JSONResponse(data)\n\n@app.post("/api/prices/upsert")upsert_price(item: Dict[str, Any]) -> Dict[str, Any]:\n    prices_path = GUI_DIR / "prices.json"\n    data = _read_json(prices_path, {"models": []})\n    models: List[Dict[str, Any]] = list(data.get("models", []))\n    key = (str(item.get("provider")), str(item.get("model")))\n    idx = next((i for i, m in enumerate(models) if (str(m.get("provider")), str(m.get("model"))) == key), None)\n    if idx is None:\n        models.append(item)\n    else:\n        models[idx].update(item)\n    data["models"] = models\n    data["last_updated"] = __import__('datetime').datetime.utcnow().strftime('%Y-%m-%d')\n    _write_json(prices_path, data)\n    return {"ok": True, "count": len(models)}\n\n@app.get("/api/keywords")
get_keywords() -> Dict[str, Any]:\n    def extract_terms(obj: Any) -> List[str]:\n        out: List[str] = []\n        try:\n            if isinstance(obj, list):\n                for it in obj:\n                    if isinstance(it, str):\n                        out.append(it)\n                    elif isinstance(it, dict):\n                        # common shapes\n                        for key in ("keyword", "term", "key", "name"):\n                            if key in it and isinstance(it[key], str):\n                                out.append(it[key])\n                                break\n            elif isinstance(obj, dict):\n                # prefer "agro" or "agro" buckets, else flatten all lists\n                for bucket in ("agro", "agro"):\n                    if bucket in obj and isinstance(obj[bucket], list):\n                        out.extend(extract_terms(obj[bucket]))\n                        return out\n                for v in obj.values():\n                    out.extend(extract_terms(v))\n        except Exception:\n            pass\n        return out\n    discr_raw = _read_json(repo_root() / "discriminative_keywords.json", {})\n    sema_raw = _read_json(repo_root() / "semantic_keywords.json", {})\n    llm_raw = _read_json(repo_root() / "llm_keywords.json", {})\n    manual_raw = _read_json(repo_root() / "manual_keywords.json", [])\n    discr = extract_terms(discr_raw)\n    sema = extract_terms(sema_raw)\n    llm = extract_terms(llm_raw)\n    manual = extract_terms(manual_raw) if manual_raw else []\n    repos_cfg = load_repos()\n    repo_k = []\n    for r in repos_cfg.get("repos", []):\n        for k in r.get("keywords", []) or []:\n            if isinstance(k, str):\n                repo_k.append(k)\n    def uniq(xs: List[str]) -> List[str]:\n        seen = set(); out: List[str] = []\n        for k in xs:\n            k2 = str(k)\n            if k2 not in seen:\n                out.append(k2); seen.add(k2)\n        return out\n    discr = uniq(discr)\n    sema = uniq(sema)\n    llm = uniq(llm)\n    manual = uniq(manual)\n    repo_k = uniq(repo_k)\n    allk = uniq((discr or []) + (sema or []) + (llm or []) + (manual or []) + (repo_k or []))\n    return {"discriminative": discr, "semantic": sema, "llm": llm, "manual": manual, "repos": repo_k, "keywords": allk}\n\n@app.post("/api/keywords/add")
add_keyword(body: Dict[str, Any]) -> Dict[str, Any]:\n    """Add a manually created keyword to the appropriate category."""\n    keyword = body.get("keyword", "").strip()\n    category = body.get("category", "")  # 'discriminative', 'semantic', or empty\n\n    if not keyword:\n        return {"error": "Keyword is required"}\n\n    # Map category to file\n    category_files = {\n        "discriminative": "discriminative_keywords.json",\n        "semantic": "semantic_keywords.json"\n    }\n\n    if category and category in category_files:\n        file_path = repo_root() / category_files[category]\n\n        # Read existing data\n        data = _read_json(file_path, {})\n        if not isinstance(data, dict):\n            data = {}\n\n        # Add keyword to the appropriate structure\n        # The structure appears to be a list or dict, let's handle both\n        if isinstance(data, list):\n            if keyword not in data:\n                data.append(keyword)\n                data.sort()\n        else:\n            # If it's a dict, add to a 'manual' key\n            if "manual" not in data:\n                data["manual"] = []\n            if keyword not in data["manual"]:\n                data["manual"].append(keyword)\n                data["manual"].sort()\n\n        # Write back to file\n        try:\n            with open(file_path, "w") as f:\n                json.dump(data, f, indent=2)\n            return {"ok": True, "keyword": keyword, "category": category}\n        except Exception as e:\n            return {"error": f"Failed to save keyword: {str(e)}"}\n    else:\n        # If no category specified, add to a manual keywords file\n        manual_path = repo_root() / "manual_keywords.json"\n        data = _read_json(manual_path, [])\n        if not isinstance(data, list):\n            data = []\n        if keyword not in data:\n            data.append(keyword)\n            data.sort()\n        try:\n            with open(manual_path, "w") as f:\n                json.dump(data, f, indent=2)\n            return {"ok": True, "keyword": keyword, "category": "manual"}\n        except Exception as e:\n            return {"error": f"Failed to save keyword: {str(e)}"}\n\n@app.post("/api/keywords/generate")
generate_keywords(body: Dict[str, Any]) -> Dict[str, Any]:\n    """Generate keywords using either heuristics or an LLM (GUI‑selectable).\n\n    Body: { repo: str, mode?: 'heuristic' | 'llm', max_files?: int }\n    - heuristic: runs scripts/analyze_keywords.py and scripts/analyze_keywords_v2.py\n    - llm: samples files and uses metadata_enricher.enrich to accumulate keywords\n    """\n    import subprocess\n    import time\n    from common.config_loader import get_repo_paths\n\n    repo = body.get("repo")\n    mode = (body.get("mode") or os.getenv("KEYWORDS_GEN_MODE", "heuristic")).strip().lower()\n    max_files = int(body.get("max_files") or os.getenv("KEYWORDS_MAX_FILES", "60") or 60)\n    if not repo:\n        return {"error": "repo parameter required", "ok": False}\n\n    results: Dict[str, Any] = {\n        "ok": True,\n        "repo": repo,\n        "mode": mode,\n        "discriminative": {"count": 0, "file": "discriminative_keywords.json"},\n        "semantic": {"count": 0, "file": "semantic_keywords.json"},\n        "llm": {"count": 0, "file": "llm_keywords.json"},\n        "total_count": 0,\n        "duration_seconds": 0,\n    }\n\n    start_time = time.time()\n\n    # Heuristic pipeline (existing behavior)\n    def run_heuristic() -> None:\n        """Inline heuristic generation (no external scripts).\n\n        More permissive than before: computes TF–IDF over all tokens with a\n        small stopword list and falls back to top-frequency tokens when needed.\n        """\n        nonlocal results\n        import re\n        try:\n            bases = get_repo_paths(repo)\n        except Exception as e:\n            results["ok"] = False\n            results["error"] = str(e)\n            return\n\n        # Gather candidate files\n        exts = {".py", ".rb", ".ts", ".tsx", ".js", ".jsx", ".go", ".rs", ".java", ".cs", ".yml", ".yaml", ".md"}\n        files: List[Path] = []\n        for base in bases:\n            p = Path(base).expanduser()\n            if not p.exists():\n                continue\n            for root, dirs, fnames in os.walk(p):\n                dirs[:] = [d for d in dirs if d not in {".git", "node_modules", "__pycache__", ".venv", "dist", "build"}]\n                for fn in fnames:\n                    if Path(fn).suffix.lower() in exts:\n                        files.append(Path(root) / fn)\n        if not files:\n            results["ok"] = False\n            results["error"] = f"No source files found for repo {repo}"\n            return\n\n        # Tokenization helpers\n        str_rx = re.compile(r'["\'].*?["\']', re.S)\n        hash_comment = re.compile(r'#.*?\n')\n        sl_comment = re.compile(r'//.*?\n')\n        ident_rx = re.compile(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b')\n        stop = set([\n            'the','and','that','with','this','from','into','your','you','for','are','was','have','has','will','can','not','out','one','two',\n            'def','class','import','return','const','let','var','function','void','null','true','false','elif','else','try','except','finally',\n            'self','args','kwargs','none','object','module','package','public','private','static','final','new','extends','implements','using',\n            'todo','fixme','note','copyright','license','utf','ascii','error','warn','info','data','item','value','result','type','types'\n        ])\n\n        def extract_tokens(text: str) -> List[str]:\n            text = str_rx.sub('', text)\n            text = hash_comment.sub('\n', text)\n            text = sl_comment.sub('\n', text)\n            toks = ident_rx.findall(text)\n            return [t.lower() for t in toks if len(t) > 2]\n\n        # Discriminative (TF–IDF)\n        file_tokens: Dict[str, set[str]] = {}\n        global_counts: Counter[str] = Counter()\n        for fp in files:\n            try:\n                code = fp.read_text(encoding='utf-8', errors='ignore')\n            except Exception:\n                continue\n            toks = set(t for t in extract_tokens(code) if t not in stop)\n            file_tokens[str(fp)] = toks\n            for t in toks:\n                global_counts[t] += 1\n        num_files = max(1, len(file_tokens))\n        doc_freq: Counter[str] = Counter()\n        for toks in file_tokens.values():\n            doc_freq.update(toks)\n        import math as _m\n        keyword_scores: Dict[str, float] = {}\n        for token, df in doc_freq.items():\n            if df <= 1:\n                continue\n            idf = _m.log(num_files / (1.0 + df)) if num_files > 1 else 0.0\n            tf = global_counts[token]\n            score = tf * (idf if idf > 0 else 1.0)\n            keyword_scores[token] = float(score)\n        topn_discr = int(os.getenv("KEYWORDS_TOPN_DISCR", "60") or 60)\n        discr_sorted = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:topn_discr]\n        discr_list = [k for k, _ in discr_sorted]\n        if not discr_list:\n            # fallback: top tokens by document frequency\n            discr_list = [k for k, _ in doc_freq.most_common(topn_discr) if k not in stop]\n        # Persist\n        discr_path = repo_root() / "discriminative_keywords.json"\n        discr_data = _read_json(discr_path, {})\n        if not isinstance(discr_data, dict):\n            discr_data = {}\n        discr_data[str(repo)] = discr_list\n        _write_json(discr_path, discr_data)\n        results["discriminative"]["count"] = len(discr_list)\n\n        # Semantic (domain-ish): frequency across files with directory boost\n        dir_terms: set[str] = set()\n        for fp in files:\n            for part in Path(fp).parts:\n                s = re.sub(r'[^a-zA-Z0-9_]+', ' ', part)\n                for w in s.split():\n                    if len(w) > 2:\n                        dir_terms.add(w.lower())\n        term_files: Dict[str, set[str]] = defaultdict(set)\n        term_counts: Counter[str] = Counter()\n        for fp in files:\n            try:\n                code = Path(fp).read_text(encoding='utf-8', errors='ignore')\n            except Exception:\n                continue\n            terms = [t for t in extract_tokens(code) if t not in stop]\n            rel = str(fp)\n            for t in terms:\n                term_counts[t] += 1\n                term_files[t].add(rel)\n        scored: list[tuple[str, float]] = []\n        for t, fileset in term_files.items():\n            fc = len(fileset)\n            if fc >= 2 and fc <= max(3, int(0.5 * num_files)):\n                dir_boost = 2.0 if t in dir_terms else 1.0\n                score = (term_counts[t] * fc * dir_boost) / (num_files + 1)\n                scored.append((t, score))\n        topn_sem = int(os.getenv("KEYWORDS_TOPN_SEM", "60") or 60)\n        sem_sorted = sorted(scored, key=lambda x: x[1], reverse=True)[:topn_sem]\n        sem_list = [k for k, _ in sem_sorted]\n        if not sem_list:\n            sem_list = [k for k, _ in term_counts.most_common(topn_sem) if k not in stop]\n        sem_path = repo_root() / "semantic_keywords.json"\n        sem_data = _read_json(sem_path, {})\n        if not isinstance(sem_data, dict):\n            sem_data = {}\n        sem_data[str(repo)] = sem_list\n        _write_json(sem_path, sem_data)\n        results["semantic"]["count"] = len(sem_list)\n\n        # Emergency fallback: still zero? derive from file and directory names\n        if (results["discriminative"]["count"] or 0) == 0 and (results["semantic"]["count"] or 0) == 0:\n            base_terms: Counter[str] = Counter()\n            for fp in files:\n                parts = Path(fp).parts\n                for part in parts:\n                    part = re.sub(r'[^a-zA-Z0-9_]+', ' ', part)\n                    for w in part.split():\n                        w = w.lower()\n                        if len(w) > 2 and w not in stop:\n                            base_terms[w] += 1\n            emer = [k for k, _ in base_terms.most_common(40)]\n            if emer:\n                discr_data[str(repo)] = emer[:20]\n                sem_data[str(repo)] = emer[:20]\n                _write_json(discr_path, discr_data)\n                _write_json(sem_path, sem_data)\n                results["discriminative"]["count"] = len(discr_data[str(repo)])\n                results["semantic"]["count"] = len(sem_data[str(repo)])\n\n    # LLM pipeline (new)\n    def run_llm(backend_override: str | None = None, model_override: str | None = None) -> None:\n        nonlocal results\n        try:\n            from common.metadata import enrich  # uses MLX or Ollama based on env\n        except Exception as e:  # pragma: no cover\n            results["ok"] = False\n            results["error"] = f"LLM backend unavailable: {e}"\n            return\n\n        # Collect candidate files (reuse indexer filters loosely)\n        exts = {".py", ".rb", ".ts", ".tsx", ".js", ".jsx", ".go", ".rs", ".java", ".cs", ".yml", ".yaml", ".md"}\n        files: List[Path] = []\n        try:\n            bases = get_repo_paths(repo)\n        except Exception as e:\n            results["ok"] = False\n            results["error"] = str(e)\n            return\n        for base in bases:\n            p = Path(base).expanduser()\n            if not p.exists():\n                continue\n            for root, dirs, fnames in os.walk(p):\n                # prune noisy dirs\n                dirs[:] = [d for d in dirs if d not in {".git", "node_modules", "__pycache__", ".venv", "dist", "build"}]\n                for fn in fnames:\n                    if Path(fn).suffix.lower() in exts:\n                        files.append(Path(root) / fn)\n        # Sample limited number deterministically: smallest paths first for stability\n        files = sorted(files, key=lambda pp: (len(str(pp)), str(pp)))[:max_files]\n\n        counts: Counter[str] = Counter()\n        per_file_limit = int(os.getenv("KEYWORDS_PER_FILE", "10") or 10)\n        # Temporarily override enrich backend/model if provided\n        old_env = {"ENRICH_BACKEND": os.environ.get("ENRICH_BACKEND"), "ENRICH_MODEL_OPENAI": os.environ.get("ENRICH_MODEL_OPENAI"), "GEN_MODEL": os.environ.get("GEN_MODEL")}\n        if backend_override:\n            os.environ["ENRICH_BACKEND"] = backend_override\n        if model_override:\n            # prefer specific openai enrich model, else set GEN_MODEL used by openai client\n            os.environ["ENRICH_MODEL_OPENAI"] = model_override\n            os.environ["GEN_MODEL"] = model_override\n        try:\n            for fp in files:\n                try:\n                    text = fp.read_text(encoding="utf-8", errors="ignore")\n                except Exception:\n                    continue\n                # clip to manageable size\n                text = text[:8000]\n                meta = enrich(str(fp), Path(fp).suffix.lstrip('.'), text) or {}\n                kws = [str(k).strip().lower() for k in (meta.get("keywords") or []) if isinstance(k, str)]\n                for k in kws[:per_file_limit]:\n                    if k:\n                        counts[k] += 1\n        finally:\n            # restore environment\n            for k, v in old_env.items():\n                if v is None:\n                    if k in os.environ:\n                        del os.environ[k]\n                else:\n                    os.environ[k] = v\n        # Persist results\n        top_total = int(os.getenv("KEYWORDS_MAX_TOTAL", "200") or 200)\n        ranked = [k for k, _ in counts.most_common(top_total)]\n        out_path = repo_root() / "llm_keywords.json"\n        data = _read_json(out_path, {})\n        if not isinstance(data, dict):\n            data = {}\n        data[str(repo)] = ranked\n        _write_json(out_path, data)\n        results["llm"]["count"] = len(ranked)\n\n    try:\n        if mode == "llm":\n            backend = (body.get("backend") or os.getenv("ENRICH_BACKEND") or "openai").strip().lower()\n            model_override = None\n            if backend == "openai":\n                model_override = body.get("openai_model") or os.getenv("ENRICH_MODEL_OPENAI") or os.getenv("GEN_MODEL")\n            run_llm(backend_override=backend, model_override=model_override)\n            # If LLM produced nothing, fall back to heuristics for useful output\n            if (results.get("llm", {}).get("count") or 0) == 0:\n                run_heuristic()\n        else:\n            run_heuristic()\n        # Compose totals (heuristic writes discr/semantic; llm writes llm)\n        results["total_count"] = (\n            (results.get("discriminative", {}).get("count") or 0)\n            + (results.get("semantic", {}).get("count") or 0)\n            + (results.get("llm", {}).get("count") or 0)\n        )\n        results["duration_seconds"] = round(time.time() - start_time, 2)\n    except subprocess.TimeoutExpired:\n        results["ok"] = False\n        results["error"] = "Keyword generation timed out (300s limit)"\n    except Exception as e:\n        results["ok"] = False\n        results["error"] = str(e)\n\n    return results\n\n@app.post("/api/scan-hw")
scan_hw() -> Dict[str, Any]:\n    # Lightweight local scan without new deps\n    import platform, shutil\n    info = {\n        "os": platform.system(),\n        "arch": platform.machine(),\n        "cpu_cores": os.cpu_count() or 0,\n        "mem_gb": None,\n    }\n    # Try to get memory (Darwin via sysctl; Linux via /proc/meminfo)\n    try:\n        if info["os"] == "Darwin":\n            import subprocess\n            out = subprocess.check_output(["sysctl", "-n", "hw.memsize"], text=True).strip()\n            info["mem_gb"] = round(int(out) / (1024**3), 2)\n        elif Path("/proc/meminfo").exists():\n            txt = Path("/proc/meminfo").read_text()\n            for line in txt.splitlines():\n                if line.startswith("MemTotal:"):\n                    kb = int(line.split()[1]); info["mem_gb"] = round(kb/1024/1024, 2)\n                    break\n    except Exception:\n        pass\n    runtimes = {\n        "ollama": bool(os.getenv("OLLAMA_URL") or shutil.which("ollama")),\n        "coreml": info["os"] == "Darwin",\n        "cuda": bool(shutil.which("nvidia-smi")),\n        "mps": info["os"] == "Darwin",\n    }\n    tools = {"uvicorn": bool(shutil.which("uvicorn")), "docker": bool(shutil.which("docker"))}\n    return {"info": info, "runtimes": runtimes, "tools": tools}\n\n@app.get("/api/repo/size")
get_repo_size(path: str = Query(..., description="Path to repo/folder")) -> Dict[str, Any]:\n    """Calculate total size of a repo/folder for onboarding wizard."""\n    try:\n        p = Path(path).expanduser().resolve()\n        if not p.exists():\n            raise HTTPException(status_code=404, detail="Path not found")\n        if not p.is_dir():\n            raise HTTPException(status_code=400, detail="Path must be a directory")\n\n        total_size = 0\n        file_count = 0\n\n        for root, dirs, files in os.walk(p):\n            # Skip common noise directories\n            dirs[:] = [d for d in dirs if d not in {'.git', 'node_modules', '__pycache__', '.venv', 'dist', 'build', 'out', '.next'}]\n            for f in files:\n                try:\n                    total_size += (Path(root) / f).stat().st_size\n                    file_count += 1\n                except (OSError, PermissionError):\n                    pass\n\n        mb = total_size / (1024 * 1024)\n        return {\n            "path": str(p),\n            "bytes": total_size,\n            "mb": round(mb, 1),\n            "human": f"{mb:.1f} MB" if mb >= 1 else f"{total_size / 1024:.1f} KB",\n            "file_count": file_count,\n            "over_10mb": mb > 10.0\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))
_find_price(provider: str, model: Optional[str]) -> Optional[Dict[str, Any]]:\n    """Generic price lookup (backwards-compat) — used for generation rows."""\n    data = _read_json(GUI_DIR / "prices.json", {"models": []})\n    models = data.get("models", [])\n    # Prefer exact provider+model, else fallback to first matching provider\n    try:\n        prov = str(provider or '').lower()\n        mdl = str(model or '').lower()\n        for m in models:\n            if str(m.get("provider", "")).lower() == prov and (not mdl or str(m.get("model", "")).lower() == mdl):\n                return m\n        # Model-only match (provider mismatch or unknown)\n        if mdl:\n            for m in models:\n                if str(m.get("model", "")).lower() == mdl:\n                    return m\n        for m in models:\n            if str(m.get("provider", "")).lower() == prov:\n                return m\n    except Exception:\n        pass\n    return None
_find_price_kind(provider: str, model: Optional[str], kind: str) -> Optional[Dict[str, Any]]:\n    """Find a price row constrained by kind: 'gen' | 'embed' | 'rerank'."""\n    data = _read_json(GUI_DIR / "prices.json", {"models": []})\n    models = data.get("models", [])\n    prov = str(provider or '').lower()\n    mdl = str(model or '').lower()\n\n    def is_embed(m):\n        return (m is not None) and (('embed_per_1k' in m) or ('embed' in str(m.get('family','')).lower()))\n\n    def is_rerank(m):\n        fam_mod = (str(m.get('family','')) + str(m.get('model',''))).lower()\n        return (m is not None) and (('rerank_per_1k' in m) or ('rerank' in fam_mod))\n\n    def is_gen(m):\n        u = str(m.get('unit','')).lower()\n        return (u == '1k_tokens') and (not is_embed(m)) and (not is_rerank(m))\n\n    kind_pred = {'gen': is_gen, 'embed': is_embed, 'rerank': is_rerank}.get(kind, lambda _m: True)\n\n    cand = [m for m in models if kind_pred(m)]\n    # exact provider+model\n    for m in cand:\n        if (str(m.get('provider','')).lower() == prov) and (not mdl or str(m.get('model','')).lower() == mdl):\n            return m\n    # model-only\n    if mdl:\n        for m in cand:\n            if str(m.get('model','')).lower() == mdl:\n                return m\n    # first for provider among kind\n    for m in cand:\n        if str(m.get('provider','')).lower() == prov:\n            return m\n    # fallback any kind+provider\n    for m in models:\n        if str(m.get('provider','')).lower() == prov:\n            return m\n    return None
_estimate_cost(\n    gen_provider: str,\n    gen_model: Optional[str],\n    tokens_in: int,\n    tokens_out: int,\n    embeds: int,\n    reranks: int,\n    requests_per_day: int,\n    embed_provider: Optional[str] = None,\n    embed_model: Optional[str] = None,\n    rerank_provider: Optional[str] = None,\n    rerank_model: Optional[str] = None,\n) -> Dict[str, Any]:\n    """Estimate daily and monthly costs using gui/prices.json.\n\n    Semantics (simple and robust):\n      - tokens_in/out are per-request tokens; multiplied by requests_per_day for generation costs.\n      - embeds is total embedding tokens per day (already aggregated) unless zero.\n      - reranks is total rerank "units" per day:\n          * if price row has rerank_per_1k → interpret as tokens; cost = (reranks/1000) * rerank_per_1k.\n          * elif price row has per_request → interpret as count of requests; cost = reranks * per_request.\n          * else if price row unit == 'request' → cost = reranks * per_request (if available), else 0.\n      - Any missing fields default to 0.\n    """\n    rpd = max(1, int(requests_per_day or 0))\n\n    # Generation\n    price_gen = _find_price_kind(gen_provider, gen_model, 'gen') or {}\n    per_1k_in = float(price_gen.get("input_per_1k", 0.0) or 0.0)\n    per_1k_out = float(price_gen.get("output_per_1k", 0.0) or 0.0)\n    per_req = float(price_gen.get("per_request", 0.0) or 0.0)\n    # tokens_in/out are per request\n    gen_cost = (tokens_in/1000.0) * per_1k_in * rpd + (tokens_out/1000.0) * per_1k_out * rpd + per_req * rpd\n\n    # Embeddings (separate provider/model); "embeds" is total tokens per day\n    emb_cost = 0.0\n    emb_row = None\n    if embeds > 0:\n        if not embed_provider and gen_provider == 'openai':\n            embed_provider = 'openai'\n            embed_model = embed_model or 'text-embedding-3-small'\n        emb_row = _find_price_kind(embed_provider or gen_provider, embed_model, 'embed')\n        if emb_row:\n            emb_cost = (embeds/1000.0) * float(emb_row.get("embed_per_1k", 0.0) or 0.0)\n\n    # Rerank; "reranks" interpreted by price row\n    rr_cost = 0.0\n    rr_row = None\n    if reranks > 0:\n        rr_row = _find_price_kind(rerank_provider or 'cohere', rerank_model or 'rerank-3.5', 'rerank')\n        if rr_row:\n            per_1k_rr = float(rr_row.get("rerank_per_1k", 0.0) or 0.0)\n            per_req_rr = float(rr_row.get("per_request", 0.0) or 0.0)\n            unit = str(rr_row.get("unit") or '').lower()\n            if unit == 'request':\n                # Treat input `reranks` as number of requests\n                if per_req_rr > 0.0:\n                    rr_cost = float(reranks) * per_req_rr\n                elif per_1k_rr > 0.0:\n                    rr_cost = (reranks/1000.0) * per_1k_rr\n            elif per_1k_rr > 0.0:\n                rr_cost = (reranks/1000.0) * per_1k_rr\n            elif per_req_rr > 0.0:\n                # Treat "reranks" as number of rerank calls for the day\n                rr_cost = float(reranks) * per_req_rr\n            elif unit == 'request' and per_req_rr == 0.0:\n                rr_cost = 0.0\n\n    daily = float(gen_cost + emb_cost + rr_cost)\n    breakdown = {\n        "generation": {\n            "row": price_gen,\n            "tokens_in_per_req": tokens_in,\n            "tokens_out_per_req": tokens_out,\n            "requests_per_day": rpd,\n            "cost_daily": round(gen_cost, 6),\n        },\n        "embeddings": {\n            "row": (emb_row or None),\n            "tokens_daily": embeds,\n            "cost_daily": round(emb_cost, 6),\n        } if embeds > 0 else None,\n        "rerank": {\n            "row": (rr_row or None),\n            "units_daily": reranks,\n            "cost_daily": round(rr_cost, 6),\n        } if reranks > 0 else None,\n    }\n    return {"daily": round(daily, 6), "monthly": round(daily*30.0, 4), "breakdown": breakdown}\n\n@app.post("/api/cost/estimate")
cost_estimate(payload: Dict[str, Any]) -> Dict[str, Any]:\n    gen_provider = str(payload.get("gen_provider") or payload.get("provider") or "openai")\n    gen_model = payload.get("gen_model")\n    tokens_in = int(payload.get("tokens_in") or 0)\n    tokens_out = int(payload.get("tokens_out") or 0)\n    embeds = int(payload.get("embeds") or 0)\n    reranks = int(payload.get("reranks") or 0)\n    rpd = int(payload.get("requests_per_day") or 0)\n    emb_prov = payload.get("embed_provider")\n    emb_model = payload.get("embed_model")\n    rr_prov = payload.get("rerank_provider")\n    rr_model = payload.get("rerank_model")\n    return _estimate_cost(gen_provider, gen_model, tokens_in, tokens_out, embeds, reranks, rpd,\n                          embed_provider=emb_prov, embed_model=emb_model,\n                          rerank_provider=rr_prov, rerank_model=rr_model)\n\n@app.post("/api/cost/estimate_pipeline")cost_estimate_pipeline(payload: Dict[str, Any]) -> Dict[str, Any]:\n    # same shape as estimate(), kept for compatibility\n    return cost_estimate(payload)\n\n@app.get("/api/profiles")
profiles_list() -> Dict[str, Any]:\n    prof_dir = GUI_DIR / "profiles"\n    prof_dir.mkdir(parents=True, exist_ok=True)\n    names = []\n    for p in prof_dir.glob("*.json"):\n        names.append(p.stem)\n    return {"profiles": sorted(names), "default": None}\n\n@app.get("/api/profiles/{name}")profiles_get(name: str) -> Dict[str, Any]:\n    prof_dir = GUI_DIR / "profiles"\n    path = prof_dir / f"{name}.json"\n    if not path.exists():\n        raise HTTPException(status_code=404, detail=f"Profile '{name}' not found")\n    prof = _read_json(path)\n    return {"ok": True, "name": name, "profile": prof}\n\n@app.post("/api/profiles/save")profiles_save(payload: Dict[str, Any]) -> Dict[str, Any]:\n    name = str(payload.get("name") or "").strip()\n    prof = payload.get("profile") or {}\n    if not name:\n        raise HTTPException(status_code=400, detail="missing name")\n    path = GUI_DIR / "profiles" / f"{name}.json"\n    _write_json(path, prof)\n    return {"ok": True, "name": name}\n\n@app.post("/api/profiles/apply")
profiles_apply(payload: Dict[str, Any]) -> Dict[str, Any]:\n    prof = payload.get("profile") or {}\n    applied = []\n    for k, v in prof.items():\n        os.environ[str(k)] = str(v)\n        applied.append(str(k))\n    return {"ok": True, "applied_keys": applied}\n\n# --- Auto-profile v2\ntry:\n    from autoprofile import autoprofile as _ap_select\nexcept Exception:\n    _ap_select = None\n\n@app.post("/api/profile/autoselect")api_profile_autoselect(payload: Dict[str, Any]):\n    if _ap_select is None:\n        raise HTTPException(status_code=500, detail="autoprofile module not available")\n    prices = _read_prices()\n    env, reason = _ap_select(payload, prices)\n    if not env:\n        raise HTTPException(status_code=422, detail=reason)\n    return {"env": env, "reason": reason}\n\n@app.post("/api/checkpoint/config")
checkpoint_config() -> Dict[str, Any]:\n    """Write a timestamped checkpoint of current env + repos to gui/profiles."""\n    cfg = get_config()\n    from datetime import datetime\n    ts = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n    out_dir = GUI_DIR / "profiles"\n    out_dir.mkdir(parents=True, exist_ok=True)\n    path = out_dir / f"checkpoint-{ts}.json"\n    _write_json(path, cfg)\n    return {"ok": True, "path": str(path)}\n\n# --- Index + Cards: comprehensive status with all metrics ---\n_INDEX_STATUS: List[str] = []\n_INDEX_METADATA: Dict[str, Any] = {}\n\n@app.post("/api/index/start")
index_start() -> Dict[str, Any]:\n    """Start indexing with real subprocess execution."""\n    global _INDEX_STATUS, _INDEX_METADATA\n    import subprocess\n    import threading\n\n    _INDEX_STATUS = ["Indexing started..."]\n    _INDEX_METADATA = {}\n\n    def run_index():\n        global _INDEX_STATUS, _INDEX_METADATA\n        try:\n            repo = os.getenv("REPO", "agro")\n            _INDEX_STATUS.append(f"Indexing repository: {repo}")\n\n            # Run the actual indexer\n            result = subprocess.run(\n                ["python", "index_repo.py"],\n                capture_output=True,\n                text=True,\n                cwd=repo_root(),\n                env={**os.environ, "REPO": repo}\n            )\n\n            if result.returncode == 0:\n                _INDEX_STATUS.append("✓ Indexing completed successfully")\n                _INDEX_METADATA = _get_index_stats()\n            else:\n                _INDEX_STATUS.append(f"✗ Indexing failed: {result.stderr[:200]}")\n        except Exception as e:\n            _INDEX_STATUS.append(f"✗ Error: {str(e)}")\n\n    # Run in background\n    thread = threading.Thread(target=run_index, daemon=True)\n    thread.start()\n\n    return {"ok": True, "message": "Indexing started in background"}\n\n@app.get("/api/index/status")
index_status() -> Dict[str, Any]:\n    """Return comprehensive indexing status with all metrics."""\n    if not _INDEX_METADATA:\n        # Return basic status if no metadata yet\n        return {\n            "lines": _INDEX_STATUS,\n            "running": len(_INDEX_STATUS) > 0 and not any("completed" in s or "failed" in s for s in _INDEX_STATUS),\n            "metadata": _get_index_stats()  # Always provide current stats\n        }\n\n    return {\n        "lines": _INDEX_STATUS,\n        "running": False,\n        "metadata": _INDEX_METADATA\n    }\n\n@app.post("/api/cards/build")cards_build() -> Dict[str, Any]:\n    """Legacy one-shot build (kept for compatibility). Prefer /api/cards/build/start."""\n    try:\n        import subprocess\n        result = subprocess.run(\n            [sys.executable, "-m", "indexer.build_cards"],\n            capture_output=True,\n            text=True,\n            timeout=300\n        )\n        return {\n            "ok": result.returncode == 0,\n            "stdout": result.stdout,\n            "stderr": result.stderr\n        }\n    except Exception as e:\n        return {"ok": False, "error": str(e)}\n\n# -------- Cards Builder (Jobs + SSE) --------\n@app.post("/api/cards/build/start")
cards_build_start(repo: Optional[str] = Query(None), enrich: int = Query(1)) -> Dict[str, Any]:\n    from server.cards_builder import get_job_for_repo, start_job\n    r = (repo or os.getenv('REPO', 'agro')).strip()\n    existing = get_job_for_repo(r)\n    if existing and existing.status == 'running':\n        raise HTTPException(status_code=409, detail=f"A cards build job is already running for repo {r}")\n    try:\n        job = start_job(r, enrich=bool(int(enrich)))\n        return {"job_id": job.job_id, "repo": r}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get("/api/cards/build/stream/{job_id}")cards_build_stream(job_id: str):\n    from server.cards_builder import get_job\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail="Job not found")\n    def gen():\n        for evt in job.events():\n            yield evt\n    return StreamingResponse(gen(), media_type='text/event-stream')\n\n\n@app.get("/api/cards/build/status/{job_id}")
cards_build_status(job_id: str) -> Dict[str, Any]:\n    from server.cards_builder import get_job\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail="Job not found")\n    snap = job.snapshot()\n    snap.update({"status": job.status})\n    if job.error:\n        snap["error"] = job.error\n    return snap\n\n\n@app.post("/api/cards/build/cancel/{job_id}")cards_build_cancel(job_id: str) -> Dict[str, Any]:\n    from server.cards_builder import cancel_job\n    ok = cancel_job(job_id)\n    if not ok:\n        raise HTTPException(status_code=404, detail="Job not found")\n    return {"ok": True}\n\n\n@app.get("/api/cards/build/logs")cards_build_logs() -> Dict[str, Any]:\n    from server.cards_builder import read_logs\n    return read_logs()\n\n# ---------------- Embedded Editor ----------------\n@app.get("/health/editor")
editor_health() -> Dict[str, Any]:\n    """Check embedded editor health"""\n    try:\n        import requests\n\n        status_path = Path(__file__).parent.parent / "out" / "editor" / "status.json"\n\n        if not status_path.exists():\n            return {"ok": False, "error": "No status file", "enabled": False}\n\n        with open(status_path, 'r') as f:\n            status = json.load(f)\n\n        if not status.get("enabled", False):\n            return {"ok": False, "reason": status.get("reason", "disabled"), "enabled": False}\n\n        # Probe the editor URL\n        url = status.get("url", "")\n        try:\n            resp = requests.get(url, timeout=2)\n            if resp.status_code == 200:\n                return {\n                    "ok": True,\n                    "enabled": True,\n                    "port": status.get("port"),\n                    "url": url,\n                    "started_at": status.get("started_at")\n                }\n            else:\n                return {\n                    "ok": False,\n                    "error": f"HTTP {resp.status_code}",\n                    "enabled": True,\n                    "url": url\n                }\n        except requests.RequestException as e:\n            return {\n                "ok": False,\n                "error": f"Connection failed: {str(e)}",\n                "enabled": True,\n                "url": url\n            }\n    except Exception as e:\n        return {"ok": False, "error": str(e), "enabled": False}\n\n@app.post("/api/editor/restart")
editor_restart() -> Dict[str, Any]:\n    """Restart the embedded editor"""\n    try:\n        import subprocess\n\n        scripts_dir = Path(__file__).parent.parent / "scripts"\n\n        # Stop first\n        down_script = scripts_dir / "editor_down.sh"\n        if down_script.exists():\n            subprocess.run([str(down_script)], check=False)\n\n        # Start\n        up_script = scripts_dir / "editor_up.sh"\n        if up_script.exists():\n            result = subprocess.run(\n                [str(up_script)],\n                capture_output=True,\n                text=True,\n                timeout=60\n            )\n            return {\n                "ok": result.returncode == 0,\n                "stdout": result.stdout,\n                "stderr": result.stderr\n            }\n        else:\n            return {"ok": False, "error": "editor_up.sh not found"}\n    except Exception as e:\n        return {"ok": False, "error": str(e)}\n\n@app.get("/api/cards")
cards_list() -> Dict[str, Any]:\n    """Return cards index information"""\n    try:\n        from common.config_loader import out_dir\n        repo = os.getenv('REPO', 'agro').strip()\n        base = _Path(out_dir(repo))\n        cards_path = base / "cards.jsonl"\n        progress_path = (_Path(os.getenv('OUT_DIR_BASE') or _Path(__file__).resolve().parents[1] / 'out') / 'cards' / repo / 'progress.json')\n\n        cards = []\n        count = 0\n        if cards_path.exists():\n            with cards_path.open('r', encoding='utf-8') as f:\n                for i, line in enumerate(f):\n                    if not line.strip():\n                        continue\n                    if len(cards) < 10:\n                        try:\n                            cards.append(json.loads(line))\n                        except Exception:\n                            pass\n                    count = i + 1\n        last_build = None\n        if progress_path.exists():\n            try:\n                last_build = json.loads(progress_path.read_text())\n            except Exception:\n                last_build = None\n        return {"count": count, "cards": cards, "path": str(cards_path), "last_build": last_build}\n    except Exception as e:\n        return {"count": 0, "cards": [], "error": str(e)}\n\n# ---------------- Autotune ----------------\n@app.get("/api/autotune/status")
autotune_status() -> Dict[str, Any]:\n    """Return autotune status. Pro feature stub."""\n    return {"enabled": False, "current_mode": None}\n\n@app.post("/api/autotune/status")autotune_update(payload: Dict[str, Any]) -> Dict[str, Any]:\n    """Update autotune settings. Pro feature stub."""\n    return {"ok": True, "enabled": payload.get("enabled", False), "current_mode": payload.get("current_mode")}\n\n# ---------------- Git hooks helpers ----------------
_git_hooks_dir() -> Path:\n    root = repo_root()\n    return root / ".git" / "hooks"\n\n_HOOK_POST_CHECKOUT = """#!/usr/bin/env bash\n# Auto-index on branch changes when AUTO_INDEX=1\n[ "${AUTO_INDEX:-0}" != "1" ] && exit 0\nrepo_root="$(git rev-parse --show-toplevel)"\ncd "$repo_root" || exit 0\nif [ -d .venv ]; then . .venv/bin/activate; fi\nexport REPO=agro EMBEDDING_TYPE=local SKIP_DENSE=1\nexport OUT_DIR_BASE="./out.noindex-shared"\npython index_repo.py >/dev/null 2>&1 || true\n"""\n\n_HOOK_POST_COMMIT = """#!/usr/bin/env bash\n# Auto-index on commit when AUTO_INDEX=1\n[ "${AUTO_INDEX:-0}" != "1" ] && exit 0\nrepo_root="$(git rev-parse --show-toplevel)"\ncd "$repo_root" || exit 0\nif [ -d .venv ]; then . .venv/bin/activate; fi\nexport REPO=agro EMBEDDING_TYPE=local SKIP_DENSE=1\nexport OUT_DIR_BASE="./out.noindex-shared"\npython index_repo.py >/dev/null 2>&1 || true\n"""\n\n@app.get("/api/git/hooks/status")
git_hooks_status() -> Dict[str, Any]:\n    d = _git_hooks_dir()\n    pc = d / "post-checkout"\n    pm = d / "post-commit"\n    return {\n        "dir": str(d),\n        "post_checkout": pc.exists(),\n        "post_commit": pm.exists(),\n        "enabled_hint": "export AUTO_INDEX=1"\n    }\n\n@app.post("/api/git/hooks/install")git_hooks_install() -> Dict[str, Any]:\n    d = _git_hooks_dir()\n    try:\n        d.mkdir(parents=True, exist_ok=True)\n        pc = d / "post-checkout"\n        pm = d / "post-commit"\n        pc.write_text(_HOOK_POST_CHECKOUT)\n        pm.write_text(_HOOK_POST_COMMIT)\n        os.chmod(pc, 0o755)\n        os.chmod(pm, 0o755)\n        return {"ok": True, "message": "Installed git hooks. Enable with: export AUTO_INDEX=1"}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# ---------------- Golden Questions Management ----------------_golden_path() -> Path:\n    return Path(os.getenv('GOLDEN_PATH', 'golden.json'))\n\n@app.get("/api/golden")
golden_list() -> Dict[str, Any]:\n    """List all golden questions."""\n    gp = _golden_path()\n    if not gp.exists():\n        return {"questions": [], "count": 0}\n    data = _read_json(gp, [])\n    if not isinstance(data, list):\n        data = []\n    # Filter out comment entries\n    questions = [q for q in data if isinstance(q, dict) and "q" in q]\n    return {"questions": questions, "count": len(questions)}\n\n@app.post("/api/golden")golden_add(payload: Dict[str, Any]) -> Dict[str, Any]:\n    """Add a new golden question."""\n    gp = _golden_path()\n    data = _read_json(gp, [])\n    if not isinstance(data, list):\n        data = []\n\n    # Validate required fields\n    q = str(payload.get("q") or "").strip()\n    if not q:\n        raise HTTPException(status_code=400, detail="Question text required")\n\n    new_q = {\n        "q": q,\n        "repo": str(payload.get("repo") or os.getenv("REPO", "agro")),\n        "expect_paths": list(payload.get("expect_paths") or [])\n    }\n\n    data.append(new_q)\n    _write_json(gp, data)\n    return {"ok": True, "index": len(data) - 1, "question": new_q}\n\n@app.put("/api/golden/{index}")
golden_update(index: int, payload: Dict[str, Any]) -> Dict[str, Any]:\n    """Update an existing golden question."""\n    gp = _golden_path()\n    data = _read_json(gp, [])\n    if not isinstance(data, list):\n        raise HTTPException(status_code=404, detail="No golden questions found")\n\n    # Find actual questions (skip comments)\n    questions = [i for i, q in enumerate(data) if isinstance(q, dict) and "q" in q]\n    if index < 0 or index >= len(questions):\n        raise HTTPException(status_code=404, detail="Question not found")\n\n    actual_index = questions[index]\n\n    # Update fields\n    if "q" in payload:\n        data[actual_index]["q"] = str(payload["q"])\n    if "repo" in payload:\n        data[actual_index]["repo"] = str(payload["repo"])\n    if "expect_paths" in payload:\n        data[actual_index]["expect_paths"] = list(payload["expect_paths"])\n\n    _write_json(gp, data)\n    return {"ok": True, "index": index, "question": data[actual_index]}\n\n@app.delete("/api/golden/{index}")
golden_delete(index: int) -> Dict[str, Any]:\n    """Delete a golden question."""\n    gp = _golden_path()\n    data = _read_json(gp, [])\n    if not isinstance(data, list):\n        raise HTTPException(status_code=404, detail="No golden questions found")\n\n    # Find actual questions (skip comments)\n    questions = [i for i, q in enumerate(data) if isinstance(q, dict) and "q" in q]\n    if index < 0 or index >= len(questions):\n        raise HTTPException(status_code=404, detail="Question not found")\n\n    actual_index = questions[index]\n    deleted = data.pop(actual_index)\n\n    _write_json(gp, data)\n    return {"ok": True, "deleted": deleted}\n\n@app.post("/api/golden/test")
golden_test(payload: Dict[str, Any]) -> Dict[str, Any]:\n    """Test a single golden question and return retrieval results."""\n    q = str(payload.get("q") or "").strip()\n    if not q:\n        raise HTTPException(status_code=400, detail="Question required")\n\n    repo = str(payload.get("repo") or os.getenv("REPO", "agro"))\n    expect_paths = list(payload.get("expect_paths") or [])\n    final_k = int(payload.get("final_k") or os.getenv("EVAL_FINAL_K", "5"))\n    use_multi = payload.get("use_multi", os.getenv("EVAL_MULTI", "1") == "1")\n\n    # Run search\n    if use_multi:\n        docs = search_routed_multi(q, repo_override=repo, m=4, final_k=final_k)\n    else:\n        from retrieval.hybrid_search import search_routed\n        docs = search_routed(q, repo_override=repo, final_k=final_k)\n\n    paths = [d.get("file_path", "") for d in docs]\n\n    # Check hit\n    def hit(paths: List[str], expect: List[str]) -> bool:\n        return any(any(exp in p for p in paths) for exp in expect)\n\n    top1_hit = hit(paths[:1], expect_paths) if paths else False\n    topk_hit = hit(paths, expect_paths) if paths else False\n\n    return {\n        "ok": True,\n        "question": q,\n        "repo": repo,\n        "expect_paths": expect_paths,\n        "top1_path": paths[:1],\n        "top1_hit": top1_hit,\n        "topk_hit": topk_hit,\n        "top_paths": paths[:final_k],\n        "all_results": [\n            {\n                "file_path": d.get("file_path", ""),\n                "start_line": d.get("start_line", 0),\n                "end_line": d.get("end_line", 0),\n                "rerank_score": float(d.get("rerank_score", 0.0) or 0.0)\n            }\n            for d in docs\n        ]\n    }\n\n# ---------------- Evaluation System ----------------\n_EVAL_STATUS: Dict[str, Any] = {\n    "running": False,\n    "progress": 0,\n    "total": 0,\n    "current_question": "",\n    "results": None\n}\n\n@app.post("/api/eval/run")
eval_run(payload: Dict[str, Any] = {}) -> Dict[str, Any]:\n    """Run full evaluation suite in background."""\n    global _EVAL_STATUS\n    import threading\n\n    if _EVAL_STATUS["running"]:\n        return {"ok": False, "error": "Evaluation already running"}\n\n    use_multi = payload.get("use_multi", os.getenv("EVAL_MULTI", "1") == "1")\n    final_k = int(payload.get("final_k") or os.getenv("EVAL_FINAL_K", "5"))\n\n    def run_eval():\n        global _EVAL_STATUS\n        _EVAL_STATUS = {\n            "running": True,\n            "progress": 0,\n            "total": 0,\n            "current_question": "",\n            "results": None\n        }\n\n        try:\n            from eval_loop import run_eval_with_results\n            # Temporarily set env vars\n            old_multi = os.environ.get("EVAL_MULTI")\n            old_k = os.environ.get("EVAL_FINAL_K")\n            os.environ["EVAL_MULTI"] = "1" if use_multi else "0"\n            os.environ["EVAL_FINAL_K"] = str(final_k)\n\n            try:\n                results = run_eval_with_results()\n                _EVAL_STATUS["results"] = results\n                _EVAL_STATUS["progress"] = results.get("total", 0)\n                _EVAL_STATUS["total"] = results.get("total", 0)\n            finally:\n                # Restore env\n                if old_multi is not None:\n                    os.environ["EVAL_MULTI"] = old_multi\n                elif "EVAL_MULTI" in os.environ:\n                    del os.environ["EVAL_MULTI"]\n                if old_k is not None:\n                    os.environ["EVAL_FINAL_K"] = old_k\n                elif "EVAL_FINAL_K" in os.environ:\n                    del os.environ["EVAL_FINAL_K"]\n\n        except Exception as e:\n            _EVAL_STATUS["results"] = {"error": str(e)}\n        finally:\n            _EVAL_STATUS["running"] = False\n\n    thread = threading.Thread(target=run_eval, daemon=True)\n    thread.start()\n\n    return {"ok": True, "message": "Evaluation started"}\n\n@app.get("/api/eval/status")
eval_status() -> Dict[str, Any]:\n    """Get current evaluation status."""\n    return {\n        "running": _EVAL_STATUS["running"],\n        "progress": _EVAL_STATUS["progress"],\n        "total": _EVAL_STATUS["total"],\n        "current_question": _EVAL_STATUS["current_question"]\n    }\n\n@app.get("/api/eval/results")eval_results() -> Dict[str, Any]:\n    """Get last evaluation results."""\n    if _EVAL_STATUS["results"] is None:\n        return {"ok": False, "message": "No evaluation results available"}\n    return _EVAL_STATUS["results"]\n\n@app.post("/api/eval/baseline/save")eval_baseline_save() -> Dict[str, Any]:\n    """Save current evaluation results as baseline."""\n    if _EVAL_STATUS["results"] is None:\n        raise HTTPException(status_code=400, detail="No evaluation results to save")\n\n    baseline_path = Path(os.getenv("BASELINE_PATH", "eval_baseline.json"))\n    _write_json(baseline_path, _EVAL_STATUS["results"])\n    return {"ok": True, "path": str(baseline_path)}\n\n@app.get("/api/eval/baseline/compare")
eval_baseline_compare() -> Dict[str, Any]:\n    """Compare current results with baseline."""\n    if _EVAL_STATUS["results"] is None:\n        raise HTTPException(status_code=400, detail="No current evaluation results")\n\n    baseline_path = Path(os.getenv("BASELINE_PATH", "eval_baseline.json"))\n    if not baseline_path.exists():\n        return {"ok": False, "message": "No baseline found"}\n\n    baseline = _read_json(baseline_path, {})\n    current = _EVAL_STATUS["results"]\n\n    curr_top1 = current.get("top1_accuracy", 0)\n    base_top1 = baseline.get("top1_accuracy", 0)\n    curr_topk = current.get("topk_accuracy", 0)\n    base_topk = baseline.get("topk_accuracy", 0)\n\n    delta_top1 = curr_top1 - base_top1\n    delta_topk = curr_topk - base_topk\n\n    # Find regressions and improvements\n    regressions = []\n    improvements = []\n\n    curr_results = current.get("results", [])\n    base_results = baseline.get("results", [])\n\n    for i, (curr_res, base_res) in enumerate(zip(curr_results, base_results)):\n        if curr_res.get("question") != base_res.get("question"):\n            continue\n        if base_res.get("top1_hit") and not curr_res.get("top1_hit"):\n            regressions.append({\n                "index": i,\n                "question": curr_res.get("question"),\n                "repo": curr_res.get("repo")\n            })\n        elif not base_res.get("top1_hit") and curr_res.get("top1_hit"):\n            improvements.append({\n                "index": i,\n                "question": curr_res.get("question"),\n                "repo": curr_res.get("repo")\n            })\n\n    return {\n        "ok": True,\n        "baseline": {\n            "top1_accuracy": base_top1,\n            "topk_accuracy": base_topk,\n            "timestamp": baseline.get("timestamp")\n        },\n        "current": {\n            "top1_accuracy": curr_top1,\n            "topk_accuracy": curr_topk,\n            "timestamp": current.get("timestamp")\n        },\n        "delta": {\n            "top1": delta_top1,\n            "topk": delta_topk\n        },\n        "regressions": regressions,\n        "improvements": improvements,\n        "has_regressions": len(regressions) > 0\n    }
from __future__ import annotations\n\nimport os\nimport json\nimport time\nimport uuid\nimport queue\nimport threading\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Iterator, List\n\nfrom common.config_loader import out_dir\nfrom server.env_model import generate_text\n\n\nQUICK_TIPS = [\n    "Put repo-specific nouns in Discriminative to improve filename/path hits.",\n    "Add Semantic synonyms: auth→oauth,jwt,bearer; events→sse,ws,subscribe.",\n    "Short, concrete briefs beat generic text; include unique module names.",\n    "Boost paths you care about (e.g., app/,lib/,config/,scripts/,server/,api/).",\n    "Flip Enrich code chunks on for semantic cards; then Build, not Refresh.",\n]\n\n_progress_dir(repo: str) -> Path:\n    base = Path(os.getenv("OUT_DIR_BASE") or Path(__file__).resolve().parents[1] / "out")\n    return base / "cards" / repo\n\n_logs_path() -> Path:\n    base = Path(os.getenv("OUT_DIR_BASE") or Path(__file__).resolve().parents[1] / "out")\n    return base / "logs" / "cards_build.log"
_model_info() -> Dict[str, str]:\n    # Embed\n    et = (os.getenv("EMBEDDING_TYPE", "openai") or "openai").lower()\n    if et == "voyage":\n        embed = "voyage-code-3"\n    elif et == "local":\n        embed = "BAAI/bge-small-en-v1.5"\n    else:\n        embed = "text-embedding-3-large"\n    # Enrich\n    enrich = os.getenv("ENRICH_MODEL") or os.getenv("GEN_MODEL") or "gpt-4o-mini"\n    # Rerank\n    rr_backend = (os.getenv("RERANK_BACKEND", "local") or "local").lower()\n    if rr_backend == "cohere":\n        rerank = os.getenv("COHERE_RERANK_MODEL", "rerank-3.5")\n    else:\n        rerank = os.getenv("RERANKER_MODEL", "BAAI/bge-reranker-v2-m3")\n    return {"embed": embed, "enrich": str(enrich), "rerank": rerank}\n\n_read_jsonl(path: Path) -> Iterator[Dict[str, Any]]:\n    with path.open("r", encoding="utf-8") as f:\n        for line in f:\n            if not line.strip():\n                continue\n            try:\n                yield json.loads(line)\n            except Exception:\n                continue
_log(msg: str) -> None:\n    p = _logs_path()\n    p.parent.mkdir(parents=True, exist_ok=True)\n    ts = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())\n    try:\n        p.write_text(p.read_text() + f"[{ts}] {msg}\n") if p.exists() else p.write_text(f"[{ts}] {msg}\n")\n    except Exception:\n        # Best-effort only\n        pass\n\n\n@dataclass
CardsBuildJob:\n    repo: str\n    enrich: bool = True\n    job_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    started_at: float = field(default_factory=time.time)\n    stage: str = "scan"\n    total: int = 0\n    done: int = 0\n    last_emit_at: float = field(default_factory=time.time)\n    last_done: int = 0\n    status: str = "running"  # running|done|error|cancelled\n    error: Optional[str] = None\n    _queue: "queue.Queue[str]" = field(default_factory=lambda: queue.Queue(maxsize=1000))\n    _cancel: threading.Event = field(default_factory=threading.Event)\n    _thread: Optional[threading.Thread] = None\n\n    def start(self) -> None:\n        t = threading.Thread(target=self._run, daemon=True)\n        self._thread = t\n        t.start()\n\n    def cancel(self) -> None:\n        self._cancel.set()\n        self.status = "cancelled"\n        self._emit_event("cancelled", {"message": "User cancelled"})\n\n    def events(self) -> Iterator[str]:\n        while True:\n            try:\n                evt = self._queue.get(timeout=1.0)\n                yield evt\n                if evt.startswith("event: done") or evt.startswith("event: cancelled") or evt.startswith("event: error"):\n                    break\n            except queue.Empty:\n                if self.status in {"done", "cancelled", "error"}:\n                    break\n                continue\n\n    def snapshot(self) -> Dict[str, Any]:\n        return self._progress_payload(tip=None)\n\n    def _emit_event(self, event: str, data: Dict[str, Any]) -> None:\n        try:\n            payload = json.dumps(data, ensure_ascii=False)\n            s = f"event: {event}\ndata: {payload}\n\n"\n            self._queue.put_nowait(s)\n        except Exception:\n            pass\n\n    def _progress_payload(self, tip: Optional[str]) -> Dict[str, Any]:\n        pct = (float(self.done) / float(self.total) * 100.0) if self.total > 0 else 0.0\n        elapsed = max(0.001, time.time() - self.started_at)\n        rate = self.done / elapsed\n        eta = int((self.total - self.done) / rate) if rate > 0 and self.total > self.done else 0\n        if rate >= 1200:\n            thr = f"{rate/1000.0:.1f}k chunks/min"\n        else:\n            thr = f"{rate*60.0:.1f} chunks/min"\n        data = {\n            "repo": self.repo,\n            "stage": self.stage,\n            "total": int(self.total),\n            "done": int(self.done),\n            "pct": round(pct, 2),\n            "model": _model_info(),\n            "tip": tip or QUICK_TIPS[int(time.time()) % len(QUICK_TIPS)],\n            "started_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(self.started_at)),\n            "eta_s": int(max(0, eta)),\n            "throughput": thr,\n        }\n        # Persist snapshot\n        try:\n            prog_path = _progress_dir(self.repo) / "progress.json"\n            prog_path.parent.mkdir(parents=True, exist_ok=True)\n            prog_path.write_text(json.dumps(data, indent=2))\n        except Exception:\n            pass\n        return data\n\n    def _emit_progress(self, tip: Optional[str] = None) -> None:\n        data = self._progress_payload(tip)\n        self._emit_event("progress", data)\n\n    def _ensure_cards_dirs(self) -> Dict[str, Path]:\n        base = Path(out_dir(self.repo))\n        base.mkdir(parents=True, exist_ok=True)\n        return {\n            "base": base,\n            "chunks": base / "chunks.jsonl",\n            "cards": base / "cards.jsonl",\n            "cards_txt": base / "cards.txt",\n            "bm25_dir": base / "bm25_cards",\n        }\n\n    def _run(self) -> None:\n        try:\n            _log(f"cards-build start repo={self.repo} enrich={self.enrich}")\n            paths = self._ensure_cards_dirs()\n            chunks_path = paths["chunks"]\n            if not chunks_path.exists():\n                self.status = "error"\n                self.error = f"No chunks found for repo {self.repo}. Please index first."\n                self._emit_event("error", {"message": self.error})\n                return\n            # Stage: scan\n            self.stage = "scan"\n            self.total = sum(1 for _ in chunks_path.open("r", encoding="utf-8"))\n            self.done = 0\n            self._emit_progress(QUICK_TIPS[0])\n            # Stage: chunk (noop for cards build)\n            self.stage = "chunk"\n            self.done = self.total\n            self._emit_progress(QUICK_TIPS[1])\n            # Stage: summarize (enrich) or fast heuristic\n            self.stage = "summarize" if self.enrich else "summarize"\n            self.done = 0\n            self._emit_progress(QUICK_TIPS[2])\n\n            max_chunks = int(os.getenv("CARDS_MAX", "0") or "0")\n            written = 0\n            with paths["cards"].open("w", encoding="utf-8") as out_json, paths["cards_txt"].open("w", encoding="utf-8") as out_txt:\n                for idx, ch in enumerate(_read_jsonl(chunks_path)):\n                    if self._cancel.is_set():\n                        self.status = "cancelled"\n                        self._emit_event("cancelled", {"message": "Cancelled by user"})\n                        return\n                    code = (ch.get("code") or "")[:2000]\n                    fp = ch.get("file_path", "")\n                    if self.enrich:\n                        prompt = (\n                            "Summarize this code chunk for retrieval as a JSON object with keys: "\n                            "symbols (array of names: functions/classes/components/routes), purpose (short sentence), routes (array of route paths if any). "\n                            "Respond with only the JSON.\n\n"\n                        )\n                        user = prompt + code\n                        try:\n                            text, _meta = generate_text(user_input=user, system_instructions=None, reasoning_effort=None, response_format={"type": "json_object"})\n                            content = (text or "").strip()\n                            card: Dict[str, Any]\n                            try:\n                                card = json.loads(content)\n                            except Exception:\n                                # Fuzzy parse: try to extract a JSON object substring; else treat as free-text purpose\n                                try:\n                                    start = content.find('{'); end = content.rfind('}')\n                                    if start != -1 and end != -1 and end > start:\n                                        card = json.loads(content[start:end+1])\n                                    else:\n                                        raise ValueError('no json braces')\n                                except Exception:\n                                    # Free-text fallback becomes purpose; derive symbols/routes heuristically\n                                    syms: List[str] = []\n                                    routes: List[str] = []\n                                    try:\n                                        import re\n                                        syms = [m[1] for m in re.findall(r"\b(class|def|function|interface|type)\s+([A-Za-z_][A-Za-z0-9_]*)", code)][:5]\n                                        routes = re.findall(r"['\"](/[^'\"\s]*)['\"]", code)[:5]\n                                    except Exception:\n                                        pass\n                                    card = {"symbols": syms, "purpose": content[:240], "routes": routes}\n                        except Exception:\n                            card = {"symbols": [], "purpose": "", "routes": []}\n                    else:\n                        # Heuristic fallback (no external models)\n                        syms: List[str] = []\n                        try:\n                            import re\n                            syms = re.findall(r"\b(class|def|function|interface|type)\s+([A-Za-z_][A-Za-z0-9_]*)", code)\n                            syms = [s[1] for s in syms][:5]\n                        except Exception:\n                            syms = []\n                        purpose = f"High-level card from {os.path.basename(fp)}"\n                        routes = []\n                        try:\n                            import re\n                            routes = re.findall(r"['\"](/[^'\"\s]*)['\"]", code)[:5]\n                        except Exception:\n                            routes = []\n                        card = {"symbols": syms, "purpose": purpose, "routes": routes}\n                    card["file_path"] = fp\n                    card["id"] = ch.get("id")\n                    # Ensure minimal purpose is present\n                    if not (card.get("purpose") or "").strip():\n                        base = os.path.basename(fp)\n                        syml = card.get("symbols") or []\n                        card["purpose"] = (f"Defines {'/'.join(syml[:2])} in {base}" if syml else f"High-level summary for {base}")\n                    out_json.write(json.dumps(card, ensure_ascii=False) + "\n")\n                    text_out = " ".join(card.get("symbols", [])) + "\n" + card.get("purpose", "") + "\n" + " ".join(card.get("routes", [])) + "\n" + fp\n                    out_txt.write(text_out.replace("\n", " ") + "\n")\n                    written += 1\n                    self.done = idx + 1\n                    now = time.time()\n                    if now - self.last_emit_at >= 0.5:\n                        self._emit_progress(None)\n                        self.last_emit_at = now\n                    if max_chunks and written >= max_chunks:\n                        break\n\n            # Stage: write (already written incrementally)\n            self.stage = "write"\n            self._emit_progress(QUICK_TIPS[3])\n\n            # Stage: sparse (build BM25 index for cards)\n            self.stage = "sparse"\n            try:\n                import bm25s  # type: ignore\n                from bm25s.tokenization import Tokenizer  # type: ignore\n                from Stemmer import Stemmer  # type: ignore\n                stemmer = Stemmer("english")\n                tok = Tokenizer(stemmer=stemmer, stopwords="en")\n                docs = [ln.strip() for ln in paths["cards_txt"].read_text(encoding="utf-8").splitlines() if ln.strip()]\n                tokens = tok.tokenize(docs)\n                retriever = bm25s.BM25(method="lucene", k1=1.2, b=0.65)\n                retriever.index(tokens)\n                try:\n                    retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}\n                except Exception:\n                    pass\n                paths["bm25_dir"].mkdir(parents=True, exist_ok=True)\n                retriever.save(str(paths["bm25_dir"]))\n                tok.save_vocab(save_dir=str(paths["bm25_dir"]))\n                tok.save_stopwords(save_dir=str(paths["bm25_dir"]))\n                _log(f"cards-build bm25 ok repo={self.repo} docs={len(docs)} dir={paths['bm25_dir']}")\n            except Exception as e:\n                _log(f"cards-build bm25 failed: {e}")\n\n            # Stage: finalize\n            self.stage = "finalize"\n            self.done = self.total\n            snap = self._progress_payload(QUICK_TIPS[4])\n            snap["result"] = {"cards_written": written, "duration_s": int(time.time() - self.started_at)}\n            try:\n                prog_path = _progress_dir(self.repo) / "progress.json"\n                prog_path.write_text(json.dumps(snap, indent=2))\n            except Exception:\n                pass\n            self.status = "done"\n            self._emit_event("done", snap)\n            _log(f"cards-build done repo={self.repo} cards={written}")\n        except Exception as e:\n            self.status = "error"\n            self.error = str(e)\n            self._emit_event("error", {"message": str(e)})\n            _log(f"cards-build error: {e}")
_Registry:\n    def __init__(self) -> None:\n        self._lock = threading.Lock()\n        self.jobs_by_id: Dict[str, CardsBuildJob] = {}\n        self.jobs_by_repo: Dict[str, str] = {}\n\n    def start(self, repo: str, enrich: bool) -> CardsBuildJob:\n        with self._lock:\n            if repo in self.jobs_by_repo:\n                jid = self.jobs_by_repo[repo]\n                job = self.jobs_by_id.get(jid)\n                if job and job.status == "running":\n                    raise RuntimeError(f"Job already running for repo {repo}")\n            job = CardsBuildJob(repo=repo, enrich=enrich)\n            self.jobs_by_id[job.job_id] = job\n            self.jobs_by_repo[repo] = job.job_id\n        job.start()\n        return job\n\n    def get(self, job_id: str) -> Optional[CardsBuildJob]:\n        return self.jobs_by_id.get(job_id)\n\n    def get_by_repo(self, repo: str) -> Optional[CardsBuildJob]:\n        jid = self.jobs_by_repo.get(repo)\n        return self.jobs_by_id.get(jid) if jid else None\n\n    def cancel(self, job_id: str) -> bool:\n        job = self.jobs_by_id.get(job_id)\n        if not job:\n            return False\n        job.cancel()\n        return True\n\n\nREGISTRY = _Registry()
start_job(repo: str, enrich: bool) -> CardsBuildJob:\n    return REGISTRY.start(repo.strip(), bool(int(enrich) if isinstance(enrich, (int, str)) else enrich))\n\nget_job(job_id: str) -> Optional[CardsBuildJob]:\n    return REGISTRY.get(job_id)\n\nget_job_for_repo(repo: str) -> Optional[CardsBuildJob]:\n    return REGISTRY.get_by_repo(repo.strip())\n\ncancel_job(job_id: str) -> bool:\n    return REGISTRY.cancel(job_id)\n\nread_logs(tail_bytes: int = 16384) -> Dict[str, Any]:\n    p = _logs_path()\n    if not p.exists():\n        return {"ok": True, "content": "", "path": str(p)}\n    try:\n        data = p.read_bytes()\n        if len(data) > tail_bytes:\n            data = data[-tail_bytes:]\n        return {"ok": True, "content": data.decode("utf-8", errors="ignore"), "path": str(p)}\n    except Exception as e:\n        return {"ok": False, "error": str(e), "path": str(p)}
#!/usr/bin/env python3\nfrom __future__ import annotations\n\n"""\nMCP server exposing RAG tools for Codex/Claude integration (stdio transport).\n\nTools (sanitized names for OpenAI tool spec):\n  - rag_answer(repo, question) → full LangGraph answer + citations\n  - rag_search(repo, question) → retrieval-only (for debugging)\nCompatibility: accepts legacy names "rag.answer" and "rag.search" on tools/call.\n"""\nimport sys\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport urllib.request, urllib.error, urllib.parse\nimport json as _json\n\n# Import canonical modules (no sys.path hacks)\nfrom server.langgraph_app import build_graph\nfrom retrieval.hybrid_search import search_routed_multi\nfrom common.config_loader import list_repos
MCPServer:\n    """Minimal MCP server over stdio."""\n\n    def __init__(self):\n        self.graph = None\n        self._init_graph()\n\n    def _init_graph(self):\n        try:\n            self.graph = build_graph()\n        except Exception as e:\n            self._error(f"Failed to initialize graph: {e}")\n\n    def _error(self, msg: str):\n        print(f"ERROR: {msg}", file=sys.stderr)\n\n    def _log(self, msg: str):\n        print(f"LOG: {msg}", file=sys.stderr)\n\n    def handle_rag_answer(self, repo: str, question: str) -> Dict[str, Any]:\n        if not self.graph:\n            self._init_graph()\n        if not self.graph:\n            return {"error": "Graph not initialized", "answer": "", "citations": [], "repo": repo or "unknown"}\n\n        try:\n            allowed = set(list_repos())\n            if repo not in allowed:\n                return {"error": f"invalid repo '{repo}', allowed={sorted(allowed)}", "answer": "", "citations": [], "repo": repo or "unknown"}\n            cfg = {"configurable": {"thread_id": f"mcp-{repo or 'default'}"}}\n            state = {"question": question, "documents": [], "generation": "", "iteration": 0, "confidence": 0.0, "repo": repo}\n            result = self.graph.invoke(state, cfg)\n            docs = result.get("documents", [])[:5]\n            citations = [f"{d['file_path']}:{d['start_line']}-{d['end_line']}" for d in docs]\n            return {"answer": result.get("generation", ""), "citations": citations, "repo": result.get("repo", repo or "unknown"), "confidence": float(result.get("confidence", 0.0) or 0.0)}\n        except Exception as e:\n            self._error(f"rag.answer error: {e}")\n            return {"error": str(e), "answer": "", "citations": [], "repo": repo or "unknown"}\n\n    def handle_rag_search(self, repo: str, question: str, top_k: int = 10) -> Dict[str, Any]:\n        try:\n            allowed = set(list_repos())\n            if repo not in allowed:\n                return {"error": f"invalid repo '{repo}', allowed={sorted(allowed)}", "results": [], "repo": repo or "unknown", "count": 0}\n            docs = search_routed_multi(question, repo_override=repo, m=4, final_k=top_k)\n            results = [{\n                "file_path": d.get("file_path", ""),\n                "start_line": d.get("start_line", 0),\n                "end_line": d.get("end_line", 0),\n                "language": d.get("language", ""),\n                "rerank_score": float(d.get("rerank_score", 0.0) or 0.0),\n                "repo": d.get("repo", repo or "unknown")\n            } for d in docs]\n            return {"results": results, "repo": repo or "unknown", "count": len(results)}\n        except Exception as e:\n            self._error(f"rag.search error: {e}")\n            return {"error": str(e), "results": [], "repo": repo or "unknown", "count": 0}\n\n    # --- Netlify helpers ---\n    def _netlify_api(self, path: str, method: str = "GET", data: dict | None = None) -> dict:\n        api_key = os.getenv("NETLIFY_API_KEY")\n        if not api_key:\n            raise RuntimeError("NETLIFY_API_KEY not set in environment")\n        url = f"https://api.netlify.com/api/v1{path}"\n        req = urllib.request.Request(url, method=method)\n        req.add_header("Authorization", f"Bearer {api_key}")\n        req.add_header("Content-Type", "application/json")\n        body = _json.dumps(data).encode("utf-8") if data is not None else None\n        try:\n            with urllib.request.urlopen(req, data=body, timeout=30) as resp:\n                raw = resp.read().decode("utf-8")\n                return _json.loads(raw) if raw else {}\n        except urllib.error.HTTPError as he:\n            err_body = he.read().decode("utf-8", errors="ignore")\n            raise RuntimeError(f"Netlify HTTP {he.code}: {err_body}")\n\n    def _netlify_find_site_by_domain(self, domain: str) -> dict | None:\n        sites = self._netlify_api("/sites", method="GET")\n        if isinstance(sites, list):\n            domain_low = (domain or "").strip().lower()\n            for s in sites:\n                for key in ("custom_domain", "url", "ssl_url"):\n                    val = (s.get(key) or "").lower()\n                    if val and domain_low in val:\n                        return s\n        return None\n\n    def handle_netlify_deploy(self, domain: str) -> Dict[str, Any]:\n        targets: list[str]\n        if domain == "both":\n            targets = ["project.net", "project.dev"]\n        else:\n            targets = [domain]\n        results = []\n        for d in targets:\n            site = self._netlify_find_site_by_domain(d)\n            if not site:\n                results.append({"domain": d, "status": "not_found"})\n                continue\n            site_id = site.get("id")\n            if not site_id:\n                results.append({"domain": d, "status": "no_site_id"})\n                continue\n            try:\n                build = self._netlify_api(f"/sites/{site_id}/builds", method="POST", data={})\n                results.append({"domain": d, "status": "triggered", "site_id": site_id, "build_id": build.get("id")})\n            except Exception as e:\n                results.append({"domain": d, "status": "error", "error": str(e)})\n        return {"results": results}\n\n    # --- Web tools (allowlisted) ---\n    _WEB_ALLOWED = {"openai.com", "platform.openai.com", "github.com", "openai.github.io"}\n\n    def _is_allowed_url(self, url: str) -> bool:\n        try:\n            u = urllib.parse.urlparse(url)\n            host = (u.netloc or "").lower()\n            return any(host == h or host.endswith("." + h) for h in self._WEB_ALLOWED)\n        except Exception:\n            return False\n\n    def handle_web_get(self, url: str, max_bytes: int = 20000) -> Dict[str, Any]:\n        if not (url or "").startswith("http"):\n            return {"error": "url must start with http(s)"}\n        if not self._is_allowed_url(url):\n            return {"error": "host not allowlisted"}\n        req = urllib.request.Request(url, method="GET", headers={"User-Agent": "project-rag-mcp/1.0"})\n        try:\n            with urllib.request.urlopen(req, timeout=20) as resp:\n                raw = resp.read(max_bytes + 1)\n                clipped = raw[:max_bytes]\n                return {\n                    "url": url,\n                    "status": resp.status,\n                    "length": len(raw),\n                    "clipped": len(raw) > len(clipped),\n                    "content_preview": clipped.decode("utf-8", errors="ignore")\n                }\n        except urllib.error.HTTPError as he:\n            body = he.read().decode("utf-8", errors="ignore")\n            return {"url": url, "status": he.code, "error": body[:1000]}\n        except Exception as e:\n            return {"url": url, "error": str(e)}\n\n    def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:\n        method = request.get("method")\n        req_id = request.get("id")\n\n        if method == "tools/list":\n            tools = [\n                {\n                    "name": "rag_answer",\n                    "description": "Get a synthesized answer with citations from local codebase",\n                    "inputSchema": {\n                        "type": "object",\n                        "properties": {\n                            "repo": {"type": "string"},\n                            "question": {"type": "string"}\n                        },\n                        "required": ["repo", "question"]\n                    }\n                },\n                {\n                    "name": "rag_search",\n                    "description": "Retrieval-only search (returns file paths + line ranges)",\n                    "inputSchema": {\n                        "type": "object",\n                        "properties": {\n                            "repo": {"type": "string"},\n                            "question": {"type": "string"},\n                            "top_k": {"type": "integer", "default": 10}\n                        },\n                        "required": ["repo", "question"]\n                    }\n                },\n                {\n                    "name": "netlify_deploy",\n                    "description": "Trigger a Netlify build for project.net, project.dev, or both (uses NETLIFY_API_KEY)",\n                    "inputSchema": {\n                        "type": "object",\n                        "properties": {\n                            "domain": {"type": "string", "enum": ["project.net", "project.dev", "both"], "default": "both"}\n                        }\n                    }\n                },\n                {\n                    "name": "web_get",\n                    "description": "HTTP GET (allowlisted hosts only: openai.com, platform.openai.com, github.com, openai.github.io)",\n                    "inputSchema": {\n                        "type": "object",\n                        "properties": {\n                            "url": {"type": "string"},\n                            "max_bytes": {"type": "integer", "default": 20000}\n                        },\n                        "required": ["url"]\n                    }\n                }\n            ]\n            return {"jsonrpc": "2.0", "id": req_id, "result": tools}\n\n        elif method == "tools/call":\n            params = request.get("params", {})\n            tool_name = params.get("name")\n            args = params.get("arguments", {})\n\n            if tool_name in ("rag.answer", "rag_answer"):\n                result = self.handle_rag_answer(repo=args.get("repo"), question=args.get("question", ""))\n                return {"jsonrpc": "2.0", "id": req_id, "result": {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}}\n            elif tool_name in ("rag.search", "rag_search"):\n                result = self.handle_rag_search(repo=args.get("repo"), question=args.get("question", ""), top_k=args.get("top_k", 10))\n                return {"jsonrpc": "2.0", "id": req_id, "result": {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}}\n            elif tool_name in ("netlify.deploy", "netlify_deploy"):\n                domain = args.get("domain", "both")\n                result = self.handle_netlify_deploy(domain)\n                return {"jsonrpc": "2.0", "id": req_id, "result": {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}}\n            elif tool_name in ("web.get", "web_get"):\n                url = args.get("url", "")\n                max_bytes = args.get("max_bytes", 20000)\n                result = self.handle_web_get(url, max_bytes=max_bytes)\n                return {"jsonrpc": "2.0", "id": req_id, "result": {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}}\n            else:\n                return {"jsonrpc": "2.0", "id": req_id, "error": {"code": -32601, "message": f"Unknown tool: {tool_name}"}}\n\n        elif method == "initialize":\n            return {"jsonrpc": "2.0", "id": req_id, "result": {"protocolVersion": "2024-11-05", "capabilities": {"tools": {}}, "serverInfo": {"name": "project-rag-mcp", "version": "1.0.0"}}}\n\n        else:\n            return {"jsonrpc": "2.0", "id": req_id, "error": {"code": -32601, "message": f"Method not found: {method}"}}\n\n    def run(self):\n        self._log("MCP server starting (stdio mode)...")\n        for line in sys.stdin:\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                request = json.loads(line)\n                response = self.handle_request(request)\n                print(json.dumps(response), flush=True)\n            except json.JSONDecodeError as e:\n                self._error(f"Invalid JSON: {e}")\n                print(json.dumps({"jsonrpc": "2.0", "id": None, "error": {"code": -32700, "message": "Parse error"}}), flush=True)\n            except Exception as e:\n                self._error(f"Unexpected error: {e}")\n                print(json.dumps({"jsonrpc": "2.0", "id": None, "error": {"code": -32603, "message": f"Internal error: {e}"}}), flush=True)\n\n\nif __name__ == "__main__":\n    server = MCPServer()\n    server.run()
from __future__ import annotations\n\n# MCP package initializer. Exposes convenient imports for shims/tools.\n\nfrom .server import MCPServer  # re-export for convenience
from __future__ import annotations\nimport os\nfrom typing import Dict, Any\n\nfrom fastmcp import FastMCP\n\n# Canonical imports\nfrom server.langgraph_app import build_graph\nfrom retrieval.hybrid_search import search_routed_multi\nfrom common.config_loader import list_repos\n\n\nmcp = FastMCP("rag-service")\n_graph = None\n\n_get_graph():\n    global _graph\n    if _graph is None:\n        _graph = build_graph()\n    return _graph\n\n\n@mcp.tool()
answer(repo: str, question: str) -> Dict[str, Any]:\n    """Answer a codebase question using local LangGraph (retrieval+generation). Returns text + citations."""\n    g = _get_graph()\n    allowed = set(list_repos())\n    if repo not in allowed:\n        return {"error": f"invalid repo '{repo}', allowed={sorted(allowed)}"}\n    cfg = {"configurable": {"thread_id": f"http-{repo}"}}\n    state = {\n        "question": question,\n        "documents": [],\n        "generation": "",\n        "iteration": 0,\n        "confidence": 0.0,\n        "repo": repo,\n    }\n    res = g.invoke(state, cfg)\n    docs = res.get("documents", [])[:5]\n    citations = [f"{d['file_path']}:{d['start_line']}-{d['end_line']}" for d in docs]\n    return {\n        "answer": res.get("generation", ""),\n        "citations": citations,\n        "repo": res.get("repo", repo),\n        "confidence": float(res.get("confidence", 0.0) or 0.0),\n    }\n\n\n@mcp.tool()
search(repo: str, question: str, top_k: int = 10) -> Dict[str, Any]:\n    """Retrieve relevant code locations without generation."""\n    allowed = set(list_repos())\n    if repo not in allowed:\n        return {"error": f"invalid repo '{repo}', allowed={sorted(allowed)}"}\n    docs = search_routed_multi(question, repo_override=repo, m=4, final_k=top_k)\n    results = [{\n        "file_path": d.get("file_path", ""),\n        "start_line": d.get("start_line", 0),\n        "end_line": d.get("end_line", 0),\n        "language": d.get("language", ""),\n        "rerank_score": float(d.get("rerank_score", 0.0) or 0.0),\n        "repo": d.get("repo", repo),\n    } for d in docs]\n    return {"results": results, "repo": repo, "count": len(results)}\n\n\nif __name__ == "__main__":\n    # Serve over HTTP for remote MCP (platform evals). Use env overrides for host/port/path.\n    host = os.getenv("MCP_HTTP_HOST", "0.0.0.0")\n    port = int(os.getenv("MCP_HTTP_PORT", "8013"))\n    path = os.getenv("MCP_HTTP_PATH", "/mcp")\n    mcp.run(transport="http", host=host, port=port, path=path)
import express from 'express';\nimport fetch from 'node-fetch';\n\nconst app = express();\nconst PORT = process.env.PORT || 8014;\nconst RAG_API_URL = process.env.RAG_API_URL || 'http://127.0.0.1:8012';\n\napp.get('/health', (req, res) => {\n  res.json({ status: 'ok', proxy: true, target: RAG_API_URL });\n});\n\n// JSON answer proxy\napp.get('/mcp/answer', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// JSON search proxy\napp.get('/mcp/search', async (req, res) => {\n  try {\n    const { q, repo, top_k, token } = req.query;\n    const u = new URL('/search', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    if (top_k) u.searchParams.set('top_k', String(top_k));
const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// SSE proxy for streaming answer\napp.get('/mcp/answer_stream', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer_stream', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n\n    const r = await fetch(u.toString(), { headers });\n    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');\n    res.setHeader('Cache-Control', 'no-cache');\n    res.setHeader('X-Accel-Buffering', 'no');\n\n    if (!r.ok || !r.body) {\n      res.write(`data: [ERROR] upstream ${r.status}\n\n`);\n      return res.end();\n    }\n\n    const reader = r.body.getReader();\n    const decoder = new TextDecoder();\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n      res.write(decoder.decode(value));\n      // flush
}\n    res.end();\n  } catch (e) {\n    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');\n    res.write(`data: [ERROR] ${String(e)}\n\n`);\n    res.end();\n  }\n});\n\napp.listen(PORT, () => {\n  console.log(`Node proxy listening on :${PORT}, targeting ${RAG_API_URL}`);\n});
from __future__ import annotations\n\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\n_CACHE: Dict[str, Any] = {}\n\n_repos_file_path() -> Path:\n    env_path = os.getenv("REPOS_FILE")\n    if env_path:\n        return Path(env_path).expanduser().resolve()\n    return Path(__file__).resolve().parents[1] / "repos.json"\n\nload_repos() -> Dict[str, Any]:\n    global _CACHE\n    if "config" in _CACHE:\n        return _CACHE["config"]\n    p = _repos_file_path()\n    if p.exists():\n        try:\n            data = json.loads(p.read_text())\n            if isinstance(data, dict) and isinstance(data.get("repos"), list):\n                _CACHE["config"] = data\n                return data\n        except Exception:\n            pass\n    env_repo = (os.getenv("REPO") or "default").strip()\n    env_path = os.getenv("REPO_PATH") or os.getenv(f"REPO_{env_repo.upper()}_PATH")\n    if env_path:\n        cfg = {"default_repo": env_repo, "repos": [{"name": env_repo, "path": env_path}]}\n        _CACHE["config"] = cfg\n        return cfg\n    cfg = {"default_repo": None, "repos": []}\n    _CACHE["config"] = cfg\n    return cfg
list_repos() -> List[str]:\n    cfg = load_repos()\n    return [str(r.get("name")) for r in cfg.get("repos", []) if r.get("name")]\n\nget_default_repo() -> str:\n    cfg = load_repos()\n    if cfg.get("default_repo"):\n        return str(cfg["default_repo"]).strip()\n    repos = cfg.get("repos", [])\n    if repos:\n        return str(repos[0].get("name"))\n    return (os.getenv("REPO") or "default").strip()\n\n_find_repo(name: str) -> Optional[Dict[str, Any]]:\n    name_low = (name or "").strip().lower()\n    if not name_low:\n        return None\n    for r in load_repos().get("repos", []):\n        if (r.get("name") or "").strip().lower() == name_low:\n            return r\n    return None\n\nget_repo_paths(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        raise ValueError(f"Unknown repo: {name}. Known: {', '.join(list_repos()) or '[]'}")\n    p = r.get("path")\n    if isinstance(p, list):\n        return [str(Path(x).expanduser()) for x in p]\n    if isinstance(p, str):\n        return [str(Path(p).expanduser())]\n    raise ValueError(f"Repo `{name}` missing 'path' in repos.json")
_out_base_dir() -> Path:\n    root = Path(__file__).resolve().parents[1]\n    env_base = os.getenv("OUT_DIR_BASE") or os.getenv("RAG_OUT_BASE")\n    if env_base:\n        p = Path(env_base).expanduser()\n        if not p.is_absolute():\n            p = (root / p)\n        return p\n    for cand in ("out.noindex-shared", "out.noindex-gui", "out.noindex-devclean", "out.noindex"):\n        if (root / cand).exists():\n            return root / cand\n    return root / "out"\n\nout_dir(name: str) -> str:\n    return str(_out_base_dir() / name)\n\nget_repo_keywords(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        return []\n    kws = r.get("keywords") or []\n    return [str(k).lower() for k in kws if isinstance(k, str)]\n\npath_boosts(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        return []\n    lst = r.get("path_boosts") or []\n    return [str(x) for x in lst if isinstance(x, str)]
layer_bonuses(name: str) -> Dict[str, Dict[str, float]]:\n    r = _find_repo(name)\n    if not r:\n        return {}\n    lb = r.get("layer_bonuses") or {}\n    out: Dict[str, Dict[str, float]] = {}\n    for intent, d in (lb.items() if isinstance(lb, dict) else []):\n        if not isinstance(d, dict):\n            continue\n        out[intent] = {k: float(v) for k, v in d.items() if isinstance(v, (int, float))}\n    return out\n\nchoose_repo_from_query(query: str, default: Optional[str] = None) -> str:\n    q = (query or "").lower().strip()\n    if ":" in q:\n        cand, _ = q.split(":", 1)\n        cand = cand.strip()\n        if cand in [r.lower() for r in list_repos()]:\n            return cand\n    best = None\n    best_hits = 0\n    for name in list_repos():\n        hits = 0\n        for kw in get_repo_keywords(name):\n            if kw and kw in q:\n                hits += 1\n        if hits > best_hits:\n            best = name\n            best_hits = hits\n    if best:\n        return best\n    return (default or get_default_repo())
from __future__ import annotations\n\nfrom typing import Dict, Any\n\nenrich(file_path: str, lang: str, code: str) -> Dict[str, Any]:\n    """Best-effort metadata enrichment stub used by indexers.\n\n    In production you can route to MLX/Ollama or any local pipeline.\n    \n    Args:\n        file_path: Path to the file being enriched\n        lang: Language/extension (e.g., 'py', 'ts', 'js')\n        code: Source code content\n    """\n    summary = (code or "").splitlines()[:4]\n    return {\n        "summary": " ".join(x.strip() for x in summary if x.strip())[:240],\n        "keywords": [],\n        "file_path": file_path,\n        "lang": lang,\n    }
from __future__ import annotations\n\nimport os\nfrom pathlib import Path\n\n_as_dir(p: str | Path | None) -> Path:\n    if not p:\n        return Path("")\n    pp = Path(str(p)).expanduser()\n    return pp if pp.is_absolute() else (Path(__file__).resolve().parents[1] / pp)\n\nrepo_root() -> Path:\n    env = os.getenv("REPO_ROOT")\n    if env:\n        return _as_dir(env)\n    return Path(__file__).resolve().parents[1]\n\nfiles_root() -> Path:\n    return _as_dir(os.getenv("FILES_ROOT")) or repo_root()\n\ngui_dir() -> Path:\n    env = os.getenv("GUI_DIR")\n    return _as_dir(env) if env else (repo_root() / "gui")\n\ndocs_dir() -> Path:\n    env = os.getenv("DOCS_DIR")\n    return _as_dir(env) if env else (repo_root() / "docs")\n\ndata_dir() -> Path:\n    env = os.getenv("DATA_DIR")\n    return _as_dir(env) if env else (repo_root() / "data")
from __future__ import annotations\n\n# Expose filtering helpers used by indexer\n\nPRUNE_DIRS = {\n    ".git", ".github", ".gitlab", ".venv", "node_modules", "dist", "build", "target", "__pycache__",\n    "coverage", ".tox", ".mypy_cache", ".pytest_cache", ".idea", ".vscode"\n}\n\n_prune_dirs_in_place(dirs: list[str]) -> None:\n    for d in list(dirs):\n        if d in PRUNE_DIRS:\n            try:\n                dirs.remove(d)\n            except Exception:\n                pass\n\n_should_index_file(name: str) -> bool:\n    n = (name or "").lower()\n    # Skip obvious binary or large files by suffix\n    skip_suffixes = (".min.js", ".png", ".jpg", ".jpeg", ".gif", ".webp", ".pdf", ".zip", ".tar", ".gz")\n    if any(n.endswith(s) for s in skip_suffixes):\n        return False\n    # Skip lock files and cache\n    skip_contains = ("lock", ".cache")\n    if any(s in n for s in skip_contains):\n        return False\n    return True
"""Shared helpers (paths, config, filtering, metadata, Qdrant utils)."""
from __future__ import annotations\n\n"""Qdrant recreate fallback wrappers to avoid hard failures on 404/exists."""\nrecreate_collection(client, collection_name: str, vectors_config):\n    try:\n        return client.recreate_collection(collection_name=collection_name, vectors_config=vectors_config)\n    except Exception as e:\n        # If API doesn't support recreate, try delete/create sequence\n        try:\n            client.delete_collection(collection_name)\n        except Exception:\n            pass\n        return client.create_collection(collection_name=collection_name, vectors_config=vectors_config)
import math\nimport os\nfrom typing import List, Dict, Any\nfrom rerankers import Reranker  # type: ignore[import-untyped]\nfrom typing import Optional\n\ntry:\n    from dotenv import load_dotenv\n    load_dotenv(override=False)\nexcept Exception:\n    pass\n\n_HF_PIPE = None\n_RERANKER = None\n\nDEFAULT_MODEL = os.getenv('RERANKER_MODEL', 'BAAI/bge-reranker-v2-m3')\nRERANK_BACKEND = (os.getenv('RERANK_BACKEND', 'local') or 'local').lower()\nCOHERE_MODEL = os.getenv('COHERE_RERANK_MODEL', 'rerank-3.5')\n_sigmoid(x: float) -> float:\n    try:\n        return 1.0 / (1.0 + math.exp(-float(x)))\n    except Exception:\n        return 0.0\n_normalize(score: float, model_name: str) -> float:\n    if any(k in model_name.lower() for k in ['bge-reranker', 'cross-encoder', 'mxbai', 'jina-reranker']):\n        return _sigmoid(score)\n    return float(score)
_maybe_init_hf_pipeline(model_name: str) -> Optional[Any]:\n    global _HF_PIPE\n    if _HF_PIPE is not None:\n        return _HF_PIPE\n    try:\n        if 'jinaai/jina-reranker' in model_name.lower():\n            os.environ.setdefault('TRANSFORMERS_TRUST_REMOTE_CODE', '1')\n            from transformers import pipeline\n            _HF_PIPE = pipeline(\n                task='text-classification',\n                model=model_name,\n                tokenizer=model_name,\n                trust_remote_code=True,\n                device_map='auto'\n            )\n            return _HF_PIPE\n    except Exception:\n        _HF_PIPE = None\n    return _HF_PIPE\nget_reranker() -> Reranker:\n    global _RERANKER\n    if _RERANKER is None:\n        model_name = DEFAULT_MODEL\n        if _maybe_init_hf_pipeline(model_name):\n            return None\n        os.environ.setdefault('TRANSFORMERS_TRUST_REMOTE_CODE', '1')\n        _RERANKER = Reranker(model_name, model_type='cross-encoder', trust_remote_code=True)\n    return _RERANKER
rerank_results(query: str, results: List[Dict], top_k: int = 10, trace: Any = None) -> List[Dict]:\n    if not results:\n        return []\n    if RERANK_BACKEND in ('none', 'off', 'disabled'):\n        for i, r in enumerate(results):\n            r['rerank_score'] = float(1.0 - (i * 0.01))\n        return results[:top_k]\n    model_name = DEFAULT_MODEL\n    # --- tracing: record input set size\n    try:\n        if trace is not None and hasattr(trace, 'add'):\n            trace.add('reranker.rank', {\n                'model': model_name,\n                'input_topN': len(results or []),\n                'output_topK': int(top_k),\n            })\n    except Exception:\n        pass\n    if RERANK_BACKEND == 'cohere':\n        try:\n            import cohere\n            api_key = os.getenv('COHERE_API_KEY')\n            if not api_key:\n                raise RuntimeError('COHERE_API_KEY not set')\n            client = cohere.Client(api_key=api_key)\n            docs = []\n            for r in results:\n                file_ctx = r.get('file_path', '')\n                code_snip = (r.get('code') or r.get('text') or '')[:700]\n                docs.append(f"{file_ctx}\n\n{code_snip}")\n            rr = client.rerank(model=COHERE_MODEL, query=query, documents=docs, top_n=len(docs))\n            scores = [getattr(x, 'relevance_score', 0.0) for x in rr.results]\n            max_s = max(scores) if scores else 1.0\n            for item in rr.results:\n                idx = int(getattr(item, 'index', 0))\n                score = float(getattr(item, 'relevance_score', 0.0))\n                results[idx]['rerank_score'] = (score / max_s) if max_s else 0.0\n            results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n            top = results[:top_k]\n            try:\n                if trace is not None and hasattr(trace, 'add'):\n                    trace.add('reranker.rank', {\n                        'model': f'cohere:{COHERE_MODEL}',\n                        'scores': [\n                            {\n                                'path': r.get('file_path'),\n                                'start': r.get('start_line'),\n                                'end': r.get('end_line'),\n                                'rerank_score': float(r.get('rerank_score', 0.0) or 0.0),\n                            } for r in top\n                        ]\n                    })\n            except Exception:\n                pass\n            return top\n        except Exception:\n            pass\n    pipe = _maybe_init_hf_pipeline(model_name)\n    if pipe is not None:\n        pairs = []\n        for r in results:\n            code_snip = (r.get('code') or r.get('text') or '')[:700]\n            pairs.append({'text': query, 'text_pair': code_snip})\n        try:\n            out = pipe(pairs, truncation=True)  # type: ignore[misc]\n            raw = []\n            for i, o in enumerate(out):\n                score = float(o.get('score', 0.0))\n                s = _normalize(score, model_name)\n                results[i]['rerank_score'] = s\n                raw.append(s)\n            if raw:\n                mn, mx = min(raw), max(raw)\n                rng = (mx - mn)\n                if rng > 1e-9:\n                    for r in results:\n                        r['rerank_score'] = (float(r.get('rerank_score', 0.0)) - mn) / rng\n                elif mx != 0.0:\n                    for r in results:\n                        r['rerank_score'] = float(r.get('rerank_score', 0.0)) / abs(mx)\n            results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n            top = results[:top_k]\n            try:\n                if trace is not None and hasattr(trace, 'add'):\n                    trace.add('reranker.rank', {\n                        'model': f'hf:{model_name}',\n                        'scores': [\n                            {\n                                'path': r.get('file_path'),\n                                'start': r.get('start_line'),\n                                'end': r.get('end_line'),\n                                'rerank_score': float(r.get('rerank_score', 0.0) or 0.0),\n                            } for r in top\n                        ]\n                    })\n            except Exception:\n                pass\n            return top\n        except Exception:\n            pass\n    docs = []\n    for r in results:\n        file_ctx = r.get('file_path', '')\n        code_snip = (r.get('code') or r.get('text') or '')[:600]\n        docs.append(f"{file_ctx}\n\n{code_snip}")\n    rr = get_reranker()\n    if rr is None and _maybe_init_hf_pipeline(model_name) is not None:\n        return results[:top_k]\n    ranked = rr.rank(query=query, docs=docs, doc_ids=list(range(len(docs))))  # type: ignore[attr-defined]\n    raw_scores = []\n    for res in ranked.results:\n        idx = res.document.doc_id\n        s = _normalize(res.score, model_name)\n        results[idx]['rerank_score'] = s\n        raw_scores.append(s)\n    if raw_scores:\n        mn, mx = min(raw_scores), max(raw_scores)\n        rng = (mx - mn)\n        if rng > 1e-9:\n            for r in results:\n                r['rerank_score'] = (float(r.get('rerank_score', 0.0)) - mn) / rng\n        elif mx != 0.0:\n            for r in results:\n                r['rerank_score'] = float(r.get('rerank_score', 0.0)) / abs(mx)\n    results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n    top = results[:top_k]\n    try:\n        if trace is not None and hasattr(trace, 'add'):\n            trace.add('reranker.rank', {\n                'model': f'local:{model_name}',\n                'scores': [\n                    {\n                        'path': r.get('file_path'),\n                        'start': r.get('start_line'),\n                        'end': r.get('end_line'),\n                        'rerank_score': float(r.get('rerank_score', 0.0) or 0.0),\n                    } for r in top\n                ]\n            })\n    except Exception:\n        pass\n    return top
import os\nimport json\nimport collections\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom common.config_loader import choose_repo_from_query, get_default_repo, out_dir\nfrom dotenv import load_dotenv, find_dotenv\n\n# Load any existing env ASAP so downstream imports (e.g., rerank backend) see them\ntry:\n    load_dotenv(override=False)\nexcept Exception:\n    pass\n\nfrom qdrant_client import QdrantClient, models\nimport bm25s\nfrom bm25s.tokenization import Tokenizer\nfrom Stemmer import Stemmer\nfrom .rerank import rerank_results as ce_rerank\nfrom server.env_model import generate_text
_classify_query(q: str) -> str:\n    ql = (q or '').lower()\n    if any(k in ql for k in ['ui', 'react', 'component', 'tsx', 'page', 'frontend', 'render', 'css']):\n        return 'ui'\n    if any(k in ql for k in ['notification', 'pushover', 'apprise', 'hubspot', 'provider', 'integration', 'adapter', 'webhook']):\n        return 'integration'\n    if any(k in ql for k in ['diagnostic', 'health', 'event log', 'phi', 'mask', 'hipaa', 'middleware', 'auth', 'token', 'oauth', 'hmac']):\n        return 'server'\n    if any(k in ql for k in ['sdk', 'client library', 'python sdk', 'node sdk']):\n        return 'sdk'\n    if any(k in ql for k in ['infra', 'asterisk', 'sip', 't.38', 'ami', 'freeswitch', 'egress', 'cloudflared']):\n        return 'infra'\n    return 'server'
_project_layer_bonus(layer: str, intent: str) -> float:\n    layer_lower = (layer or '').lower()\n    intent_lower = (intent or 'server').lower()\n    table = {\n        'server': {'kernel': 0.10, 'plugin': 0.04, 'ui': 0.00, 'docs': 0.00, 'tests': 0.00, 'infra': 0.02},\n        'integration': {'integration': 0.12, 'kernel': 0.04, 'ui': 0.00, 'docs': 0.00, 'tests': 0.00, 'infra': 0.00},\n        'ui': {'ui': 0.12, 'docs': 0.06, 'kernel': 0.02, 'plugin': 0.02, 'tests': 0.00, 'infra': 0.00},\n        'sdk': {'kernel': 0.04, 'docs': 0.02},\n        'infra': {'infra': 0.12, 'kernel': 0.04}\n    }\n    return table.get(intent_lower, {}).get(layer_lower, 0.0)
_project_layer_bonus(layer: str, intent: str) -> float:  # override for other repo profile\n    layer_lower = (layer or '').lower()\n    intent_lower = (intent or 'server').lower()\n    table = {\n        'server': {'server': 0.10, 'integration': 0.06, 'fax': 0.30, 'admin console': 0.10, 'sdk': 0.00, 'infra': 0.00, 'docs': 0.02},\n        'integration': {'provider': 0.12, 'traits': 0.10, 'server': 0.06, 'ui': 0.00, 'sdk': 0.00, 'infra': 0.02, 'docs': 0.00},\n        'ui': {'ui': 0.12, 'docs': 0.06, 'server': 0.02, 'hipaa': 0.20},\n        'sdk': {'sdk': 0.12, 'server': 0.04, 'docs': 0.02},\n        'infra': {'infra': 0.12, 'server': 0.04, 'provider': 0.04}\n    }\n    return table.get(intent_lower, {}).get(layer_lower, 0.0)\n\n_provider_plugin_hint(fp: str, code: str) -> float:\n    fp = (fp or '').lower()\n    code = (code or '').lower()\n    keys = ['provider', 'providers', 'integration', 'adapter', 'webhook', 'pushover', 'apprise', 'hubspot']\n    return 0.06 if any(k in fp or k in code for k in keys) else 0.0
_origin_bonus(origin: str, mode: str) -> float:\n    origin = (origin or '').lower()\n    mode = (mode or 'prefer_first_party').lower()\n    if mode == 'prefer_first_party':\n        return 0.06 if origin == 'first_party' else (-0.08 if origin == 'vendor' else 0.0)\n    if mode == 'prefer_vendor':\n        return 0.06 if origin == 'vendor' else 0.0\n    return 0.0\n\n_feature_bonus(query: str, fp: str, code: str) -> float:\n    ql = (query or '').lower()\n    fp = (fp or '').lower()\n    code = (code or '').lower()\n    bumps = 0.0\n    if any(k in ql for k in ['diagnostic', 'health', 'event log', 'phi', 'hipaa']):\n        if ('diagnostic' in fp) or ('diagnostic' in code) or ('event' in fp and 'log' in fp):\n            bumps += 0.06\n    return bumps\n\n_card_bonus(chunk_id: str, card_chunk_ids: set) -> float:\n    """Boost chunks that matched via card-based retrieval."""\n    return 0.08 if str(chunk_id) in card_chunk_ids else 0.0\n\n_path_bonus(fp: str) -> float:\n    fp = (fp or '').lower()\n    bonus = 0.0\n    for sfx, b in [\n        ('/identity/', 0.12),\n        ('/auth/', 0.12),\n        ('/server', 0.10),\n        ('/backend', 0.10),\n        ('/api/', 0.08),\n    ]:\n        if sfx in fp:\n            bonus += b\n    return bonus
_project_path_boost(fp: str, repo_tag: str) -> float:\n    import os as _os\n    if (repo_tag or '').lower() != 'project':\n        return 0.0\n    cfg = _os.getenv('project_PATH_BOOSTS', 'app/,lib/,config/,scripts/,server/,api/,api/app,app/services,app/routers,api/admin_ui,app/plugins')\n    tokens = [t.strip().lower() for t in cfg.split(',') if t.strip()]\n    s = (fp or '').lower()\n    bonus = 0.0\n    for tok in tokens:\n        if tok and tok in s:\n            bonus += 0.06\n    return min(bonus, 0.18)\n\n\ntry:\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / ".env"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\n\nQDRANT_URL = os.getenv('QDRANT_URL', 'http://127.0.0.1:6333')\nREPO = os.getenv('REPO', 'project')\nVENDOR_MODE = os.getenv('VENDOR_MODE', 'prefer_first_party')\nCOLLECTION = os.getenv('COLLECTION_NAME', f'code_chunks_{REPO}')
_lazy_import_openai():\n    from openai import OpenAI\n    return OpenAI(api_key=os.getenv("OPENAI_API_KEY"))\n\n_lazy_import_voyage():\n    import voyageai\n    return voyageai.Client(api_key=os.getenv("VOYAGE_API_KEY"))\n\n\n_local_embed_model = None\n\n_get_embedding(text: str, kind: str = "query") -> list[float]:\n    et = (os.getenv("EMBEDDING_TYPE", "openai") or "openai").lower()\n    if et == "voyage":\n        vo = _lazy_import_voyage()\n        out = vo.embed([text], model="voyage-code-3", input_type=kind, output_dimension=512)\n        return out.embeddings[0]\n    if et == "local":\n        global _local_embed_model\n        if _local_embed_model is None:\n            from sentence_transformers import SentenceTransformer\n            _local_embed_model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n        return _local_embed_model.encode([text], normalize_embeddings=True, show_progress_bar=False)[0].tolist()\n    client = _lazy_import_openai()\n    resp = client.embeddings.create(input=text, model="text-embedding-3-large")\n    return resp.data[0].embedding
rrf(dense: list, sparse: list, k: int = 10, kdiv: int = 60) -> list:\n    score: dict = collections.defaultdict(float)\n    for rank, pid in enumerate(dense, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    for rank, pid in enumerate(sparse, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    ranked = sorted(score.items(), key=lambda x: x[1], reverse=True)\n    return [pid for pid, _ in ranked[:k]]\n\n_load_chunks(repo: str) -> List[Dict]:\n    p = os.path.join(out_dir(repo), 'chunks.jsonl')\n    chunks: List[Dict] = []\n    if os.path.exists(p):\n        with open(p, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                o.pop('code', None)\n                o.pop('summary', None)\n                o.pop('keywords', None)\n                chunks.append(o)\n    return chunks
_load_bm25_map(idx_dir: str):\n    pid_json = os.path.join(idx_dir, 'bm25_point_ids.json')\n    if os.path.exists(pid_json):\n        m = json.load(open(pid_json))\n        return [m[str(i)] for i in range(len(m))]\n    map_path = os.path.join(idx_dir, 'chunk_ids.txt')\n    if os.path.exists(map_path):\n        with open(map_path, 'r', encoding='utf-8') as f:\n            ids = [line.strip() for line in f if line.strip()]\n        return ids\n    return None\n\n_load_cards_bm25(repo: str):\n    idx_dir = os.path.join(out_dir(repo), 'bm25_cards')\n    try:\n        import bm25s\n        retr = bm25s.BM25.load(idx_dir)\n        return retr\n    except Exception:\n        return None
_load_cards_map(repo: str) -> Dict:\n    cards_file = os.path.join(out_dir(repo), 'cards.jsonl')\n    cards_by_idx = {}\n    cards_by_chunk_id = {}\n    try:\n        with open(cards_file, 'r', encoding='utf-8') as f:\n            for idx, line in enumerate(f):\n                card = json.loads(line)\n                chunk_id = str(card.get('id', ''))\n                if chunk_id:\n                    cards_by_idx[idx] = chunk_id\n                    cards_by_chunk_id[chunk_id] = card\n        return {'by_idx': cards_by_idx, 'by_chunk_id': cards_by_chunk_id}\n    except Exception:\n        return {'by_idx': {}, 'by_chunk_id': {}}
search(query: str, repo: str, topk_dense: int = 75, topk_sparse: int = 75, final_k: int = 10, trace: object | None = None) -> List[Dict]:\n    chunks = _load_chunks(repo)\n    if not chunks:\n        return []\n    dense_pairs = []\n    qc = QdrantClient(url=QDRANT_URL)\n    coll = os.getenv('COLLECTION_NAME', f'code_chunks_{repo}')\n    try:\n        e = _get_embedding(query, kind="query")\n    except Exception:\n        e = []\n    try:\n        backend = (os.getenv('VECTOR_BACKEND','qdrant') or 'qdrant').lower()\n        if backend == 'faiss':\n            # Experimental FAISS backend (offline). If not present, fall back to sparse-only.\n            dense_pairs = []\n        else:\n            dres = qc.query_points(\n                collection_name=coll,\n                query=e,\n                using='dense',\n                limit=topk_dense,\n                with_payload=models.PayloadSelectorInclude(include=['file_path', 'start_line', 'end_line', 'language', 'layer', 'repo', 'hash', 'id'])\n            )\n            points = getattr(dres, 'points', dres)\n            dense_pairs = [(str(p.id), dict(p.payload)) for p in points]\n    except Exception:\n        dense_pairs = []\n\n    idx_dir = os.path.join(out_dir(repo), 'bm25_index')\n    retriever = bm25s.BM25.load(idx_dir)\n    tokenizer = Tokenizer(stemmer=Stemmer('english'), stopwords='en')\n    tokens = tokenizer.tokenize([query])\n    ids, _ = retriever.retrieve(tokens, k=topk_sparse)\n    ids = ids.tolist()[0] if hasattr(ids, 'tolist') else list(ids[0])\n    id_map = _load_bm25_map(idx_dir)\n    by_chunk_id = {str(c['id']): c for c in chunks}\n    sparse_pairs = []\n    for i in ids:\n        if id_map is not None:\n            if 0 <= i < len(id_map):\n                pid_or_cid = id_map[i]\n                key = str(pid_or_cid)\n                if key in by_chunk_id:\n                    sparse_pairs.append((key, by_chunk_id[key]))\n                else:\n                    if 0 <= i < len(chunks):\n                        sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n        else:\n            if 0 <= i < len(chunks):\n                sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n\n    card_chunk_ids: set = set()\n    cards_retr = _load_cards_bm25(repo)\n    if cards_retr is not None:\n        try:\n            cards_map = _load_cards_map(repo)\n            tokens = tokenizer.tokenize([query])\n            c_ids, _ = cards_retr.retrieve(tokens, k=min(topk_sparse, 30))\n            c_ids_flat = c_ids[0] if hasattr(c_ids, '__getitem__') else c_ids\n            for card_idx in c_ids_flat:\n                chunk_id = cards_map['by_idx'].get(int(card_idx))\n                if chunk_id:\n                    card_chunk_ids.add(str(chunk_id))\n        except Exception:\n            pass\n\n    dense_ids = [pid for pid, _ in dense_pairs]\n    sparse_ids = [pid for pid, _ in sparse_pairs]\n    fused = rrf(dense_ids, sparse_ids, k=max(final_k, 2 * final_k)) if dense_pairs else sparse_ids[:final_k]\n    by_id = {pid: p for pid, p in (dense_pairs + sparse_pairs)}\n    docs = [by_id[pid] for pid in fused if pid in by_id]\n    HYDRATION_MODE = (os.getenv('HYDRATION_MODE', 'lazy') or 'lazy').lower()\n    if HYDRATION_MODE != 'none':\n        _hydrate_docs_inplace(repo, docs)\n    # tracing: pre-rerank candidate snapshot\n    try:\n        if trace is not None and hasattr(trace, 'add'):\n            cands = []\n            seen_pre = set()\n            # Use union of bm25+dense by earliest rank observed\n            rank_map_dense = {pid: i+1 for i, pid in enumerate(dense_ids[:max(final_k, 50)])}\n            rank_map_sparse = {pid: i+1 for i, pid in enumerate(sparse_ids[:max(final_k, 50)])}\n            for pid in list(rank_map_dense.keys()) + list(rank_map_sparse.keys()):\n                if pid in seen_pre: continue\n                seen_pre.add(pid)\n                meta = by_id.get(pid, {})\n                cands.append({\n                    'path': meta.get('file_path'),\n                    'start': meta.get('start_line'),\n                    'end': meta.get('end_line'),\n                    'card_hit': str(meta.get('id','')) in card_chunk_ids,\n                    'bm25_rank': rank_map_sparse.get(pid),\n                    'dense_rank': rank_map_dense.get(pid),\n                })\n            trace.add('retriever.retrieve', {\n                'k_sparse': int(topk_sparse),\n                'k_dense': int(topk_dense),\n                'candidates': cands[:max(final_k, 50)],\n            })\n    except Exception:\n        pass\n\n    docs = ce_rerank(query, docs, top_k=final_k, trace=trace)\n\n    intent = _classify_query(query)\n    for d in docs:\n        fp = d.get('file_path', '')\n        layer = (d.get('layer') or '').lower()\n        score = float(d.get('rerank_score', 0.0) or 0.0)\n        # Card hit bonus (semantic cards retrieval via BM25 over summaries)\n        try:\n            cid = str(d.get('id', '') or '')\n            if cid and cid in card_chunk_ids:\n                d['card_hit'] = True\n                score += _card_bonus(cid, card_chunk_ids)\n        except Exception:\n            pass\n        score += _path_bonus(fp)\n        score += _project_layer_bonus(layer, intent)\n        score += _provider_plugin_hint(fp, d.get('code', '') or '')\n        score += _origin_bonus(d.get('origin', ''), os.getenv('VENDOR_MODE', VENDOR_MODE))\n        score += _feature_bonus(query, fp, d.get('code', '') or '')\n        d['rerank_score'] = score\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n    return docs[:final_k]
_hydrate_docs_inplace(repo: str, docs: list[dict]) -> None:\n    needed_ids: set[str] = set()\n    needed_hashes: set[str] = set()\n    for d in docs:\n        if d.get('code'):\n            continue\n        cid = str(d.get('id', '') or '')\n        h = d.get('hash')\n        if cid:\n            needed_ids.add(cid)\n        if h:\n            needed_hashes.add(h)\n    if not needed_ids and not needed_hashes:\n        return\n    jl = os.path.join(out_dir(repo), 'chunks.jsonl')\n    max_chars = int(os.getenv('HYDRATION_MAX_CHARS', '2000') or '2000')\n    found_by_id: dict[str, str] = {}\n    found_by_hash: dict[str, str] = {}\n    try:\n        with open(jl, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                cid = str(o.get('id', '') or '')\n                h = o.get('hash')\n                code = (o.get('code') or '')\n                if max_chars > 0 and code:\n                    code = code[:max_chars]\n                if cid and cid in needed_ids and cid not in found_by_id:\n                    found_by_id[cid] = code\n                if h and h in needed_hashes and h not in found_by_hash:\n                    found_by_hash[h] = code\n                if len(found_by_id) >= len(needed_ids) and len(found_by_hash) >= len(needed_hashes):\n                    break\n    except FileNotFoundError:\n        return\n    for d in docs:\n        if not d.get('code'):\n            cid = str(d.get('id', '') or '')\n            h = d.get('hash')\n            d['code'] = found_by_id.get(cid) or (found_by_hash.get(h) if h else '') or ''
_apply_filename_boosts(docs: list[dict], question: str) -> None:\n    terms = set((question or '').lower().replace('/', ' ').replace('-', ' ').split())\n    for d in docs:\n        fp = (d.get('file_path') or '').lower()\n        fn = os.path.basename(fp)\n        parts = fp.split('/')\n        score = float(d.get('rerank_score', 0.0) or 0.0)\n        if any(t and t in fn for t in terms):\n            score *= 1.5\n        if any(t and t in p for t in terms for p in parts):\n            score *= 1.2\n        d['rerank_score'] = score\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n\nroute_repo(query: str, default_repo: str | None = None) -> str:\n    try:\n        return choose_repo_from_query(query, default=(default_repo or get_default_repo()))\n    except Exception:\n        q = (query or '').lower().strip()\n        if ':' in q:\n            cand, _ = q.split(':', 1)\n            cand = cand.strip()\n            if cand:\n                return cand\n        return (default_repo or os.getenv('REPO', 'project') or 'project').strip()
search_routed(query: str, repo_override: str | None = None, final_k: int = 10, trace: object | None = None):\n    repo = (repo_override or route_repo(query, default_repo=os.getenv('REPO', 'project')) or os.getenv('REPO', 'project')).strip()\n    return search(query, repo=repo, final_k=final_k, trace=trace)\n\nexpand_queries(query: str, m: int = 4) -> list[str]:\n    if m <= 1:\n        return [query]\n    try:\n        sys = "Rewrite a developer query into multiple search-friendly variants without changing meaning."\n        user = f"Count: {m}\nQuery: {query}\nOutput one variant per line, no numbering."\n        text, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n        lines = [ln.strip('- ').strip() for ln in (text or '').splitlines() if ln.strip()]\n        uniq = []\n        for ln in lines:\n            if ln and ln not in uniq:\n                uniq.append(ln)\n        return (uniq or [query])[:m]\n    except Exception:\n        return [query]
search_routed_multi(query: str, repo_override: str | None = None, m: int = 4, final_k: int = 10, trace: object | None = None):\n    repo = (repo_override or route_repo(query) or os.getenv('REPO', 'project')).strip()\n    variants = expand_queries(query, m=m)\n    try:\n        if trace is not None and hasattr(trace, 'add'):\n            trace.add('router.decide', {\n                'policy': 'code',  # heuristic profile\n                'intent': _classify_query(query),\n                'query_original': query,\n                'query_rewrites': variants[1:] if len(variants) > 1 else [],\n                'knobs': {\n                    'topk_sparse': int(os.getenv('TOPK_SPARSE', '75') or 75),\n                    'topk_dense': int(os.getenv('TOPK_DENSE', '75') or 75),\n                    'final_k': int(final_k),\n                    'hydration_mode': (os.getenv('HYDRATION_MODE', 'lazy') or 'lazy'),\n                },\n            })\n    except Exception:\n        pass\n    all_docs = []\n    for qv in variants:\n        docs = search(qv, repo=repo, final_k=final_k, trace=trace)\n        all_docs.extend(docs)\n    seen = set()\n    uniq = []\n    for d in all_docs:\n        key = (d.get('file_path'), d.get('start_line'), d.get('end_line'))\n        if key in seen:\n            continue\n        seen.add(key)\n        uniq.append(d)\n    try:\n        from .rerank import rerank_results as _rr\n        reranked = _rr(query, uniq, top_k=final_k)\n        _apply_filename_boosts(reranked, query)\n        return reranked\n    except Exception:\n        return uniq[:final_k]
"""Retrieval package (hybrid search, reranking, chunking, caches).\n\nModules here are the canonical locations. Root-level shims import from here\nto preserve backward compatibility while we reorganize folders.\n"""
import os\nimport re\nimport hashlib\nfrom typing import Dict, List, Optional\n\ntry:\n    from tree_sitter_languages import get_parser as _ts_get_parser  # type: ignore\nexcept Exception:\n    _ts_get_parser = None\n\nLANG_MAP = {\n    ".py": "python", ".js": "javascript", ".jsx": "javascript",\n    ".ts": "typescript", ".tsx": "typescript",\n    ".go": "go", ".java": "java", ".rs": "rust",\n    ".c": "c", ".h": "c", ".cpp": "cpp", ".cc": "cpp", ".hpp": "cpp",\n}\n\nOVERLAP_LINES = 20\n\nFUNC_NODES = {\n    "python": {"function_definition", "class_definition"},\n    "javascript": {"function_declaration", "class_declaration", "method_definition", "arrow_function"},\n    "typescript": {"function_declaration", "class_declaration", "method_signature", "method_definition", "arrow_function"},\n    "go": {"function_declaration", "method_declaration"},\n    "java": {"class_declaration", "method_declaration"},\n    "rust": {"function_item", "impl_item"},\n    "c": {"function_definition"},\n    "cpp": {"function_definition", "class_specifier"},\n}\n\nIMPORT_NODES = {\n    "python": {"import_statement", "import_from_statement"},\n    "javascript": {"import_declaration"},\n    "typescript": {"import_declaration"},\n    "go": {"import_declaration"},\n    "java": {"import_declaration"},\n    "rust": {"use_declaration"},\n    "c": set(), "cpp": set(),\n}
lang_from_path(path:str)->Optional[str]:\n    _, ext = os.path.splitext(path)\n    return LANG_MAP.get(ext.lower())\nnonws_len(s:str)->int:\n    return len(re.sub(r"\s+", "", s))\nextract_imports(src:str, lang:str)->List[str]:\n    try:\n        if _ts_get_parser is None:\n            raise RuntimeError("tree_sitter_languages not available")\n        parser = _ts_get_parser(lang)\n        tree = parser.parse(bytes(src, "utf-8"))\n        imports = []\n        def walk(n):\n            if n.type in IMPORT_NODES.get(lang, set()):\n                imports.append(src[n.start_byte:n.end_byte])\n            for c in n.children:\n                walk(c)\n        walk(tree.root_node)\n        return imports\n    except Exception:\n        if lang == "python":\n            return re.findall(r"^(?:from\s+[^\n]+|import\s+[^\n]+)$", src, flags=re.M)\n        if lang in {"javascript","typescript"}:\n            return re.findall(r"^import\s+[^\n]+;$", src, flags=re.M)\n        return []
greedy_fallback(src:str, fpath:str, lang:str, target:int)->List[Dict]:\n    sep = r"(?:\nclass\s+|\ndef\s+)" if lang=="python" else r"(?:\nclass\s+|\nfunction\s+)"\n    parts = re.split(sep, src)\n    if len(parts) < 2:\n        out, cur, acc = [], [], 0\n        for line in src.splitlines(True):\n            cur.append(line)\n            acc += nonws_len(line)\n            if acc >= target:\n                out.append("".join(cur))\n                cur, acc = [], 0\n        if cur:\n            out.append("".join(cur))\n        return [{\n            "id": hashlib.md5((fpath+str(i)+s[:80]).encode()).hexdigest()[:12],\n            "file_path": fpath, "language": lang, "type":"blob","name":None,\n            "start_line": 1, "end_line": s.count("\n")+1, "imports": extract_imports(src, lang), "code": s\n        } for i,s in enumerate(out)]\n    else:\n        rejoined, buf, acc = [], [], 0\n        for p in parts:\n            if acc + nonws_len(p) > target and buf:\n                s = "".join(buf)\n                rejoined.append(s)\n                buf, acc = [], 0\n            buf.append(p)\n            acc += nonws_len(p)\n        if buf:\n            rejoined.append("".join(buf))\n        return [{\n            "id": hashlib.md5((fpath+str(i)+s[:80]).encode()).hexdigest()[:12],\n            "file_path": fpath, "language": lang, "type":"section","name":None,\n            "start_line": 1, "end_line": s.count("\n")+1, "imports": extract_imports(s, lang), "code": s\n        } for i,s in enumerate(rejoined)]
collect_files(roots:List[str])->List[str]:\n    import fnmatch\n    out=[]\n    skip_dirs = {".git","node_modules",".venv","venv","dist","build","__pycache__",".next",".turbo",".parcel-cache",".pytest_cache","vendor","third_party",".bundle","Pods"}\n    exclude_patterns = []\n    for root in roots:\n        parent_dir = os.path.dirname(root) if os.path.isfile(root) else root\n        exclude_file = os.path.join(parent_dir, 'data', 'exclude_globs.txt')\n        if os.path.exists(exclude_file):\n            try:\n                with open(exclude_file, 'r') as f:\n                    patterns = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n                    exclude_patterns.extend(patterns)\n            except Exception:\n                pass\n    for root in roots:\n        for dp, dns, fns in os.walk(root):\n            dns[:] = [d for d in dns if d not in skip_dirs and not d.startswith('.venv') and not d.startswith('venv')]\n            for fn in fns:\n                p = os.path.join(dp, fn)\n                skip = False\n                for pattern in exclude_patterns:\n                    if fnmatch.fnmatch(p, pattern) or fnmatch.fnmatch(os.path.relpath(p, root), pattern):\n                        skip = True\n                        break\n                if not skip and lang_from_path(p):\n                    out.append(p)\n    return out
_guess_name(lang:str, text:str)->Optional[str]:\n    if lang=="python":\n        m = re.search(r"^(?:def|class)\s+([A-Za-z_][A-Za-z0-9_]*)", text, flags=re.M)\n        return m.group(1) if m else None\n    if lang in {"javascript","typescript"}:\n        m = re.search(r"^(?:function|class)\s+([A-Za-z_$][A-Za-z0-9_$]*)", text, flags=re.M)\n        return m.group(1) if m else None\n    return None
chunk_code(src:str, fpath:str, lang:str, target:int=900)->List[Dict]:\n    try:\n        if _ts_get_parser is None:\n            raise RuntimeError("tree_sitter_languages not available")\n        parser = _ts_get_parser(lang)\n        tree = parser.parse(bytes(src, "utf-8"))\n        wanted = FUNC_NODES.get(lang, set())\n        nodes = []\n        stack = [tree.root_node]\n        while stack:\n            n = stack.pop()\n            if n.type in wanted:\n                nodes.append(n)\n            stack.extend(n.children)\n        if not nodes:\n            return greedy_fallback(src, fpath, lang, target)\n        chunks: List[Dict] = []\n        all_lines = src.splitlines()\n        for i, n in enumerate(nodes):\n            text = src[n.start_byte:n.end_byte]\n            if nonws_len(text) > target:\n                for j, sub in enumerate(greedy_fallback(text, fpath, lang, target)):\n                    sub["id"] = hashlib.md5((fpath+f"/{i}:{j}"+sub["code"][:80]).encode()).hexdigest()[:12]\n                    sub["start_line"] = n.start_point[0]+1\n                    sub["end_line"] = sub["start_line"] + sub["code"].count("\n")\n                    chunks.append(sub)\n            else:\n                name = _guess_name(lang, text)\n                start_line = n.start_point[0] + 1\n                end_line = n.end_point[0] + 1\n                actual_start = max(1, start_line - OVERLAP_LINES) if OVERLAP_LINES > 0 else start_line\n                chunk_text = "\n".join(all_lines[actual_start-1:end_line])\n                chunks.append({\n                    "id": hashlib.md5((fpath+str(i)+text[:80]).encode()).hexdigest()[:12],\n                    "file_path": fpath,\n                    "language": lang,\n                    "type": "unit",\n                    "name": name,\n                    "start_line": actual_start,\n                    "end_line": end_line,\n                    "imports": extract_imports(src, lang),\n                    "code": chunk_text,\n                })\n        return chunks\n    except Exception:\n        return greedy_fallback(src, fpath, lang, target)
import os, json\nimport tiktoken
EmbeddingCache:\n    def __init__(self, outdir: str):\n        os.makedirs(outdir, exist_ok=True)\n        self.path = os.path.join(outdir, "embed_cache.jsonl")\n        self.cache = {}\n        if os.path.exists(self.path):\n            with open(self.path, "r", encoding="utf-8") as f:\n                for line in f:\n                    try:\n                        o = json.loads(line)\n                        self.cache[o["hash"]] = o["vec"]\n                    except Exception:\n                        pass\n\n    def get(self, h: str):\n        return self.cache.get(h)\n\n    def put(self, h: str, v):\n        self.cache[h] = v\n\n    def save(self):\n        with open(self.path, "w", encoding="utf-8") as f:\n            for h, v in self.cache.items():\n                f.write(json.dumps({"hash": h, "vec": v}) + "\n")\n\n    def prune(self, valid_hashes: set):\n        before = len(self.cache)\n        self.cache = {h: v for h, v in self.cache.items() if h in valid_hashes}\n        after = len(self.cache)\n        pruned = before - after\n        if pruned > 0:\n            self.save()\n        return pruned\n\n    def embed_texts(self, client, texts, hashes, model="text-embedding-3-large", batch=64):\n        embs = [None] * len(texts)\n        to_embed, idx_map = [], []\n        for i, (t, h) in enumerate(zip(texts, hashes)):\n            v = self.get(h)\n            if v is None:\n                idx_map.append(i)\n                to_embed.append(t)\n            else:\n                embs[i] = v\n        enc = tiktoken.get_encoding('cl100k_base')\n\n        def _clip_for_openai(text: str, max_tokens: int = 8000) -> str:\n            toks = enc.encode(text)\n            if len(toks) <= max_tokens:\n                return text\n            return enc.decode(toks[:max_tokens])\n\n        for i in range(0, len(to_embed), batch):\n            sub = [_clip_for_openai(t) for t in to_embed[i:i + batch]]\n            r = client.embeddings.create(model=model, input=sub)\n            for j, d in enumerate(r.data):\n                orig = idx_map[i + j]\n                vec = d.embedding\n                embs[orig] = vec\n                self.put(hashes[orig], vec)\n        return embs
#!/usr/bin/env python3\nfrom __future__ import annotations\nfrom fastapi.testclient import TestClient\nimport io\nfrom pathlib import Path\nimport json, sys\nROOT = Path(__file__).resolve().parents[1]\nsys.path.insert(0, str(ROOT))\n# Provide a lightweight stub for rerankers to avoid import-time type errors\nimport types as _types\nif 'rerankers' not in sys.modules:\n    m = _types.ModuleType('rerankers')\n    class Reranker:  # minimal placeholder\n        def __init__(self, *a, **k):\n            pass\n    m.Reranker = Reranker\n    sys.modules['rerankers'] = m\nimport serve_rag
main() -> int:\n    app = serve_rag.app\n    c = TestClient(app)\n\n    # Prices\n    r = c.get('/api/prices')\n    assert r.status_code == 200, r.text\n    models = r.json().get('models', [])\n    print('prices models:', len(models))\n\n    # Upsert a model\n    r = c.post('/api/prices/upsert', json={"provider":"local","model":"qwen3-coder:14b","unit":"request"})\n    assert r.status_code == 200 and r.json().get('ok'), r.text\n\n    # Cost estimate\n    r = c.post('/api/cost/estimate', json={"provider":"openai","model":"gpt-4o-mini","tokens_in":500,"tokens_out":800,"embeds":0,"reranks":0,"requests_per_day":100})\n    assert r.status_code == 200, r.text\n    print('cost:', r.json().get('daily'), r.json().get('monthly'))\n\n    # Secrets ingest\n    buf = io.BytesIO(b"OPENAI_API_KEY=sk-test-xyz\nREPO=agro\n")\n    files = {"file": ("tmp.env", buf, "text/plain")}\n    data = {"persist": "true"}\n    r = c.post('/api/secrets/ingest', files=files, data=data)\n    assert r.status_code == 200, r.text\n    r = c.get('/api/config')\n    env = r.json().get('env', {})\n    assert env.get('OPENAI_API_KEY') == 'sk-test-xyz', env\n    print('env OPENAI_API_KEY:', env.get('OPENAI_API_KEY'))\n\n    # Autotune\n    r = c.get('/api/autotune/status')\n    assert r.status_code == 200\n    print('autotune:', r.json())\n\n    return 0\n\n\nif __name__ == '__main__':\n    raise SystemExit(main())
#!/usr/bin/env python3\n"""Quick token test for docs - measure actual usage"""\nimport os\nos.environ["OLLAMA_URL"] = "http://127.0.0.1:11434/api"\nos.environ["GEN_MODEL"] = "qwen3-coder:30b"\n\nimport sys\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model("gpt-4o")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\n# Test 1: Claude Alone (read full files)\nfrom pathlib import Path\nquestion = "How are fax jobs created and dispatched"\nkeywords = ["fax", "jobs", "created", "dispatched"]\nrepo_path = os.getenv('project_PATH', '/abs/path/to/project')\n\nfull_content = ""\nfor py_file in list(Path(repo_path).rglob('*.py'))[:10]:\n    try:\n        content = py_file.read_text(errors='ignore')\n        if any(kw in content.lower() for kw in keywords):\n            full_content += f"\n{'='*70}\n{content}\n"\n    except:\n        pass\n\ntokens_claude_alone = count_tokens(full_content)\nprint(f"1. Claude Alone: {tokens_claude_alone:,} tokens")
# Test 2: MCP metadata only (simulate what Claude Code gets)\nmcp_response = """{"results": [\n  {"file_path": "server.py", "start_line": 120, "end_line": 145, "score": 0.89},\n  {"file_path": "tasks.py", "start_line": 67, "end_line": 89, "score": 0.85},\n  {"file_path": "models.py", "start_line": 234, "end_line": 267, "score": 0.78}\n], "count": 3}"""\n\n# Tool schema (sent with every request)\ntool_schema = """{"tools": [{"name": "rag_search", "description": "Search codebase", "inputSchema": {...}}]}"""\n\ntokens_mcp = count_tokens(mcp_response + tool_schema)\nprint(f"2. Claude + RAG via MCP: {tokens_mcp:,} tokens")\n\n# Calculate savings\nsaved = tokens_claude_alone - tokens_mcp\npct = (saved / tokens_claude_alone * 100) if tokens_claude_alone > 0 else 0\nreduction = tokens_claude_alone / tokens_mcp if tokens_mcp > 0 else 0\n\nprint(f"\nSavings: {saved:,} tokens ({pct:.1f}%)")\nprint(f"Reduction: {reduction:.1f}x")\n\n# Cost (gpt-4o: $2.50/1M input)\ncost_alone = tokens_claude_alone * (2.50 / 1_000_000)\ncost_mcp = tokens_mcp * (2.50 / 1_000_000)
cost_saved = cost_alone - cost_mcp\n\nprint(f"\nPer query: ${cost_saved:.6f} saved")\nprint(f"Per 100 queries: ${cost_saved * 100:.2f} saved")\nprint(f"Per month (100/day): ${cost_saved * 3000:.2f} saved")
#!/usr/bin/env python3\nimport os, sys, json, urllib.request, urllib.error\n\nAPI = "https://api.netlify.com/api/v1"\napi(path: str, method: str = "GET", data: dict | None = None) -> dict:\n    token = os.getenv("NETLIFY_API_KEY")\n    if not token:\n        print("NETLIFY_API_KEY not set", file=sys.stderr)\n        sys.exit(2)\n    url = f"{API}{path}"\n    req = urllib.request.Request(url, method=method)\n    req.add_header("Authorization", f"Bearer {token}")\n    req.add_header("Content-Type", "application/json")\n    body = json.dumps(data).encode("utf-8") if data is not None else None\n    with urllib.request.urlopen(req, data=body, timeout=30) as resp:\n        raw = resp.read().decode("utf-8")\n        return json.loads(raw) if raw else {}\nfind_site(domain: str) -> dict | None:\n    sites = api("/sites", "GET")\n    dom = (domain or "").strip().lower()\n    if isinstance(sites, list):\n        for s in sites:\n            for key in ("custom_domain", "url", "ssl_url"):\n                val = (s.get(key) or "").lower()\n                if val and dom in val:\n                    return s\n    return None
trigger(domain: str) -> dict:\n    s = find_site(domain)\n    if not s:\n        return {"domain": domain, "status": "not_found"}\n    sid = s.get("id")\n    if not sid:\n        return {"domain": domain, "status": "no_site_id"}\n    try:\n        b = api(f"/sites/{sid}/builds", "POST", {})\n        return {"domain": domain, "status": "triggered", "site_id": sid, "build_id": b.get("id")}\n    except Exception as e:\n        return {"domain": domain, "status": "error", "error": str(e)}
main():\n    if len(sys.argv) < 2:\n        print("Usage: netlify_deploy.py [project.net|project.dev|both|list]", file=sys.stderr)\n        sys.exit(2)\n    cmd = sys.argv[1].strip().lower()\n    if cmd == "list":\n        sites = api("/sites", "GET")\n        out = []\n        for s in sites if isinstance(sites, list) else []:\n            out.append({"id": s.get("id"), "name": s.get("name"), "url": s.get("url"), "custom_domain": s.get("custom_domain")})\n        print(json.dumps(out, indent=2))\n        return\n    domains = ["project.net", "project.dev"] if cmd == "both" else [cmd]\n    results = [trigger(d) for d in domains]\n    print(json.dumps(results, indent=2))\n\nif __name__ == "__main__":\n    main()
#!/usr/bin/env python3\nimport os, sys, re\n\nSCAN_ALL = os.getenv("SCAN_ALL", "0").lower() in {"1","true","yes"}\nROOTS = [os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))]\nif SCAN_ALL:\n    ROOTS += [\n        os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        os.getenv('project_PATH', '/abs/path/to/project'),\n    ]\n\nBAD_PATTERNS = [\n    r"\bChatCompletion\b",\n    r"\bclient\.chat\.completions\b",\n    r"\bassistants?\.v1\b",\n    r"\bgpt-3\.5\b",\n    r"\bgpt-4(?!\.1|o)\b",\n    r"\bgpt-4o(-mini)?\b",\n    r"\btext-embedding-ada\b",\n    r"\btext-embedding-00[23]\b",\n]\nALLOWLIST_FILES = {\n    # add filenames you want ignored (e.g., historical docs)\n}\n\nSKIP_DIRS = {".git", ".venv", "venv", "node_modules", "dist", "build", "vendor", "third_party", "site-packages", "__pycache__"}\n\nscan_file(path: str) -> list[str]:\n    try:\n        with open(path, "r", errors="ignore") as f:\n            s = f.read()\n    except Exception:\n        return []\n    hits = []\n    for pat in BAD_PATTERNS:\n        if re.search(pat, s):\n            hits.append(pat)\n    return hits
main() -> int:\n    offenders = []\n    for root in ROOTS:\n        if not os.path.isdir(root):\n            continue\n        for base, dirs, files in os.walk(root):\n            # prune skip dirs\n            dirs[:] = [d for d in dirs if d not in SKIP_DIRS and not d.startswith('.')]\n            for name in files:\n                if name in ALLOWLIST_FILES:\n                    continue\n                # Scan code files only (skip docs like .md)\n                if not any(name.endswith(ext) for ext in (".py", ".ts", ".tsx", ".js", ".rb")):\n                    continue\n                path = os.path.join(base, name)\n                # skip this guard file and sitecustomize self-detection\n                if path.endswith("scripts/guard_legacy_api.py") or path.endswith("sitecustomize.py"):\n                    continue\n                hits = scan_file(path)\n                if hits:\n                    offenders.append((path, hits))\n    if offenders:\n        print("\u274c Legacy APIs/models detected:")\n        for p, pats in offenders:\n            print(f"- {p}")\n            for pat in pats:\n                print(f"    \u21b3 {pat}")\n        print("\nAction: replace Chat Completions with Responses API calls; update model pins (e.g., gpt-4o-mini-latest or a dated pin).")\n        print("Docs:")\n        print("  https://openai.com/index/new-tools-and-features-in-the-responses-api/")\n        print("  https://openai.com/index/introducing-upgrades-to-codex/")\n        return 2\n    print("\u2713 No legacy APIs/models detected.")\n    return 0\n\n\nif __name__ == "__main__":\n    raise SystemExit(main())
#!/usr/bin/env python3\n"""Measure MCP tool schema overhead - the part sent on EVERY request"""\nimport sys, os\nimport json\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model("gpt-4o")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\n# Get tool schemas\nfrom server.mcp.server import MCPServer\nserver = MCPServer()\ntools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\ntools_resp = server.handle_request(tools_req)\ntools_json = json.dumps(tools_resp['result']['tools'], indent=2)\n\nschema_tokens = count_tokens(tools_json)\n\nprint("=" * 80)\nprint("MCP TOOL SCHEMA OVERHEAD (sent with EVERY Claude Code request)")\nprint("=" * 80)\nprint(f"Schema tokens: {schema_tokens:,}")\nprint(f"Schema size: {len(tools_json):,} bytes")\nprint(f"\nThis overhead is ADDED to every single request.")\nprint(f"Even if MCP response is small, you always pay for the tool schemas.\n")
# Show the actual schema\nprint("Tool schemas:")\nfor tool in tools_resp['result']['tools']:\n    print(f"  - {tool['name']}: {len(json.dumps(tool)):,} bytes")\n\nwith open('/tmp/mcp_schema.json', 'w') as f:\n    f.write(tools_json)\nprint(f"\nFull schema saved to: /tmp/mcp_schema.json")
#!/usr/bin/env python3\n"""\nCompare token usage across three approaches:\n1. Claude alone (no RAG) - reads full files\n2. RAG via direct Python calls (hybrid_search.py)\n3. RAG via MCP tools (what Claude Code uses)\n\nThis shows actual token savings from using RAG.\n"""\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\n\n# Try tiktoken for precise counts\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\n    print("✓ Using tiktoken for precise token counts\n")\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print("⚠️  tiktoken not installed - using estimates (1 token ≈ 4 chars)")\n    print("   Install: pip install tiktoken\n")\n\ncount_tokens(text: str, model: str = "gpt-4o") -> int:\n    """Count tokens precisely or estimate"""\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    return len(text) // 4\n\n\n# ============================================================\n# Approach 1: Claude Alone (Traditional - NO RAG)\n# ============================================================
measure_claude_alone(question: str, repo: str):\n    """\n    Simulate what Claude would do WITHOUT RAG:\n    - Extract keywords from question\n    - Grep files for those keywords\n    - Read 5-10 full files\n    """\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'error': f'Repo not found: {repo}'}\n\n    # Extract keywords (what Claude would search for)\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find matching files\n    matched_files = []\n    combined_text = ""\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        # Skip vendor/node_modules\n        if any(skip in str(py_file) for skip in ['node_modules', '.venv', 'vendor', '.git']):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n\n            # If keywords match, Claude would read this ENTIRE file\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                combined_text += f"\n{'='*70}\n{py_file}\n{'='*70}\n{content}\n"\n\n                if len(matched_files) >= 10:  # Limit to 10 files\n                    break\n        except:\n            pass\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'Claude Alone (no RAG)',\n        'files_read': len(matched_files),\n        'chars': len(combined_text),\n        'tokens': tokens,\n        'files': matched_files[:5]  # Show first 5\n    }\n\n\n# ============================================================\n# Approach 2: RAG via Direct Python\n# ============================================================
measure_rag_python(question: str, repo: str, top_k: int = 10):\n    """Use hybrid_search.py directly (local Python calls)"""\n    try:\n        from retrieval.hybrid_search import search_routed_multi\n\n        results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n        # Combine retrieved chunks\n        combined_text = ""\n        for r in results:\n            combined_text += f"{r['file_path']}:{r['start_line']}-{r['end_line']}\n"\n            combined_text += r.get('code', '') + "\n\n"\n\n        tokens = count_tokens(combined_text)\n\n        return {\n            'approach': 'RAG (direct Python)',\n            'chunks': len(results),\n            'chars': len(combined_text),\n            'tokens': tokens,\n            'files_touched': len(set(r['file_path'] for r in results)),\n            'top_scores': [r['rerank_score'] for r in results[:3]]\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 3: RAG via MCP (What Claude Code Uses)\n# ============================================================
measure_rag_mcp(question: str, repo: str, top_k: int = 10):\n    """\n    Simulate MCP tool call (what Claude Code actually uses).\n    This calls the same backend as direct Python but through MCP layer.\n    """\n    try:\n        from server.mcp.server import MCPServer\n\n        # Call rag_search tool\n        req = {\n            'jsonrpc': '2.0',\n            'id': 1,\n            'method': 'tools/call',\n            'params': {\n                'name': 'rag_search',\n                'arguments': {\n                    'repo': repo,\n                    'question': question,\n                    'top_k': top_k\n                }\n            }\n        }\n\n        server = MCPServer()\n        resp = server.handle_request(req)\n\n        # Extract results\n        result_text = resp['result']['content'][0]['text']\n        result_data = json.loads(result_text)\n\n        # MCP returns file paths + line ranges (no full code in the response)\n        # But we need to count what gets sent to Claude\n        combined_text = result_text  # This is what Claude receives\n\n        tokens = count_tokens(combined_text)\n\n        return {\n            'approach': 'RAG (via MCP tools)',\n            'chunks': result_data.get('count', 0),\n            'chars': len(combined_text),\n            'tokens': tokens,\n            'mcp_result_size': len(result_text)\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Run Comparison\n# ============================================================
run_test(question: str, repo: str):\n    """Run all three approaches and compare"""\n    print(f"\n{'='*70}")\n    print(f"TEST: {question}")\n    print(f"REPO: {repo}")\n    print(f"{'='*70}\n")\n\n    # Method 1: Claude alone\n    print("⏳ Measuring: Claude Alone (traditional grep + read files)...")\n    claude_alone = measure_claude_alone(question, repo)\n\n    # Method 2: RAG Python\n    print("⏳ Measuring: RAG via Direct Python...")\n    rag_python = measure_rag_python(question, repo, top_k=10)\n\n    # Method 3: RAG MCP\n    print("⏳ Measuring: RAG via MCP tools...")\n    rag_mcp = measure_rag_mcp(question, repo, top_k=10)\n\n    # Print results\n    print(f"\n{'='*70}")\n    print("RESULTS:")\n    print(f"{'='*70}\n")\n\n    # Claude Alone\n    if 'error' not in claude_alone:\n        print(f"1️⃣  CLAUDE ALONE (no RAG):")\n        print(f"   Files read: {claude_alone['files_read']}")\n        print(f"   Total tokens: {claude_alone['tokens']:,}")\n        print(f"   Characters: {claude_alone['chars']:,}")\n\n    # RAG Python\n    if 'error' not in rag_python:\n        print(f"\n2️⃣  RAG (Direct Python):")\n        print(f"   Chunks retrieved: {rag_python['chunks']}")\n        print(f"   Files touched: {rag_python['files_touched']}")\n        print(f"   Total tokens: {rag_python['tokens']:,}")\n        print(f"   Top scores: {[f'{s:.3f}' for s in rag_python.get('top_scores', [])]}")\n\n    # RAG MCP\n    if 'error' not in rag_mcp:\n        print(f"\n3️⃣  RAG (via MCP - what Claude Code uses):")\n        print(f"   Chunks retrieved: {rag_mcp['chunks']}")\n        print(f"   Total tokens: {rag_mcp['tokens']:,}")\n\n    # Calculate savings\n    if all('error' not in r for r in [claude_alone, rag_python, rag_mcp]):\n        alone_tokens = claude_alone['tokens']\n        python_tokens = rag_python['tokens']\n        mcp_tokens = rag_mcp['tokens']\n\n        print(f"\n{'='*70}")\n        print("💰 TOKEN SAVINGS:")\n        print(f"{'='*70}")\n\n        # Python vs Alone\n        saved_python = alone_tokens - python_tokens\n        pct_python = (saved_python / alone_tokens * 100) if alone_tokens > 0 else 0\n\n        print(f"\nRAG Python vs Claude Alone:")\n        print(f"   Tokens saved: {saved_python:,}")\n        print(f"   Percentage: {pct_python:.1f}%")\n        print(f"   Reduction: {alone_tokens / max(python_tokens, 1):.1f}x smaller")\n\n        # MCP vs Alone\n        saved_mcp = alone_tokens - mcp_tokens\n        pct_mcp = (saved_mcp / alone_tokens * 100) if alone_tokens > 0 else 0\n\n        print(f"\nRAG MCP vs Claude Alone:")\n        print(f"   Tokens saved: {saved_mcp:,}")\n        print(f"   Percentage: {pct_mcp:.1f}%")\n        print(f"   Reduction: {alone_tokens / max(mcp_tokens, 1):.1f}x smaller")\n\n        # Cost estimate (gpt-4o: $2.50/1M input tokens)\n        cost_per_token = 2.50 / 1_000_000\n\n        print(f"\n💵 COST SAVINGS (gpt-4o @ $2.50/1M input tokens):")\n        print(f"   Per query (Python): ${saved_python * cost_per_token:.6f}")\n        print(f"   Per 1000 queries (Python): ${saved_python * cost_per_token * 1000:.2f}")\n        print(f"   Per query (MCP): ${saved_mcp * cost_per_token:.6f}")\n        print(f"   Per 1000 queries (MCP): ${saved_mcp * cost_per_token * 1000:.2f}")\n\n    return {\n        'question': question,\n        'repo': repo,\n        'claude_alone': claude_alone.get('tokens', 0),\n        'rag_python': rag_python.get('tokens', 0),\n        'rag_mcp': rag_mcp.get('tokens', 0)\n    }\n\n\nif __name__ == '__main__':\n    # Test cases\n    tests = [\n        ("Where is OAuth token validated", "project"),\n        ("How are fax jobs created and dispatched", "project"),\n        ("EventStream component event types in dropdown", "project"),\n    ]\n\n    results = []\n\n    for question, repo in tests:\n        try:\n            result = run_test(question, repo)\n            results.append(result)\n        except Exception as e:\n            print(f"\n❌ Error: {e}")\n\n    # Overall summary\n    if results:\n        print(f"\n\n{'='*70}")\n        print("📊 OVERALL SUMMARY")\n        print(f"{'='*70}\n")\n\n        total_alone = sum(r['claude_alone'] for r in results)\n        total_python = sum(r['rag_python'] for r in results)\n        total_mcp = sum(r['rag_mcp'] for r in results)\n\n        print(f"Total queries: {len(results)}")\n        print(f"\nClaude Alone: {total_alone:,} tokens")\n        print(f"RAG Python: {total_python:,} tokens")\n        print(f"RAG MCP: {total_mcp:,} tokens")\n\n        if total_alone > 0:\n            print(f"\nAverage reduction (Python): {total_alone / max(total_python, 1):.1f}x")\n            print(f"Average reduction (MCP): {total_alone / max(total_mcp, 1):.1f}x")\n\n            saved_python = total_alone - total_python\n            saved_mcp = total_alone - total_mcp\n\n            print(f"\nTotal saved (Python): {saved_python:,} tokens ({saved_python/total_alone*100:.1f}%)")\n            print(f"Total saved (MCP): {saved_mcp:,} tokens ({saved_mcp/total_alone*100:.1f}%)")
#!/usr/bin/env python3\nimport sys, json, re\n\n"""\nUsage:\n  python scripts/eval_gate_guard.py <answers.jsonl>\n\nWhere each line is a JSON object containing:\n  {"q": "...", "repo": "project", "answer": "..."}\nThis fails if the answer lacks a [repo: ...] header or no file path-like citation.\n"""\n\nHEADER_RE = re.compile(r"^\[repo:\s*(project|project)\]", re.I | re.M)\nPATH_RE = re.compile(r"[A-Za-z0-9_\-./]+?\.[A-Za-z0-9_]+:\d+-\d+")\n\nok(answer: str) -> bool:\n    if not HEADER_RE.search(answer or ""):\n        return False\n    if not PATH_RE.search(answer or ""):\n        return False\n    return True
main():\n    if len(sys.argv) < 2:\n        print("usage: python scripts/eval_gate_guard.py <answers.jsonl>")\n        sys.exit(2)\n    bad = 0\n    with open(sys.argv[1], "r", errors="ignore") as f:\n        for i, line in enumerate(f, 1):\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                obj = json.loads(line)\n            except Exception:\n                print(f"line {i}: not json")\n                bad += 1\n                continue\n            ans = obj.get("answer", "")\n            if not ok(ans):\n                print(f"line {i}: FAIL (missing repo header or file citation)")\n                bad += 1\n    if bad:\n        print(f"\u274c guard failed: {bad} bad answer(s)")\n        sys.exit(3)\n    print("\u2713 guard passed")\n    sys.exit(0)\n\n\nif __name__ == "__main__":\n    main()
import json\nimport os\nimport re\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\nshould_skip_directory(path):\n    """Skip vendor/dependency directories"""\n    skip_patterns = [\n        'node_modules', '.venv', 'venv', '__pycache__', \n        '.git', 'dist', 'build', 'vendor', 'tmp',\n        'test', 'tests', 'spec', 'specs',  # test files\n        'migrations', 'db/migrate',  # migrations\n        'locale', 'locales', 'i18n',  # translations\n        '.bundle', 'coverage', '.pytest_cache'\n    ]\n    return any(skip in path for skip in skip_patterns)
extract_semantic_terms(file_path, code):\n    """Extract meaningful business/domain terms"""\n    terms = set()\n    \n    # 1. Extract from file/directory names (most semantic!)\n    path_parts = file_path.split('/')\n    for part in path_parts:\n        # Clean up: UserController.rb -> user, controller\n        cleaned = re.sub(r'[._-]', ' ', part)\n        words = re.findall(r'[A-Z][a-z]+|[a-z]+', cleaned)\n        terms.update(w.lower() for w in words if len(w) > 3)\n    \n    # 2. Extract class names (PascalCase)\n    class_names = re.findall(r'\bclass ([A-Z][a-zA-Z0-9_]+)', code)\n    for name in class_names:\n        # Split camelCase: AIStudioComponent -> ai, studio, component\n        words = re.findall(r'[A-Z][a-z]+|[A-Z]+(?=[A-Z]|$)', name)\n        terms.update(w.lower() for w in words if len(w) > 2)\n    \n    # 3. Extract function names (meaningful ones only)\n    func_names = re.findall(r'\b(?:def|function|const)\s+([a-z][a-zA-Z0-9_]+)', code)\n    for name in func_names:\n        # Only keep multi-word functions: validate_oauth not just get\n        if '_' in name:\n            words = name.split('_')\n            terms.update(w for w in words if len(w) > 3)\n    \n    # 4. Extract from comments (gold mine!)\n    comments = re.findall(r'(?:#|//|/\*|\*)\s*(.+)', code)\n    for comment in comments:\n        # Extract capitalized words (likely domain terms)\n        words = re.findall(r'\b[A-Z][a-z]{2,}\b', comment)\n        terms.update(w.lower() for w in words)\n    \n    # 5. Extract string literals (API endpoints, routes, etc)\n    strings = re.findall(r'["\']([^"\']{5,50})["\']', code)\n    for s in strings:\n        if '/' in s:  # likely a route\n            parts = s.split('/')\n            terms.update(p.lower() for p in parts if p.isalpha() and len(p) > 3)\n    \n    # Filter out programming keywords\n    stop_words = {\n        'return', 'function', 'class', 'const', 'import', 'export',\n        'from', 'self', 'this', 'super', 'none', 'null', 'true', 'false',\n        'async', 'await', 'yield', 'raise', 'assert', 'break', 'continue',\n        'string', 'number', 'boolean', 'object', 'array', 'type', 'interface',\n        'params', 'args', 'kwargs', 'options', 'config', 'props', 'state'\n    }\n    \n    return {t for t in terms if t not in stop_words and t.isalpha()}
analyze_repo_semantic(repo_path, repo_name):\n    """Find meaningful business domain terms"""\n    term_counts = Counter()\n    term_files = defaultdict(set)\n    directory_terms = Counter()\n    \n    total_files = 0\n    \n    for root, dirs, files in os.walk(repo_path):\n        # Skip vendor directories\n        if should_skip_directory(root):\n            continue\n        \n        # Remove skippable dirs from traversal\n        dirs[:] = [d for d in dirs if not should_skip_directory(os.path.join(root, d))]\n        \n        # Analyze directory name itself\n        dir_name = os.path.basename(root)\n        if dir_name and len(dir_name) > 3:\n            directory_terms[dir_name.lower()] += 1\n        \n        for file in files:\n            # Only source code files\n            if not any(file.endswith(ext) for ext in ['.py', '.js', '.ts', '.tsx', '.rb', '.yml', '.java']):\n                continue\n            \n            file_path = os.path.join(root, file)\n            rel_path = os.path.relpath(file_path, repo_path)\n            \n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    code = f.read()\n                    \n                terms = extract_semantic_terms(rel_path, code)\n                \n                for term in terms:\n                    term_counts[term] += 1\n                    term_files[term].add(rel_path)\n                \n                total_files += 1\n            except:\n                continue\n    \n    # Calculate relevance scores\n    scored_terms = []\n    for term, count in term_counts.items():\n        file_count = len(term_files[term])\n        \n        # Score formula:\n        # - Appears in multiple files (2-20% of codebase) = domain term\n        # - Too rare (1 file) = noise\n        # - Too common (>20% files) = generic utility\n        if file_count >= 2 and file_count <= total_files * 0.2:\n            # Boost if term appears in directory names (very semantic)\n            dir_boost = 2.0 if term in directory_terms else 1.0\n            \n            # Calculate domain specificity score\n            score = (count * file_count * dir_boost) / (total_files + 1)\n            \n            scored_terms.append({\n                'term': term,\n                'score': score,\n                'files': file_count,\n                'mentions': count,\n                'in_directories': term in directory_terms,\n                'sample_files': list(term_files[term])[:3]\n            })\n    \n    # Sort by score\n    scored_terms.sort(key=lambda x: x['score'], reverse=True)\n    \n    return scored_terms, total_files, directory_terms\n\nif __name__ == '__main__':\n    repos = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n    \n    all_results = {}\n    \n    for repo_name, repo_path in repos.items():\n        print(f'\n{"="*80}')\n        print(f'SEMANTIC ANALYSIS: {repo_name}')\n        print(f'{"="*80}')\n        \n        terms, total_files, directories = analyze_repo_semantic(repo_path, repo_name)\n        all_results[repo_name] = terms[:50]\n        \n        print(f'\nAnalyzed {total_files} files')\n        print(f'Found {len(terms)} meaningful domain terms')\n        print(f'\nTop 30 Business/Domain Keywords:\n')\n        \n        for i, t in enumerate(terms[:30], 1):\n            dir_marker = '📁' if t['in_directories'] else '  '\n            print(f'{i:2}. {dir_marker} {t["term"]:20} | Score: {t["score"]:8.1f} | {t["files"]:3} files | {t["mentions"]:4} mentions')\n        \n        # Show sample context\n        print(f'\n📄 Sample file locations for top terms:')\n        for t in terms[:5]:\n            print(f'\n  {t["term"]}:')\n            for f in t['sample_files']:\n                print(f'    - {f}')\n    \n    # Cross-analysis\n    print(f'\n{"="*80}')\n    print('CROSS-REPO COMPARISON')\n    print(f'{"="*80}')\n    \n    viv_terms = {t['term'] for t in all_results['project'][:30]}\n    fax_terms = {t['term'] for t in all_results['project'][:30]}\n    \n    shared = viv_terms & fax_terms\n    viv_only = viv_terms - fax_terms\n    fax_only = fax_terms - viv_terms\n    \n    print(f'\n🔄 Shared terms ({len(shared)}):')\n    if shared:\n        print(f'   {", ".join(sorted(shared)[:10])}')\n    \n    print(f'\n💊 PROJECT-specific ({len(viv_only)}):')\n    print(f'   {", ".join(sorted(list(viv_only)[:15]))}')\n    \n    print(f'\n📠 PROJECT-specific ({len(fax_only)}):')\n    print(f'   {", ".join(sorted(list(fax_only)[:15]))}')\n    \n    # Generate suggested queries\n    print(f'\n{"="*80}')\n    print('SUGGESTED EVAL QUERIES (based on actual terms)')\n    print(f'{"="*80}')\n    \n    for repo_name, terms in all_results.items():\n        print(f'\n{repo_name.upper()}:')\n        top_terms = terms[:10]\n        \n        # Generate natural queries\n        queries = []\n        for t in top_terms[:5]:\n            queries.append(f'  - "Where is {t["term"]} implemented?"')\n            if t['in_directories']:\n                queries.append(f'  - "How does {t["term"]} work?"')\n        \n        for q in queries[:8]:\n            print(q)\n    \n    # Save\n    with open('semantic_keywords.json', 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    print(f'\n✓ Saved to semantic_keywords.json')
#!/usr/bin/env python3\n"""\nCompare token usage across FOUR approaches:\n\n1. Claude Alone (no RAG) - reads full files via grep\n2. RAG CLI Standalone - RAG answers directly (no Claude)\n3. Claude + RAG Direct - Claude gets full code chunks from RAG\n4. Claude + RAG via MCP - Claude gets MCP metadata responses\n\nShows actual tokens sent to LLM in each scenario.\n"""\n\nimport sys\nimport os\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\nimport json\nfrom pathlib import Path\n\n# Try tiktoken for precise counts\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print("⚠️  Install tiktoken for precise counts: pip install tiktoken\n")
count_tokens(text: str, model: str = "gpt-4o") -> int:\n    """Count tokens precisely or estimate"""\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    return len(text) // 4\n\n\n# ============================================================\n# Approach 1: Claude Alone (Traditional - NO RAG)\n# ============================================================
approach1_claude_alone(question: str, repo: str):\n    """\n    Claude without RAG:\n    - Extract keywords\n    - Grep files\n    - Read 5-10 FULL files\n    """\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'project': os.getenv('project_PATH', '/abs/path/to/project')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'error': f'Repo not found: {repo_path}'}\n\n    # Keywords from question\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find files\n    matched_files = []\n    full_content = ""\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        if any(skip in str(py_file) for skip in ['node_modules', '.venv', 'vendor', '.git', '__pycache__']):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                full_content += f"\n{'='*70}\nFile: {py_file}\n{'='*70}\n{content}\n"\n\n                if len(matched_files) >= 10:\n                    break\n        except:\n            pass\n\n    tokens = count_tokens(full_content)\n\n    return {\n        'method': '1. Claude Alone (no RAG)',\n        'description': 'Reads full files matching keywords',\n        'files_read': len(matched_files),\n        'tokens': tokens,\n        'sample_files': [Path(f).name for f in matched_files[:3]]\n    }\n\n\n# ============================================================\n# Approach 2: RAG CLI Standalone (no Claude)\n# ============================================================
approach2_rag_standalone(question: str, repo: str):\n    """\n    RAG CLI standalone - full answer generation without Claude.\n    Counts the generated answer + citations.\n    """\n    try:\n        from server.langgraph_app import build_graph\n\n        # Build graph and run (with required thread_id config)\n        graph = build_graph()\n        result = graph.invoke(\n            {\n                "question": question,\n                "repo": repo,\n            },\n            config={"configurable": {"thread_id": "test-comparison"}}\n        )\n\n        # What gets generated\n        answer_text = result.get('answer', '')\n        citations_text = '\n'.join([\n            f"{c.get('file_path', '')}:{c.get('start_line', '')}-{c.get('end_line', '')}"\n            for c in result.get('citations', [])\n        ])\n\n        full_output = f"Answer:\n{answer_text}\n\nCitations:\n{citations_text}"\n        tokens = count_tokens(full_output)\n\n        return {\n            'method': '2. RAG CLI Standalone',\n            'description': 'RAG generates answer directly (no Claude)',\n            'tokens': tokens,\n            'answer_length': len(answer_text),\n            'citations_count': len(result.get('citations', []))\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 3: Claude + RAG Direct (full chunks)\n# ============================================================
approach3_claude_plus_rag_direct(question: str, repo: str, top_k: int = 10):\n    """\n    Claude gets full code chunks from RAG.\n    This is what would happen if Claude called hybrid_search directly.\n    """\n    try:\n        from retrieval.hybrid_search import search_routed_multi\n\n        results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n        # Build what gets sent to Claude\n        context = "Retrieved code chunks:\n\n"\n        for r in results:\n            context += f"File: {r['file_path']}:{r['start_line']}-{r['end_line']}\n"\n            context += f"Score: {r['rerank_score']:.3f}\n"\n            context += f"Code:\n{r.get('code', '')}\n\n"\n\n        tokens = count_tokens(context)\n\n        return {\n            'method': '3. Claude + RAG Direct',\n            'description': 'Claude gets full code chunks from RAG',\n            'chunks': len(results),\n            'tokens': tokens,\n            'files_touched': len(set(r['file_path'] for r in results))\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 4: Claude + RAG via MCP (metadata only)\n# ============================================================
approach4_claude_plus_rag_mcp(question: str, repo: str, top_k: int = 10):\n    """\n    Claude gets MCP tool response (metadata, no full code).\n    This is what I (Claude Code) actually receive.\n\n    IMPORTANT: MCP tool schemas are sent with EVERY request!\n    """\n    try:\n        from server.mcp.server import MCPServer\n\n        server = MCPServer()\n\n        # Get tool schemas (sent with every request)\n        tools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\n        tools_resp = server.handle_request(tools_req)\n        tools_json = json.dumps(tools_resp['result']['tools'])\n        schema_tokens = count_tokens(tools_json)\n\n        # Get the actual search response\n        search_req = {\n            'jsonrpc': '2.0',\n            'id': 1,\n            'method': 'tools/call',\n            'params': {\n                'name': 'rag_search',\n                'arguments': {\n                    'repo': repo,\n                    'question': question,\n                    'top_k': top_k\n                }\n            }\n        }\n\n        search_resp = server.handle_request(search_req)\n\n        # The MCP response is what Claude receives\n        mcp_response = search_resp['result']['content'][0]['text']\n        response_tokens = count_tokens(mcp_response)\n\n        # Total = schemas + response\n        total_tokens = schema_tokens + response_tokens\n\n        # Parse to get metadata\n        result_data = json.loads(mcp_response)\n\n        return {\n            'method': '4. Claude + RAG via MCP',\n            'description': 'Claude gets MCP metadata (paths + scores only) + tool schemas',\n            'chunks': result_data.get('count', 0),\n            'tokens': total_tokens,\n            'schema_tokens': schema_tokens,\n            'response_tokens': response_tokens,\n            'breakdown': f'{schema_tokens} (schemas) + {response_tokens} (response)'\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Run Comparison\n# ============================================================
run_comparison(question: str, repo: str):\n    """Run all four approaches and compare"""\n    print(f"\n{'='*75}")\n    print(f"QUESTION: {question}")\n    print(f"REPO: {repo}")\n    print(f"{'='*75}\n")\n\n    results = []\n\n    # Run each approach\n    approaches = [\n        ("Claude Alone", approach1_claude_alone),\n        ("RAG CLI Standalone", approach2_rag_standalone),\n        ("Claude + RAG Direct", approach3_claude_plus_rag_direct),\n        ("Claude + RAG via MCP", approach4_claude_plus_rag_mcp),\n    ]\n\n    for name, func in approaches:\n        print(f"⏳ Testing: {name}...")\n        result = func(question, repo)\n        results.append(result)\n\n    # Print results\n    print(f"\n{'='*75}")\n    print("RESULTS (tokens sent to LLM):")\n    print(f"{'='*75}\n")\n\n    for i, result in enumerate(results, 1):\n        if 'error' in result:\n            print(f"{i}. {result.get('method', 'Unknown')}: ERROR - {result['error']}")\n            continue\n\n        print(f"{i}. {result['method']}")\n        print(f"   {result['description']}")\n        print(f"   Tokens: {result['tokens']:,}")\n\n        # Show method-specific details\n        if 'files_read' in result:\n            print(f"   Files read: {result['files_read']}")\n            if result.get('sample_files'):\n                print(f"   Sample: {', '.join(result['sample_files'])}")\n\n        if 'chunks' in result:\n            print(f"   Chunks: {result['chunks']}")\n\n        if 'files_touched' in result:\n            print(f"   Files: {result['files_touched']}")\n\n        if 'citations_count' in result:\n            print(f"   Citations: {result['citations_count']}")\n\n        if 'breakdown' in result:\n            print(f"   Breakdown: {result['breakdown']}")\n\n        print()\n\n    # Calculate savings\n    valid_results = [r for r in results if 'error' not in r and 'tokens' in r]\n\n    if len(valid_results) >= 2:\n        baseline = valid_results[0]['tokens']  # Claude alone\n\n        print(f"{'='*75}")\n        print("💰 SAVINGS vs Claude Alone:")\n        print(f"{'='*75}\n")\n\n        for result in valid_results[1:]:\n            tokens = result['tokens']\n            saved = baseline - tokens\n            pct = (saved / baseline * 100) if baseline > 0 else 0\n            reduction = baseline / tokens if tokens > 0 else 0\n\n            print(f"{result['method']}:")\n            print(f"   Tokens saved: {saved:,}")\n            print(f"   Percentage: {pct:.1f}%")\n            print(f"   Reduction: {reduction:.1f}x")\n\n            # Cost (gpt-4o: $2.50/1M input)\n            cost_saved = saved * (2.50 / 1_000_000)\n            print(f"   $ saved/query: ${cost_saved:.6f}")\n            print(f"   $ saved/1000: ${cost_saved * 1000:.2f}\n")\n\n    return results\n\n\n# ============================================================\n# Main\n# ============================================================\n\nif __name__ == '__main__':\n    if not HAS_TIKTOKEN:\n        print("Installing tiktoken for accurate counts...")\n        os.system("pip install -q tiktoken")\n        try:\n            import tiktoken\n            HAS_TIKTOKEN = True\n            print("✓ tiktoken installed\n")\n        except:\n            print("⚠️  Using estimates (1 token ≈ 4 chars)\n")\n\n    # Test cases\n    tests = [\n        ("Where is OAuth token validated", "project"),\n        ("How are fax jobs created and dispatched", "project"),\n    ]\n\n    all_results = []\n\n    for question, repo in tests:\n        try:\n            results = run_comparison(question, repo)\n            all_results.append({\n                'question': question,\n                'repo': repo,\n                'results': results\n            })\n        except Exception as e:\n            print(f"\n❌ Error: {e}\n")\n\n    # Overall summary\n    if all_results:\n        print(f"\n{'='*75}")\n        print("📊 SUMMARY")\n        print(f"{'='*75}\n")\n\n        print(f"Total queries tested: {len(all_results)}\n")\n\n        # Average by method\n        methods = ['Claude Alone', 'RAG CLI Standalone', 'Claude + RAG Direct', 'Claude + RAG via MCP']\n\n        for method in methods:\n            tokens = []\n            for test in all_results:\n                for r in test['results']:\n                    if r.get('method', '').startswith(method.split()[0]) and 'tokens' in r:\n                        tokens.append(r['tokens'])\n\n            if tokens:\n                avg = sum(tokens) / len(tokens)\n                print(f"{method}: {avg:,.0f} avg tokens")\n\n        print(f"\n🎯 Recommendation:")\n        print(f"   Use MCP tools for maximum token efficiency")\n        print(f"   Use RAG CLI for standalone Q&A without Claude")\n        print(f"   Use Direct calls for custom integrations")
#!/usr/bin/env python3\n"""\nInteractive quick setup to:\n  1) Add the current working directory as a repo (repos.json)\n  2) Optionally index it\n  3) Ensure venv + deps\n  4) Optionally start infra (Qdrant/Redis via docker compose)\n  5) Register MCP servers with Codex CLI and Claude Code\n\nRun this from the ROOT of the repo you want to index:\n  python /path/to/rag-service/scripts/quick_setup.py\n\nNotes:\n  - Never writes secrets without confirmation\n  - Creates timestamped backups of modified config files\n  - Uses Rich spinners/progress so users always see activity\n"""\nimport os\nimport sys\nimport json\nimport time\nimport platform\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\ntry:\n    from rich.console import Console\n    from rich.panel import Panel\n    from rich.prompt import Confirm, Prompt\n    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn\nexcept Exception:\n    print("This setup requires 'rich'. Install with: pip install rich", file=sys.stderr)\n    sys.exit(1)\n\nconsole = Console()
write_repos_json(rag_root: Path, name: str, code_path: Path) -> Path:\n    p = os.getenv('REPOS_FILE') or str(rag_root / 'repos.json')\n    repos_path = Path(p)\n    cfg = {'default_repo': name, 'repos': []}\n    if repos_path.exists():\n        try:\n            cfg = json.loads(repos_path.read_text())\n            if not isinstance(cfg, dict):\n                cfg = {'default_repo': name, 'repos': []}\n        except Exception:\n            cfg = {'default_repo': name, 'repos': []}\n    # Update or append\n    repos = cfg.get('repos') or []\n    found = False\n    for r in repos:\n        if (r.get('name') or '').strip().lower() == name.lower():\n            r['path'] = str(code_path)\n            found = True\n            break\n    if not found:\n        repos.append({'name': name, 'path': str(code_path), 'keywords': [], 'path_boosts': [], 'layer_bonuses': {}})\n    cfg['repos'] = repos\n    # Ask to set default\n    if Confirm.ask(f"Make [bold]{name}[/bold] the default repo?", default=True):\n        cfg['default_repo'] = name\n    repos_path.write_text(json.dumps(cfg, indent=2))\n    return repos_path
_venv_python(repo_root: Path) -> Path:\n    if platform.system().lower().startswith('win'):\n        return repo_root / '.venv' / 'Scripts' / 'python.exe'\n    return repo_root / '.venv' / 'bin' / 'python'
ensure_venv_and_deps(rag_root: Path, progress: Progress, task_id) -> bool:\n    """Create .venv and install deps if needed."""\n    py = _venv_python(rag_root)\n    # Create venv if missing\n    if not py.exists():\n        progress.update(task_id, description='Creating virtualenv (.venv)')\n        try:\n            subprocess.check_call([sys.executable, '-m', 'venv', str(rag_root / '.venv')])\n        except subprocess.CalledProcessError as e:\n            console.print(f"[red]Failed to create venv:[/red] {e}")\n            return False\n    # Install deps\n    progress.update(task_id, description='Installing dependencies')\n    try:\n        reqs = [str(rag_root / 'requirements-rag.txt'), str(rag_root / 'requirements.txt')]\n        for req in reqs:\n            if Path(req).exists():\n                subprocess.check_call([str(py), '-m', 'pip', 'install', '--disable-pip-version-check', '-r', req])\n        # quick sanity imports\n        subprocess.check_call([str(py), '-c', 'import fastapi,qdrant_client,bm25s,langgraph;print("ok")'])\n        return True\n    except subprocess.CalledProcessError as e:\n        console.print(f"[red]Dependency install failed:[/red] {e}")\n        return False
start_infra(rag_root: Path, progress: Progress, task_id) -> None:\n    progress.update(task_id, description='Starting Qdrant/Redis (docker compose)')\n    up = rag_root / 'scripts' / 'up.sh'\n    if not up.exists():\n        progress.update(task_id, description='Infra script not found (skipping)')\n        time.sleep(0.3)\n        return\n    try:\n        subprocess.check_call(['bash', str(up)])\n    except Exception as e:\n        console.print(f"[yellow]Infra start skipped/failed:[/yellow] {e}")\n    # quick qdrant ping\n    progress.update(task_id, description='Verifying Qdrant/Redis health')\n    try:\n        subprocess.check_call(['bash', '-lc', 'curl -s http://127.0.0.1:6333/collections >/dev/null || true'])\n    except Exception:\n        pass\n\ndetect_codex() -> str | None:\n    path = shutil.which('codex')\n    return path
codex_register(rag_root: Path, progress: Progress, task_id) -> None:\n    path = detect_codex()\n    if not path:\n        progress.update(task_id, description='Codex CLI not found (skip)')\n        time.sleep(0.3)\n        return\n    py = _venv_python(rag_root)\n    server = rag_root / 'mcp_server.py'\n    name = 'rag-service'\n    progress.update(task_id, description='Registering MCP with Codex')\n    try:\n        # remove existing silently\n        subprocess.run(['codex', 'mcp', 'remove', name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        subprocess.check_call(['codex', 'mcp', 'add', name, '--', str(py), str(server)])\n    except subprocess.CalledProcessError as e:\n        console.print(f"[yellow]Codex registration failed:[/yellow] {e}")
_claude_config_path() -> Path | None:\n    sysname = platform.system().lower()\n    home = Path.home()\n    if 'darwin' in sysname or 'mac' in sysname:\n        return (home / 'Library' / 'Application Support' / 'Claude' / 'claude_desktop_config.json')\n    if 'linux' in sysname:\n        return (home / '.config' / 'Claude' / 'claude_desktop_config.json')\n    if 'windows' in sysname or 'win' in sysname:\n        appdata = os.getenv('APPDATA')\n        if appdata:\n            return Path(appdata) / 'Claude' / 'claude_desktop_config.json'\n    return None
claude_register(rag_root: Path, progress: Progress, task_id) -> None:\n    cfgp = _claude_config_path()\n    if not cfgp:\n        progress.update(task_id, description='Claude config path not found (skip)')\n        time.sleep(0.3)\n        return\n    cfgp.parent.mkdir(parents=True, exist_ok=True)\n    py = _venv_python(rag_root)\n    server = rag_root / 'mcp_server.py'\n    # Load existing\n    data = {}\n    if cfgp.exists():\n        try:\n            data = json.loads(cfgp.read_text())\n        except Exception:\n            data = {}\n        # backup\n        bak = cfgp.with_suffix(cfgp.suffix + f'.bak.{time.strftime("%Y%m%d-%H%M%S")}')\n        bak.write_text(json.dumps(data, indent=2))\n    # Merge entry\n    ms = data.get('mcpServers') or {}\n    ms['rag-service'] = {\n        'command': str(py),\n        'args': [str(server)],\n        'env': {\n            'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY', '')\n        }\n    }\n    data['mcpServers'] = ms\n    progress.update(task_id, description='Writing Claude config')\n    cfgp.write_text(json.dumps(data, indent=2))
main():\n    rag_root = Path(__file__).resolve().parents[1]\n    # Allow explicit path override for code repo\n    forced_path = None\n    forced_name = None\n    argv = sys.argv[1:]\n    for i, a in enumerate(argv):\n        if a.startswith('--path='):\n            forced_path = a.split('=', 1)[1].strip()\n        elif a == '--path' and i+1 < len(argv):\n            forced_path = argv[i+1].strip()\n        elif a.startswith('--name='):\n            forced_name = a.split('=', 1)[1].strip()\n        elif a == '--name' and i+1 < len(argv):\n            forced_name = argv[i+1].strip()\n\n    code_root = Path(forced_path or os.getcwd()).resolve()\n    suggested = (forced_name or code_root.name.lower().replace(' ', '-').replace('_', '-'))\n    title = "RAG Service — Quick Setup"\n    msg = (\n        f"Detected current directory:\n[bold]{code_root}[/bold]\n\n"\n        "Create or update repos.json to include this path?\n"\n    )\n    console.print(Panel(msg, title=title, border_style="cyan"))\n    if not Confirm.ask("Add this repo?", default=True):\n        console.print("[yellow]Canceled.[/yellow]")\n        return\n    name = forced_name or Prompt.ask("Repository name", default=suggested)\n    repos_path = write_repos_json(rag_root, name, code_root)\n    console.print(f"[green]✓[/green] Updated {repos_path}")\n\n    # Offer to index\n    console.print(Panel(\n        "Index now? This builds BM25 and embeddings; it may take time and bill your provider if configured.",\n        title="Index Repository", border_style="yellow"\n    ))\n    do_index = Confirm.ask("Start indexing now?", default=False)\n\n    console.print(Panel("Setup environment and agents?", title="Agents & Infra", border_style="cyan"))\n    do_env = Confirm.ask("Ensure virtualenv + dependencies?", default=True)\n    do_infra = Confirm.ask("Start Qdrant/Redis (docker compose)?", default=True)\n    do_codex = Confirm.ask("Register Codex MCP?", default=True)\n    do_claude = Confirm.ask("Register Claude MCP?", default=True)\n\n    with Progress(\n        SpinnerColumn(style='cyan'),\n        TextColumn("{task.description}"),\n        BarColumn(bar_width=None),\n        TimeElapsedColumn(),\n        transient=True,\n    ) as progress:\n        if do_env:\n            t = progress.add_task("Preparing environment", total=None)\n            ok = ensure_venv_and_deps(rag_root, progress, t)\n            progress.remove_task(t)\n            if not ok:\n                console.print("[red]Environment setup failed; continuing without guarantees.[/red]")\n        if do_infra:\n            t = progress.add_task("Starting infra", total=None)\n            start_infra(rag_root, progress, t)\n            progress.remove_task(t)\n        if do_index:\n            t = progress.add_task("Indexing repository", total=None)\n            env = os.environ.copy()\n            env['REPO'] = name\n            try:\n                subprocess.check_call([str(_venv_python(rag_root)), str(rag_root / 'index_repo.py')], env=env, cwd=str(rag_root))\n                console.print(f"[green]✓[/green] Indexed repo: [bold]{name}[/bold]")\n            except subprocess.CalledProcessError as e:\n                console.print(f"[red]Indexing failed:[/red] {e}")\n            progress.remove_task(t)\n        if do_codex:\n            t = progress.add_task("Registering Codex", total=None)\n            codex_register(rag_root, progress, t)\n            progress.remove_task(t)\n        if do_claude:\n            t = progress.add_task("Registering Claude", total=None)\n            claude_register(rag_root, progress, t)\n            progress.remove_task(t)\n\n    # Friendly next-steps banner\n    console.print(Panel(\n        "Setup complete. Next steps:\n"\n        " • Type 'codex' and try: Use rag_search to find OAuth in your repo\n"\n        f" • Or run API: uvicorn serve_rag:app --host 127.0.0.1 --port 8012\n"\n        f" • CLI streaming: python chat_cli.py --stream --api-url http://127.0.0.1:8012\n",\n        title="You're ready!", border_style="green"\n    ))\n\n\nif __name__ == '__main__':\n    main()
#!/usr/bin/env python3\nfrom __future__ import annotations\nimport os, time, json, tempfile, signal, subprocess\nfrom pathlib import Path\nfrom playwright.sync_api import sync_playwright, expect\n\nROOT = Path(__file__).resolve().parents[1]\nBASE = "http://127.0.0.1:8012"\n\nwait_health(timeout=20):\n    import urllib.request, urllib.error\n    start = time.time()\n    while time.time() - start < timeout:\n        try:\n            with urllib.request.urlopen(f"{BASE}/health", timeout=2) as resp:\n                if resp.status == 200:\n                    return True\n        except Exception:\n            time.sleep(0.5)\n    return False
main() -> int:\n    # Use existing server\n    assert wait_health(5), "server not running on 8012"\n\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=False)\n        ctx = browser.new_context()\n        page = ctx.new_page()\n        page.goto(f"{BASE}/gui/", wait_until="domcontentloaded")\n        page.wait_for_timeout(1000)\n\n        # Test Health button\n        print("Testing health button...")\n        page.click('#btn-health')\n        page.wait_for_timeout(1000)\n        hs = page.locator('#health-status').text_content()\n        print(f"  health: {hs}")\n\n        # Test Overview section load\n        print("\nTesting overview section...")\n        overview_text = page.locator('#overview-section').text_content()\n        print(f"  overview contains {len(overview_text)} chars")\n        if "—" in overview_text or not overview_text.strip():\n            print("  ❌ Overview appears empty/placeholder")\n        else:\n            print("  ✓ Overview has content")\n\n        # Test Configure button (wizard)\n        print("\nTesting configure button...")\n        page.click('#btn-wizard')\n        page.wait_for_timeout(2000)\n        wizard_out = page.locator('#wizard-output').text_content()\n        print(f"  wizard output: {wizard_out[:200] if wizard_out else '(empty)'}")\n        if not wizard_out or wizard_out.strip() == "":\n            print("  ❌ Wizard produced no output")\n        else:\n            print("  ✓ Wizard generated output")\n\n        # Test Cost calc with select_option\n        print("\nTesting cost calculator...")\n        page.select_option('#cost-provider', 'openai')\n        page.select_option('#cost-model', 'gpt-4o-mini')\n        page.fill('#cost-in', '500')\n        page.fill('#cost-out', '800')\n        page.fill('#cost-rpd', '100')\n        page.click('#btn-estimate')\n        page.wait_for_timeout(1000)\n        daily = page.locator('#cost-daily').text_content()\n        print(f"  cost daily: {daily}")\n        if daily == "—":\n            print("  ❌ Cost calc not working")\n        else:\n            print("  ✓ Cost calc working")\n\n        print("\n\nPress Enter to close browser...")\n        input()\n        browser.close()\n    return 0\n\n\nif __name__ == '__main__':\n    raise SystemExit(main())
#!/usr/bin/env python3\n"""\nMeasure actual token savings from RAG vs traditional file reading.\nCompares targeted RAG retrieval against reading full files.\n"""\n\nimport sys\nimport os\nfrom pathlib import Path\nfrom retrieval.hybrid_search import search_routed_multi\n\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print("⚠️  tiktoken not installed - using rough estimates (1 token ≈ 4 chars)")\n    print("   Install with: pip install tiktoken\n")\n\ncount_tokens(text: str, model: str = "gpt-4o") -> int:\n    """Count tokens precisely if tiktoken available, else estimate"""\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    # Fallback: rough estimate\n    return len(text) // 4
measure_rag_tokens(question: str, repo: str, top_k: int = 10):\n    """Measure tokens using RAG hybrid search"""\n    results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n    # Combine all retrieved code\n    combined_text = ""\n    for r in results:\n        combined_text += f"File: {r['file_path']}:{r['start_line']}-{r['end_line']}\n"\n        combined_text += r.get('code', '') + "\n\n"\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'RAG (hybrid search)',\n        'chunks': len(results),\n        'text': combined_text,\n        'tokens': tokens,\n        'files_touched': len(set(r['file_path'] for r in results))\n    }
measure_traditional_tokens(question: str, repo: str, max_files: int = 10):\n    """\n    Simulate traditional approach: grep for keywords, read full files.\n    This is what you'd do WITHOUT RAG.\n    """\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'approach': 'Traditional', 'error': f'Repo not found: {repo_path}'}\n\n    # Extract keywords from question (simulate what a human would grep for)\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find files containing keywords\n    combined_text = ""\n    matched_files = []\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        if 'node_modules' in str(py_file) or '.venv' in str(py_file):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n\n            # If any keyword appears, a human would likely read this whole file\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                combined_text += f"\n{'='*60}\nFile: {py_file}\n{'='*60}\n"\n                combined_text += content + "\n"\n\n                if len(matched_files) >= max_files:\n                    break\n        except Exception as e:\n            pass\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'Traditional (grep + read full files)',\n        'files_read': len(matched_files),\n        'text': combined_text,\n        'tokens': tokens\n    }
run_comparison(question: str, repo: str):\n    """Run both approaches and compare"""\n    print(f"\n{'='*70}")\n    print(f"Question: {question}")\n    print(f"Repository: {repo}")\n    print(f"{'='*70}\n")\n\n    # Measure RAG\n    print("⏳ Running RAG hybrid search...")\n    rag = measure_rag_tokens(question, repo, top_k=10)\n\n    # Measure traditional\n    print("⏳ Simulating traditional grep + file reading...")\n    trad = measure_traditional_tokens(question, repo, max_files=10)\n\n    # Print results\n    print(f"\n{'='*70}")\n    print("📊 RESULTS:")\n    print(f"{'='*70}")\n\n    print(f"\n🔍 RAG Approach:")\n    print(f"   Chunks retrieved: {rag['chunks']}")\n    print(f"   Files touched: {rag['files_touched']}")\n    print(f"   Total tokens: {rag['tokens']:,}")\n\n    print(f"\n📁 Traditional Approach (grep + read full files):")\n    print(f"   Files read: {trad['files_read']}")\n    print(f"   Total tokens: {trad['tokens']:,}")\n\n    # Calculate savings\n    if trad['tokens'] > 0 and rag['tokens'] > 0:\n        saved = trad['tokens'] - rag['tokens']\n        saved_pct = (saved / trad['tokens']) * 100\n        reduction = trad['tokens'] / rag['tokens']\n\n        print(f"\n{'='*70}")\n        print("💰 TOKEN SAVINGS:")\n        print(f"{'='*70}")\n        print(f"   Tokens saved: {saved:,} tokens")\n        print(f"   Percentage saved: {saved_pct:.1f}%")\n        print(f"   Reduction factor: {reduction:.1f}x smaller")\n\n        # Cost estimate (rough: $15/1M input tokens for gpt-4o)\n        cost_per_token = 15 / 1_000_000\n        cost_saved = saved * cost_per_token\n        print(f"   Cost saved per query: ${cost_saved:.6f}")\n        print(f"   Cost saved per 1000 queries: ${cost_saved * 1000:.2f}")\n\n    return rag, trad\n\n\nif __name__ == '__main__':\n    # Test queries\n    test_cases = [\n        ("Where is OAuth token validated", "project"),\n        ("How are fax jobs created and dispatched", "project"),\n        ("EventStream component event types", "project"),\n        ("provider health status implementation", "project"),\n    ]\n\n    results = []\n\n    for question, repo in test_cases:\n        try:\n            rag, trad = run_comparison(question, repo)\n            results.append({\n                'question': question,\n                'repo': repo,\n                'rag_tokens': rag['tokens'],\n                'trad_tokens': trad['tokens'],\n                'savings': trad['tokens'] - rag['tokens']\n            })\n        except Exception as e:\n            print(f"\n❌ Error testing '{question}': {e}")\n\n    # Summary\n    if results:\n        print(f"\n\n{'='*70}")\n        print("📈 OVERALL SUMMARY")\n        print(f"{'='*70}")\n\n        total_rag = sum(r['rag_tokens'] for r in results)\n        total_trad = sum(r['trad_tokens'] for r in results)\n        total_saved = total_trad - total_rag\n\n        print(f"\nTotal queries tested: {len(results)}")\n        print(f"Total RAG tokens: {total_rag:,}")\n        print(f"Total traditional tokens: {total_trad:,}")\n        print(f"Total saved: {total_saved:,} tokens ({(total_saved/total_trad*100):.1f}%)")\n        print(f"Average reduction: {total_trad/total_rag:.1f}x\n")
#!/usr/bin/env python3\n"""\nMake a repos.json from simple CLI args.\n\nUsage examples:\n  python scripts/make_repos_json.py repo-a=/abs/path/a repo-b=/abs/path/b --default repo-a\n\nEnvironment fallbacks:\n  REPO and REPO_PATH if provided (single repo).\n\nBehavior:\n  - Writes repos.json in repo root (or REPOS_FILE location if set)\n  - If repos.json exists, writes a timestamped backup next to it\n"""\nimport os, sys, json, time\nfrom pathlib import Path\n\nparse_args(argv):\n    pairs = []\n    default_repo = None\n    for arg in argv:\n        if arg == '--help' or arg == '-h':\n            print(__doc__)\n            sys.exit(0)\n        if arg.startswith('--default='):\n            default_repo = arg.split('=',1)[1].strip()\n            continue\n        if arg == '--default':\n            # next token is default\n            # handled in caller for simplicity\n            continue\n        if '=' in arg:\n            name, path = arg.split('=',1)\n            name = name.strip()\n            path = path.strip()\n            if name and path:\n                pairs.append((name, path))\n    # Handle "--default name" form\n    if '--default' in argv:\n        i = argv.index('--default')\n        if i+1 < len(argv):\n            default_repo = argv[i+1].strip()\n    return pairs, default_repo
main():\n    args = sys.argv[1:]\n    pairs, default_repo = parse_args(args)\n\n    # Fallback to env for single-repo if no pairs passed\n    if not pairs:\n        env_repo = (os.getenv('REPO') or '').strip()\n        env_path = (os.getenv('REPO_PATH') or '').strip()\n        if env_repo and env_path:\n            pairs = [(env_repo, env_path)]\n            if not default_repo:\n                default_repo = env_repo\n        else:\n            print('No repo arguments provided and REPO/REPO_PATH not set. Example: repo-a=/abs/path/a')\n            sys.exit(2)\n\n    # Build config structure\n    repos = []\n    for name, path in pairs:\n        repos.append({\n            'name': name,\n            'path': str(Path(path).expanduser()),\n            'keywords': [],\n            'path_boosts': [],\n            'layer_bonuses': {}\n        })\n\n    if not default_repo:\n        default_repo = repos[0]['name']\n\n    cfg = {'default_repo': default_repo, 'repos': repos}\n\n    # Output path\n    out = os.getenv('REPOS_FILE') or str(Path(__file__).resolve().parents[1] / 'repos.json')\n    outp = Path(out)\n    outp_parent = outp.parent\n    outp_parent.mkdir(parents=True, exist_ok=True)\n\n    # Backup existing\n    if outp.exists():\n        ts = time.strftime('%Y%m%d-%H%M%S')\n        bak = outp.with_suffix(outp.suffix + f'.bak.{ts}')\n        bak.write_text(outp.read_text())\n        print(f'Backed up existing {outp} -> {bak}')\n\n    outp.write_text(json.dumps(cfg, indent=2))\n    print(f'Wrote {outp} with {len(repos)} repo(s); default_repo={default_repo}')\n\n\nif __name__ == '__main__':\n    main()
import os\nfrom retrieval.hybrid_search import search_routed_multi\n\nTESTS = [\n    ('project','ai studio','easy'),\n    ('project','TBAC trait system','easy'),\n    ('project','plugin builder','easy'),\n    ('project','webhook verification','easy'),\n    ('project','three lane gateway','medium'),\n    ('project','plugin sandbox isolation','medium'),\n    ('project','provider adapter traits','medium'),\n    ('project','canonical event normalization','medium'),\n    ('project','how does TBAC prevent PHI access','hard'),\n    ('project','what is the general purpose of project','hard'),\n    ('project','how do different providers interact','hard'),\n]\n\nos.environ.setdefault('EMBEDDING_TYPE', 'local')\n\nby_diff = {}\nfor repo, q, d in TESTS:\n    docs = search_routed_multi(q, repo_override=repo, final_k=5)\n    s = (docs or [{}])[0].get('rerank_score', 0.0)\n    by_diff.setdefault(d, []).append(s)\n\nprint('\n' + '='*80)\nprint('FINAL PERFORMANCE METRICS')\nprint('='*80)\n\nTARGET = {'easy':0.80, 'medium':0.70, 'hard':0.65}\nall_scores = []\nfor d, arr in by_diff.items():
avg = sum(arr)/max(1,len(arr))\n    all_scores.extend(arr)\n    status = '✓' if avg >= TARGET[d] else '✗'\n    print(f"{status} {d.upper():7} | Avg: {avg:.3f} | Target: {TARGET[d]:.3f}")\n\noverall = sum(all_scores)/max(1,len(all_scores))\nprint(f"\n{'Overall Average:':20} {overall:.3f}")\nprint('='*80)
import json\nimport os\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\nimport re\nextract_tokens(code):\n    """Extract meaningful tokens from code"""\n    # Remove strings and comments\n    code = re.sub(r'["\'].*?["\']', '', code)\n    code = re.sub(r'#.*?\n', '', code)\n    code = re.sub(r'//.*?\n', '', code)\n    \n    # Extract identifiers (camelCase, snake_case, etc)\n    tokens = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', code)\n    return [t.lower() for t in tokens if len(t) > 2]
analyze_repo(repo_path):\n    """Analyze a repo for discriminative keywords"""\n    file_tokens = defaultdict(set)  # file -> set of tokens\n    global_counts = Counter()  # token -> total count\n    \n    for root, dirs, files in os.walk(repo_path):\n        # Skip common ignore patterns\n        dirs[:] = [d for d in dirs if d not in {'.git', 'node_modules', '__pycache__', '.venv', 'dist', 'build'}]\n        \n        for file in files:\n            if not any(file.endswith(ext) for ext in ['.py', '.js', '.ts', '.tsx', '.rb', '.java', '.go']):\n                continue\n                \n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    code = f.read()\n                    tokens = extract_tokens(code)\n                    file_tokens[file_path].update(tokens)\n                    global_counts.update(tokens)\n            except:\n                continue\n    \n    # Calculate TF-IDF style scores\n    num_files = len(file_tokens)\n    doc_freq = Counter()  # how many files contain each token\n    \n    for tokens in file_tokens.values():\n        doc_freq.update(tokens)\n    \n    # Score = term frequency * inverse document frequency\n    keyword_scores = {}\n    for token, total_count in global_counts.items():\n        df = doc_freq[token]\n        idf = num_files / df if df > 0 else 0\n        \n        # High score = appears often but in few files (discriminative)\n        # Low score = appears everywhere (stop word) or rarely (noise)\n        if df > 1 and df < num_files * 0.05:  # in 2+ files but <5% of files\n            keyword_scores[token] = total_count * idf\n    \n    return keyword_scores, doc_freq, num_files
find_discriminative_keywords(repo_path, top_n=50):\n    """Find the most discriminative keywords in a repo"""\n    keyword_scores, doc_freq, num_files = analyze_repo(repo_path)\n    \n    # Sort by score\n    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n    \n    results = []\n    for token, score in sorted_keywords[:top_n]:\n        results.append({\n            'keyword': token,\n            'score': round(score, 2),\n            'appears_in_files': doc_freq[token],\n            'file_percentage': round(100 * doc_freq[token] / num_files, 1)\n        })\n    \n    return results\n\nif __name__ == '__main__':\n    repos = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'project': os.getenv('project_PATH', '/abs/path/to/project')\n    }\n    \n    all_results = {}\n    \n    for repo_name, repo_path in repos.items():\n        print(f'\n{"="*80}')\n        print(f'ANALYZING: {repo_name}')\n        print(f'{"="*80}')\n        \n        keywords = find_discriminative_keywords(repo_path, top_n=30)\n        all_results[repo_name] = keywords\n        \n        print(f'\nTop 30 Discriminative Keywords (best for queries):\n')\n        for i, kw in enumerate(keywords, 1):\n            print(f'{i:2}. {kw["keyword"]:20} | Score: {kw["score"]:8.1f} | In {kw["appears_in_files"]:3} files ({kw["file_percentage"]:4.1f}%)')\n    \n    # Find cross-contamination terms\n    print(f'\n{"="*80}')\n    print('CROSS-CONTAMINATION ANALYSIS')\n    print(f'{"="*80}')\n    \n    viv_keywords = {k['keyword'] for k in all_results['project'][:30]}\n    fax_keywords = {k['keyword'] for k in all_results['project'][:30]}\n    \n    overlap = viv_keywords & fax_keywords\n    print(f'\nShared keywords (cause confusion): {len(overlap)}')\n    if overlap:\n        print(f'  {", ".join(sorted(overlap))}')\n    \n    print(f'\nPROJECT-only keywords (use these!): {len(viv_keywords - fax_keywords)}')\n    print(f'  {", ".join(sorted(list(viv_keywords - fax_keywords)[:10]))}')\n    \n    print(f'\nPROJECT-only keywords (use these!): {len(fax_keywords - viv_keywords)}')\n    print(f'  {", ".join(sorted(list(fax_keywords - viv_keywords)[:10]))}')\n    \n    # Save to file\n    with open('discriminative_keywords.json', 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    print(f'\n✓ Results saved to discriminative_keywords.json')
#!/usr/bin/env python3\n"""Debug GUI by opening it and printing console errors"""\nfrom __future__ import annotations\nimport time\nfrom playwright.sync_api import sync_playwright\n\nBASE = "http://127.0.0.1:8012"
main():\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=False)\n        ctx = browser.new_context()\n        page = ctx.new_page()\n\n        # Capture console messages\n        console_msgs = []\n        page.on("console", lambda msg: console_msgs.append(f"[{msg.type}] {msg.text}"))\n        page.on("pageerror", lambda err: print(f"❌ PAGE ERROR: {err}"))\n\n        print(f"Opening {BASE}/gui/...")\n        page.goto(f"{BASE}/gui/", wait_until="domcontentloaded")\n        page.wait_for_timeout(2000)\n\n        # Check overview populated\n        print("\n=== Overview Section ===")\n        try:\n            health = page.locator('#dash-health').text_content()\n            repo = page.locator('#dash-repo').text_content()\n            autotune = page.locator('#dash-autotune').text_content()\n            cards = page.locator('#dash-cards').text_content()\n            print(f"Health: {health}")\n            print(f"Repo: {repo}")\n            print(f"Autotune: {autotune}")\n            print(f"Cards: {cards}")\n            if all(x != "—" for x in [health, repo, autotune, cards]):\n                print("✓ Overview populated")\n            else:\n                print("❌ Overview still has placeholders")\n        except Exception as e:\n            print(f"❌ Error reading overview: {e}")\n\n        # Test wizard button\n        print("\n=== Testing Wizard Button ===")\n        try:\n            page.fill('#budget', '10')\n            page.click('#btn-wizard-oneclick')\n            page.wait_for_timeout(3000)\n            tri_out = page.locator('#tri-out').text_content()\n            print("Full tri-output:")\n            print(tri_out)\n            if "Press button" in tri_out or len(tri_out) < 20:\n                print("❌ Wizard didn't generate output")\n            else:\n                print("✓ Wizard generated output")\n        except Exception as e:\n            print(f"❌ Wizard error: {e}")\n\n        # Test cost calculator with blur events\n        print("\n=== Testing Cost Calculator ===")\n        try:\n            print("Typing 500 into cost-in and blurring...")\n            page.fill('#cost-in', '500')\n            page.locator('#cost-in').blur()\n            page.wait_for_timeout(300)\n            val = page.input_value('#cost-in')\n            print(f"  Value after blur: '{val}'")\n\n            print("Typing 800 into cost-out and blurring...")\n            page.fill('#cost-out', '800')\n            page.locator('#cost-out').blur()\n            page.wait_for_timeout(300)\n            val2 = page.input_value('#cost-out')\n            print(f"  Value after blur: '{val2}'")\n\n            if not val or not val2:\n                print("❌ Cost inputs being cleared")\n            else:\n                print(f"✓ Cost inputs retained (values: {val}, {val2})")\n\n            # Test with larger number (comma formatting disabled for type="number" inputs)\n            print("Testing with 5000 (no comma formatting expected for number inputs)...")\n            page.fill('#cost-in', '5000')\n            page.locator('#cost-in').blur()\n            page.wait_for_timeout(300)\n            val3 = page.input_value('#cost-in')\n            print(f"  5000 after blur: '{val3}'")\n            if val3 == '5000':\n                print("✓ Number input retains value")\n            else:\n                print(f"❌ Unexpected value: {val3}")\n        except Exception as e:\n            print(f"❌ Cost calculator error: {e}")\n\n        # Print console\n        print("\n=== Console Messages ===")\n        for msg in console_msgs:\n            print(msg)\n\n        browser.close()\n        return 0\n\nif __name__ == '__main__':\n    main()
#!/usr/bin/env python3\n"""\nComplete, transparent comparison:\n- Qwen 3 vs OpenAI gpt-4o\n- Actual MCP tool schema overhead\n- Real latency measurements\n- Quality comparison\n"""\nimport sys\nimport os\nimport json\nimport time\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model("gpt-4o")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\nprint("=" * 80)\nprint("COMPLETE MODEL COMPARISON - TRANSPARENT MEASUREMENTS")\nprint("=" * 80)\n\n# Test query\nquestion = "How are fax jobs created and dispatched"\nrepo = "project"\n\nprint(f"\nTest query: '{question}'")\nprint(f"Repo: {repo}\n")\n\n# ==================================================================\n# 1. MEASURE MCP TOOL SCHEMA OVERHEAD (sent on EVERY request)\n# ==================================================================\nprint("1. MCP Tool Schema Overhead")\nprint("-" * 80)\n\nfrom server.mcp.server import MCPServer
server = MCPServer()\ntools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\ntools_resp = server.handle_request(tools_req)\ntools_json = json.dumps(tools_resp['result']['tools'])\nschema_tokens = count_tokens(tools_json)\n\nprint(f"Tool schemas (sent with EVERY request): {schema_tokens:,} tokens")\nprint(f"Schema size: {len(tools_json):,} bytes\n")\n\n# ==================================================================\n# 2. MCP SEARCH RESPONSE SIZE\n# ==================================================================\nprint("2. MCP Search Response")\nprint("-" * 80)\n\nsearch_req = {\n    'jsonrpc': '2.0',\n    'id': 1,\n    'method': 'tools/call',\n    'params': {\n        'name': 'rag_search',\n        'arguments': {'repo': repo, 'question': question, 'top_k': 10}\n    }\n}\n\nstart = time.time()\nsearch_resp = server.handle_request(search_req)\nsearch_latency = time.time() - start\n\nmcp_response = search_resp['result']['content'][0]['text']\nresponse_tokens = count_tokens(mcp_response)\ntotal_mcp_tokens = schema_tokens + response_tokens
print(f"Response tokens: {response_tokens:,}")\nprint(f"Total MCP tokens: {total_mcp_tokens:,} ({schema_tokens} schema + {response_tokens} response)")\nprint(f"Search latency: {search_latency:.2f}s\n")\n\n# ==================================================================\n# 3. QWEN 3 GENERATION\n# ==================================================================\nprint("3. Qwen 3 Generation (Local)")\nprint("-" * 80)\n\nos.environ["OLLAMA_URL"] = "http://127.0.0.1:11434/api"\nos.environ["GEN_MODEL"] = "qwen3-coder:30b"\n\nfrom server.env_model import generate_text\n\n# Parse MCP response to get context\nresult_data = json.loads(mcp_response)\ncontext = f"Retrieved {result_data['count']} code locations:\n"\nfor r in result_data['results'][:5]:\n    context += f"- {r['file_path']}:{r['start_line']}-{r['end_line']} (score: {r['rerank_score']:.3f})\n"\n\nprompt = f"{context}\n\nQuestion: {question}\nAnswer:"\n\nstart = time.time()\nqwen_answer, _ = generate_text(prompt, model="qwen3-coder:30b")\nqwen_latency = time.time() - start
qwen_output_tokens = count_tokens(qwen_answer)\nqwen_total_tokens = total_mcp_tokens + qwen_output_tokens\n\nprint(f"Answer length: {len(qwen_answer)} chars")\nprint(f"Output tokens: {qwen_output_tokens:,}")\nprint(f"Total tokens (MCP + generation): {qwen_total_tokens:,}")\nprint(f"Generation latency: {qwen_latency:.2f}s")\nprint(f"Cost: $0.00 (local)")\nprint(f"\nAnswer preview: {qwen_answer[:200]}...\n")\n\n# ==================================================================\n# 4. OPENAI GPT-4O GENERATION\n# ==================================================================\nprint("4. OpenAI gpt-4o Generation (API)")\nprint("-" * 80)\n\n# Use OpenAI for generation\nfrom openai import OpenAI\nclient = OpenAI()\n\nstart = time.time()\ntry:\n    response = client.chat.completions.create(\n        model="gpt-4o",\n        messages=[{"role": "user", "content": prompt}],\n        max_tokens=500\n    )\n    openai_answer = response.choices[0].message.content\n    openai_latency = time.time() - start\n    \n    openai_output_tokens = count_tokens(openai_answer)
openai_total_tokens = total_mcp_tokens + openai_output_tokens\n    \n    # gpt-4o pricing (as of Oct 2025): $2.50/1M input, $10/1M output\n    input_cost = total_mcp_tokens * (2.50 / 1_000_000)\n    output_cost = openai_output_tokens * (10.00 / 1_000_000)\n    total_cost = input_cost + output_cost\n    \n    print(f"Answer length: {len(openai_answer)} chars")\n    print(f"Output tokens: {openai_output_tokens:,}")\n    print(f"Total tokens (MCP + generation): {openai_total_tokens:,}")\n    print(f"Generation latency: {openai_latency:.2f}s")\n    print(f"Cost: ${total_cost:.6f} (${input_cost:.6f} input + ${output_cost:.6f} output)")\n    print(f"\nAnswer preview: {openai_answer[:200]}...\n")\nexcept Exception as e:\n    print(f"ERROR: {e}\n")\n    openai_answer = None\n\n# ==================================================================\n# 5. COMPARISON TABLE\n# ==================================================================\nprint("=" * 80)\nprint("SUMMARY COMPARISON")\nprint("=" * 80)\n\nprint("\nTOKEN BREAKDOWN:")\nprint(f"  MCP tool schemas:     {schema_tokens:,} tokens (sent on EVERY request)")
print(f"  MCP search response:  {response_tokens:,} tokens")\nprint(f"  Qwen 3 output:        {qwen_output_tokens:,} tokens")\nif openai_answer:\n    print(f"  gpt-4o output:        {openai_output_tokens:,} tokens")\n\nprint(f"\nTOTAL TOKENS:")\nprint(f"  Qwen 3:   {qwen_total_tokens:,} tokens")\nif openai_answer:\n    print(f"  gpt-4o:   {openai_total_tokens:,} tokens")\n\nprint(f"\nLATENCY:")\nprint(f"  MCP search:       {search_latency:.2f}s")\nprint(f"  Qwen 3 generate:  {qwen_latency:.2f}s")\nif openai_answer:\n    print(f"  gpt-4o generate:  {openai_latency:.2f}s")\n\nprint(f"\nCOST PER QUERY:")\nprint(f"  Qwen 3:   $0.00 (local)")\nif openai_answer:\n    print(f"  gpt-4o:   ${total_cost:.6f}")\n\nprint(f"\nANSWER QUALITY:")\nprint(f"  Qwen 3:   {len(qwen_answer)} chars - {qwen_answer[:100]}...")\nif openai_answer:\n    print(f"  gpt-4o:   {len(openai_answer)} chars - {openai_answer[:100]}...")\n\nprint("\n" + "=" * 80)\nprint(f"SAVED TO: /tmp/full_comparison_results.json")\nprint("=" * 80)\n\n# Save results\nresults = {\n    "query": question,\n    "repo": repo,\n    "mcp": {\n        "schema_tokens": schema_tokens,
"response_tokens": response_tokens,\n        "total_tokens": total_mcp_tokens,\n        "latency_s": search_latency\n    },\n    "qwen3": {\n        "output_tokens": qwen_output_tokens,\n        "total_tokens": qwen_total_tokens,\n        "latency_s": qwen_latency,\n        "cost_usd": 0.0,\n        "answer": qwen_answer\n    }\n}\n\nif openai_answer:\n    results["gpt4o"] = {\n        "output_tokens": openai_output_tokens,\n        "total_tokens": openai_total_tokens,\n        "latency_s": openai_latency,\n        "cost_usd": total_cost,\n        "answer": openai_answer\n    }\n\nwith open('/tmp/full_comparison_results.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint("\nDone!")
import os\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Tuple, List\n\nfrom config_loader import layer_bonuses as _layer_bonuses_cfg, path_boosts as _path_boosts_cfg\n\n\n_OVERRIDES: Dict[str, Any] | None = None\n\n_overrides_path() -> Path:\n    # Keep with UI assets for simplicity\n    return Path(__file__).parent / "ui" / "runtime_overrides.json"\n\n_load_overrides() -> Dict[str, Any]:\n    global _OVERRIDES\n    if _OVERRIDES is not None:\n        return _OVERRIDES\n    p = _overrides_path()\n    if p.exists():\n        try:\n            _OVERRIDES = json.loads(p.read_text())\n        except Exception:\n            _OVERRIDES = {}\n    else:\n        _OVERRIDES = {}\n    return _OVERRIDES\n\n_get_override(repo: Optional[str], key: str) -> Any:\n    ov = _load_overrides()\n    # Precedence: per-repo -> _global\n    if repo:\n        rp = ov.get(repo)\n        if isinstance(rp, dict) and key in rp:\n            return rp[key]\n    g = ov.get("_global")\n    if isinstance(g, dict) and key in g:\n        return g[key]\n    return None
_coerce(value: Any, typ: str) -> Any:\n    if value is None:\n        return None\n    try:\n        if typ == "int":\n            return int(value)\n        if typ == "float":\n            return float(value)\n        if typ == "bool":\n            if isinstance(value, bool):\n                return value\n            s = str(value).strip().lower()\n            return s in {"1", "true", "yes", "on"}\n        if typ == "str":\n            return str(value)\n        if typ == "list[str]":\n            if isinstance(value, list):\n                return [str(x) for x in value]\n            return [x.strip() for x in str(value).split(',') if x.strip()]\n    except Exception:\n        return None\n    return value\n\nget_str(repo: Optional[str], key: str, env_key: Optional[str] = None, default: Optional[str] = None) -> Optional[str]:\n    v = _get_override(repo, key)\n    if v is None and env_key:\n        v = os.getenv(env_key)\n    return _coerce(v if v is not None else default, "str")\n\nget_int(repo: Optional[str], key: str, env_default: Optional[int] = None, default: Optional[int] = None) -> int:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, "int")\n    return int(out) if out is not None else int(default or 0)
get_float(repo: Optional[str], key: str, env_default: Optional[float] = None, default: Optional[float] = None) -> float:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, "float")\n    return float(out) if out is not None else float(default or 0.0)\n\nget_bool(repo: Optional[str], key: str, env_default: Optional[bool] = None, default: Optional[bool] = None) -> bool:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, "bool")\n    return bool(out) if out is not None else bool(default or False)\n\n\n# High-level helpers\nget_conf_thresholds(repo: Optional[str]) -> Tuple[float, float, float]:\n    t1 = get_float(repo, "CONF_TOP1", float(os.getenv("CONF_TOP1", "0.62")), 0.62)\n    a5 = get_float(repo, "CONF_AVG5", float(os.getenv("CONF_AVG5", "0.55")), 0.55)\n    anyc = get_float(repo, "CONF_ANY", float(os.getenv("CONF_ANY", "0.55")), 0.55)\n    return t1, a5, anyc
get_topk(repo: Optional[str]) -> Tuple[int, int, int]:\n    kd = get_int(repo, "TOPK_DENSE", int(os.getenv("TOPK_DENSE", "75") or 75), 75)\n    ks = get_int(repo, "TOPK_SPARSE", int(os.getenv("TOPK_SPARSE", "75") or 75), 75)\n    fk = get_int(repo, "FINAL_K", int(os.getenv("FINAL_K", "10") or 10), 10)\n    return kd, ks, fk\n\nget_mq_rewrites(repo: Optional[str]) -> int:\n    return get_int(repo, "MQ_REWRITES", int(os.getenv("MQ_REWRITES", "2") or 2), 2)\n\nget_reranker_config(repo: Optional[str]) -> Dict[str, str]:\n    return {\n        "backend": (get_str(repo, "RERANK_BACKEND", "RERANK_BACKEND", "local") or "local").lower(),\n        "model": get_str(repo, "RERANKER_MODEL", "RERANKER_MODEL", "BAAI/bge-reranker-v2-m3"),\n        "cohere_model": get_str(repo, "COHERE_RERANK_MODEL", "COHERE_RERANK_MODEL", "rerank-3.5"),\n    }
get_path_boosts(repo: Optional[str]) -> List[str]:\n    # Use repos.json, with optional env override per-repo (e.g., PROJECT_PATH_BOOSTS)\n    lst = _path_boosts_cfg(repo or "")\n    env_key = f"{(repo or '').upper()}_PATH_BOOSTS" if repo else None\n    if env_key:\n        env_val = os.getenv(env_key)\n        if not env_val and (repo or "").lower() == "project":\n            env_val = os.getenv("project_PATH_BOOSTS")\n        if env_val:\n            lst.extend([t.strip() for t in env_val.split(',') if t.strip()])\n    # De-dup while preserving order\n    seen = set(); out = []\n    for t in lst:\n        tl = t.strip().lower()\n        if tl and tl not in seen:\n            seen.add(tl); out.append(tl)\n    return out\n\nget_layer_bonuses(repo: Optional[str]) -> Dict[str, Dict[str, float]]:\n    return _layer_bonuses_cfg(repo or "")
#!/usr/bin/env python3\n"""\nEnterprise Compatibility Watchdog (stub)\n\n- Reads compat_rules.json and prints a summary\n- Intended to be extended with collectors (GitHub issues, release notes) and emit rules/alerts\n"""\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\n\nROOT = Path(__file__).resolve().parent\nRULES = ROOT / "compat_rules.json"\n\nmain() -> int:\n    if RULES.exists():\n        try:\n            data = json.loads(RULES.read_text())\n        except Exception:\n            data = []\n    else:\n        data = []\n    print(f"[watchdog] Loaded {len(data)} compat rule(s) from {RULES}")\n    for i, r in enumerate(data[:10], start=1):\n        print(f"  {i}. {r.get('id')} — {r.get('message')}")\n    return 0\n\n\nif __name__ == "__main__":\n    raise SystemExit(main())
"""\nFeature gating helpers.\n\n- is_pro(): True if edition/tier is 'pro' or 'enterprise'\n- is_enterprise(): True if edition/tier is 'enterprise'\n\nEnv controls (any of these work):\n- AGRO_EDITION=oss|pro|enterprise  (preferred)\n- TIER=free|pro|enterprise         (back-compat)\n- PRO_ENABLED=true/false           (optional override)\n- ENTERPRISE_ENABLED=true/false    (optional override)\n"""\nimport os\n\n_truthy(val: str | None) -> bool:\n    if not val:\n        return False\n    return val.strip().lower() in {"1", "true", "yes", "on"}\n\nis_pro() -> bool:\n    edition = (os.getenv("AGRO_EDITION") or os.getenv("TIER") or "").strip().lower()\n    if edition in {"pro", "enterprise"}:\n        return True\n    # Optional explicit override\n    if _truthy(os.getenv("PRO_ENABLED")):\n        return True\n    if _truthy(os.getenv("ENTERPRISE_ENABLED")):\n        return True\n    return False\n\nis_enterprise() -> bool:\n    edition = (os.getenv("AGRO_EDITION") or os.getenv("TIER") or "").strip().lower()\n    if edition == "enterprise":\n        return True\n    if _truthy(os.getenv("ENTERPRISE_ENABLED")):\n        return True\n    return False
#!/usr/bin/env python3\n"""\nAutotune autoscaler (stub):\n- Samples local CPU/RAM (and GPU later) via psutil\n- Reads gui/autotune_policy.json\n- During off hours, POSTs /api/autotune/status with a suggested mode (ECO/BALANCED/TURBO)\n\nDefaults:\n- Does not change env or persist profiles; only signals current_mode to the server stub\n- Business hours gate: leaves user settings untouched during business hours\n"""\nfrom __future__ import annotations\nimport argparse\nimport json\nimport os\nimport sys\nimport time\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\n\ntry:\n    import psutil  # type: ignore\nexcept Exception:\n    psutil = None  # type: ignore\n\nimport requests  # type: ignore\n\nROOT = Path(__file__).resolve().parent\nGUI = ROOT / "gui"\nPOLICY_PATH = GUI / "autotune_policy.json"\n\n\n@dataclassMetrics:\n    cpu: float\n    mem: float\n    gpu: Optional[float] = None
load_policy(path: Path) -> Dict[str, Any]:\n    try:\n        return json.loads(path.read_text())\n    except Exception:\n        return {\n            "business_hours": {"start": "09:00", "end": "18:00", "days": [1, 2, 3, 4, 5]},\n            "thresholds": {"cpu_hot": 0.8, "mem_hot": 0.85, "gpu_hot": 0.85},\n            "modes": {\n                "ECO": {"when": {"cpu_util_max": 0.25, "mem_util_max": 0.50, "gpu_util_max": 0.30}},\n                "BALANCED": {"when": {"cpu_util_max": 0.55, "mem_util_max": 0.70, "gpu_util_max": 0.60}},\n                "TURBO": {"when": {"cpu_util_max": 0.90, "mem_util_max": 0.90, "gpu_util_max": 0.90}},\n            },\n        }\n\nparse_hhmm(s: str) -> tuple[int, int]:\n    h, m = s.split(":")\n    return int(h), int(m)
is_business_hours(now: Optional[time.struct_time], policy: Dict[str, Any]) -> bool:\n    if now is None:\n        now = time.localtime()\n    days = set(policy.get("business_hours", {}).get("days", [1, 2, 3, 4, 5]))\n    if now.tm_wday + 1 not in days:\n        return False\n    start_s = policy.get("business_hours", {}).get("start", "09:00")\n    end_s = policy.get("business_hours", {}).get("end", "18:00")\n    sh, sm = parse_hhmm(start_s)\n    eh, em = parse_hhmm(end_s)\n    tmin = now.tm_hour * 60 + now.tm_min\n    start_m = sh * 60 + sm\n    end_m = eh * 60 + em\n    return start_m <= tmin <= end_m\n\nsample_metrics() -> Metrics:\n    if psutil is None:\n        return Metrics(cpu=0.0, mem=0.0, gpu=None)\n    cpu = psutil.cpu_percent(interval=0.3) / 100.0\n    mem = psutil.virtual_memory().percent / 100.0\n    # TODO: GPU (Metal/CUDA) sampling in future\n    return Metrics(cpu=cpu, mem=mem, gpu=None)
pick_mode(m: Metrics, policy: Dict[str, Any]) -> Optional[str]:\n    # Simple rule: choose the first mode whose 'when' limits are not exceeded\n    modes = policy.get("modes", {})\n    order = ["ECO", "BALANCED", "TURBO"]\n    for name in order:\n        spec = modes.get(name, {}).get("when", {})\n        cpu_ok = m.cpu <= float(spec.get("cpu_util_max", 1.0))\n        mem_ok = m.mem <= float(spec.get("mem_util_max", 1.0))\n        gpu_lim = spec.get("gpu_util_max")\n        gpu_ok = True if gpu_lim is None or m.gpu is None else m.gpu <= float(gpu_lim)\n        if cpu_ok and mem_ok and gpu_ok:\n            return name\n    return None\n\npost_status(host: str, enabled: bool, mode: Optional[str]) -> None:\n    try:\n        requests.post(\n            f"{host}/api/autotune/status",\n            json={"enabled": enabled, "current_mode": mode},\n            timeout=3,\n        )\n    except Exception:\n        pass
main(argv: list[str]) -> int:\n    p = argparse.ArgumentParser(description="Autotune autoscaler (stub)")\n    p.add_argument("--host", default=os.getenv("AUTOTUNE_HOST", "http://127.0.0.1:8012"))\n    p.add_argument("--interval", type=int, default=int(os.getenv("AUTOTUNE_INTERVAL", "15")))\n    args = p.parse_args(argv)\n\n    policy = load_policy(POLICY_PATH)\n    print(f"[autoscaler] Using policy {POLICY_PATH}")\n    print(f"[autoscaler] Posting to {args.host} every {args.interval}s (off-hours only)")\n\n    while True:\n        now = time.localtime()\n        bh = is_business_hours(now, policy)\n        m = sample_metrics()\n        if not bh:\n            mode = pick_mode(m, policy)\n            post_status(args.host, enabled=True, mode=mode)\n        time.sleep(max(3, args.interval))\n\n    return 0\n\n\nif __name__ == "__main__":\n    raise SystemExit(main(sys.argv[1:]))
import os\nfrom dotenv import load_dotenv\n\nload_dotenv('env/project.env')\nfrom serve_rag import app\n\nif __name__ == '__main__':\n    import uvicorn\n    os.environ['COLLECTION_NAME'] = os.environ.get('COLLECTION_NAME', f"{os.environ['REPO']}_{os.environ.get('COLLECTION_SUFFIX','default')}")\n    port = int(os.environ.get('PORT', '8012'))\n    uvicorn.run(app, host='127.0.0.1', port=port)
// AGRO GUI app.js (complete with all handlers)\n(function () {\n    // Backend API base: respects ?api= override; defaults to local FastAPI\n    const API_BASE = (() => {\n        try {\n            const u = new URL(window.location.href);\n            const q = new URLSearchParams(u.search);\n            const override = q.get('api');\n            if (override) return override.replace(/\/$/, '');\n            // Prefer same-origin whenever we were served over HTTP(S)\n            if (u.protocol.startsWith('http')) return u.origin;\n            // Fallback to local default\n            return 'http://127.0.0.1:8012';\n        } catch { return 'http://127.0.0.1:8012'; }\n    })();\n    // Expose the resolved API base for diagnostics\n    try { window.API_BASE = API_BASE; } catch {}\n    const api = (p) => `${API_BASE}${p}`;\n    const $ = (sel) => document.querySelector(sel);\n    const $$ = (sel) => Array.from(document.querySelectorAll(sel));\n\n    const state = {\n        prices: null,\n        config: null,\n        profiles: [],\n        defaultProfile: null,\n    };\n\n    // ---------------- Theme Engine ----------------\n    function resolveTheme(mode) {\n        const m = String(mode || 'auto').toLowerCase();\n        if (m === 'light' || m === 'dark') return m;
const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n        return prefersDark ? 'dark' : 'light';\n    }\n\n    function applyTheme(mode) {\n        const t = resolveTheme(mode);\n        try { document.documentElement.setAttribute('data-theme', t); } catch {}\n        // Best-effort normalize legacy inline dark styles to tokenized vars\n        try {\n            const mappings = [\n                ['#0a0a0a', 'var(--card-bg)'],\n                ['#0f0f0f', 'var(--code-bg)'],\n                ['#111111', 'var(--panel-bg)'],\n                ['#1a1a1a', 'var(--bg-elev2)'],\n                ['#2a2a2a', 'var(--line)'],\n                ['#333', 'var(--line)'],\n                ['#666', 'var(--fg-muted)'],\n                ['#888', 'var(--fg-muted)'],\n                ['#ddd', 'var(--fg)'],\n                ['#ffffff', 'var(--fg)'],\n                ['#5b9dff', 'var(--link)'],\n                ['#00ff88', 'var(--accent)'],\n                ['#ff9b5e', 'var(--accent)'],\n                ['#ff6b6b', 'var(--err)']\n            ];\n            const nodes = document.querySelectorAll('[style*="#0a0a0a"], [style*="#0f0f0f"], [style*="#111111"], [style*="#1a1a1a"], [style*="#2a2a2a"], [style*="#333"], [style*="#666"], [style*="#888"], [style*="#ddd"], [style*="#ffffff"], [style*="#5b9dff"], [style*="#00ff88"], [style*="#ff9b5e"], [style*="#ff6b6b"]');
nodes.forEach(el => {\n                let s = el.getAttribute('style') || '';\n                mappings.forEach(([k, v]) => { s = s.replaceAll(k, v); });\n                el.setAttribute('style', s);\n            });\n        } catch {}\n    }\n\n    function initThemeFromEnv(env) {\n        try {\n            const saved = localStorage.getItem('THEME_MODE');\n            const envMode = env && env.THEME_MODE ? String(env.THEME_MODE) : 'auto';\n            const mode = saved || envMode || 'auto';\n            // Set both selectors if present\n            const selTop = document.getElementById('theme-mode');\n            const selMisc = document.getElementById('misc-theme-mode');\n            if (selTop) selTop.value = mode;\n            if (selMisc) selMisc.value = mode;\n            applyTheme(mode);\n            // React to system changes when Auto\n            if (window.matchMedia) {\n                const mq = window.matchMedia('(prefers-color-scheme: dark)');\n                const onChange = () => {\n                    const current = (selTop && selTop.value) || (selMisc && selMisc.value) || mode;\n                    if (String(current||'auto').toLowerCase() === 'auto') applyTheme('auto');\n                };\n                try { mq.addEventListener('change', onChange); } catch { try { mq.addListener(onChange); } catch {} }\n            }\n        } catch {}\n    }\n\n    // ---------------- Tabs ----------------
let storageCalculatorLoaded = false;\n\n    function loadStorageCalculator() {\n        if (storageCalculatorLoaded) return;\n        const container = document.getElementById('storage-calculator-container');\n        if (!container) return;\n\n        // Load the HTML template\n        if (typeof getStorageCalculatorHTML === 'function') {\n            container.innerHTML = getStorageCalculatorHTML();\n\n            // Initialize the calculator\n            if (typeof initStorageCalculator === 'function') {\n                initStorageCalculator();\n            }\n\n            storageCalculatorLoaded = true;\n        }\n    }\n\n    function switchTab(tabName) {\n        const groups = {\n            models: ['generation','embeddings','reranking'],\n            retrieval: ['retrieval','confidence'],\n            repos: ['repos','indexing'],\n            // Show full Tools group: base panel + eval + misc\n            // Note: there is no 'tab-calculator' anymore; storage has its own tab\n            tools: ['tools','eval','misc'],\n            infra: ['infra'],\n            dashboard: ['dashboard'],\n            chat: ['chat'],\n            storage: ['storage']\n        };\n        const show = groups[tabName] || [tabName];\n        $$('.tab-content').forEach(el => el.classList.remove('active'));\n        show.forEach(id => { const el = document.getElementById(`tab-${id}`); if (el) el.classList.add('active'); });
$$('.tab-bar button').forEach(el => el.classList.remove('active'));\n        const btn = document.querySelector(`.tab-bar button[data-tab="${tabName}"]`);\n        if (btn) btn.classList.add('active');\n\n        // Load storage calculator when the tab is opened\n        if (tabName === 'storage') {\n            loadStorageCalculator();\n        }\n\n        // Initialize onboarding when first opened\n        if (tabName === 'onboarding') {\n            ensureOnboardingInit();\n        }\n    }\n\n    function bindTabs() {\n        $$('.tab-bar button').forEach(btn => {\n            btn.addEventListener('click', () => {\n                const tab = btn.getAttribute('data-tab');\n                switchTab(tab);\n            });\n        });\n        const traceBtn = document.getElementById('btn-trace-latest');\n        if (traceBtn){ traceBtn.addEventListener('click', loadLatestTrace); }\n    }\n\n    // ---------------- Tooltips (modular) ----------------\n    // Delegates to external module /gui/js/tooltips.js\n\n    // ---------------- Global Search ----------------\n    function clearHighlights() { $$('.hl').forEach(m => { const t=document.createTextNode(m.textContent); m.replaceWith(t); }); }\n    function highlightMatches(root, q) {
if (!q) return; const rx = new RegExp(q.replace(/[.*+?^${}()|[\]\\]/g,'\\$&'), 'ig');\n        const walker = document.createTreeWalker(root, NodeFilter.SHOW_TEXT, null);\n        const hits = [];\n        while (walker.nextNode()) {\n            const n = walker.currentNode; if (!n.nodeValue || !n.parentElement) continue;\n            if (/SCRIPT|STYLE|IFRAME/.test(n.parentElement.tagName)) continue;\n            const m = n.nodeValue.match(rx); if (!m) continue;\n            const span = document.createElement('mark'); span.className='hl'; span.textContent = n.nodeValue;\n            const html = n.nodeValue.replace(rx, s => `<mark class="hl">${s}</mark>`);\n            const frag = document.createElement('span'); frag.innerHTML = html;\n            n.parentElement.replaceChild(frag, n);\n            hits.push(frag.querySelector('mark.hl'));\n        }\n        return hits;\n    }\n\n    function bindGlobalSearch() {\n        const box = document.getElementById('global-search');\n        if (!box) return;\n        function run(q, jump=false) {\n            clearHighlights();\n            if (!q) return;\n            const hits = highlightMatches(document.querySelector('.content'), q);\n            if (jump && hits && hits.length) hits[0].scrollIntoView({behavior:'smooth', block:'center'});
}\n        box.addEventListener('keydown', (e)=>{ if ((e.ctrlKey||e.metaKey) && e.key.toLowerCase()==='k'){ e.preventDefault(); box.focus(); box.select(); }});\n        box.addEventListener('input', ()=> run(box.value.trim()));\n        box.addEventListener('keydown', (e)=>{ if (e.key==='Enter') run(box.value.trim(), true); });\n    }\n\n    // ---------------- Git Hooks ----------------\n    async function refreshHooksStatus(){\n        try{\n            const d = await (await fetch(api('/api/git/hooks/status'))).json();\n            const el = $('#hooks-status'); if (el) el.textContent = (d.post_checkout && d.post_commit) ? `Installed @ ${d.dir}` : 'Not installed';\n        }catch{ const el=$('#hooks-status'); if(el) el.textContent='Status unavailable'; }\n    }\n\n    async function installHooks(){\n        try{\n            const r = await fetch(api('/api/git/hooks/install'), { method:'POST' });\n            const d = await r.json();\n            alert(d.message || 'Hooks installed');\n            await refreshHooksStatus();\n        }catch(e){ alert('Failed to install hooks: ' + e.message); }\n    }\n\n    // ---------------- Health ----------------\n    async function checkHealth() {
try {\n            const r = await fetch(api('/health'));\n            const d = await r.json();\n            $('#health-status').textContent = d.ok || d.status === 'healthy' ? `OK @ ${d.ts || new Date().toISOString()}` : 'Not OK';\n        } catch (e) {\n            $('#health-status').textContent = 'Error';\n        }\n    }\n\n    // ---------------- Routing Trace Panel ----------------\n    function _fmtTable(rows, headers){\n        const cols = headers.length;\n        const widths = new Array(cols).fill(0);\n        const all = [headers].concat(rows);\n        all.forEach(r => r.forEach((c,i)=>{ widths[i] = Math.max(widths[i], String(c||'').length); }));\n        const line = (r)=> r.map((c,i)=> String(c||'').padEnd(widths[i])).join('  ');\n        return ['```', line(headers), line(widths.map(w=>'-'.repeat(w))), ...rows.map(line), '```'].join('\n');\n    }\n\n    async function loadLatestTrace(targetId='trace-output'){\n        try{\n            const repoSel = document.querySelector('select[name="REPO"]');\n            const repo = repoSel && repoSel.value ? `?repo=${encodeURIComponent(repoSel.value)}` : '';\n            const r = await fetch(api(`/api/traces/latest${repo}`));\n            const d = await r.json();
const el = document.getElementById(targetId);\n            if (!el) return;\n            if (!d || !d.trace){ el.textContent = 'No traces yet. Enable LangChain Tracing V2 in Misc and run a query via /answer.'; return; }\n            const t = d.trace;\n            const decide = (t.events||[]).find(ev=>ev.kind==='router.decide');\n            const rer = (t.events||[]).find(ev=>ev.kind==='reranker.rank');\n            const gate = (t.events||[]).find(ev=>ev.kind==='gating.outcome');\n            const header = [];\n            header.push(`Policy: ${(decide?.data?.policy)||'—'}`);\n            header.push(`Intent: ${(decide?.data?.intent)||'—'}`);\n            header.push(`Final K: ${(rer?.data?.output_topK)||'—'}`);\n            header.push(`Vector: ${((d && d.repo) ? (document.querySelector('[name="VECTOR_BACKEND"]').value||'qdrant'):'qdrant')}`);\n\n            const parts = [];\n            parts.push(header.join('  •  '));\n            parts.push('');\n            // Candidates\n            const pre = (t.events||[]).find(ev=>ev.kind==='retriever.retrieve');\n            if (pre && Array.isArray(pre.data?.candidates)){\n                const rows = pre.data.candidates.slice(0,10).map(c=>[\n                    (c.path||'').split('/').slice(-2).join('/'), c.bm25_rank||'', c.dense_rank||''
]);\n                parts.push('Pre‑rerank candidates (top 10):');\n                parts.push(_fmtTable(rows, ['path','bm25','dense']));\n                parts.push('');\n            }\n            // Rerank results\n            if (rer && Array.isArray(rer.data?.scores)){\n                const rows = rer.data.scores.slice(0,10).map(s=>[\n                    (s.path||'').split('/').slice(-2).join('/'), (s.rerank_score!=null? Number(s.rerank_score).toFixed(3):'' )\n                ]);\n                parts.push('Post‑rerank (top 10):');\n                parts.push(_fmtTable(rows, ['path','score']));\n                parts.push('');\n            }\n            // Event list\n            parts.push('Events:');\n            for (const ev of (t.events||[])){\n                parts.push(`- ${ev.ts || ''} • ${ev.kind}`);\n            }\n            el.textContent = parts.join('\n');\n        }catch(e){ const el=$('#trace-output'); if(el) el.textContent = 'Failed to load trace: '+e.message; }\n    }\n\n    // ---------------- Chat ----------------\n    function appendChatMessage(role, text){\n        const box = document.getElementById('chat-messages'); if (!box) return;\n        const wrap = document.createElement('div');\n        wrap.style.marginBottom = '12px';\n        const who = document.createElement('div');\n        who.style.fontSize = '11px';
who.style.color = role === 'user' ? '#5b9dff' : '#00ff88';\n        who.style.textTransform = 'uppercase';\n        who.style.letterSpacing = '0.5px';\n        who.textContent = role === 'user' ? 'You' : 'Assistant';\n        const msg = document.createElement('div');\n        msg.style.background = '#0f0f0f';\n        msg.style.border = '1px solid #2a2a2a';\n        msg.style.borderRadius = '6px';\n        msg.style.padding = '10px';\n        msg.style.whiteSpace = 'pre-wrap';\n        msg.textContent = text;\n        wrap.appendChild(who); wrap.appendChild(msg);\n        box.appendChild(wrap);\n        // auto-scroll if near bottom\n        try { box.scrollTop = box.scrollHeight; } catch {}\n    }\n\n    async function sendChat(){\n        const ta = document.getElementById('chat-input'); if (!ta) return;\n        const q = (ta.value || '').trim(); if (!q) return;\n        appendChatMessage('user', q);\n        ta.value = '';\n        const repoSel = document.getElementById('chat-repo-select');\n        const repo = repoSel && repoSel.value ? repoSel.value : undefined;\n        try{\n            const qs = new URLSearchParams({ q });\n            if (repo) qs.set('repo', repo);\n            const r = await fetch(api(`/answer?${qs.toString()}`));
const d = await r.json();\n            const text = (d && d.answer) ? d.answer : '—';\n            appendChatMessage('assistant', text);\n            // load trace if the dropdown is open\n            const det = document.getElementById('chat-trace');\n            if (det && det.open){ await loadLatestTrace('chat-trace-output'); }\n            // optional auto-open in LangSmith (project runs page)\n            try{\n                const env = (state.config?.env)||{};\n                if ((env.TRACING_MODE||'').toLowerCase()==='langsmith' && ['1','true','on'].includes(String(env.TRACE_AUTO_LS||'0').toLowerCase())){\n                    const prj = (env.LANGCHAIN_PROJECT||'agro');\n                    const url = `https://smith.langchain.com/projects/${encodeURIComponent(prj)}/runs`;\n                    window.open(url, '_blank');\n                }\n            }catch{}\n        }catch(e){ appendChatMessage('assistant', `Error: ${e.message}`); }\n    }\n\n    // ---------------- Config ----------------\n    async function loadConfig() {\n        try {\n            try { await fetch(api('/api/env/reload'), { method: 'POST' }); } catch {}\n            const r = await fetch(api('/api/config'));\n            const d = await r.json();\n            state.config = d;\n            populateConfigForm(d);\n            // Apply theme after fields are populated so selects reflect env
initThemeFromEnv(d.env || {});\n        } catch (e) {\n            console.error('Failed to load config:', e);\n        }\n    }\n\n    function populateConfigForm(data) {\n        const env = data.env || {};\n\n        // Fill all env variable fields\n        Object.entries(env).forEach(([k, v]) => {\n            const field = document.querySelector(`[name="${k}"]`);\n            if (!field) return;\n\n            if (field.type === 'checkbox') {\n                field.checked = String(v).toLowerCase() === 'true' || v === '1' || v === true;\n            } else if (field.tagName === 'SELECT') {\n                field.value = v;\n            } else {\n                field.value = v;\n            }\n        });\n\n        // Populate repo select\n        const repoSelect = $('#repo-select');\n        if (repoSelect) {\n            repoSelect.innerHTML = '';\n            (data.repos || []).forEach((repo) => {\n                const opt = document.createElement('option');\n                opt.value = repo.name;\n                opt.textContent = repo.name;\n                repoSelect.appendChild(opt);\n            });\n            if (env.REPO) {\n                repoSelect.value = env.REPO;\n            } else if (data.default_repo) {\n                repoSelect.value = data.default_repo;\n            }\n        }\n\n        // Seed Cards Builder defaults\n        try {\n            const def = String(env.CARDS_ENRICH_DEFAULT ?? '1');\n            const sel = document.getElementById('cards-enrich-default'); if (sel) sel.value = def;
const chk = document.getElementById('cards-enrich-toggle'); if (chk) chk.checked = def === '1';\n        } catch {}\n\n        // Seed cost panel defaults from pricing if fields are empty\n        if (state.prices && Array.isArray(state.prices.models) && state.prices.models.length) {\n            if (!$('#cost-provider').value) $('#cost-provider').value = state.prices.models[0].provider || '';\n            if (!$('#cost-model').value) $('#cost-model').value = state.prices.models[0].model || '';\n        }\n\n        // Cost panel autopopulate from env\n        try {\n            // Generation provider heuristic: use GEN_MODEL hint if present; otherwise env keys\n            let provGuess = '';\n            const gm = env.GEN_MODEL || '';\n            if (/^gpt-|^o\w+:/i.test(gm)) provGuess = 'openai';\n            else if (/^claude/i.test(gm)) provGuess = 'anthropic';\n            else if (/^gemini/i.test(gm)) provGuess = 'google';\n            else if (env.OLLAMA_URL) provGuess = 'local';\n            else if (env.OPENAI_API_KEY) provGuess = 'openai';\n            else if (env.ANTHROPIC_API_KEY) provGuess = 'anthropic';\n            else if (env.GOOGLE_API_KEY) provGuess = 'google';\n            if (provGuess) $('#cost-provider').value = provGuess;
if (env.GEN_MODEL) $('#cost-model').value = env.GEN_MODEL;\n\n            // Embeddings\n            if (env.EMBEDDING_TYPE) {\n                const ep = document.getElementById('cost-embed-provider'); if (ep) ep.value = env.EMBEDDING_TYPE;\n                if (env.EMBEDDING_TYPE === 'openai' && document.getElementById('cost-embed-model') && !$('#cost-embed-model').value) $('#cost-embed-model').value = 'text-embedding-3-small';\n                if (env.EMBEDDING_TYPE === 'voyage' && document.getElementById('cost-embed-model') && !$('#cost-embed-model').value) $('#cost-embed-model').value = 'voyage-3-large-embed';\n            }\n            // Reranker\n            if (env.RERANK_BACKEND) {\n                const rp = document.getElementById('cost-rerank-provider'); if (rp) rp.value = env.RERANK_BACKEND;\n            }\n            if (env.COHERE_RERANK_MODEL && document.getElementById('cost-rerank-model')) $('#cost-rerank-model').value = env.COHERE_RERANK_MODEL;\n            if (env.RERANKER_MODEL && document.getElementById('cost-rerank-model') && !$('#cost-rerank-model').value) $('#cost-rerank-model').value = env.RERANKER_MODEL;
} catch {}\n\n        // Wizard defaults: seed from env\n        try { seedWizardFromEnv(env); } catch {}\n        updateWizardSummary();\n\n        // Populate repos metadata editor\n        const reposSection = $('#repos-section');\n        if (reposSection) {\n            reposSection.innerHTML = '';\n            (data.repos || []).forEach((repo) => {\n                const div = document.createElement('div');\n                div.style.cssText = 'background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 6px; padding: 16px; margin-bottom: 16px;';\n                const rname = repo.name;\n                div.innerHTML = `\n                    <h4 style=\"color: #00ff88; font-size: 14px; margin-bottom: 12px;\">Repo: ${repo.name}</h4>\n                    <div class=\"input-group\" style=\"margin-bottom: 12px;\">\n                        <label>Path</label>\n                        <input type=\"text\" name=\"repo_path_${repo.name}\" value=\"${repo.path || ''}\" />\n                    </div>\n                    <div class=\"input-group\" style=\"margin-bottom: 12px;\">\n                        <label>Keywords (comma-separated)</label>\n                        <input type=\"text\" name=\"repo_keywords_${repo.name}\" value=\"${(repo.keywords||[]).join(',')}\" list=\"keywords-list\" placeholder=\"search or type to add\" />
</div>\n                    <div class=\"input-group\" style=\"margin-bottom: 12px;\">\n                        <label>Path Boosts (comma-separated)</label>\n                        <input type=\"text\" name=\"repo_pathboosts_${repo.name}\" value=\"${(repo.path_boosts||[]).join(',')}\" />\n                    </div>\n                    <div class=\"input-group\">\n                        <label>Layer Bonuses (JSON)</label>\n                        <textarea name=\"repo_layerbonuses_${repo.name}\" rows=\"3\">${repo.layer_bonuses ? JSON.stringify(repo.layer_bonuses, null, 2) : ''}</textarea>\n                    </div>\n                    <div class=\"input-group full-width\" style=\"margin-top:12px;\">\n                        <label>Keyword Manager</label>\n                        <div style=\"display:grid; grid-template-columns: 1fr auto 1fr; gap:8px; align-items:center;\">\n                            <div>\n                                <div style=\"display:flex; gap:6px; margin-bottom:6px;\">\n                                    <input type=\"text\" id=\"kw-filter-${rname}\" placeholder=\"filter...\" style=\"width:60%;\">\n                                    <select id=\"kw-src-${rname}\">\n                                        <option value=\"all\">All</option>\n                                        <option value=\"discriminative\">Discriminative</option>\n                                        <option value=\"semantic\">Semantic</option>
<option value=\"repos\">Repo</option>\n                                    </select>\n                                    <button class=\"small-button\" id=\"kw-new-${rname}\" style=\"background:#00ff88; color:#000; padding:4px 8px; font-size:11px;\" title=\"Add New Keyword\">+</button>\n                                </div>\n                                <select id=\"kw-all-${rname}\" multiple size=\"8\" style=\"width:100%;\"></select>\n                            </div>\n                            <div style=\"display:flex; flex-direction:column; gap:8px;\">\n                                <button class=\"small-button\" id=\"kw-add-${rname}\">&gt;&gt;</button>\n                                <button class=\"small-button\" id=\"kw-rem-${rname}\">&lt;&lt;</button>\n                            </div>\n                            <div>\n                                <div class=\"small\" style=\"margin-bottom:6px;\">Repo Keywords</div>\n                                <select id=\"kw-repo-${rname}\" multiple size=\"8\" style=\"width:100%;\"></select>\n                            </div>\n                        </div>\n                    </div>\n                `;\n                reposSection.appendChild(div);\n\n                // Hook keyword manager events\n                const fld = div.querySelector(`[name=\"repo_keywords_${rname}\"]`);\n                const allSel = div.querySelector(`#kw-all-${rname}`);\n                const repoSel = div.querySelector(`#kw-repo-${rname}`);\n                const srcSel = div.querySelector(`#kw-src-${rname}`);
// Ensure LLM source option is available\n                try {\n                    if (srcSel && !Array.from(srcSel.options).some(o => o.value === 'llm')) {\n                        const opt = document.createElement('option');\n                        opt.value = 'llm';\n                        opt.textContent = 'LLM';\n                        const before = Array.from(srcSel.options).find(o => o.value === 'repos');\n                        if (before) srcSel.insertBefore(opt, before); else srcSel.appendChild(opt);\n                    }\n                } catch {}\n                const filter = div.querySelector(`#kw-filter-${rname}`);\n                const addBtn = div.querySelector(`#kw-add-${rname}`);\n                const remBtn = div.querySelector(`#kw-rem-${rname}`);\n                const newBtn = div.querySelector(`#kw-new-${rname}`);\n\n                function currentRepoKws() {\n                    return (fld.value || '').split(',').map(s => s.trim()).filter(Boolean);\n                }\n                function setRepoKws(arr) {\n                    fld.value = arr.join(',');\n                    // repaint repo list\n                    repoSel.innerHTML = '';\n                    arr.forEach(k => { const o=document.createElement('option'); o.value=k; o.textContent=k; repoSel.appendChild(o); });\n                }\n                function sourceList() {\n                    const cat = (srcSel.value||'all');\n                    const catMap = (state.keywordsCatalog||{});
let base = [];\n                    if (cat === 'all') base = catMap.keywords||[]; else base = catMap[cat]||[];\n                    const f = (filter.value||'').toLowerCase();\n                    const inRepo = new Set(currentRepoKws());\n                    return base.filter(k => !inRepo.has(k) && (!f || k.toLowerCase().includes(f)));\n                }\n                function paintSource() {\n                    allSel.innerHTML = '';\n                    sourceList().slice(0,500).forEach(k => { const o=document.createElement('option'); o.value=k; o.textContent=k; allSel.appendChild(o); });\n                }\n                addBtn.addEventListener('click', () => {\n                    const cur = currentRepoKws();\n                    const selected = Array.from(allSel.selectedOptions).map(o=>o.value);\n                    const next = Array.from(new Set([...cur, ...selected]));\n                    setRepoKws(next); paintSource();\n                });\n                remBtn.addEventListener('click', () => {\n                    const cur = currentRepoKws();\n                    const remove = new Set(Array.from(repoSel.selectedOptions).map(o=>o.value));\n                    const next = cur.filter(k => !remove.has(k));\n                    setRepoKws(next); paintSource();\n                });\n                srcSel.addEventListener('change', paintSource);\n                filter.addEventListener('input', paintSource);
// Handle add new keyword button\n                newBtn.addEventListener('click', () => {\n                    // Create a custom dialog for adding keywords\n                    const dialog = document.createElement('div');\n                    dialog.style.cssText = `\n                        position: fixed;\n                        top: 50%;\n                        left: 50%;\n                        transform: translate(-50%, -50%);\n                        background: #0a0a0a;\n                        border: 1px solid #00ff88;\n                        border-radius: 8px;\n                        padding: 20px;\n                        z-index: 10000;\n                        min-width: 300px;\n                        box-shadow: 0 8px 24px rgba(0,0,0,0.8);\n                    `;\n\n                    dialog.innerHTML = `\n                        <h4 style="color: #00ff88; margin-bottom: 16px;">Add New Keyword</h4>\n                        <div style="margin-bottom: 12px;">\n                            <label style="display: block; color: #999; font-size: 11px; margin-bottom: 4px;">Keyword</label>\n                            <input type="text" id="new-kw-input" style="width: 100%; background: #1a1a1a; border: 1px solid #333; color: #fff; padding: 8px; border-radius: 4px;" placeholder="Enter keyword...">\n                        </div>\n                        <div style="margin-bottom: 16px;">\n                            <label style="display: block; color: #999; font-size: 11px; margin-bottom: 4px;">Category (optional)</label>\n                            <select id="new-kw-category" style="width: 100%; background: #1a1a1a; border: 1px solid #333; color: #fff; padding: 8px; border-radius: 4px;">
<option value="">None (appears in All only)</option>\n                                <option value="discriminative">Discriminative</option>\n                                <option value="semantic">Semantic</option>\n                            </select>\n                        </div>\n                        <div style="display: flex; gap: 8px; justify-content: flex-end;">\n                            <button id="cancel-kw" style="background: #1a1a1a; color: #999; border: 1px solid #333; padding: 6px 16px; border-radius: 4px; cursor: pointer;">Cancel</button>\n                            <button id="add-kw" style="background: #00ff88; color: #000; border: none; padding: 6px 16px; border-radius: 4px; cursor: pointer; font-weight: 600;">Add</button>\n                        </div>\n                    `;\n\n                    // Add backdrop\n                    const backdrop = document.createElement('div');\n                    backdrop.style.cssText = 'position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0,0,0,0.5); z-index: 9999;';\n\n                    document.body.appendChild(backdrop);\n                    document.body.appendChild(dialog);\n\n                    const input = dialog.querySelector('#new-kw-input');\n                    const categorySelect = dialog.querySelector('#new-kw-category');\n                    const addButton = dialog.querySelector('#add-kw');
const cancelButton = dialog.querySelector('#cancel-kw');\n\n                    // Focus input\n                    input.focus();\n\n                    const cleanup = () => {\n                        document.body.removeChild(dialog);\n                        document.body.removeChild(backdrop);\n                    };\n\n                    const addKeyword = async () => {\n                        const newKeyword = input.value.trim();\n                        const category = categorySelect.value;\n\n                        if (newKeyword) {\n                            // Add to global catalog if not exists\n                            if (!state.keywordsCatalog) state.keywordsCatalog = { keywords: [] };\n                            if (!state.keywordsCatalog.keywords) state.keywordsCatalog.keywords = [];\n\n                            // Add to the 'all' category if not already there\n                            if (!state.keywordsCatalog.keywords.includes(newKeyword)) {\n                                state.keywordsCatalog.keywords.push(newKeyword);\n                                state.keywordsCatalog.keywords.sort();\n\n                                // Also add to specific category if selected\n                                if (category) {\n                                    if (!state.keywordsCatalog[category]) state.keywordsCatalog[category] = [];\n                                    if (!state.keywordsCatalog[category].includes(newKeyword)) {\n                                        state.keywordsCatalog[category].push(newKeyword);\n                                        state.keywordsCatalog[category].sort();\n                                    }\n                                }\n\n                                // Update the datalist for autocomplete
const list = document.getElementById('keywords-list');\n                                if (list) {\n                                    const opt = document.createElement('option');\n                                    opt.value = newKeyword;\n                                    list.appendChild(opt);\n                                }\n\n                                // Update keywords count display\n                                const kc = document.getElementById('keywords-count');\n                                if (kc) kc.textContent = String(state.keywordsCatalog.keywords.length);\n\n                                // Save to server for persistence\n                                try {\n                                    const response = await fetch(api('/api/keywords/add'), {\n                                        method: 'POST',\n                                        headers: { 'Content-Type': 'application/json' },\n                                        body: JSON.stringify({ keyword: newKeyword, category: category })\n                                    });\n                                    const result = await response.json();\n                                    if (result.ok) {\n                                        showStatus(`Added keyword: ${newKeyword}${category ? ` (${category})` : ''}`, 'success');\n                                    } else {\n                                        showStatus(`Failed to persist keyword: ${result.error}`, 'warning');\n                                    }\n                                } catch (e) {\n                                    console.warn('Failed to save keyword to server:', e);\n                                }\n                            }\n\n                            // Refresh the source list to show the new keyword\n                            paintSource();\n\n                            // Select the new keyword in the all list if visible\n                            setTimeout(() => {\n                                const options = Array.from(allSel.options);
const newOption = options.find(o => o.value === newKeyword);\n                                if (newOption) {\n                                    newOption.selected = true;\n                                    // Auto-focus to make it visible\n                                    allSel.focus();\n                                }\n                            }, 100);\n\n                            cleanup();\n                        }\n                    };\n\n                    // Event handlers\n                    addButton.addEventListener('click', addKeyword);\n                    cancelButton.addEventListener('click', cleanup);\n                    input.addEventListener('keydown', (e) => {\n                        if (e.key === 'Enter') addKeyword();\n                        if (e.key === 'Escape') cleanup();\n                    });\n                });\n\n                // initial fill using existing values + catalog (if loaded later, loadKeywords will repaint)\n                setRepoKws((repo.keywords||[]));\n                if (state.keywordsCatalog) paintSource();\n            });\n        }\n\n        // Attach tooltips after DOM is populated\n        try { window.Tooltips && window.Tooltips.attachTooltips && window.Tooltips.attachTooltips(); } catch {}\n    }\n\n    function gatherConfigForm() {\n        const update = { env: {}, repos: [] };\n\n        // Gather all env vars from form\n        const envFields = $$('[name]').filter(f => !f.name.startsWith('repo_'));\n        envFields.forEach(field => {\n            const key = field.name;\n            let val;\n\n            if (field.type === 'checkbox') {\n                val = field.checked;
} else if (field.type === 'number') {\n                val = field.value;\n            } else {\n                val = field.value;\n            }\n\n            if (val !== '' && val !== null && val !== undefined) {\n                update.env[key] = val;\n            }\n        });\n\n        // Gather repo-specific fields\n        const repoFields = $$('[name^="repo_"]');\n        const repoMap = {};\n\n        repoFields.forEach(field => {\n            const parts = field.name.split('_');\n            const fieldType = parts[1]; // path, keywords, pathboosts, layerbonuses\n            const repoName = parts.slice(2).join('_');\n\n            if (!repoMap[repoName]) {\n                repoMap[repoName] = { name: repoName };\n            }\n\n            if (fieldType === 'keywords' || fieldType === 'pathboosts') {\n                const key = fieldType === 'pathboosts' ? 'path_boosts' : 'keywords';\n                repoMap[repoName][key] = field.value.split(',').map(s => s.trim()).filter(Boolean);\n            } else if (fieldType === 'layerbonuses') {\n                try {\n                    repoMap[repoName]['layer_bonuses'] = field.value ? JSON.parse(field.value) : {};\n                } catch (e) {\n                    alert(`Invalid JSON for ${repoName} layer_bonuses: ${e.message}`);\n                    return null;\n                }\n            } else if (fieldType === 'path') {\n                repoMap[repoName]['path'] = field.value;\n            }\n        });\n\n        update.repos = Object.values(repoMap);
return update;\n    }\n\n    async function saveConfig() {\n        const body = gatherConfigForm();\n        if (!body) return;\n\n        try {\n            const r = await fetch(api('/api/config'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(body)\n            });\n\n            if (!r.ok) {\n                alert('Save failed');\n                return;\n            }\n\n            const result = await r.json();\n            if (result.status === 'success') {\n                alert('Configuration updated successfully!');\n                await loadConfig(); // Reload to confirm\n            }\n        } catch (e) {\n            alert('Error saving config: ' + e.message);\n        }\n    }\n\n    // ---------------- Prices & Cost ----------------\n    async function loadPrices() {\n        try {\n            const r = await fetch(api('/api/prices'));\n            state.prices = await r.json();\n            populatePriceDatalists();\n        } catch (e) {\n            console.error('Failed to load prices:', e);\n        }\n    }\n\n    function unique(xs) { return Array.from(new Set(xs)); }\n\n    function populatePriceDatalists() {\n        if (!state.prices || !Array.isArray(state.prices.models)) return;\n\n        const models = state.prices.models;\n        const providers = unique(models.map(m => (m.provider || '').trim()).filter(Boolean));
const allModels = unique(models.map(m => (m.model || '').trim()).filter(Boolean));\n\n        const providerSelect = document.getElementById('cost-provider');\n        const modelList = document.getElementById('model-list');\n        const genList = document.getElementById('gen-model-list');\n        const rrList = document.getElementById('rerank-model-list');\n        const embList = document.getElementById('embed-model-list');\n\n        function setOpts(el, vals) {\n            if (!el) return;\n            el.innerHTML = '';\n            vals.forEach(v => {\n                const opt = document.createElement('option');\n                opt.value = v;\n                if (el.tagName === 'SELECT') opt.textContent = v;\n                el.appendChild(opt);\n            });\n        }\n\n        if (providerSelect && providerSelect.tagName === 'SELECT') {\n            // refill provider select only if empty, preserve user choice\n            if (providerSelect.options.length <= 1) setOpts(providerSelect, providers);\n        }\n\n        // Partition models into categories for filtering\n        // Inference models: unit == '1k_tokens' and no embed/rerank fields (cost may be 0 for local)\n        const isGen = (m)=> {\n            const u = String(m.unit || '').toLowerCase();
const hasEmbed = Object.prototype.hasOwnProperty.call(m, 'embed_per_1k');\n            const hasRerank = Object.prototype.hasOwnProperty.call(m, 'rerank_per_1k');\n            return u === '1k_tokens' && !hasEmbed && !hasRerank;\n        };\n        const isEmbed = (m)=> Object.prototype.hasOwnProperty.call(m, 'embed_per_1k');\n        const isRerank = (m)=> Object.prototype.hasOwnProperty.call(m, 'rerank_per_1k') || /rerank/i.test(String(m.family||'')+String(m.model||''));\n        const genModels = unique(models.filter(isGen).map(m => m.model));\n        const rrModels = unique(models.filter(isRerank).map(m => m.model));\n        const embModels = unique(models.filter(isEmbed).map(m => m.model));\n\n        // Populate datalists with null checks\n        if (modelList) setOpts(modelList, allModels);\n        if (genList) setOpts(genList, genModels);\n        if (rrList) setOpts(rrList, rrModels);\n        if (embList) setOpts(embList, embModels);\n\n        // Default provider only; leave model empty so datalist shows all options on first focus\n        if (!$('#cost-provider').value && providers.length) $('#cost-provider').value = providers[0];
if (!$('#cost-model').value) $('#cost-model').value = '';\n\n        // Filter model options when provider changes AND update the input value\n        const onProv = () => {\n            const modelInput = $('#cost-model');\n            if (!modelInput || !modelList) return;\n\n            const p = $('#cost-provider').value.trim().toLowerCase();\n            const provModels = unique(models.filter(m => (m.provider||'').toLowerCase()===p && isGen(m)).map(m => m.model));\n            if (!provModels.length) {\n                // Fall back to all inference models so the dropdown is still usable\n                const allGen = unique(models.filter(isGen).map(m => m.model));\n                if (modelList) setOpts(modelList, allGen);\n                modelInput.value = '';\n                try { showStatus(`No inference models for provider "${p}" — showing all models.`, 'warn'); } catch {}\n                return;\n            }\n            if (modelList) setOpts(modelList, provModels);\n            // If current value isn't a model for this provider, clear so the datalist shows all options\n            if (!provModels.includes(modelInput.value)) {\n                modelInput.value = '';\n            }\n        };\n\n        if (providerSelect) providerSelect.addEventListener('change', onProv);\n        onProv(); // Initialize
// ---- Provider-specific filtering for Embeddings and Reranker ----\n        function normProvList(sel, kind){\n            const p = String(sel||'').toLowerCase();\n            if (p === 'mxbai') return ['huggingface'];\n            if (p === 'hugging face') return ['huggingface'];\n            if (p === 'local'){\n                // For local: embeddings prefer local/ollama; rerank prefer huggingface/local\n                return (kind==='embed') ? ['local','ollama'] : ['huggingface','local','ollama','mlx'];\n            }\n            return [p];\n        }\n        function updateEmbedList(){\n            const sel = document.getElementById('cost-embed-provider');\n            const input = document.getElementById('cost-embed-model');\n            if (!sel || !embList) return;\n            const prov = String(sel.value||'').toLowerCase();\n            const prows = normProvList(prov, 'embed');\n            let items = models.filter(m => isEmbed(m) && prows.includes(String(m.provider||'').toLowerCase())).map(m => m.model);\n            // If provider is mxbai, prefer Mixedbread embeddings; if none present, include all HF embeddings\n            if (prov === 'mxbai') {\n                const mb = items.filter(s => /mixedbread/i.test(s));\n                items = mb.length ? mb : models.filter(m => isEmbed(m) && String(m.provider||'').toLowerCase()==='huggingface').map(m => m.model);
}\n            if (!items.length) items = unique(models.filter(isEmbed).map(m => m.model));\n            if (embList) setOpts(embList, unique(items));\n            if (input && items.length && !items.includes(input.value)) input.value = '';\n        }\n        function normProviderName(p){\n            p = String(p||'').toLowerCase();\n            if (p === 'hf' || p === 'hugging face') return 'huggingface';\n            return p;\n        }\n        function updateRerankList(){\n            const sel = document.getElementById('cost-rerank-provider');\n            const input = document.getElementById('cost-rerank-model');\n            if (!sel || !rrList) return;\n            const p = normProviderName(sel.value||'');\n            let items;\n            if (!p) {\n                items = models.filter(isRerank).map(m => m.model);\n            } else if (p === 'cohere') {\n                items = models.filter(m => isRerank(m) && String(m.provider||'').toLowerCase()==='cohere').map(m => m.model);\n            } else if (p === 'huggingface') {\n                items = models.filter(m => isRerank(m) && String(m.provider||'').toLowerCase()==='huggingface').map(m => m.model);\n            } else if (p === 'local') {\n                // Prefer HF rerankers for local\n                items = models.filter(m => isRerank(m) && (String(m.provider||'').toLowerCase()==='huggingface' || String(m.provider||'').toLowerCase()==='local' || String(m.provider||'').toLowerCase()==='ollama')).map(m => m.model);
} else if (p === 'none') {\n                items = [];\n            } else {\n                items = models.filter(m => isRerank(m) && String(m.provider||'').toLowerCase()===p).map(m => m.model);\n            }\n            if (!items.length) items = unique(models.filter(isRerank).map(m => m.model));\n            if (rrList) setOpts(rrList, unique(items));\n            if (input && items.length && !items.includes(input.value)) input.value = '';\n        }\n        const embProvSel = document.getElementById('cost-embed-provider');\n        const rrProvSel = document.getElementById('cost-rerank-provider');\n        if (embProvSel) embProvSel.addEventListener('change', updateEmbedList);\n        if (rrProvSel) rrProvSel.addEventListener('change', updateRerankList);\n        updateEmbedList();\n        updateRerankList();\n    }\n\n    async function estimateCost() {\n        try{\n            const d = await (window.CostLogic && window.CostLogic.estimateFromUI ? window.CostLogic.estimateFromUI(API_BASE) : Promise.reject(new Error('CostLogic missing')));\n            $('#cost-daily').textContent = `$${Number(d.daily||0).toFixed(4)}`;\n            $('#cost-monthly').textContent = `$${Number(d.monthly||0).toFixed(2)}`;
}catch(e){ alert('Cost estimation failed: ' + e.message); }\n    }\n\n    // ---------------- Hardware Scan & Profiles ----------------\n    function formatHardwareScan(data) {\n        if (!data || typeof data !== 'object') return 'No scan data';\n        const info = data.info || {};\n        const rt = data.runtimes || {};\n        const parts = [];\n\n        if (info.os) parts.push(`<div class="section"><span class="key">OS:</span> <span class="value">${info.os}</span></div>`);\n        if (info.cpu_cores) parts.push(`<div class="section"><span class="key">CPU Cores:</span> <span class="value">${info.cpu_cores}</span></div>`);\n        if (info.mem_gb) parts.push(`<div class="section"><span class="key">Memory:</span> <span class="value">${info.mem_gb} GB</span></div>`);\n        if (info.gpu) parts.push(`<div class="section"><span class="key">GPU:</span> <span class="value">${info.gpu}</span></div>`);\n\n        const activeRuntimes = Object.keys(rt).filter(k => rt[k]);\n        if (activeRuntimes.length) {\n            parts.push(`<div class="section"><span class="key">Runtimes:</span> <span class="value">${activeRuntimes.join(', ')}</span></div>`);
}\n\n        return parts.join('');\n    }\n\n    async function scanHardware() {\n        try {\n            const r = await fetch(api('/api/scan-hw'), { method: 'POST' });\n            const d = await r.json();\n            const scanOut = $('#scan-out');\n            scanOut.innerHTML = formatHardwareScan(d);\n            scanOut.dataset.scanData = JSON.stringify(d);\n            updateWizardSummary();\n            return d;\n        } catch (e) {\n            alert('Hardware scan failed: ' + e.message);\n            return null;\n        }\n    }\n\n    function proposeProfile(scan, budget) {\n        // Budget-aware defaults (avoid paid providers at $0)\n        const hasLocal = scan?.runtimes?.ollama || scan?.runtimes?.coreml;\n        const rprov = (Number(budget) === 0) ? (hasLocal ? 'local' : 'none') : 'cohere';\n        const prof = {\n            GEN_MODEL: hasLocal && Number(budget) === 0 ? 'qwen3-coder:14b' : 'gpt-4o-mini',\n            EMBEDDING_TYPE: (Number(budget) === 0) ? (hasLocal ? 'local' : 'mxbai') : 'openai',\n            RERANK_BACKEND: rprov,\n            MQ_REWRITES: Number(budget) > 50 ? '6' : '3',\n            TOPK_SPARSE: '75',\n            TOPK_DENSE: '75',\n            FINAL_K: Number(budget) > 50 ? '20' : '10',\n            HYDRATION_MODE: 'lazy',\n        };\n        return prof;\n    }\n\n    function _tooltipHtmlForKey(k){\n        try{\n            const map = (window.Tooltips && window.Tooltips.buildTooltipMap && window.Tooltips.buildTooltipMap()) || {};
return map[k] || `<span class="tt-title">${k}</span><div>No detailed tooltip available yet. See our docs.</div><div class="tt-links"><a href="/files/README.md" target="_blank" rel="noopener">Main README</a> <a href="/docs/README.md" target="_blank" rel="noopener">Docs Index</a></div>`;\n        }catch{return `<span class="tt-title">${k}</span><div>No details found.</div>`}\n    }\n\n    function formatProfile(prof) {\n        if (!prof || typeof prof !== 'object') return '(Preview will appear here)';\n        const parts = [];\n\n        const keyGroups = {\n            'Generation': ['GEN_MODEL', 'ENRICH_MODEL', 'ENRICH_MODEL_OLLAMA'],\n            'Embeddings': ['EMBEDDING_TYPE', 'VOYAGE_EMBED_DIM', 'EMBEDDING_DIM'],\n            'Reranking': ['RERANK_BACKEND', 'COHERE_RERANK_MODEL', 'RERANKER_MODEL'],\n            'Retrieval': ['MQ_REWRITES', 'FINAL_K', 'TOPK_SPARSE', 'TOPK_DENSE', 'HYDRATION_MODE'],\n        };\n\n        for (const [group, keys] of Object.entries(keyGroups)) {\n            const groupItems = keys.filter(k => prof[k] !== undefined).map(k => {\n                const tip = _tooltipHtmlForKey(k);\n                const val = String(prof[k]);
return `<div class="kv">\n                    <span class="key">${k}:</span>\n                    <span class="value">${val}</span>\n                    <span class="tooltip-wrap"><span class="help-icon" tabindex="0" aria-label="Help: ${k}">?</span><div class="tooltip-bubble">${tip}</div></span>\n                </div>`;\n            });\n            if (groupItems.length) {\n                parts.push(`<div class="section"><strong style="color:#5b9dff;">${group}</strong>${groupItems.join('')}</div>`);\n            }\n        }\n\n        if (prof.__estimate__) {\n            const est = prof.__estimate__;\n            parts.push(`<div class="section"><strong style="color:#b794f6;">Cost Estimate</strong><div><span class="key">Daily:</span> <span class="value">$${Number(est.daily||0).toFixed(4)}</span></div><div><span class="key">Monthly:</span> <span class="value">$${Number(est.monthly||0).toFixed(2)}</span></div></div>`);\n        }\n\n        return parts.join('');\n    }\n\n    function bindPreviewTooltips(){\n        const root = document.getElementById('profile-preview');\n        if (!root) return;\n        root.querySelectorAll('.kv .help-icon').forEach(icon => {\n            const wrap = icon.parentElement;
const bubble = wrap && wrap.querySelector('.tooltip-bubble');\n            if (!wrap || !bubble) return;\n            function show(){ bubble.classList.add('tooltip-visible'); }\n            function hide(){ bubble.classList.remove('tooltip-visible'); }\n            icon.addEventListener('mouseenter', show);\n            icon.addEventListener('mouseleave', hide);\n            icon.addEventListener('focus', show);\n            icon.addEventListener('blur', hide);\n            icon.addEventListener('click', (e)=>{ e.stopPropagation(); bubble.classList.toggle('tooltip-visible'); });\n            document.addEventListener('click', (evt)=>{ if (!wrap.contains(evt.target)) bubble.classList.remove('tooltip-visible'); });\n        });\n    }\n\n    async function generateProfileWizard() {\n        let scan = null;\n        const scanOut = $('#scan-out');\n        // Try to extract scan from data attribute or re-scan\n        if (scanOut.dataset.scanData) {\n            try { scan = JSON.parse(scanOut.dataset.scanData); } catch {}\n        }\n        if (!scan) scan = await scanHardware();\n        const budget = parseFloat($('#budget').value || '0');\n        const prof = (window.ProfileLogic && window.ProfileLogic.buildWizardProfile) ? window.ProfileLogic.buildWizardProfile(scan, budget) : {};
// Try a pipeline cost preview\n        const payload = (window.CostLogic && window.CostLogic.buildPayloadFromUI) ? window.CostLogic.buildPayloadFromUI() : {\n            gen_provider:'openai', gen_model:'gpt-4o-mini', tokens_in:0, tokens_out:0, embeds:0, reranks:0, requests_per_day:0\n        };\n        try {\n            const r = await fetch(api('/api/cost/estimate_pipeline'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });\n            const d = await r.json();\n            prof.__estimate__ = d;\n        } catch {}\n        $('#profile-preview').innerHTML = formatProfile(prof);\n        bindPreviewTooltips();\n        $('#profile-preview').dataset.profileData = JSON.stringify(prof);\n        updateWizardSummary();\n        return prof;\n    }\n\n    async function applyProfileWizard() {\n        let prof = null;\n        const preview = $('#profile-preview');\n        if (preview.dataset.profileData) {\n            try { prof = JSON.parse(preview.dataset.profileData); } catch {}\n        }\n        if (!prof || typeof prof !== 'object') prof = await generateProfileWizard();\n        // Remove cost estimate from applied profile\n        if (prof.__estimate__) delete prof.__estimate__;
try {\n            const r = await fetch(api('/api/profiles/apply'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ profile: prof }) });\n            const d = await r.json();\n            alert(`Profile applied: ${d.applied_keys?.join(', ') || 'ok'}`);\n            await loadConfig();\n        } catch (e) { alert('Failed to apply profile: ' + e.message); }\n    }\n\n    // Tri-Candidate Generation (from docs)\n    function generateCandidates(scan, budget) {\n        const hasLocal = !!(scan?.runtimes?.ollama || scan?.runtimes?.coreml);\n        const mem = (scan?.info?.mem_gb || 8);\n        const budgetNum = Number(budget) || 0;\n\n        // Three baseline candidates\n        const local = {\n            name: 'local',\n            env: {\n                GEN_MODEL: hasLocal ? 'qwen3-coder:14b' : 'gpt-4o-mini',\n                EMBEDDING_TYPE: hasLocal ? 'local' : 'mxbai',\n                RERANK_BACKEND: hasLocal ? 'local' : 'none',\n                MQ_REWRITES: mem >= 32 ? '4' : '3',\n                FINAL_K: mem >= 32 ? '10' : '8',\n                TOPK_DENSE: '60', TOPK_SPARSE: '60', HYDRATION_MODE: 'lazy'\n            }\n        };\n        const cheapCloud = {\n            name: 'cheap_cloud',\n            env: {\n                GEN_MODEL: 'gpt-4o-mini', EMBEDDING_TYPE: 'openai', RERANK_BACKEND: 'local',
MQ_REWRITES: budgetNum > 25 ? '4' : '3',\n                FINAL_K: budgetNum > 25 ? '10' : '8',\n                TOPK_DENSE: '75', TOPK_SPARSE: '75', HYDRATION_MODE: 'lazy'\n            }\n        };\n        const premium = {\n            name: 'premium',\n            env: {\n                GEN_MODEL: 'gpt-4o-mini', EMBEDDING_TYPE: 'openai', RERANK_BACKEND: 'cohere',\n                MQ_REWRITES: budgetNum > 100 ? '6' : '4',\n                FINAL_K: budgetNum > 100 ? '20' : '12',\n                TOPK_DENSE: '120', TOPK_SPARSE: '120', HYDRATION_MODE: 'lazy'\n            }\n        };\n        return [local, cheapCloud, premium];\n    }\n\n    async function triCostSelect() {\n        // Use current Cost panel inputs for tokens and rpd\n        const base = {\n            tokens_in: parseInt($('#cost-in').value || '500', 10),\n            tokens_out: parseInt($('#cost-out').value || '800', 10),\n            embeds: parseInt($('#cost-embeds').value || '0', 10),\n            reranks: parseInt($('#cost-rerank').value || '0', 10),\n            requests_per_day: parseInt($('#cost-rpd').value || '100', 10)\n        };\n        const budget = parseFloat($('#budget').value || '0');\n        const scanOut = $('#scan-out');\n        let scan = null;\n        if (scanOut && scanOut.dataset.scanData) {\n            try { scan = JSON.parse(scanOut.dataset.scanData); } catch {}
}\n        if (!scan) scan = await scanHardware();\n\n        const cands = generateCandidates(scan, budget);\n\n        const rows = [];\n        for (const c of cands) {\n            // Decide provider/model from env for cost call\n            const provider = (c.env.GEN_MODEL || '').match(/:/) ? 'local' : 'openai';\n            const model = c.env.GEN_MODEL || 'gpt-4o-mini';\n            const payload = (window.CostLogic && window.CostLogic.buildPayloadFromUI) ? window.CostLogic.buildPayloadFromUI() : { gen_provider: provider, gen_model: model, ...base };\n            payload.gen_provider = provider; payload.gen_model = model;\n\n            // local electricity optional if provider==local\n            if (provider === 'local') {\n                const kwh = $('#cost-kwh')?.value;\n                const watts = $('#cost-watts')?.value;\n                const hours = $('#cost-hours')?.value;\n                if (kwh) payload.kwh_rate = parseFloat(kwh);\n                if (watts) payload.watts = parseInt(watts, 10);\n                if (hours) payload.hours_per_day = parseFloat(hours);\n            }\n            // Call cost API\n            const r = await fetch(api('/api/cost/estimate'), {\n                method: 'POST',\n                headers: {'Content-Type':'application/json'},\n                body: JSON.stringify(payload)
});\n            const d = await r.json();\n            rows.push({\n                name: c.name,\n                env: c.env,\n                provider,\n                model,\n                daily: d.daily,\n                monthly: d.monthly,\n                breakdown: d.breakdown\n            });\n        }\n\n        // Rank by monthly (ascending), then prefer cheaper that meet budget if budget>0\n        const ranked = rows.sort((a,b) => a.monthly - b.monthly);\n        let winner = ranked[0];\n        if (budget > 0) {\n            const within = ranked.filter(r => r.monthly <= budget);\n            if (within.length) winner = within[within.length - 1]; // Pick most expensive within budget\n        }\n\n        const triOut = $('#tri-out');\n        if (triOut) {\n            const lines = [];\n            ranked.forEach(r => {\n                const mark = r.name === winner.name ? '✓' : ' ';\n                const header = `${mark} ${r.name.toUpperCase().padEnd(15)} $${r.monthly.toFixed(2)}/mo`;\n                lines.push(header);\n                lines.push(`  Inference:  ${r.env.GEN_MODEL || '—'}`);\n                lines.push(`  Embedding:  ${r.env.EMBEDDING_TYPE || '—'}`);\n                lines.push(`  Rerank:     ${r.env.RERANK_BACKEND || 'none'}`);\n                lines.push(`  MQ:${r.env.MQ_REWRITES||'3'}  Final-K:${r.env.FINAL_K||'10'}  Sparse:${r.env.TOPK_SPARSE||'75'}  Dense:${r.env.TOPK_DENSE||'75'}`);
lines.push('');\n            });\n            triOut.textContent = lines.join('\n').trim();\n        }\n\n        return { winner, ranked };\n    }\n\n    async function triChooseAndApply() {\n        console.log('[AUTO-PROFILE] Button clicked - starting triChooseAndApply');\n\n        // Show loading state\n        const placeholder = $('#profile-placeholder');\n        const resultsContent = $('#profile-results-content');\n        console.log('[AUTO-PROFILE] Elements found:', { placeholder: !!placeholder, resultsContent: !!resultsContent });\n\n        if (placeholder) placeholder.style.display = 'flex';\n        if (resultsContent) resultsContent.style.display = 'none';\n\n        // Add loading spinner to placeholder\n        if (placeholder) {\n            placeholder.innerHTML = `\n                <div style="display:flex;flex-direction:column;align-items:center;justify-content:center;">\n                    <div style="width:48px;height:48px;border:3px solid #2a2a2a;border-top-color:#00ff88;border-radius:50%;animation:spin 1s linear infinite;margin-bottom:16px;"></div>\n                    <p style="font-size:14px;color:#666;">Analyzing hardware and generating profile...</p>
</div>\n                <style>@keyframes spin { to { transform: rotate(360deg); } }</style>\n            `;\n        }\n\n        const { winner, ranked } = await triCostSelect();\n        const budget = Number($('#budget')?.value || 0);\n\n        // Scan hardware if not already done\n        let scan = state.hwScan;\n        if (!scan) {\n            try {\n                const r = await fetch(api('/api/scan-hw'), { method: 'POST' });\n                scan = await r.json();\n                state.hwScan = scan;\n            } catch (e) {\n                console.error('HW scan failed:', e);\n                scan = null;\n            }\n        }\n\n        // Render rich profile display using ProfileRenderer\n        if (window.ProfileRenderer && resultsContent) {\n            try {\n                const html = window.ProfileRenderer.renderProfileResults(winner.env, scan, budget);\n                resultsContent.innerHTML = html;\n                // Bind tooltips inside the rendered preview\n                if (window.ProfileRenderer.bindTooltips) window.ProfileRenderer.bindTooltips(resultsContent);\n\n                // Hide placeholder, show results\n                if (placeholder) placeholder.style.display = 'none';\n                resultsContent.style.display = 'block';\n            } catch (err) {\n                console.error('ProfileRenderer error:', err);\n                // Fallback to simple display\n                if (resultsContent) {
resultsContent.innerHTML = '<pre style="color:#ff6b6b;padding:20px;">Error rendering profile: ' + err.message + '</pre>';\n                    resultsContent.style.display = 'block';\n                    if (placeholder) placeholder.style.display = 'none';\n                }\n            }\n        } else {\n            console.error('ProfileRenderer not available:', { hasRenderer: !!window.ProfileRenderer, hasContent: !!resultsContent });\n            // Fallback to old method\n            if (resultsContent) {\n                resultsContent.innerHTML = '<pre style="padding:20px;color:#aaa;">' + JSON.stringify(winner.env, null, 2) + '</pre>';\n                resultsContent.style.display = 'block';\n                if (placeholder) placeholder.style.display = 'none';\n            }\n        }\n\n        // Wire up action buttons (always, regardless of renderer)\n        const applyBtn = document.getElementById('apply-profile-btn');\n        if (applyBtn) {\n            applyBtn.addEventListener('click', async () => {\n                const r = await fetch(api('/api/profiles/apply'), {\n                    method: 'POST',\n                    headers: { 'Content-Type':'application/json' },\n                    body: JSON.stringify({ profile: winner.env })\n                });\n                if (!r.ok) {\n                    alert('Apply failed');\n                    return;
}\n                alert(`✓ Applied: ${winner.name} ($${winner.monthly.toFixed(2)}/mo)\n\nSettings are now active. Refresh the page to see updated values.`);\n                await loadConfig();\n            });\n        }\n\n        const exportBtn = document.getElementById('export-profile-btn');\n        if (exportBtn) {\n            exportBtn.addEventListener('click', () => {\n                const blob = new Blob([JSON.stringify(winner.env, null, 2)], { type: 'application/json' });\n                const url = URL.createObjectURL(blob);\n                const a = document.createElement('a');\n                a.href = url;\n                a.download = `profile-${winner.name.toLowerCase().replace(/[^a-z0-9]/g, '-')}-${Date.now()}.json`;\n                a.click();\n                URL.revokeObjectURL(url);\n            });\n        }\n\n        const saveBtn = document.getElementById('save-profile-btn');\n        if (saveBtn) {\n            saveBtn.addEventListener('click', async () => {\n                const name = prompt('Profile name:', winner.name.toLowerCase().replace(/[^a-z0-9]/g, '-'));\n                if (!name) return;\n                const r = await fetch(api('/api/profiles/save'), {\n                    method: 'POST',\n                    headers: { 'Content-Type':'application/json' },\n                    body: JSON.stringify({ name, profile: winner.env })
});\n                if (r.ok) {\n                    alert(`✓ Saved as "${name}"`);\n                    await loadProfiles();\n                } else {\n                    alert('Save failed');\n                }\n            });\n        }\n    }\n\n    // Wizard helpers\n    function buildWizardProfile(scan, budget) {\n        // Legacy single-profile builder (kept for compatibility)\n        const hasLocal = scan?.runtimes?.ollama || scan?.runtimes?.coreml;\n        const budgetNum = Number(budget) || 0;\n        const defaultGen = hasLocal && budgetNum === 0 ? 'qwen3-coder:14b' : 'gpt-4o-mini';\n        const defaultEmb = budgetNum === 0 ? (hasLocal ? 'local' : 'mxbai') : 'openai';\n        const defaultRprov = budgetNum === 0 ? (hasLocal ? 'local' : 'none') : 'cohere';\n\n        const profile = {\n            GEN_MODEL: defaultGen,\n            EMBEDDING_TYPE: defaultEmb,\n            RERANK_BACKEND: defaultRprov,\n            MQ_REWRITES: budgetNum > 50 ? '6' : '3',\n            FINAL_K: budgetNum > 50 ? '20' : '10',\n            TOPK_SPARSE: budgetNum > 50 ? '120' : '75',\n            TOPK_DENSE: budgetNum > 50 ? '120' : '75',\n            HYDRATION_MODE: 'lazy',\n        };\n        return profile;\n    }\n\n    function seedWizardFromEnv(env) {\n        const wzGen = $('#wizard-gen-model');\n        if (wzGen && env.GEN_MODEL) wzGen.value = env.GEN_MODEL;\n        const wzEmb = $('#wizard-embed-provider');
if (wzEmb && env.EMBEDDING_TYPE) wzEmb.value = env.EMBEDDING_TYPE;\n        const wzRprov = $('#wizard-rerank-provider');\n        if (wzRprov && env.RERANK_BACKEND) wzRprov.value = env.RERANK_BACKEND;\n        const wzRmod = $('#wizard-rerank-model');\n        if (wzRmod && (env.COHERE_RERANK_MODEL || env.RERANKER_MODEL)) wzRmod.value = env.COHERE_RERANK_MODEL || env.RERANKER_MODEL;\n    }\n\n    function loadWizardFromEnv() {\n        const env = (state.config && state.config.env) || {};\n        seedWizardFromEnv(env);\n        updateWizardSummary();\n    }\n\n    function updateWizardSummary() {\n        const scanOut = $('#scan-out');\n        let hw = '';\n        if (scanOut && scanOut.dataset.scanData) {\n            try {\n                const s = JSON.parse(scanOut.dataset.scanData);\n                hw = `${s.info?.cpu_cores||'?'} cores, ${s.info?.mem_gb||'?'} GB RAM, runtimes: ${Object.keys(s.runtimes||{}).filter(k=>s.runtimes[k]).join(', ')||'none'}`;\n            } catch { hw = '(hardware not scanned)'; }\n        } else {\n            hw = '(hardware not scanned)';\n        }\n        const gen = ($('#wizard-gen-model')?.value || '(GEN_MODEL not set)');\n        const emb = ($('#wizard-embed-provider')?.value || (state.config?.env?.EMBEDDING_TYPE || '(use current)'));
const rprov = ($('#wizard-rerank-provider')?.value || (state.config?.env?.RERANK_BACKEND || '(use current)'));\n        const rmod = ($('#wizard-rerank-model')?.value || state.config?.env?.COHERE_RERANK_MODEL || state.config?.env?.RERANKER_MODEL || '');\n        const budget = $('#budget')?.value || '0';\n        const line = `Hardware: ${hw}\nModels: gen=${gen}, emb=${emb}, rerank=${rprov}${rmod?`:${rmod}`:''}\nBudget: $${budget}/mo`;\n        const el = $('#wizard-summary'); if (el) el.textContent = line;\n    }\n\n    // Keep summary in sync\n    ;['wizard-gen-model','wizard-embed-provider','wizard-rerank-provider','wizard-rerank-model','budget'].forEach(id => {\n        const el = document.getElementById(id); if (el) el.addEventListener('input', updateWizardSummary);\n    });\n\n    async function applyProfile() {\n        const scanText = $('#scan-out').textContent;\n        if (!scanText || scanText === '') {\n            alert('Please scan hardware first');\n            return;\n        }\n\n        const scan = JSON.parse(scanText);\n        const budget = parseFloat($('#budget').value || '0');\n        const prof = proposeProfile(scan, budget);
try {\n            const r = await fetch(api('/api/profiles/apply'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ profile: prof })\n            });\n\n            const d = await r.json();\n            alert(`Profile applied: ${d.applied_keys.join(', ')}`);\n            await loadConfig();\n        } catch (e) {\n            alert('Failed to apply profile: ' + e.message);\n        }\n    }\n\n    async function loadProfiles() {\n        try {\n            const r = await fetch(api('/api/profiles'));\n            const d = await r.json();\n            state.profiles = d.profiles || [];\n            state.defaultProfile = d.default || null;\n\n            const ul = $('#profiles-ul');\n            const tooltip = $('#profile-tooltip');\n            ul.innerHTML = '';\n\n            state.profiles.forEach((name) => {\n                const li = document.createElement('li');\n                li.textContent = name;\n                li.style.cssText = 'padding: 6px 8px; color: #aaa; cursor: pointer; border-radius: 4px; transition: all 0.15s ease;';\n\n                li.addEventListener('mouseenter', async (e) => {\n                    li.style.background = '#1a1a1a';\n                    li.style.color = '#00ff88';\n                    await showProfileTooltip(name, e);\n                });\n\n                li.addEventListener('mouseleave', () => {\n                    li.style.background = 'transparent';
li.style.color = '#aaa';\n                    hideProfileTooltip();\n                });\n\n                li.addEventListener('click', () => loadAndApplyProfile(name));\n                ul.appendChild(li);\n            });\n        } catch (e) {\n            console.error('Failed to load profiles:', e);\n        }\n    }\n\n    async function showProfileTooltip(name, event) {\n        const tooltip = $('#profile-tooltip');\n        if (!tooltip) return;\n\n        try {\n            // Fetch the profile data\n            const r = await fetch(api(`/api/profiles/${encodeURIComponent(name)}`));\n            if (!r.ok) return;\n\n            const d = await r.json();\n            const prof = d.profile || {};\n\n            // Build tooltip content\n            let html = `<div class="tooltip-header">${name}</div>`;\n\n            const entries = Object.entries(prof);\n            if (entries.length === 0) {\n                html += '<div style="color: #666; font-size: 11px; font-style: italic;">Empty profile</div>';\n            } else {\n                entries.forEach(([key, value]) => {\n                    const displayValue = String(value).length > 40\n                        ? String(value).substring(0, 37) + '...'\n                        : String(value);\n                    html += `\n                        <div class="tooltip-item">\n                            <div class="tooltip-key">${key}</div>\n                            <div class="tooltip-value">${displayValue}</div>\n                        </div>\n                    `;\n                });
}\n\n            tooltip.innerHTML = html;\n\n            // Position tooltip near the mouse\n            const rect = event.target.getBoundingClientRect();\n            tooltip.style.left = (rect.right + 10) + 'px';\n            tooltip.style.top = rect.top + 'px';\n            tooltip.style.display = 'block';\n\n        } catch (e) {\n            console.error('Failed to load profile for tooltip:', e);\n        }\n    }\n\n    function hideProfileTooltip() {\n        const tooltip = $('#profile-tooltip');\n        if (tooltip) {\n            tooltip.style.display = 'none';\n        }\n    }\n\n    async function loadAndApplyProfile(name) {\n        try {\n            // Load the profile data\n            const r = await fetch(api(`/api/profiles/${encodeURIComponent(name)}`));\n            if (!r.ok) {\n                alert(`Failed to load profile "${name}"`);\n                return;\n            }\n            const d = await r.json();\n            const prof = d.profile || {};\n\n            // Apply the profile\n            const applyRes = await fetch(api('/api/profiles/apply'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ profile: prof })\n            });\n\n            if (!applyRes.ok) {\n                alert(`Failed to apply profile "${name}"`);\n                return;\n            }\n\n            const applyData = await applyRes.json();\n            alert(`✓ Profile "${name}" applied successfully!\n\nApplied keys: ${applyData.applied_keys?.join(', ') || 'none'}`);
// Reload config to show updated values in UI\n            await loadConfig();\n        } catch (e) {\n            alert(`Error loading profile "${name}": ${e.message}`);\n        }\n    }\n\n    async function saveProfile() {\n        const name = $('#profile-name').value.trim();\n        if (!name) {\n            alert('Enter a profile name');\n            return;\n        }\n\n        // Prefer wizard preview if present; otherwise build from scan\n        let prof = null;\n        const preview = $('#profile-preview');\n        if (preview.dataset.profileData) {\n            try { prof = JSON.parse(preview.dataset.profileData); } catch {}\n        }\n        if (!prof) {\n            const scanOut = $('#scan-out');\n            if (!scanOut.dataset.scanData) { alert('Please scan hardware first'); return; }\n            const scan = JSON.parse(scanOut.dataset.scanData);\n            const budget = parseFloat($('#budget').value || '0');\n            prof = proposeProfile(scan, budget);\n        }\n        // Remove cost estimate before saving\n        if (prof.__estimate__) delete prof.__estimate__;\n\n        try {\n            const r = await fetch(api('/api/profiles/save'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ name, profile: prof })\n            });\n\n            if (!r.ok) {\n                alert('Save failed');
return;\n            }\n\n            await loadProfiles();\n            alert(`Saved profile: ${name}`);\n        } catch (e) {\n            alert('Failed to save profile: ' + e.message);\n        }\n    }\n\n    // ---------------- Secrets Ingest (Drag & Drop) ----------------\n    function bindDropzone() {\n        const dz = $('#dropzone');\n        const fi = $('#file-input');\n\n        function openPicker() {\n            fi.click();\n        }\n\n        dz.addEventListener('click', openPicker);\n\n        dz.addEventListener('dragover', (e) => {\n            e.preventDefault();\n            dz.style.background = '#111111';\n        });\n\n        dz.addEventListener('dragleave', (e) => {\n            dz.style.background = '';\n        });\n\n        dz.addEventListener('drop', async (e) => {\n            e.preventDefault();\n            dz.style.background = '';\n            const file = e.dataTransfer.files?.[0];\n            if (file) await ingestFile(file);\n        });\n\n        fi.addEventListener('change', async (e) => {\n            const file = e.target.files?.[0];\n            if (file) await ingestFile(file);\n            fi.value = '';\n        });\n    }\n\n    async function ingestFile(file) {\n        const persist = $('#persist-secrets').checked;\n        const fd = new FormData();\n        fd.append('file', file);\n        fd.append('persist', String(persist));\n\n        try {\n            const r = await fetch(api('/api/secrets/ingest'), {
method: 'POST',\n                body: fd\n            });\n\n            const d = await r.json();\n            $('#ingest-out').textContent = JSON.stringify(d, null, 2);\n            await loadConfig();\n        } catch (e) {\n            alert('Secrets ingest failed: ' + e.message);\n        }\n    }\n\n    // ---------------- Quick Action Helpers ----------------\n    function setButtonState(btn, state) {\n        if (!btn) return;\n        btn.classList.remove('loading', 'success', 'error');\n        if (state === 'loading') btn.classList.add('loading');\n        else if (state === 'success') btn.classList.add('success');\n        else if (state === 'error') btn.classList.add('error');\n    }\n\n    function showStatus(message, type = 'info') {\n        const status = document.getElementById('dash-index-status');\n        const bar = document.getElementById('dash-index-bar');\n        if (!status) return;\n\n        const timestamp = new Date().toLocaleTimeString();\n        const color = type === 'success' ? '#00ff88' : type === 'error' ? '#ff6b6b' : '#5b9dff';\n        const icon = type === 'success' ? '✓' : type === 'error' ? '✗' : '•';\n\n        status.innerHTML = `<span style="color:${color};">${icon}</span> <span style="color:#666;">[${timestamp}]</span> ${message}`;
if (bar) {\n            if (type === 'loading') {\n                bar.style.width = '50%';\n                bar.style.opacity = '0.6';\n            } else if (type === 'success') {\n                bar.style.width = '100%';\n                bar.style.opacity = '1';\n                setTimeout(() => { bar.style.width = '0%'; }, 2000);\n            } else if (type === 'error') {\n                bar.style.width = '100%';\n                bar.style.background = '#ff6b6b';\n                bar.style.opacity = '1';\n                setTimeout(() => {\n                    bar.style.width = '0%';\n                    bar.style.background = 'linear-gradient(90deg, #ff9b5e 0%, #ff6b9d 100%)';\n                }, 2000);\n            }\n        }\n    }\n\n    // Simulated progress ticker for long-running actions\n    function startSimProgress(label, total = 80, tips = []) {\n        const status = document.getElementById('dash-index-status');\n        const bar = document.getElementById('dash-index-bar');\n        let step = 0; let tipIdx = 0;\n        function tick() {\n            step = Math.min(total, step + 1);\n            const pct = Math.min(90, Math.max(5, Math.floor((step / Math.max(1,total)) * 90)));\n            if (bar) { bar.style.width = pct + '%'; bar.style.opacity = '0.9'; }\n            const tip = tips.length ? (tips[tipIdx % tips.length]) : '';\n            tipIdx++;\n            if (status) {\n                status.innerHTML = `\n                    <div class="mono" style="color:#bbb;">
🔎 ${label}<br>\n                        Scanning ${step} of ${total}… ${tip ? `<span style='color:#666'>(${tip})</span>` : ''}\n                    </div>\n                `;\n            }\n        }\n        const id = setInterval(tick, 900);\n        tick();\n        return {\n            stop: () => {\n                clearInterval(id);\n                if (bar) { bar.style.width = '100%'; bar.style.opacity = '1'; setTimeout(()=>{ bar.style.width='0%'; }, 1500); }\n            }\n        };\n    }\n\n    function bindQuickAction(btnId, handler) {\n        const btn = document.getElementById(btnId);\n        if (!btn) return;\n\n        btn.addEventListener('click', async (e) => {\n            e.preventDefault();\n            setButtonState(btn, 'loading');\n\n            try {\n                await handler();\n                setButtonState(btn, 'success');\n                setTimeout(() => setButtonState(btn, null), 1500);\n            } catch (err) {\n                console.error(`[${btnId}] Error:`, err);\n                setButtonState(btn, 'error');\n                setTimeout(() => setButtonState(btn, null), 2000);\n            }\n        });\n    }\n\n    // ---------------- Quick Actions ----------------\n    async function changeRepo() {\n        showStatus('Loading repositories...', 'loading');\n\n        try {\n            const response = await fetch(api('/api/config'));\n            const data = await response.json();\n            const repos = data.repos || [];
const currentRepo = (data.env && data.env.REPO) || data.default_repo || 'agro';\n\n            if (repos.length === 0) {\n                showStatus('No repositories configured', 'error');\n                return;\n            }\n\n            // Create a dialog-like selection UI\n            const repoHtml = repos.map((repo, idx) => {\n                const isActive = repo.slug === currentRepo;\n                return `\n                    <button\n                        class="small-button"\n                        data-repo="${repo.slug}"\n                        style="\n                            margin-bottom: 8px;\n                            background: ${isActive ? '#00ff88' : '#1a1a1a'};\n                            color: ${isActive ? '#000' : '#aaa'};\n                            border: 1px solid ${isActive ? '#00ff88' : '#2a2a2a'};\n                            width: 100%;\n                            text-align: left;\n                            padding: 12px;\n                            display: flex;\n                            justify-content: space-between;\n                            align-items: center;\n                        "\n                    >\n                        <span>${repo.slug}</span>\n                        ${isActive ? '<span>✓ ACTIVE</span>' : ''}\n                    </button>\n                `;\n            }).join('');\n\n            const status = document.getElementById('dash-index-status');\n            if (status) {\n                status.innerHTML = `\n                    <div style="padding: 8px;">\n                        <div style="margin-bottom: 12px; color: #00ff88; font-weight: 600;">Select Repository:</div>\n                        ${repoHtml}\n                    </div>\n                `;\n\n                // Bind click handlers\n                repos.forEach(repo => {
const btn = status.querySelector(`[data-repo="${repo.slug}"]`);\n                    if (btn && repo.slug !== currentRepo) {\n                        btn.addEventListener('click', async () => {\n                            btn.disabled = true;\n                            btn.style.opacity = '0.6';\n                            showStatus(`Switching to ${repo.slug}...`, 'loading');\n\n                            try {\n                                const updateResponse = await fetch(api('/api/env/update'), {\n                                    method: 'POST',\n                                    headers: { 'Content-Type': 'application/json' },\n                                    body: JSON.stringify({ REPO: repo.slug })\n                                });\n\n                                if (updateResponse.ok) {\n                                    showStatus(`Switched to ${repo.slug}`, 'success');\n                                    setTimeout(() => refreshDashboard(), 500);\n                                } else {\n                                    showStatus(`Failed to switch to ${repo.slug}`, 'error');\n                                }\n                            } catch (err) {\n                                showStatus(`Error switching repo: ${err.message}`, 'error');\n                            }\n                        });\n                    }\n                });\n            }\n        } catch (err) {\n            showStatus(`Error loading repos: ${err.message}`, 'error');\n        }\n    }\n\n    async function createKeywords() {\n        const btn = document.getElementById('btn-generate-keywords');\n        setButtonState(btn, 'loading');\n        showStatus('Generating keywords (this may take 2–5 minutes)...', 'loading');\n\n        try {\n            const response = await fetch(api('/api/config'));
const data = await response.json();\n            const env = (data && data.env) || (state.config && state.config.env) || {};\n            const repo = env.REPO || data.default_repo || 'agro';\n            const modeSel = document.getElementById('kw-gen-mode');\n            const mode = modeSel ? (modeSel.value || 'llm') : 'llm';\n            const maxFilesEl = document.querySelector('[name="KEYWORDS_MAX_FILES"]');\n            const max_files = maxFilesEl && maxFilesEl.value ? Number(maxFilesEl.value) : undefined;\n            // Force OpenAI 4o for this on-click run (per request)\n            const backend = 'openai';\n            let model = 'gpt-4o';\n            const tips = [\n                'After keywords, build Semantic Cards in Repos → Indexing',\n                'Add Path Boosts to steer retrieval (Repos tab)',\n                'Toggle ENRICH_CODE_CHUNKS to store per‑chunk summaries',\n                'Use shared profile to reuse indices across branches (Infrastructure)'\n            ];\n            var sim = startSimProgress(\n                mode === 'llm' ? `Mode: LLM • Backend: ${backend} • Model: ${model}` : 'Mode: Heuristic • Scanning tokens and file coverage…',\n                max_files || 80,\n                tips\n            );\n\n            // Call the keywords generation endpoint\n            const createResponse = await fetch(api('/api/keywords/generate'), {
method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ repo, mode, max_files, backend, openai_model: (backend==='openai'?model:undefined) })\n            });\n\n            if (createResponse.ok) {\n                const result = await createResponse.json();\n\n                if (result.ok) {\n                    const discr = result.discriminative?.count || 0;\n                    const sema = result.semantic?.count || 0;\n                    const total = result.total_count || 0;\n                    const duration = result.duration_seconds || 0;\n\n                    // Build detailed status message\n                    const status = `\n                        <div style="font-size:14px;font-weight:600;color:#00ff88;margin-bottom:8px;">\n                            ✓ Generated ${total} keywords for repo: ${repo}\n                        </div>\n                        <div style="font-size:12px;color:#ddd;margin-bottom:4px;">\n                            <span style="color:#b794f6;">Discriminative:</span> ${discr} keywords\n                        </div>\n                        <div style="font-size:12px;color:#ddd;margin-bottom:4px;">\n                            <span style="color:#5b9dff;">Semantic:</span> ${sema} keywords\n                        </div>\n                        <div style="font-size:12px;color:#ddd;margin-bottom:4px;">\n                            <span style="color:#00d6ff;">LLM:</span> ${result.llm?.count || 0} keywords
</div>\n                        <div style="font-size:11px;color:#999;margin-top:8px;">\n                            Completed in ${duration}s\n                        </div>\n                        <div style="font-size:11px;color:#666;margin-top:6px;">\n                            → View keywords in <span style="color:#00ff88;font-weight:600;">Repos & Indexing</span> tab\n                        </div>\n                    `;\n\n                    const statusDiv = document.getElementById('dash-index-status');\n                    if (statusDiv) {\n                        statusDiv.innerHTML = status + `\n                            <div style="margin-top:8px;">\n                                <button id="cta-build-cards" class="small-button">Build Cards Now</button>\n                            </div>\n                        `;\n                        const cta = document.getElementById('cta-build-cards');\n                        if (cta) cta.addEventListener('click', async () => { try { switchTab('repos'); startCardsBuild(); } catch(e) { showStatus('Unable to start cards build', 'error'); } });\n                    }\n\n                    // Reload keywords to populate the UI\n                    await loadKeywords();\n                    setButtonState(btn, 'success');\n                    setTimeout(()=> setButtonState(btn, null), 1500);\n                    try { if (sim && sim.stop) sim.stop(); } catch {}\n                } else {\n                    showStatus(`Failed to generate keywords: ${result.error || 'Unknown error'}`, 'error');\n                    setButtonState(btn, 'error');
setTimeout(()=> setButtonState(btn, null), 2000);\n                    try { if (sim && sim.stop) sim.stop(); } catch {}\n                }\n            } else {\n                const error = await createResponse.text();\n                showStatus(`Failed to generate keywords: ${error}`, 'error');\n                setButtonState(btn, 'error');\n                setTimeout(()=> setButtonState(btn, null), 2000);\n                try { if (sim && sim.stop) sim.stop(); } catch {}\n            }\n        } catch (err) {\n            showStatus(`Error generating keywords: ${err.message}`, 'error');\n            const btn = document.getElementById('btn-generate-keywords');\n            setButtonState(btn, 'error');\n            setTimeout(()=> setButtonState(btn, null), 2000);\n            try { if (typeof sim !== 'undefined' && sim && sim.stop) sim.stop(); } catch {}\n        }\n    }\n\n    async function reloadConfig() {\n        showStatus('Reloading configuration...', 'loading');\n\n        try {\n            const response = await fetch(api('/api/env/reload'), {\n                method: 'POST'\n            });\n\n            if (response.ok) {\n                showStatus('Configuration reloaded successfully', 'success');\n                await loadConfig();\n                await refreshDashboard();\n            } else {\n                const error = await response.text();\n                showStatus(`Failed to reload config: ${error}`, 'error');
}\n        } catch (err) {\n            showStatus(`Error reloading config: ${err.message}`, 'error');\n        }\n    }\n\n    // ---------------- Bindings ----------------\n    function bindActions() {\n        const btnHealth = $('#btn-health'); if (btnHealth) btnHealth.addEventListener('click', checkHealth);\n        const saveBtn = $('#save-btn'); if (saveBtn) saveBtn.addEventListener('click', saveConfig);\n        const btnEstimate = $('#btn-estimate'); if (btnEstimate) btnEstimate.addEventListener('click', estimateCost);\n        const btnScanHw = $('#btn-scan-hw'); if (btnScanHw) btnScanHw.addEventListener('click', scanHardware);\n        const legacyApply = document.getElementById('btn-apply-profile');\n        if (legacyApply) legacyApply.addEventListener('click', applyProfile);\n        const btnSaveProfile = $('#btn-save-profile'); if (btnSaveProfile) btnSaveProfile.addEventListener('click', saveProfile);\n        const genBtn = document.getElementById('btn-generate-profile');\n        if (genBtn) genBtn.addEventListener('click', generateProfileWizard);\n        const applyWizard = document.getElementById('btn-apply-wizard');
if (applyWizard) applyWizard.addEventListener('click', applyProfileWizard);\n        const oneClick = document.getElementById('btn-wizard-oneclick');\n        if (oneClick) oneClick.addEventListener('click', onWizardOneClick);\n        const loadCur = document.getElementById('btn-wizard-load-cur');\n        if (loadCur) loadCur.addEventListener('click', loadWizardFromEnv);\n\n        // Retrieval tab: trace button\n        const rt = document.getElementById('btn-trace-latest');\n        if (rt) rt.addEventListener('click', ()=>loadLatestTrace('trace-output'));\n        const rtLS = document.getElementById('btn-trace-open-ls');\n        if (rtLS) rtLS.addEventListener('click', ()=>{\n            try{\n                const prj = (state.config?.env?.LANGCHAIN_PROJECT||'agro');\n                const url = `https://smith.langchain.com/projects/${encodeURIComponent(prj)}/runs`;\n                window.open(url, '_blank');\n            }catch(e){ alert('Unable to open LangSmith: '+e.message); }\n        });\n\n        // Chat bindings\n        const chatSend = document.getElementById('chat-send');\n        if (chatSend) chatSend.addEventListener('click', sendChat);
const chatInput = document.getElementById('chat-input');\n        if (chatInput) chatInput.addEventListener('keydown', (e)=>{ if ((e.ctrlKey||e.metaKey) && e.key==='Enter') { e.preventDefault(); sendChat(); }});\n        const chatClear = document.getElementById('chat-clear');\n        if (chatClear) chatClear.addEventListener('click', ()=>{ const box=document.getElementById('chat-messages'); if (box) box.innerHTML='';});\n        const chatTrace = document.getElementById('chat-trace');\n        if (chatTrace) chatTrace.addEventListener('toggle', ()=>{ if (chatTrace.open) loadLatestTrace('chat-trace-output'); });\n\n        // Dopamine-y feedback on any button click\n        document.querySelectorAll('button').forEach(btn => {\n            if (btn.dataset && btn.dataset.dopamineBound) return;\n            if (!btn.dataset) btn.dataset = {};\n            btn.dataset.dopamineBound = '1';\n            btn.addEventListener('click', () => {\n                const label = (btn.textContent || btn.id || 'button').trim();\n                if (label) showStatus(`→ ${label}`, 'info');\n            });\n        });\n\n        const addGen = document.getElementById('btn-add-gen-model');
if (addGen) addGen.addEventListener('click', addGenModelFlow);\n        const addEmb = document.getElementById('btn-add-embed-model');\n        if (addEmb) addEmb.addEventListener('click', addEmbedModelFlow);\n        const addRr = document.getElementById('btn-add-rerank-model');\n        if (addRr) addRr.addEventListener('click', addRerankModelFlow);\n        const addCost = document.getElementById('btn-add-cost-model');\n        if (addCost) addCost.addEventListener('click', addCostModelFlow);\n\n        const btnAuto = document.getElementById('btn-autotune-refresh');\n        if (btnAuto) btnAuto.addEventListener('click', refreshAutotune);\n        const cbAuto = document.getElementById('autotune-enabled');\n        if (cbAuto) cbAuto.addEventListener('change', setAutotuneEnabled);\n\n        const btnIndex = document.getElementById('btn-index-start');\n        if (btnIndex) btnIndex.addEventListener('click', startIndexing);\n        document.querySelectorAll('#btn-cards-build').forEach(btn => {\n            if (!btn.dataset.cardsBuildBound) { btn.dataset.cardsBuildBound='1'; btn.addEventListener('click', () => startCardsBuild()); }
});\n        const btnCardsRefresh = document.getElementById('btn-cards-refresh');\n        if (btnCardsRefresh) btnCardsRefresh.addEventListener('click', refreshCards);\n        // Dashboard button bindings with enhanced feedback\n        bindQuickAction('dash-index-start', startIndexing);\n        bindQuickAction('dash-cards-refresh', refreshCards);\n        bindQuickAction('dash-change-repo', changeRepo);\n        bindQuickAction('dash-reload-config', reloadConfig);\n        // Keep cost panel in sync with wizard selections\n        const map = [\n            ['wizard-gen-model','cost-model'],\n            ['wizard-embed-provider','cost-embed-provider'],\n            ['wizard-rerank-provider','cost-rerank-provider'],\n            ['wizard-rerank-model','cost-rerank-model'],\n        ];\n        map.forEach(([a,b]) => { const elA = document.getElementById(a), elB = document.getElementById(b); if (elA && elB) elA.addEventListener('input', () => { elB.value = elA.value; }); });\n    }\n\n    // ---------------- Collapsible Sections ----------------\n    function bindCollapsibleSections() {\n        const headers = document.querySelectorAll('.collapsible-header');
headers.forEach(header => {\n            header.addEventListener('click', (e) => {\n                // Don't collapse if clicking on help icon\n                if (e.target.closest('.tooltip-wrap')) return;\n\n                const targetId = header.getAttribute('data-target');\n                const content = document.getElementById(targetId);\n\n                if (!content) return;\n\n                // Toggle collapsed state\n                const isCollapsed = content.classList.contains('collapsed');\n\n                if (isCollapsed) {\n                    content.classList.remove('collapsed');\n                    header.classList.remove('collapsed');\n                } else {\n                    content.classList.add('collapsed');\n                    header.classList.add('collapsed');\n                }\n\n                // Save state to localStorage\n                const storageKey = `collapsed-${targetId}`;\n                localStorage.setItem(storageKey, isCollapsed ? '0' : '1');\n            });\n\n            // Restore collapsed state from localStorage\n            const targetId = header.getAttribute('data-target');\n            const storageKey = `collapsed-${targetId}`;\n            const savedState = localStorage.getItem(storageKey);\n\n            if (savedState === '1') {\n                const content = document.getElementById(targetId);\n                if (content) {\n                    content.classList.add('collapsed');
header.classList.add('collapsed');\n                }\n            }\n        });\n\n        // Theme selectors (topbar + misc) -> live apply + sync\n        const selTop = document.getElementById('theme-mode');\n        const selMisc = document.getElementById('misc-theme-mode');\n        function onThemeChange(src) {\n            const v = src.value;\n            if (selTop && selTop !== src) selTop.value = v;\n            if (selMisc && selMisc !== src) selMisc.value = v;\n            try { localStorage.setItem('THEME_MODE', v); } catch {}\n            applyTheme(v);\n        }\n        if (selTop) selTop.addEventListener('change', () => onThemeChange(selTop));\n        if (selMisc) selMisc.addEventListener('change', () => onThemeChange(selMisc));\n    }\n\n    // ---------------- Resizable Sidepanel ----------------\n    function bindResizableSidepanel() {\n        const handle = document.querySelector('.resize-handle');\n        if (!handle) return;\n\n        const MIN_WIDTH = 300;\n        const MAX_WIDTH = 800;\n        const STORAGE_KEY = 'agro-sidepanel-width';\n\n        // Restore saved width\n        const savedWidth = localStorage.getItem(STORAGE_KEY);\n        if (savedWidth) {\n            const width = parseInt(savedWidth, 10);\n            if (width >= MIN_WIDTH && width <= MAX_WIDTH) {
document.documentElement.style.setProperty('--sidepanel-width', width + 'px');\n            }\n        }\n\n        let isDragging = false;\n        let startX = 0;\n        let startWidth = 0;\n\n        function getCurrentWidth() {\n            const rootStyle = getComputedStyle(document.documentElement);\n            const widthStr = rootStyle.getPropertyValue('--sidepanel-width').trim();\n            return parseInt(widthStr, 10) || 400;\n        }\n\n        function setWidth(width) {\n            const clampedWidth = Math.max(MIN_WIDTH, Math.min(MAX_WIDTH, width));\n            document.documentElement.style.setProperty('--sidepanel-width', clampedWidth + 'px');\n            localStorage.setItem(STORAGE_KEY, clampedWidth.toString());\n        }\n\n        handle.addEventListener('mousedown', (e) => {\n            isDragging = true;\n            startX = e.clientX;\n            startWidth = getCurrentWidth();\n            handle.classList.add('dragging');\n            document.body.style.cursor = 'col-resize';\n            document.body.style.userSelect = 'none';\n            e.preventDefault();\n        });\n\n        document.addEventListener('mousemove', (e) => {\n            if (!isDragging) return;\n            const deltaX = startX - e.clientX; // Reverse direction (dragging left increases width)
const newWidth = startWidth + deltaX;\n            setWidth(newWidth);\n        });\n\n        document.addEventListener('mouseup', () => {\n            if (!isDragging) return;\n            isDragging = false;\n            handle.classList.remove('dragging');\n            document.body.style.cursor = '';\n            document.body.style.userSelect = '';\n        });\n    }\n\n    // ---------------- Init ----------------\n    async function init() {\n        bindTabs();\n        bindActions();\n        bindGlobalSearchLive();\n        bindResizableSidepanel();\n        bindCollapsibleSections();\n        bindDropzone();\n        const hookBtn = document.getElementById('btn-install-hooks'); if (hookBtn) hookBtn.addEventListener('click', installHooks);\n        const genKwBtn = document.getElementById('btn-generate-keywords'); if (genKwBtn) genKwBtn.addEventListener('click', createKeywords);\n\n        await Promise.all([\n            loadPrices(),\n            loadConfig(),\n            loadProfiles(),\n            loadKeywords()\n        ]);\n\n        await checkHealth();\n        await refreshAutotune();\n        await refreshDashboard();\n        await refreshHooksStatus();\n        addHelpTooltips();\n        // Note: comma formatting removed for cost-* fields since they are type="number" inputs
wireDayConverters();\n    }\n\n    // Ensure init runs even if DOMContentLoaded already fired (scripts at body end)\n    if (document.readyState === 'loading') {\n        window.addEventListener('DOMContentLoaded', init);\n    } else {\n        init();\n    }\n\n    // Decide v1 (client) vs v2 (server) auto-profile\n    async function onWizardOneClick(e){\n        try{\n            const v2 = document.getElementById('apv2-enabled');\n            if (v2 && v2.checked && window.AutoProfileV2 && typeof window.AutoProfileV2.run === 'function'){\n                e.preventDefault();\n                await window.AutoProfileV2.run();\n                return;\n            }\n        }catch{}\n        return triChooseAndApply();\n    }\n\n    // ---------------- Global Search (live) ----------------\n    function bindGlobalSearchLive() {\n        const box = document.getElementById('global-search');\n        if (!box) return;\n        const pop = document.getElementById('search-results');\n        let index = [];\n        let items = []; let cursor = -1;\n        function ensureIndex(){\n            if (index.length) return index;\n            const idx=[];\n            $$('.settings-section').forEach(sec=>{\n                const title = (sec.querySelector('h3')?.textContent||'').toLowerCase();\n                sec.querySelectorAll('.input-group').forEach(g=>{
const label=(g.querySelector('label')?.textContent||'').trim();\n                    const input=g.querySelector('input,select,textarea');\n                    if (!input) return;\n                    const name=input.name||input.id||''; const ph=input.getAttribute('placeholder')||'';\n                    const content=(title+' '+label+' '+name+' '+ph).toLowerCase();\n                    idx.push({\n                        label: label||name,\n                        title: title,\n                        name: name,\n                        placeholder: ph,\n                        el: input,\n                        content\n                    });\n                });\n            });\n            index = idx; return idx;\n        }\n        function sectionGroupFor(el){\n            const tc = el.closest('.tab-content'); if (!tc) return 'dashboard';\n            const id = tc.id.replace('tab-','');\n            const map = { generation:'models', embeddings:'models', reranking:'models', retrieval:'retrieval', confidence:'retrieval', repos:'repos', indexing:'repos', infra:'infra', calculator:'tools', eval:'tools', misc:'tools', dashboard:'dashboard' };\n            return map[id] || id;\n        }\n        function go(item){\n            const tab = sectionGroupFor(item.el); switchTab(tab);\n            item.el.classList.add('search-hit'); item.el.scrollIntoView({behavior:'smooth', block:'center'});
setTimeout(()=> item.el.classList.remove('search-hit'), 1200);\n            if (pop) pop.style.display='none';\n        }\n        function highlightText(text, query){\n            if (!query) return text;\n            const regex = new RegExp(`(${query.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')})`, 'gi');\n            return text.replace(regex, '<span class="search-highlight">$1</span>');\n        }\n        function render(query=''){\n            if (!pop) return; pop.innerHTML='';\n            if (!items.length){ pop.style.display='none'; return; }\n            items.slice(0,15).forEach((r,i)=>{\n                const div=document.createElement('div');\n                div.className='item'+(i===cursor?' active':'');\n\n                const labelSpan = document.createElement('span');\n                labelSpan.className = 'item-label';\n                labelSpan.innerHTML = highlightText(r.label || r.name, query);\n\n                const contextSpan = document.createElement('span');\n                contextSpan.className = 'item-context';\n                const contextParts = [];\n                if (r.title) contextParts.push(highlightText(r.title, query));\n                if (r.name && r.name !== r.label) contextParts.push(highlightText(r.name, query));\n                contextSpan.innerHTML = contextParts.join(' • ');
div.appendChild(labelSpan);\n                if (contextParts.length > 0) div.appendChild(contextSpan);\n                div.addEventListener('click',()=>go(r));\n                pop.appendChild(div);\n            });\n            pop.style.display='block';\n        }\n        function search(q){\n            const s=q.trim().toLowerCase(); if(!s){ items=[]; render(); return; }\n            ensureIndex(); items = index.filter(x=> x.content.includes(s)); cursor=0; render(s);\n        }\n        document.addEventListener('click', (e)=>{ if (pop && !pop.contains(e.target) && e.target!==box) pop.style.display='none'; });\n        box.addEventListener('keydown', (e)=>{ if ((e.ctrlKey||e.metaKey) && e.key.toLowerCase()==='k'){ e.preventDefault(); box.focus(); box.select(); }});\n        box.addEventListener('input', ()=> search(box.value));\n        box.addEventListener('keydown', (e)=>{\n            if (!pop || pop.style.display!=='block') return;\n            if (e.key==='ArrowDown'){ e.preventDefault(); cursor=Math.min(cursor+1, items.length-1); render(); }\n            else if (e.key==='ArrowUp'){ e.preventDefault(); cursor=Math.max(cursor-1,0); render(); }\n            else if (e.key==='Enter'){ e.preventDefault(); if(items[cursor]) go(items[cursor]); }
});\n    }\n\n    // ---------------- Autotune ----------------\n    async function refreshAutotune() {\n        try {\n            const r = await fetch(api('/api/autotune/status'));\n            if (!r.ok) {\n                if (r.status === 403 || r.status === 402) {\n                    $('#autotune-mode').textContent = 'Pro required (set Edition to pro)';\n                } else {\n                    $('#autotune-mode').textContent = '—';\n                }\n                $('#autotune-enabled').checked = false;\n                return;\n            }\n            const d = await r.json();\n            $('#autotune-enabled').checked = !!d.enabled;\n            $('#autotune-mode').textContent = d.current_mode || '—';\n        } catch (e) {\n            $('#autotune-mode').textContent = '—';\n        }\n    }\n\n    // ---------------- Dashboard Summary ----------------\n    async function refreshDashboard() {\n        try {\n            const c = state.config || (await (await fetch(api('/api/config'))).json());\n            const repo = (c.env && (c.env.REPO || c.default_repo)) || '(none)';\n            const reposCount = (c.repos || []).length;\n            const dr = document.getElementById('dash-repo'); if (dr) dr.textContent = `${repo} (${reposCount} repos)`;\n        } catch {}\n\n        try {\n            const h = await (await fetch(api('/health'))).json();\n            const dh = document.getElementById('dash-health'); if (dh) dh.textContent = `${h.status}${h.graph_loaded? ' (graph ready)':''}`;
} catch {}\n\n        try {\n            const a = await (await fetch(api('/api/autotune/status'))).json();\n            const da = document.getElementById('dash-autotune'); if (da) da.textContent = a.enabled ? (a.current_mode || 'enabled') : 'disabled';\n        } catch { const da = document.getElementById('dash-autotune'); if (da) da.textContent = 'Pro required'; }\n\n        try {\n            const cards = await (await fetch(api('/api/cards'))).json();\n            const dc = document.getElementById('dash-cards'); if (dc) dc.textContent = `${cards.count || 0} cards`;\n        } catch {}\n\n        try {\n            const env = (state.config && state.config.env) || {};\n            const host = env.MCP_HTTP_HOST || '0.0.0.0';\n            const port = env.MCP_HTTP_PORT || '8013';\n            const path = env.MCP_HTTP_PATH || '/mcp';\n            const dm = document.getElementById('dash-mcp'); if (dm) dm.textContent = `${host}:${port}${path}`;\n        } catch {}\n\n        // Load initial index status to show metadata\n        try {\n            await pollIndexStatus();\n        } catch {}\n    }\n\n    // ---------------- Cards Viewer ----------------\n    async function loadCards() {\n        try {\n            const resp = await fetch(api('/api/cards'));\n            const data = await resp.json();
const cards = Array.isArray(data.cards) ? data.cards : [];\n            const last = data.last_build || null;\n            const lastBox = document.getElementById('cards-last-build');\n            if (lastBox) {\n                if (last && last.started_at) {\n                    const when = new Date(last.started_at).toLocaleString();\n                    const cnt = (last.result && last.result.cards_written) ? ` • ${last.result.cards_written} updated` : '';\n                    const dur = (last.result && typeof last.result.duration_s==='number') ? ` • ${last.result.duration_s}s` : '';\n                    lastBox.textContent = `Last build: ${when}${cnt}${dur}`;\n                    lastBox.style.display = 'block';\n                } else {\n                    lastBox.style.display = 'none';\n                }\n            }\n            const cardsContainer = document.getElementById('cards-viewer');\n            if (cardsContainer) {\n                cardsContainer.innerHTML = cards.length === 0 ?\n                    `<div style="text-align: center; padding: 24px; color: #666;">\n                        <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" style="opacity: 0.3; margin-bottom: 12px;">\n                            <rect x="3" y="4" width="18" height="16" rx="2" ry="2"></rect>
<line x1="3" y1="9" x2="21" y2="9"></line>\n                            <line x1="9" y1="4" x2="9" y2="20"></line>\n                        </svg>\n                        <div>No cards available</div>\n                        <div style="font-size: 11px; margin-top: 8px;">Click "Build Cards" to generate code cards</div>\n                    </div>` :\n                    cards.map(card => `\n                        <div class="card-item" data-filepath="${card.file_path}" data-line="${card.start_line || 1}"\n                             style="background: #1a1a1a; border: 1px solid #2a2a2a; border-radius: 6px; padding: 12px; cursor: pointer; transition: all 0.2s;"\n                             onmouseover="this.style.borderColor='#00ff88'; this.style.background='#1f1f1f';"\n                             onmouseout="this.style.borderColor='#2a2a2a'; this.style.background='#1a1a1a';">\n                            <h4 style="margin: 0 0 8px 0; color: #00ff88; font-size: 14px; font-weight: 600;">\n                                ${(card.symbols && card.symbols[0]) ? card.symbols[0] : (card.file_path || '').split('/').slice(-1)[0]}\n                            </h4>\n                            <p style="margin: 0 0 8px 0; color: #aaa; font-size: 12px; line-height: 1.4;">\n                                ${card.purpose || 'No description available'}\n                            </p>\n                            <div style="font-size: 10px; color: #666;">
<span style="color: #5b9dff;">${card.file_path || 'Unknown file'}</span>\n                                ${card.start_line ? ` : ${card.start_line}` : ''}\n                            </div>\n                        </div>\n                    `).join('');\n\n                // Add click event listeners to cards\n                document.querySelectorAll('.card-item[data-filepath]').forEach(card => {\n                    card.addEventListener('click', function() {\n                        const filePath = this.dataset.filepath;\n                        const lineNumber = this.dataset.line;\n                        jumpToLine(filePath, lineNumber);\n                    });\n                });\n            }\n        } catch (error) {\n            console.error('Error loading cards:', error);\n            const cardsContainer = document.getElementById('cards-viewer');\n            if (cardsContainer) {\n                cardsContainer.innerHTML = `<div style="text-align: center; padding: 24px; color: #ff5555;">\n                    Error loading cards: ${error.message}\n                </div>`;\n            }\n        }\n    }\n\n    function jumpToLine(filePath, lineNumber) {\n        // Enhanced navigation with visual feedback\n        console.log(`📍 Navigate to: ${filePath}:${lineNumber}`);\n\n        // Visual feedback\n        const event = new CustomEvent('cardNavigation', {\n            detail: { file: filePath, line: lineNumber }\n        });\n        window.dispatchEvent(event);
// You can add VSCode or other IDE integration here\n        // For now, show in a notification style\n        const notification = document.createElement('div');\n        notification.style.cssText = `\n            position: fixed; bottom: 20px; right: 20px;\n            background: #1a1a1a; border: 1px solid #00ff88;\n            padding: 12px 16px; border-radius: 6px;\n            color: #fff; font-size: 13px; z-index: 10000;\n            animation: slideInRight 0.3s ease;\n        `;\n        notification.innerHTML = `\n            <div style="display: flex; align-items: center; gap: 8px;">\n                <span style="color: #00ff88;">📍</span>\n                <span>Navigate to: <strong style="color: #5b9dff;">${filePath}:${lineNumber}</strong></span>\n            </div>\n        `;\n        document.body.appendChild(notification);\n        setTimeout(() => notification.remove(), 3000);\n    }\n\n    // Add refresh and build handlers\n    async function refreshCards() {\n        console.log('Refreshing cards...');\n        await loadCards();\n    }\n\n    async function buildCards() {\n        try {\n            const btn = document.getElementById('btn-cards-build');\n            if (btn) {\n                btn.disabled = true;\n                btn.textContent = 'Building Cards...';\n            }\n\n            const resp = await fetch(api('/api/cards/build'), { method: 'POST' });
const data = await resp.json();\n\n            if (data.success || data.status === 'success') {\n                console.log('✅ Cards built successfully');\n                await loadCards(); // Reload the cards\n            } else {\n                console.error('❌ Failed to build cards:', data.message || 'Unknown error');\n            }\n        } catch (error) {\n            console.error('Error building cards:', error);\n        } finally {\n            const btn = document.getElementById('btn-cards-build');\n            if (btn) {\n                btn.disabled = false;\n                btn.innerHTML = '<span style="margin-right: 4px;">⚡</span> Build Cards';\n            }\n        }\n    }\n\n    try {\n        window.jumpToLine = jumpToLine;\n        window.refreshCards = refreshCards;\n        window.buildCards = buildCards;\n    } catch {}\n\n    // Call loadCards on page load\n    document.addEventListener('DOMContentLoaded', () => {\n        loadCards();\n\n        // Add button event listeners\n        const btnRefresh = document.getElementById('btn-cards-refresh');\n        const btnBuild = document.getElementById('btn-cards-build');\n\n        if (btnRefresh) {\n            btnRefresh.addEventListener('click', refreshCards);\n        }\n\n        if (btnBuild) {\n            btnBuild.addEventListener('click', buildCards);\n        }\n    });\n\n    // ---------------- Help Tooltips ----------------
function addHelpTooltips() {\n        const HELP = {\n            // Generation\n            GEN_MODEL: 'Primary inference model for generation (e.g., gpt-4o-mini or qwen3-coder:14b).',\n            OPENAI_API_KEY: 'API key for OpenAI-compatible endpoints (generation/embeddings).',\n            OPENAI_BASE_URL: 'Optional OpenAI-compatible base URL (vLLM/proxy).',\n            OLLAMA_URL: 'Local model endpoint (Ollama or MLX serve).',\n            ENRICH_MODEL: 'Model used to enrich code chunks before embedding (text summaries).',\n            ENRICH_MODEL_OLLAMA: 'Local enrich model for Ollama/MLX.',\n            GEN_MODEL_HTTP: 'Override GEN_MODEL for HTTP server responses only.',\n            GEN_MODEL_MCP: 'Override GEN_MODEL for MCP tool responses only.',\n            GEN_MODEL_CLI: 'Override GEN_MODEL for CLI chat only.',\n            ENRICH_BACKEND: 'Force enrich backend (mlx or ollama).',\n\n            // Embeddings\n            EMBEDDING_TYPE: 'Embedding provider for dense vector search (openai, voyage, mxbai, local).',\n            VOYAGE_API_KEY: 'API key for Voyage embeddings.',\n            VOYAGE_EMBED_DIM: 'Output dimension for Voyage embeddings.',\n            EMBEDDING_DIM: 'Embedding dimension for MXBAI/local models.',
SKIP_DENSE: 'If 1, skip building dense vectors/Qdrant (sparse-only).',\n            ENRICH_CODE_CHUNKS: 'If true, store per-chunk summaries/keywords before embedding.',\n\n            // Reranking\n            RERANK_BACKEND: 'Cross-encoder reranking backend: local, hf, cohere, or none.',\n            RERANKER_MODEL: 'Local/HF cross-encoder model (e.g., BAAI/bge-reranker-v2-m3).',\n            COHERE_API_KEY: 'API key for Cohere reranking.',\n            COHERE_RERANK_MODEL: 'Cohere reranker model (e.g., rerank-3.5).',\n            TRANSFORMERS_TRUST_REMOTE_CODE: 'Allow HF models that require remote code.',\n\n            // Retrieval\n            MQ_REWRITES: 'Multi-query expansion count (more rewrites → better recall, more cost).',\n            FINAL_K: 'Final top-K after fusion + rerank (downstream consumers use these).',\n            TOPK_DENSE: 'Number of dense candidates (Qdrant) to fuse.',\n            TOPK_SPARSE: 'Number of sparse candidates (BM25) to fuse.',\n            HYDRATION_MODE: 'lazy: hydrate code snippets on demand; none: skip hydration.',\n            HYDRATION_MAX_CHARS: 'Max characters per hydrated code snippet.',\n            VENDOR_MODE: 'Prefer first-party or vendor paths when scoring files.',
project_PATH_BOOSTS: 'CSV of path substrings to boost (e.g., app/,lib/,config/).',\n            CARDS_MAX: 'Limit number of cards used for boosting (0 = all).',\n\n            // Confidence\n            CONF_TOP1: 'Accept answer if top-1 rerank score exceeds this threshold.',\n            CONF_AVG5: 'Accept if average of top-5 rerank scores exceeds this threshold.',\n            CONF_ANY: 'Accept if overall confidence exceeds this fallback threshold.',\n\n            // Infra\n            QDRANT_URL: 'Qdrant endpoint for vector search.',\n            REDIS_URL: 'Redis for LangGraph memory/checkpointer.',\n            REPO: 'Active repository tag for routing and output directories.',\n            COLLECTION_SUFFIX: 'Optional suffix to group collections in Qdrant.',\n            COLLECTION_NAME: 'Override Qdrant collection name.',\n            REPO_PATH: 'Fallback path when repos.json is absent.',\n            REPO_ROOT: 'Override project root. Affects GUI/docs/files mounts.',\n            FILES_ROOT: 'Root directory served at /files.',\n            GUI_DIR: 'Directory of GUI assets served at /gui.',\n            DOCS_DIR: 'Directory of docs served at /docs.',\n            DATA_DIR: 'Directory for local data files (excludes, keywords).',
REPOS_FILE: 'Path to repos.json configuration file.',\n            OUT_DIR_BASE: 'Base output directory for per-repo data.',\n            RAG_OUT_BASE: 'Alternate env for OUT_DIR_BASE.',\n            MCP_HTTP_HOST: 'Host for MCP HTTP server.',\n            MCP_HTTP_PORT: 'Port for MCP HTTP server.',\n            MCP_HTTP_PATH: 'Path prefix for MCP HTTP server.',\n\n            // Misc\n            AGRO_EDITION: 'Edition gate (oss, pro, enterprise). Pro/Enterprise unlock Autotune/Compat.',\n            THREAD_ID: 'LangGraph thread id (http or cli-chat).',\n            PORT: 'Uvicorn port for serve entrypoints.',\n            PROJECT_PATH: 'Optional reference path used by some helpers.',\n            LANGCHAIN_TRACING_V2: 'Enable tracing for LangChain-compatible tooling.',\n            LANGCHAIN_PROJECT: 'Tracing project name.',\n            NETLIFY_API_KEY: 'Key for Netlify actions (if used).',\n            NETLIFY_DOMAINS: 'Comma-separated domains for Netlify deploy (if used).',\n        };\n        $$('.settings-section .input-group').forEach(g=>{\n            const label = g.querySelector('label'); const input = g.querySelector('input,select,textarea');\n            if (!label || !input) return; const key = input.name || input.id; const help = HELP[key];
if (!help) return; if (label.querySelector('.help')) return;\n            const tip = document.createElement('span'); tip.className='help'; tip.title = help; tip.textContent='?';\n            label.appendChild(tip);\n        });\n    }\n\n    // ---------- Numbers formatting + per‑day converters ----------\n    function getNum(id){ const v=document.getElementById(id); if (!v) return 0; return parseInt((v.value||'').toString().replace(/,/g,'').replace(/\s/g,''),10)||0; }\n    function setNum(id, n){ const el=document.getElementById(id); if (!el) return; el.value = (Number(n)||0).toLocaleString('en-US'); }\n    function attachCommaFormatting(ids){ ids.forEach(id=>{ const el=document.getElementById(id); if(!el) return; el.addEventListener('focus',()=>{ el.value = el.value.replace(/,/g,''); }); el.addEventListener('blur',()=>{ const num=getNum(id); if(num >= 0) el.value = num.toLocaleString('en-US'); }); }); }\n    function wireDayConverters(){ const recalc=()=>{ const rpd=getNum('cost-rpd'); const inDay=getNum('cost-in-day'); const outDay=getNum('cost-out-day'); if(rpd>0){ if(inDay>0) setNum('cost-in', Math.floor(inDay/rpd)); if(outDay>0) setNum('cost-out', Math.floor(outDay/rpd)); } }; ['cost-in-day','cost-out-day','cost-rpd'].forEach(id=>{ const el=document.getElementById(id); if(el) el.addEventListener('input', recalc); }); recalc(); }
async function setAutotuneEnabled() {\n        try {\n            const enabled = document.getElementById('autotune-enabled').checked;\n            const r = await fetch(api('/api/autotune/status'), {\n                method: 'POST', headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ enabled, current_mode: null })\n            });\n            if (!r.ok) {\n                if (r.status === 403 || r.status === 402) {\n                    alert('Autotune is a Pro feature. Enable it by setting Edition to "pro" (Misc section) or PRO_ENABLED=1.');\n                    $('#autotune-enabled').checked = false;\n                    return;\n                }\n                throw new Error('HTTP ' + r.status);\n            }\n            await refreshAutotune();\n        } catch (e) {\n            alert('Failed to set Auto‑Tune: ' + e.message);\n        }\n    }\n\n    // ---------------- Keywords ----------------\n    async function loadKeywords() {\n        try {\n            const r = await fetch(api('/api/keywords'));\n            const d = await r.json();\n            state.keywordsCatalog = d;\n            const list = document.getElementById('keywords-list');\n            if (list) {\n                list.innerHTML = '';\n                (d.keywords || []).forEach(k => {\n                    const opt = document.createElement('option'); opt.value = k; list.appendChild(opt);\n                });\n            }\n            const kc = document.getElementById('keywords-count');
if (kc) kc.textContent = String((d.keywords||[]).length);\n            // repaint per-repo managers if present\n            ($$('#repos-section > div') || []).forEach(div => {\n                const srcSel = div.querySelector('[id^="kw-src-"]');\n                const filter = div.querySelector('[id^="kw-filter-"]');\n                const allSel = div.querySelector('[id^="kw-all-"]');\n                const fld = div.querySelector('[name^="repo_keywords_"]');\n                if (srcSel && filter && allSel && fld) {\n                    const cat = (srcSel.value||'all');\n                    const catMap = d; let base = cat==='all' ? (d.keywords||[]) : (d[cat]||[]);\n                    const f=(filter.value||'').toLowerCase(); const inRepo=new Set((fld.value||'').split(',').map(s=>s.trim()).filter(Boolean));\n                    allSel.innerHTML=''; base.filter(k=>!inRepo.has(k)&&(!f||k.toLowerCase().includes(f))).slice(0,500).forEach(k=>{const o=document.createElement('option');o.value=k;o.textContent=k;allSel.appendChild(o);});\n                }\n            });\n        } catch (e) { console.warn('keywords load failed', e); }\n    }\n\n    // ---------------- Indexing + Cards ----------------\n    let indexPoll = null;
function progressFromLog(lines) {\n        const text = (lines||[]).join(' ');\n        let pct = 5;\n        if (/Prepared \d+ chunks/i.test(text)) pct = 20;\n        if (/BM25 index saved/i.test(text)) pct = 60;\n        if (/Indexed \d+ chunks to Qdrant/i.test(text)) pct = 100;\n        return pct;\n    }\n\n    async function startIndexing() {\n        try {\n            showStatus('Starting indexer...', 'loading');\n            await fetch(api('/api/index/start'), { method: 'POST' });\n            if (indexPoll) clearInterval(indexPoll);\n            indexPoll = setInterval(pollIndexStatus, 800);\n            await pollIndexStatus();\n        } catch (e) {\n            showStatus('Failed to start indexer: ' + e.message, 'error');\n            throw e;\n        }\n    }\n\n    function formatBytes(bytes) {\n        if (!bytes || bytes === 0) return '0 B';\n        const k = 1024;\n        const sizes = ['B', 'KB', 'MB', 'GB'];\n        const i = Math.floor(Math.log(bytes) / Math.log(k));\n        return Math.round((bytes / Math.pow(k, i)) * 100) / 100 + ' ' + sizes[i];\n    }\n\n    function formatIndexStatus(lines, metadata) {\n        if (!metadata) {\n            if (!lines || !lines.length) return '<div style="color:#666;font-size:13px;">Ready to index...</div>';\n            return `<div style="color:#aaa;font-size:12px;">${lines.join('<br>')}</div>`;
}\n\n        // Enterprise-grade comprehensive display\n        const html = [];\n\n        // Header with repo/branch\n        html.push(`\n            <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:16px;padding-bottom:12px;border-bottom:1px solid #2a2a2a;">\n                <div style="display:flex;align-items:center;gap:12px;">\n                    <div style="width:6px;height:6px;border-radius:50%;background:#00ff88;box-shadow:0 0 8px #00ff88;"></div>\n                    <div>\n                        <div style="font-size:16px;font-weight:600;color:#fff;letter-spacing:-0.3px;">${metadata.current_repo}</div>\n                        <div style="font-size:11px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-top:2px;">\n                            Branch: <span style="color:#5b9dff;">${metadata.current_branch}</span>\n                        </div>\n                    </div>\n                </div>\n                <div style="text-align:right;font-size:10px;color:#666;">\n                    ${new Date(metadata.timestamp).toLocaleString()}\n                </div>\n            </div>\n        `);\n\n        // Configuration section\n        html.push(`\n            <div style="display:grid;grid-template-columns:1fr 1fr;gap:12px;margin-bottom:16px;">
<div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #2a2a2a;">\n                    <div style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:6px;">Embedding Model</div>\n                    <div style="font-size:14px;font-weight:600;color:#b794f6;font-family:'SF Mono',monospace;">${metadata.embedding_model}</div>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #2a2a2a;">\n                    <div style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:6px;">Keywords</div>\n                    <div style="font-size:14px;font-weight:600;color:#ff9b5e;font-family:'SF Mono',monospace;">${metadata.keywords_count.toLocaleString()}</div>\n                </div>\n            </div>\n        `);\n\n        // Index profiles section\n        if (metadata.repos && metadata.repos.length > 0) {\n            html.push(`<div style="margin-bottom:12px;"><div style="font-size:11px;font-weight:600;color:#00ff88;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:10px;">Index Profiles</div>`);
metadata.repos.forEach(repo => {\n                const totalSize = (repo.sizes.chunks || 0) + (repo.sizes.bm25 || 0) + (repo.sizes.cards || 0);\n\n                html.push(`\n                    <div style="background:#0f0f0f;border:1px solid ${repo.has_cards ? '#006622' : '#2a2a2a'};border-radius:6px;padding:12px;margin-bottom:8px;">\n                        <div style="display:flex;justify-content:space-between;align-items:start;margin-bottom:10px;">\n                            <div>\n                                <div style="font-size:13px;font-weight:600;color:#fff;margin-bottom:4px;">\n                                    ${repo.name} <span style="font-size:10px;color:#666;font-weight:400;">/ ${repo.profile}</span>\n                                </div>\n                                <div style="font-size:11px;color:#666;">\n                                    ${repo.chunk_count.toLocaleString()} chunks\n                                    ${repo.has_cards ? ' • <span style="color:#00ff88;">✓ Cards</span>' : ' • <span style="color:#666;">No cards</span>'}\n                                </div>\n                            </div>\n                            <div style="text-align:right;">\n                                <div style="font-size:14px;font-weight:600;color:#00ff88;font-family:'SF Mono',monospace;">\n                                    ${formatBytes(totalSize)}\n                                </div>\n                            </div>\n                        </div>\n                        <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:8px;font-size:10px;">
${repo.paths.chunks ? `\n                                <div style="background:#0a0a0a;padding:6px 8px;border-radius:4px;border:1px solid #1a1a1a;">\n                                    <div style="color:#888;margin-bottom:2px;">Chunks</div>\n                                    <div style="color:#5b9dff;font-family:'SF Mono',monospace;font-size:11px;">${formatBytes(repo.sizes.chunks)}</div>\n                                </div>\n                            ` : ''}\n                            ${repo.paths.bm25 ? `\n                                <div style="background:#0a0a0a;padding:6px 8px;border-radius:4px;border:1px solid #1a1a1a;">\n                                    <div style="color:#888;margin-bottom:2px;">BM25 Index</div>\n                                    <div style="color:#ff9b5e;font-family:'SF Mono',monospace;font-size:11px;">${formatBytes(repo.sizes.bm25)}</div>\n                                </div>\n                            ` : ''}\n                            ${repo.paths.cards ? `\n                                <div style="background:#0a0a0a;padding:6px 8px;border-radius:4px;border:1px solid #1a1a1a;">\n                                    <div style="color:#888;margin-bottom:2px;">Cards</div>\n                                    <div style="color:#00ff88;font-family:'SF Mono',monospace;font-size:11px;">${formatBytes(repo.sizes.cards)}</div>\n                                </div>\n                            ` : ''}\n                        </div>\n                        ${repo.paths.chunks ? `\n                            <details style="margin-top:8px;">
<summary style="cursor:pointer;font-size:10px;color:#666;padding:4px 0;">\n                                    <span style="color:#5b9dff;">▸</span> File Paths\n                                </summary>\n                                <div style="margin-top:6px;padding:8px;background:#0a0a0a;border-radius:4px;font-size:10px;font-family:'SF Mono',monospace;color:#888;">\n                                    ${repo.paths.chunks ? `<div style="margin-bottom:2px;">📄 ${repo.paths.chunks}</div>` : ''}\n                                    ${repo.paths.bm25 ? `<div style="margin-bottom:2px;">📁 ${repo.paths.bm25}</div>` : ''}\n                                    ${repo.paths.cards ? `<div>🎴 ${repo.paths.cards}</div>` : ''}\n                                </div>\n                            </details>\n                        ` : ''}\n                    </div>\n                `);\n            });\n\n            html.push(`</div>`);\n        }\n\n        // Total storage footer\n        html.push(`\n            <div style="display:flex;justify-content:space-between;align-items:center;padding-top:12px;border-top:1px solid #2a2a2a;">\n                <div style="font-size:12px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Total Index Storage</div>\n                <div style="font-size:18px;font-weight:700;color:#00ff88;font-family:'SF Mono',monospace;">\n                    ${formatBytes(metadata.total_storage)}
</div>\n            </div>\n        `);\n\n        return html.join('');\n    }\n\n    async function pollIndexStatus() {\n        try {\n            const r = await fetch(api('/api/index/status'));\n            const d = await r.json();\n            const box1 = document.getElementById('index-status');\n            const bar1 = document.getElementById('index-bar');\n            const box2 = document.getElementById('dash-index-status');\n            const bar2 = document.getElementById('dash-index-bar');\n            const lastIndexedDisplay = document.getElementById('last-indexed-display');\n\n            // Use the new comprehensive display if available\n            const formatted = (typeof window.formatIndexStatusDisplay === 'function')\n                ? window.formatIndexStatusDisplay(d.lines, d.metadata)\n                : formatIndexStatus(d.lines, d.metadata);\n\n            const pct = d.running ? 50 : (d.metadata ? 100 : 0);\n            if (box1) box1.innerHTML = formatted;\n            if (bar1) bar1.style.width = pct + '%';\n            if (box2) box2.innerHTML = formatted;\n            if (bar2) bar2.style.width = pct + '%';\n\n            // Update last indexed timestamp in sidebar\n            if (lastIndexedDisplay && d.metadata && d.metadata.timestamp) {\n                const date = new Date(d.metadata.timestamp);
lastIndexedDisplay.textContent = date.toLocaleString();\n            }\n\n            if (!d.running && indexPoll) {\n                clearInterval(indexPoll);\n                indexPoll = null;\n                // Final complete animation\n                if (bar2) {\n                    setTimeout(() => { bar2.style.width = '0%'; }, 2000);\n                }\n            }\n        } catch (e) { /* ignore */ }\n    }\n\n    // ---------------- Cards Builder (Job + SSE) ----------------\n    let cardsJob = { id: null, timer: null, sse: null };\n    let tipsTimer = null;\n    function openCardsModal() {\n        const m = document.getElementById('cards-builder-modal'); if (!m) return;\n        m.style.display = 'block';\n        const err = document.getElementById('cards-builder-error'); if (err) err.style.display = 'none';\n        const logs = document.getElementById('cards-logs-view'); if (logs) logs.style.display = 'none';\n        [\n            'scan','chunk','sparse','dense','summarize','write','finalize'\n        ].forEach(s => { const el = document.getElementById('cards-stage-'+s); if (el) { el.style.color='#aaa'; el.style.borderColor='#2a2a2a'; el.style.background='transparent'; }});\n        const mainBar = document.getElementById('cards-main-bar'); if (mainBar) mainBar.style.width = '0%';
const stats = document.getElementById('cards-progress-stats'); if (stats) stats.textContent = '0 / 0 (0%)';\n        // Bind controls once\n        const minBtn = document.getElementById('cards-builder-min'); if (minBtn && !minBtn.dataset.bound) { minBtn.dataset.bound='1'; minBtn.addEventListener('click', () => { m.style.display='none'; showStatus('Cards Builder minimized', 'info'); }); }\n        const closeBtn = document.getElementById('cards-builder-close'); if (closeBtn && !closeBtn.dataset.bound) { closeBtn.dataset.bound='1'; closeBtn.addEventListener('click', () => { m.style.display='none'; stopCardsStreams(); }); }\n        const viewLogs = document.getElementById('cards-view-logs'); if (viewLogs && !viewLogs.dataset.bound) { viewLogs.dataset.bound='1'; viewLogs.addEventListener('click', async () => { try { const r = await fetch(api('/api/cards/build/logs')); const d = await r.json(); const pre = document.getElementById('cards-logs-view'); if (pre) { pre.textContent = d.content || ''; pre.style.display = 'block'; } } catch(e) { alert('Unable to load logs'); } }); }
const cancelBtn = document.getElementById('cards-cancel'); if (cancelBtn && !cancelBtn.dataset.bound) { cancelBtn.dataset.bound='1'; cancelBtn.addEventListener('click', async () => { if (!cardsJob.id) return; try { await fetch(api('/api/cards/build/cancel/'+cardsJob.id), { method: 'POST' }); showStatus('Cards build cancelled', 'warn'); } catch (e) { showStatus('Cancel failed: '+e.message, 'error'); } }); }\n    }\n\n    function highlightStage(stage) {\n        const all = ['scan','chunk','sparse','dense','summarize','write','finalize'];\n        all.forEach(s => { const el = document.getElementById('cards-stage-'+s); if (el) { el.style.color = (s===stage? '#fff':'#aaa'); el.style.borderColor = (s===stage?'#00ff88':'#2a2a2a'); el.style.background = (s===stage?'#0f1a14':'transparent'); }});\n    }\n\n    function updateCardsModal(data) {\n        try {\n            const { pct, total, done, tip, model, stage, throughput, eta_s } = data || {};\n            const bar = document.getElementById('cards-main-bar'); if (bar) bar.style.width = `${pct||0}%`;\n            const stats = document.getElementById('cards-progress-stats'); if (stats) stats.textContent = `${done||0} / ${total||0} (${(pct||0).toFixed(1)}%) • ${throughput||''} • ETA ${eta_s||0}s`;
const tipEl = document.getElementById('cards-quick-tip'); if (tipEl && tip) tipEl.textContent = tip;\n            highlightStage(stage);\n            const e1 = document.getElementById('cards-model-embed'); if (e1 && model && model.embed) e1.textContent = `embed: ${model.embed}`;\n            const e2 = document.getElementById('cards-model-enrich'); if (e2 && model && model.enrich) e2.textContent = `enrich: ${model.enrich}`;\n            const e3 = document.getElementById('cards-model-rerank'); if (e3 && model && model.rerank) e3.textContent = `rerank: ${model.rerank}`;\n        } catch {}\n    }\n\n    function stopCardsStreams() {\n        if (cardsJob.timer) { clearInterval(cardsJob.timer); cardsJob.timer = null; }\n        if (cardsJob.sse) { try { cardsJob.sse.close(); } catch{} cardsJob.sse = null; }\n    }\n\n    async function startCardsBuild(repoOverride=null) {\n        try {\n            openCardsModal();\n            const enrich = document.getElementById('cards-enrich-toggle')?.checked ? 1 : 0;\n            const repo = repoOverride || (state?.config?.env?.REPO) || 'agro';\n            const r = await fetch(api(`/api/cards/build/start?repo=${encodeURIComponent(repo)}&enrich=${enrich}`), { method: 'POST' });
if (r.status === 409) {\n                const d = await r.json();\n                const err = document.getElementById('cards-builder-error'); if (err) { err.style.display='block'; err.textContent = d.detail || 'Job already running'; }\n                return;\n            }\n            const d = await r.json();\n            cardsJob.id = d.job_id;\n            showStatus('Cards build started…', 'loading');\n            // Set up SSE with fallback\n            try {\n                const es = new EventSource(api(`/api/cards/build/stream/${cardsJob.id}`));\n                cardsJob.sse = es;\n                es.addEventListener('progress', (ev) => { try { const data = JSON.parse(ev.data||'{}'); updateCardsModal(data); } catch{} });\n                es.addEventListener('done', async (ev) => { stopCardsStreams(); updateCardsModal(JSON.parse(ev.data||'{}')); showStatus('Cards rebuilt', 'success'); await loadCards(); });\n                es.addEventListener('error', (ev) => { /* will use polling fallback */ });\n                es.addEventListener('cancelled', (ev) => { stopCardsStreams(); const e = document.getElementById('cards-builder-error'); if (e){ e.style.display='block'; e.textContent='Cancelled'; } });\n            } catch (e) {\n                // SSE not available; use polling
cardsJob.timer = setInterval(async () => {\n                    try { const s = await (await fetch(api(`/api/cards/build/status/${cardsJob.id}`))).json(); updateCardsModal(s); if ((s.status||'')==='done'){ stopCardsStreams(); await loadCards(); showStatus('Cards rebuilt', 'success'); } if ((s.status||'')==='error'){ stopCardsStreams(); const er=document.getElementById('cards-builder-error'); if(er){er.style.display='block'; er.textContent=s.error||'Error';} showStatus('Cards build failed', 'error'); } } catch {}\n                }, 1500);\n            }\n        } catch (e) {\n            showStatus('Failed to start cards build: '+e.message, 'error');\n        }\n    }\n\n    async function refreshCards() {\n        try {\n            showStatus('Refreshing dashboard...', 'loading');\n            await refreshDashboard();\n            showStatus('Dashboard refreshed', 'success');\n        } catch (e) {\n            showStatus('Failed to refresh: ' + e.message, 'error');\n            throw e;\n        }\n    }\n\n    // ---------------- Add Model Flows ----------------\n    async function updateEnv(envUpdates) {\n        try {\n            await fetch(api('/api/config'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },
body: JSON.stringify({ env: envUpdates, repos: [] })\n            });\n        } catch (e) {\n            alert('Failed to update config: ' + e.message);\n        }\n    }\n\n    async function upsertPrice(entry) {\n        try {\n            await fetch(api('/api/prices/upsert'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(entry)\n            });\n        } catch (e) {\n            console.warn('Price upsert failed:', e);\n        }\n    }\n\n    function promptStr(msg, defVal = '') {\n        const v = window.prompt(msg, defVal);\n        return v === null ? null : v.trim();\n    }\n\n    async function addGenModelFlow() {\n        const provider = promptStr('Provider (openai, anthropic, google, local)', 'openai');\n        if (!provider) return;\n        const model = promptStr('Model ID (e.g., gpt-4o-mini or qwen3-coder:14b)', 'gpt-4o-mini');\n        if (!model) return;\n        const baseUrl = promptStr('Base URL (optional; for proxies or local, e.g., http://127.0.0.1:11434)', '');\n        let apiKey = '';\n        if (provider !== 'local') {\n            apiKey = promptStr('API Key (optional; shown locally only)', '') || '';\n        }\n\n        // Update env\n        const env = { GEN_MODEL: model };\n        if (provider === 'openai') {\n            if (apiKey) env.OPENAI_API_KEY = apiKey;
if (baseUrl) env.OPENAI_BASE_URL = baseUrl;\n        } else if (provider === 'anthropic') {\n            if (apiKey) env.ANTHROPIC_API_KEY = apiKey;\n        } else if (provider === 'google') {\n            if (apiKey) env.GOOGLE_API_KEY = apiKey;\n        } else if (provider === 'local') {\n            if (baseUrl) env.OLLAMA_URL = baseUrl;\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        // Price entry (scaffold)\n        const entry = { provider, model, family: 'gen', base_url: baseUrl || undefined };\n        if (provider === 'local') entry.unit = 'request'; else entry.unit = '1k_tokens';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Generation model added.');\n    }\n\n    async function addEmbedModelFlow() {\n        const provider = promptStr('Embedding provider (openai, voyage, local, mxbai)', 'openai');\n        if (!provider) return;\n        const model = promptStr('Embedding model ID (optional; depends on provider)', provider === 'openai' ? 'text-embedding-3-small' : '');\n        const baseUrl = promptStr('Base URL (optional)', '');\n        let apiKey = '';\n        if (provider !== 'local' && provider !== 'mxbai') {\n            apiKey = promptStr('API Key (optional)', '') || '';
}\n\n        const env = {};\n        if (provider === 'openai') {\n            env.EMBEDDING_TYPE = 'openai';\n            if (apiKey) env.OPENAI_API_KEY = apiKey;\n            if (baseUrl) env.OPENAI_BASE_URL = baseUrl;\n        } else if (provider === 'voyage') {\n            env.EMBEDDING_TYPE = 'voyage';\n            if (apiKey) env.VOYAGE_API_KEY = apiKey;\n        } else if (provider === 'mxbai') {\n            env.EMBEDDING_TYPE = 'mxbai';\n        } else if (provider === 'local') {\n            env.EMBEDDING_TYPE = 'local';\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        const entry = { provider, model: model || provider + '-embed', family: 'embed', base_url: baseUrl || undefined };\n        entry.unit = '1k_tokens';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Embedding model added.');\n    }\n\n    async function addRerankModelFlow() {\n        const provider = promptStr('Rerank provider (cohere, local, hf)', 'cohere');\n        if (!provider) return;\n        let model = promptStr('Rerank model ID (e.g., rerank-3.5 or BAAI/bge-reranker-v2-m3)', provider === 'cohere' ? 'rerank-3.5' : 'BAAI/bge-reranker-v2-m3');\n        const baseUrl = promptStr('Base URL (optional)', '');\n        let apiKey = '';\n        if (provider === 'cohere') {
apiKey = promptStr('Cohere API Key (optional)', '') || '';\n        }\n\n        const env = {};\n        if (provider === 'cohere') {\n            env.RERANK_BACKEND = 'cohere';\n            env.COHERE_RERANK_MODEL = model;\n            if (apiKey) env.COHERE_API_KEY = apiKey;\n        } else if (provider === 'local') {\n            env.RERANK_BACKEND = 'local';\n            env.RERANKER_MODEL = model;\n        } else if (provider === 'hf') {\n            env.RERANK_BACKEND = 'hf';\n            env.RERANKER_MODEL = model;\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        const entry = { provider, model, family: 'rerank', base_url: baseUrl || undefined };\n        entry.unit = provider === 'cohere' ? '1k_tokens' : 'request';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Rerank model added.');\n    }\n\n    async function addCostModelFlow() {\n        const provider = promptStr('Provider', 'openai');\n        if (!provider) return;\n        const model = promptStr('Model ID', 'gpt-4o-mini');\n        if (!model) return;\n        const baseUrl = promptStr('Base URL (optional)', '');\n        const unit = promptStr('Unit (1k_tokens or request)', provider === 'local' ? 'request' : '1k_tokens') || '1k_tokens';\n        await upsertPrice({ provider, model, family: 'misc', base_url: baseUrl || undefined, unit });
await loadPrices();\n        alert('Model added to pricing catalog.');\n    }\n\n    // -------- Embedded Editor --------\n    let editorHealthInterval = null;\n\n    async function checkEditorHealth() {\n        try {\n            const resp = await fetch(api('/health/editor'));\n            const data = await resp.json();\n            const badge = document.getElementById('editor-health-badge');\n            const badgeText = document.getElementById('editor-health-text');\n            const banner = document.getElementById('editor-status-banner');\n            const bannerMsg = document.getElementById('editor-status-message');\n            const iframe = document.getElementById('editor-iframe');\n\n            if (data.ok) {\n                badge.style.background = '#00ff88';\n                badge.style.color = '#000';\n                badgeText.textContent = '● Healthy';\n                banner.style.display = 'none';\n                if (!iframe.src && data.url) {\n                    iframe.src = data.url;\n                }\n            } else {\n                const isDisabled = !data.enabled;\n                badge.style.background = isDisabled ? '#666' : '#ff5555';\n                badge.style.color = '#fff';\n                badgeText.textContent = isDisabled ? '○ Disabled' : '● Error';\n                banner.style.display = 'block';\n                const reason = data.reason || data.error || 'Unknown error';
bannerMsg.textContent = isDisabled\n                    ? `Editor is disabled. Enable it in the Misc tab and restart.`\n                    : `Error: ${reason}. Check logs or try restarting.`;\n                iframe.src = '';\n            }\n        } catch (error) {\n            console.error('Failed to check editor health:', error);\n        }\n    }\n\n    async function openEditorWindow() {\n        try {\n            const resp = await fetch(api('/health/editor'));\n            const data = await resp.json();\n            if (data.url) {\n                window.open(data.url, '_blank');\n            } else {\n                alert('Editor URL not available');\n            }\n        } catch (error) {\n            console.error('Failed to open editor window:', error);\n        }\n    }\n\n    async function copyEditorUrl() {\n        try {\n            const resp = await fetch(api('/health/editor'));\n            const data = await resp.json();\n            if (data.url) {\n                await navigator.clipboard.writeText(data.url);\n                const btn = document.getElementById('btn-editor-copy-url');\n                const orig = btn.innerHTML;\n                btn.innerHTML = '✓ Copied!';\n                setTimeout(() => { btn.innerHTML = orig; }, 2000);\n            } else {\n                alert('Editor URL not available');\n            }\n        } catch (error) {\n            console.error('Failed to copy URL:', error);\n        }\n    }\n\n    async function restartEditor() {\n        try {
const btn = document.getElementById('btn-editor-restart');\n            btn.disabled = true;\n            btn.textContent = 'Restarting...';\n            const resp = await fetch(api('/api/editor/restart'), { method: 'POST' });\n            const data = await resp.json();\n            if (data.ok) {\n                console.log('✅ Editor restarted');\n                setTimeout(() => {\n                    const iframe = document.getElementById('editor-iframe');\n                    iframe.src = '';\n                    checkEditorHealth();\n                }, 3000);\n            } else {\n                console.error('❌ Restart failed:', data.error || data.stderr);\n                alert('Restart failed: ' + (data.error || 'Unknown error'));\n            }\n        } catch (error) {\n            console.error('Failed to restart editor:', error);\n            alert('Restart failed: ' + error.message);\n        } finally {\n            const btn = document.getElementById('btn-editor-restart');\n            btn.disabled = false;\n            btn.innerHTML = '↻ Restart';\n        }\n    }\n\n    const originalSwitchTab = window.switchTab;\n    window.switchTab = function(tabName) {\n        if (typeof originalSwitchTab === 'function') {\n            originalSwitchTab(tabName);\n        }\n        if (tabName === 'editor') {\n            if (!editorHealthInterval) {\n                checkEditorHealth();\n                editorHealthInterval = setInterval(checkEditorHealth, 10000);
}\n        } else {\n            if (editorHealthInterval) {\n                clearInterval(editorHealthInterval);\n                editorHealthInterval = null;\n            }\n        }\n    };\n\n    const btnOpenWindow = document.getElementById('btn-editor-open-window');\n    const btnCopyUrl = document.getElementById('btn-editor-copy-url');\n    const btnRestart = document.getElementById('btn-editor-restart');\n\n    if (btnOpenWindow) btnOpenWindow.addEventListener('click', openEditorWindow);\n    if (btnCopyUrl) btnCopyUrl.addEventListener('click', copyEditorUrl);\n    if (btnRestart) btnRestart.addEventListener('click', restartEditor);\n\n    // ============================================\n    // Onboarding Wizard Controller\n    // ============================================\n\n    const onboardingState = {\n        step: 1,\n        maxStep: 5,\n        projectDraft: {\n            sourceType: 'folder', // 'folder' or 'github'\n            folderPath: '',\n            githubUrl: '',\n            githubBranch: 'main',\n            githubToken: '',\n            saveToken: false\n        },\n        indexing: {\n            running: false,\n            stage: 'idle', // 'idle', 'scan', 'keywords', 'smart'\n            progress: 0\n        },\n        questions: [\n            { text: 'Where is hybrid retrieval implemented?', answer: null },
{ text: 'Where are indexing settings?', answer: null },\n            { text: 'How do I change the default model?', answer: null }\n        ],\n        settings: {\n            speed: 2, // 1-4\n            quality: 2, // 1-3\n            cloud: 1 // 1-2\n        }\n    };\n\n    function showOnboardStep(n) {\n        if (n < 1 || n > onboardingState.maxStep) return;\n        onboardingState.step = n;\n\n        // Update progress dots\n        $$('.ob-dot').forEach((dot, i) => {\n            dot.classList.remove('active', 'completed');\n            if (i + 1 === n) dot.classList.add('active');\n            else if (i + 1 < n) dot.classList.add('completed');\n        });\n\n        // Update steps\n        $$('.ob-step').forEach((step, i) => {\n            step.classList.toggle('active', i + 1 === n);\n        });\n\n        // Update navigation\n        const backBtn = $('#onboard-back');\n        const nextBtn = $('#onboard-next');\n        if (backBtn) backBtn.style.display = n === 1 ? 'none' : 'block';\n        if (nextBtn) {\n            nextBtn.textContent = n === onboardingState.maxStep ? 'Done' : 'Next →';\n        }\n\n        // Save progress to localStorage\n        try {\n            localStorage.setItem('onboarding_step', String(n));\n            localStorage.setItem('onboarding_state', JSON.stringify(onboardingState));\n        } catch (e) { /* ignore */ }
}\n\n    function nextOnboard() {\n        if (onboardingState.step === onboardingState.maxStep) {\n            // Done - switch to dashboard\n            switchTab('dashboard');\n            try { localStorage.removeItem('onboarding_step'); } catch {}\n            return;\n        }\n\n        // Validation\n        if (onboardingState.step === 2) {\n            const mode = onboardingState.projectDraft.sourceType;\n            if (mode === 'folder') {\n                const path = $('#onboard-folder-path');\n                if (path && !path.value.trim()) {\n                    alert('Please select a folder or enter a path');\n                    return;\n                }\n                onboardingState.projectDraft.folderPath = path ? path.value.trim() : '';\n            } else if (mode === 'github') {\n                const url = $('#onboard-github-url');\n                if (url && !url.value.trim()) {\n                    alert('Please enter a GitHub repository URL');\n                    return;\n                }\n                onboardingState.projectDraft.githubUrl = url ? url.value.trim() : '';\n                const branch = $('#onboard-github-branch');\n                const token = $('#onboard-github-token');\n                onboardingState.projectDraft.githubBranch = branch && branch.value.trim() ? branch.value.trim() : 'main';\n                onboardingState.projectDraft.githubToken = token ? token.value.trim() : '';
}\n        }\n\n        // Start indexing when entering step 3\n        if (onboardingState.step === 2) {\n            setTimeout(() => startIndexing(), 500);\n        }\n\n        showOnboardStep(onboardingState.step + 1);\n    }\n\n    function backOnboard() {\n        if (onboardingState.step > 1) {\n            showOnboardStep(onboardingState.step - 1);\n        }\n    }\n\n    async function startIndexing() {\n        onboardingState.indexing.running = true;\n        const bar = $('#onboard-index-bar');\n        const status = $('#onboard-index-status');\n        const log = $('#onboard-index-log');\n        const nextBtn = $('#onboard-next');\n\n        if (nextBtn) nextBtn.disabled = true;\n\n        // Stage 1: Light scan\n        updateIndexStage('scan', 20);\n        if (status) status.textContent = 'Scanning files...';\n        await new Promise(r => setTimeout(r, 1000));\n\n        // Stage 2: Keywords\n        updateIndexStage('keywords', 50);\n        if (status) status.textContent = 'Building keyword index...';\n\n        try {\n            const res = await fetch(api('/api/index/start'), { method: 'POST' });\n            if (!res.ok) throw new Error('Failed to start indexing');\n\n            // Poll status\n            let running = true;\n            while (running) {\n                await new Promise(r => setTimeout(r, 2000));
const statusRes = await fetch(api('/api/index/status'));\n                const data = await statusRes.json();\n\n                if (log && data.lines) {\n                    log.textContent = data.lines.join('\n');\n                    log.scrollTop = log.scrollHeight;\n                }\n\n                running = data.running !== false;\n\n                if (!running) {\n                    updateIndexStage('keywords', 70);\n                    if (status) status.textContent = 'Building cards...';\n\n                    // Build cards\n                    await fetch(api('/api/cards/build'), { method: 'POST' });\n\n                    // Stage 3: Smart search (attempt)\n                    updateIndexStage('smart', 100);\n                    if (status) status.textContent = 'Indexing complete!';\n\n                    if (nextBtn) nextBtn.disabled = false;\n                    onboardingState.indexing.running = false;\n                }\n            }\n        } catch (err) {\n            console.error('Indexing error:', err);\n            if (status) status.textContent = 'Indexing completed with keyword-only mode';\n            $('#onboard-index-fallback').style.display = 'block';\n            if (bar) bar.style.width = '70%';\n            if (nextBtn) nextBtn.disabled = false;\n            onboardingState.indexing.running = false;\n        }\n    }\n\n    function updateIndexStage(stage, progress) {\n        onboardingState.indexing.stage = stage;\n        onboardingState.indexing.progress = progress;
const bar = $('#onboard-index-bar');\n        if (bar) bar.style.width = progress + '%';\n\n        $$('.ob-stage').forEach(el => {\n            const s = el.getAttribute('data-stage');\n            el.classList.remove('active', 'completed');\n            if (s === stage) el.classList.add('active');\n            else if (['scan', 'keywords'].indexOf(s) < ['scan', 'keywords', 'smart'].indexOf(stage)) {\n                el.classList.add('completed');\n            }\n        });\n    }\n\n    async function askQuestion(qIndex) {\n        const input = $(`#onboard-q${qIndex}`);\n        const answerDiv = $(`#onboard-ans-${qIndex}`);\n        const traceLink = $(`#onboard-trace-${qIndex}`);\n        const btn = $(`.ob-ask-btn[data-q="${qIndex}"]`);\n\n        if (!input || !answerDiv) return;\n\n        const question = input.value.trim();\n        if (!question) return;\n\n        if (btn) btn.disabled = true;\n        answerDiv.textContent = 'Thinking...';\n        answerDiv.classList.add('visible');\n\n        try {\n            const repo = state.config && state.config.REPO ? state.config.REPO : 'agro';\n            const res = await fetch(api('/api/chat'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ question, repo })
});\n\n            if (!res.ok) throw new Error('Failed to get answer');\n\n            const data = await res.json();\n            answerDiv.textContent = data.answer || 'No answer received';\n            onboardingState.questions[qIndex - 1].answer = data.answer;\n\n            if (traceLink) traceLink.style.display = 'inline-block';\n        } catch (err) {\n            console.error('Question error:', err);\n            answerDiv.textContent = 'Error: ' + err.message;\n        } finally {\n            if (btn) btn.disabled = false;\n        }\n    }\n\n    async function showTrace(qIndex) {\n        const panel = $(`#onboard-trace-panel-${qIndex}`);\n        if (!panel) return;\n\n        if (panel.style.display === 'block') {\n            panel.style.display = 'none';\n            return;\n        }\n\n        panel.textContent = 'Loading trace...';\n        panel.style.display = 'block';\n\n        try {\n            const res = await fetch(api('/api/traces/latest'));\n            if (!res.ok) throw new Error('Failed to load trace');\n\n            const data = await res.json();\n            panel.textContent = JSON.stringify(data, null, 2);\n        } catch (err) {\n            panel.textContent = 'Error loading trace: ' + err.message;\n        }\n    }\n\n    function updateSettingsSummary() {\n        const summary = $('#onboard-summary-content');
if (!summary) return;\n\n        const { speed, quality, cloud } = onboardingState.settings;\n\n        const speedMap = {\n            1: 'MQ_REWRITES=1, LANGGRAPH_FINAL_K=10',\n            2: 'MQ_REWRITES=2, LANGGRAPH_FINAL_K=15',\n            3: 'MQ_REWRITES=3, LANGGRAPH_FINAL_K=20',\n            4: 'MQ_REWRITES=4, LANGGRAPH_FINAL_K=25'\n        };\n\n        const qualityMap = {\n            1: 'RERANK_BACKEND=none, GEN_MODEL=local',\n            2: 'RERANK_BACKEND=local, GEN_MODEL=gpt-4o-mini',\n            3: 'RERANK_BACKEND=cohere, GEN_MODEL=gpt-4o, CONF_TOP1=0.55'\n        };\n\n        const cloudMap = {\n            1: 'EMBEDDING_TYPE=local, VECTOR_BACKEND=qdrant (local)',\n            2: 'EMBEDDING_TYPE=openai, VECTOR_BACKEND=qdrant (cloud)'\n        };\n\n        summary.innerHTML = `\n            <div>Speed: ${speedMap[speed] || 'default'}</div>\n            <div>Quality: ${qualityMap[quality] || 'default'}</div>\n            <div>Cloud: ${cloudMap[cloud] || 'default'}</div>\n        `;\n    }\n\n    async function saveAsProject() {\n        const name = prompt('Enter a name for this project:');\n        if (!name || !name.trim()) return;\n\n        const { speed, quality, cloud } = onboardingState.settings;\n\n        const profile = {\n            name: name.trim(),\n            sources: onboardingState.projectDraft,
settings: {\n                MQ_REWRITES: speed,\n                LANGGRAPH_FINAL_K: 10 + (speed * 5),\n                RERANK_BACKEND: quality === 1 ? 'none' : (quality === 2 ? 'local' : 'cohere'),\n                GEN_MODEL: quality === 1 ? 'local' : 'gpt-4o-mini',\n                EMBEDDING_TYPE: cloud === 1 ? 'local' : 'openai'\n            },\n            golden: onboardingState.questions.map(q => q.text)\n        };\n\n        try {\n            const res = await fetch(api('/api/profiles/save'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(profile)\n            });\n\n            if (!res.ok) throw new Error('Failed to save project');\n\n            alert('Project saved successfully!');\n\n            // Apply profile\n            await fetch(api('/api/profiles/apply'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ profile_name: name.trim() })\n            });\n        } catch (err) {\n            console.error('Save project error:', err);\n            alert('Error saving project: ' + err.message);\n        }\n    }\n\n    async function runTinyEval() {\n        const box = $('#onboard-eval-progress');\n        const bar = $('#onboard-eval-bar');\n        const status = $('#onboard-eval-status');\n        const result = $('#onboard-eval-result');
if (!box) return;\n\n        box.style.display = 'block';\n        if (status) status.textContent = 'Running evaluation...';\n        if (bar) bar.style.width = '30%';\n\n        try {\n            await fetch(api('/api/eval/run'), { method: 'POST' });\n\n            // Poll status\n            let running = true;\n            while (running) {\n                await new Promise(r => setTimeout(r, 2000));\n                const statusRes = await fetch(api('/api/eval/status'));\n                const data = await statusRes.json();\n\n                running = data.running === true;\n\n                if (!running) {\n                    if (bar) bar.style.width = '100%';\n                    if (status) status.textContent = 'Evaluation complete';\n\n                    // Get results\n                    const resRes = await fetch(api('/api/eval/results'));\n                    const resData = await resRes.json();\n\n                    if (result && resData) {\n                        const score = resData.top1_accuracy || resData.topk_accuracy || 0;\n                        result.textContent = `Retrieval Score: ${(score * 100).toFixed(1)}%`;\n                    }\n                }\n            }\n        } catch (err) {\n            console.error('Eval error:', err);\n            if (status) status.textContent = 'Evaluation failed';\n            if (result) result.textContent = 'Error: ' + err.message;\n        }\n    }\n\n    async function askHelpQuestion() {\n        const input = $('#onboard-help-input');
const results = $('#onboard-help-results');\n        const btn = $('#onboard-help-send');\n\n        if (!input || !results) return;\n\n        const question = input.value.trim();\n        if (!question) return;\n\n        // Show immediate loading feedback\n        if (btn) {\n            btn.disabled = true;\n            btn.textContent = 'Asking...';\n            btn.style.opacity = '0.6';\n        }\n\n        results.innerHTML = '<div style="display:flex;align-items:center;gap:8px;color:var(--fg-muted);"><div style="width:16px;height:16px;border:2px solid var(--accent);border-top-color:transparent;border-radius:50%;animation:spin 0.8s linear infinite;"></div> Thinking...</div>';\n        results.classList.add('visible');\n\n        try {\n            const repo = state.config && state.config.REPO ? state.config.REPO : 'agro';\n            const res = await fetch(api('/api/chat'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ question, repo })\n            });\n\n            if (!res.ok) throw new Error('Failed to get answer');\n\n            const data = await res.json();\n            // Format answer as readable text, not code block\n            const answer = (data.answer || 'No answer received').replace(/\n/g, '<br>');
results.innerHTML = answer;\n        } catch (err) {\n            console.error('Help question error:', err);\n            results.innerHTML = '<span style="color:var(--err);">Error: ' + err.message + '</span>';\n        } finally {\n            if (btn) {\n                btn.disabled = false;\n                btn.textContent = 'Ask';\n                btn.style.opacity = '1';\n            }\n        }\n    }\n\n    function initOnboarding() {\n        // Try to resume from localStorage\n        try {\n            const savedStep = localStorage.getItem('onboarding_step');\n            const savedState = localStorage.getItem('onboarding_state');\n            if (savedStep) {\n                const step = parseInt(savedStep, 10);\n                if (step >= 1 && step <= onboardingState.maxStep) {\n                    onboardingState.step = step;\n                }\n            }\n            if (savedState) {\n                const parsed = JSON.parse(savedState);\n                Object.assign(onboardingState, parsed);\n            }\n        } catch (e) { /* ignore */ }\n\n        // Wire Step 1 - choice cards\n        $$('.ob-card').forEach(card => {\n            card.addEventListener('click', () => {\n                const choice = card.getAttribute('data-choice');\n                onboardingState.projectDraft.sourceType = choice;\n                nextOnboard();\n            });\n        });\n\n        // Wire Step 2 - mode tabs\n        $$('.ob-mode-tab').forEach(tab => {\n            tab.addEventListener('click', () => {
const mode = tab.getAttribute('data-mode');\n                onboardingState.projectDraft.sourceType = mode;\n\n                $$('.ob-mode-tab').forEach(t => t.classList.remove('active'));\n                tab.classList.add('active');\n\n                $$('.ob-mode-content').forEach(c => c.classList.remove('active'));\n                $(`#onboard-${mode}-mode`).classList.add('active');\n            });\n        });\n\n        // Wire folder picker\n        const folderBtn = $('#onboard-folder-btn');\n        const folderPicker = $('#onboard-folder-picker');\n        const folderDisplay = $('#onboard-folder-display');\n        const folderPath = $('#onboard-folder-path');\n\n        if (folderBtn && folderPicker) {\n            folderBtn.addEventListener('click', () => folderPicker.click());\n\n            folderPicker.addEventListener('change', (e) => {\n                if (e.target.files && e.target.files.length > 0) {\n                    const path = e.target.files[0].webkitRelativePath || e.target.files[0].path || '';\n                    const folderName = path.split('/')[0] || 'Selected folder';\n                    if (folderDisplay) folderDisplay.textContent = folderName;\n                    if (folderPath) folderPath.value = folderName;\n                }\n            });\n        }\n\n        // Wire Step 4 - Ask buttons
$$('.ob-ask-btn').forEach(btn => {\n            btn.addEventListener('click', () => {\n                const qIndex = parseInt(btn.getAttribute('data-q'), 10);\n                askQuestion(qIndex);\n            });\n        });\n\n        // Wire trace links\n        for (let i = 1; i <= 3; i++) {\n            const link = $(`#onboard-trace-${i}`);\n            if (link) {\n                link.addEventListener('click', (e) => {\n                    e.preventDefault();\n                    showTrace(i);\n                });\n            }\n        }\n\n        // Wire Step 4 - Save golden\n        const saveGolden = $('#onboard-save-golden');\n        if (saveGolden) {\n            saveGolden.addEventListener('click', () => {\n                alert('Golden questions saved! (Feature placeholder)');\n            });\n        }\n\n        // Wire Step 5 - Sliders\n        const speedSlider = $('#onboard-slider-speed');\n        const qualitySlider = $('#onboard-slider-quality');\n        const cloudSlider = $('#onboard-slider-cloud');\n\n        [speedSlider, qualitySlider, cloudSlider].forEach(slider => {\n            if (slider) {\n                slider.addEventListener('input', () => {\n                    if (speedSlider) onboardingState.settings.speed = parseInt(speedSlider.value, 10);\n                    if (qualitySlider) onboardingState.settings.quality = parseInt(qualitySlider.value, 10);\n                    if (cloudSlider) onboardingState.settings.cloud = parseInt(cloudSlider.value, 10);
updateSettingsSummary();\n                });\n            }\n        });\n\n        updateSettingsSummary();\n\n        // Wire Step 5 - Actions\n        const saveProject = $('#onboard-save-project');\n        const runEval = $('#onboard-run-eval');\n\n        if (saveProject) saveProject.addEventListener('click', saveAsProject);\n        if (runEval) runEval.addEventListener('click', runTinyEval);\n\n        // Wire help panel\n        const helpSend = $('#onboard-help-send');\n        if (helpSend) helpSend.addEventListener('click', askHelpQuestion);\n\n        $$('.ob-help-pill').forEach(pill => {\n            pill.addEventListener('click', () => {\n                const q = pill.getAttribute('data-q');\n                const input = $('#onboard-help-input');\n                if (input && q) {\n                    input.value = q;\n                    askHelpQuestion();\n                }\n            });\n        });\n\n        const openChat = $('#onboard-open-chat');\n        if (openChat) {\n            openChat.addEventListener('click', (e) => {\n                e.preventDefault();\n                switchTab('chat');\n            });\n        }\n\n        // Wire navigation\n        const backBtn = $('#onboard-back');\n        const nextBtn = $('#onboard-next');\n\n        if (backBtn) backBtn.addEventListener('click', backOnboard);\n        if (nextBtn) nextBtn.addEventListener('click', nextOnboard);
// Show current step\n        showOnboardStep(onboardingState.step);\n    }\n\n    // Initialize onboarding when tab is first opened\n    function ensureOnboardingInit() {\n        if (!onboardingState._initialized) {\n            initOnboarding();\n            onboardingState._initialized = true;\n        }\n    }\n})();
// Profile logic (algorithm only). Exported via window.ProfileLogic\n;(function(){\n  function proposeProfile(scan, budget){\n    const hasLocal = !!(scan && (scan.runtimes?.ollama || scan.runtimes?.coreml));\n    const rprov = (Number(budget) === 0) ? (hasLocal ? 'local' : 'cohere') : 'cohere';\n    return {\n      GEN_MODEL: hasLocal && Number(budget) === 0 ? 'qwen3-coder:14b' : 'gpt-4o-mini',\n      EMBEDDING_TYPE: (Number(budget) === 0) ? (hasLocal ? 'local' : 'openai') : 'openai',\n      RERANK_BACKEND: rprov,\n      MQ_REWRITES: Number(budget) > 50 ? '6' : '3',\n      TOPK_SPARSE: '75',\n      TOPK_DENSE: '75',\n      FINAL_K: Number(budget) > 50 ? '20' : '10',\n      HYDRATION_MODE: 'lazy',\n    };\n  }\n\n  function buildWizardProfile(scan, budget){\n    // Currently mirrors proposeProfile; kept separate for future tuning\n    return proposeProfile(scan, budget);\n  }\n\n  window.ProfileLogic = { proposeProfile, buildWizardProfile };\n})();
;(function(){\n  function apiBase(){\n    try{\n      const u = new URL(window.location.href);\n      const q = new URLSearchParams(u.search);\n      const override = q.get('api');\n      if (override) return override.replace(/\/$/, '');\n      if (u.protocol.startsWith('http')) return u.origin;\n      return 'http://127.0.0.1:8012';\n    }catch{ return 'http://127.0.0.1:8012'; }\n  }\n  function api(path){ return apiBase() + path; }\n  async function getConfig(){\n    try{ const r = await fetch(api('/api/config')); return await r.json(); }catch{ return { env:{}, repos:[] }; }\n  }\n  function csvToList(s){ return (String(s||'').split(',').map(x=>x.trim()).filter(Boolean)); }\n  function readAdvanced(){\n    const mode = document.getElementById('apv2-mode')?.value || 'balanced';\n    const budgetOverride = parseFloat(document.getElementById('apv2-budget')?.value || '');\n    const prov = Array.from(document.querySelectorAll('.apv2-prov'))\n      .filter(cb => cb.checked).map(cb => cb.value);\n    const regions = csvToList(document.getElementById('apv2-regions')?.value||'');\n    const compliance = csvToList(document.getElementById('apv2-compliance')?.value||'');
const heur = !!document.getElementById('apv2-heuristics')?.checked;\n    const wl = {\n      requests_per_day: parseInt(document.getElementById('apv2-rpd')?.value||'')||undefined,\n      tokens_in_per_req: parseInt(document.getElementById('apv2-tin')?.value||'')||undefined,\n      tokens_out_per_req: parseInt(document.getElementById('apv2-tout')?.value||'')||undefined,\n      mq_rewrites: parseInt(document.getElementById('apv2-mq')?.value||'')||undefined,\n      embed_tokens_per_req: parseInt(document.getElementById('apv2-embt')?.value||'')||undefined,\n      rerank_tokens_per_req: parseInt(document.getElementById('apv2-rrt')?.value||'')||undefined,\n    };\n    const slo = {\n      latency_target_ms: parseInt(document.getElementById('apv2-latency')?.value||'')||undefined,\n      min_qps: parseFloat(document.getElementById('apv2-minqps')?.value||'')||undefined,\n    };\n    return { mode, budgetOverride, prov, regions, compliance, heur, workload: wl, slo };\n  }\n  function setPlaceholderLoading(){\n    const placeholder = document.getElementById('profile-placeholder');
const results = document.getElementById('profile-results-content');\n    if (placeholder) {\n      placeholder.style.display='flex';\n      placeholder.innerHTML = `\n        <div style="display:flex;flex-direction:column;align-items:center;justify-content:center;">\n          <div style=\"width:48px;height:48px;border:3px solid #2a2a2a;border-top-color:#00ff88;border-radius:50%;animation:spin 1s linear infinite;margin-bottom:16px;\"></div>\n          <p id=\"apv2-phase\" style=\"font-size:14px;color:#666;\">Selecting profile with v2 engine...</p>\n        </div>\n        <style>@keyframes spin { to { transform: rotate(360deg); } }</style>`;\n    }\n    if (results) results.style.display='none';\n  }\n  function setPhase(msg){ try{ const el=document.getElementById('apv2-phase'); if (el) el.textContent=msg; }catch{}\n  }\n  function fetchWithTimeout(resource, opts){\n    const { timeout=12000, ...rest } = (opts||{});\n    return new Promise((resolve, reject)=>{\n      const id = setTimeout(()=> reject(new Error('request timeout')), timeout);\n      fetch(resource, rest).then((res)=>{ clearTimeout(id); resolve(res); }, (err)=>{ clearTimeout(id); reject(err); });
});\n  }\n  function renderResult(env, reason, scan, budget){\n    const results = document.getElementById('profile-results-content');\n    const placeholder = document.getElementById('profile-placeholder');\n    if (window.ProfileRenderer && results) {\n      try{\n        const html = window.ProfileRenderer.renderProfileResults(env, scan, budget);\n        results.innerHTML = html;\n        if (window.ProfileRenderer.bindTooltips) window.ProfileRenderer.bindTooltips(results);\n        // Append diagnostics accordion\n        try{\n          const details = document.createElement('details');\n          details.style.marginTop = '12px';\n          const sum = document.createElement('summary');\n          sum.textContent = 'Diagnostics';\n          sum.style.cursor = 'pointer';\n          sum.style.color = '#999';\n          const pre = document.createElement('pre');\n          pre.style.color = '#777'; pre.style.whiteSpace = 'pre-wrap'; pre.style.fontSize = '12px'; pre.style.padding = '10px'; pre.style.border = '1px solid #2a2a2a'; pre.style.borderRadius = '6px'; pre.style.background = '#0a0a0a';\n          pre.textContent = JSON.stringify({ objective: reason?.objective, budget: reason?.budget, weights: reason?.weights, candidates_total: reason?.candidates_total, policy_relaxed: reason?.policy_relaxed, diag: reason?.diag }, null, 2);
details.appendChild(sum); details.appendChild(pre);\n          results.appendChild(details);\n        }catch{}\n        if (placeholder) placeholder.style.display='none';\n        results.style.display='block';\n      }catch(err){\n        results.innerHTML = '<pre style="color:#ff6b6b;padding:20px;">'+(err?.message||String(err))+'</pre>';\n        results.style.display='block';\n        if (placeholder) placeholder.style.display='none';\n      }\n    }\n  }\n  async function ensureScan(){\n    try {\n      const out = document.getElementById('scan-out');\n      if (out && out.dataset.scanData){ return JSON.parse(out.dataset.scanData); }\n    }catch{}\n    try{ const r = await fetch(api('/api/scan-hw'), { method:'POST' }); return await r.json(); }catch{ return null; }\n  }\n\n  async function run(){\n    setPlaceholderLoading();\n    setPhase('Loading configuration...');\n    const cfg = await getConfig();\n    const env = (cfg && cfg.env) || {};\n    setPhase('Scanning hardware...');\n    const scan = await ensureScan();\n    const budget = parseFloat(document.getElementById('budget')?.value||'0');\n    const adv = readAdvanced();\n\n    // Fallbacks from cost panel when Advanced fields are blank
function numOrUndef(v){ const n = Number(v); return Number.isFinite(n) ? n : undefined; }\n    const costIn   = numOrUndef(document.getElementById('cost-in')?.value);\n    const costOut  = numOrUndef(document.getElementById('cost-out')?.value);\n    const costEmb  = numOrUndef(document.getElementById('cost-embeds')?.value);\n    const costRR   = numOrUndef(document.getElementById('cost-rerank')?.value);\n    const costRPD  = numOrUndef(document.getElementById('cost-rpd')?.value);\n    if (adv.workload.requests_per_day === undefined && costRPD !== undefined) adv.workload.requests_per_day = costRPD;\n    if (adv.workload.tokens_in_per_req === undefined && costIn !== undefined) adv.workload.tokens_in_per_req = costIn;\n    if (adv.workload.tokens_out_per_req === undefined && costOut !== undefined) adv.workload.tokens_out_per_req = costOut;\n    if (adv.workload.embed_tokens_per_req === undefined && costEmb !== undefined) adv.workload.embed_tokens_per_req = costEmb;\n    if (adv.workload.rerank_tokens_per_req === undefined && costRR !== undefined) adv.workload.rerank_tokens_per_req = costRR;
// MQ default from current env if not provided\n    if (adv.workload.mq_rewrites === undefined) {\n      const mq = parseInt(env.MQ_REWRITES || '');\n      adv.workload.mq_rewrites = Number.isFinite(mq) && mq>0 ? mq : undefined; // leave undefined so server can recommend\n    }\n    const payload = {\n      hardware: { runtimes: (scan && scan.runtimes) || {}, meta: (scan && scan.info) || {} },\n      policy: { providers_allowed: adv.prov.length? adv.prov : undefined, regions_allowed: adv.regions.length? adv.regions: undefined, compliance: adv.compliance.length? adv.compliance: undefined },\n      workload: Object.fromEntries(Object.entries(adv.workload).filter(([_,v])=> v!==undefined)),\n      objective: {\n        mode: adv.mode,\n        monthly_budget_usd: isNaN(adv.budgetOverride)? budget : adv.budgetOverride,\n        latency_target_ms: adv.slo.latency_target_ms,\n        min_qps: adv.slo.min_qps,\n      },\n      tuning: { use_heuristic_quality: !!adv.heur },\n      defaults: { gen_model: env.GEN_MODEL || '' }\n    };\n    try{\n      setPhase('Calling selector...');\n      const r = await fetchWithTimeout(api('/api/profile/autoselect'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload), timeout: 15000 });
if (!r.ok){ const txt = await r.text(); throw new Error(txt || 'autoselect failed'); }\n      setPhase('Rendering result...');\n      const data = await r.json();\n      renderResult(data.env, data.reason, scan, payload.objective.monthly_budget_usd || budget);\n\n      // Optional: show an estimated cost banner using current cost panel inputs and selected providers\n      try{\n        const genProvider = (data.env.GEN_MODEL && data.env.GEN_MODEL.includes(':')) ? 'local' : 'openai';\n        const genModel = data.env.GEN_MODEL || 'gpt-4o-mini';\n        const cp = {\n          gen_provider: genProvider,\n          gen_model: genModel,\n          tokens_in: (costIn || 0),\n          tokens_out: (costOut || 0),\n          embeds: (costEmb || 0),\n          reranks: (costRR || 0),\n          requests_per_day: (costRPD || 0),\n          embed_provider: data.env.EMBEDDING_TYPE || undefined,\n          rerank_provider: data.env.RERANK_BACKEND || undefined,\n          rerank_model: data.env.COHERE_RERANK_MODEL || undefined,\n        };\n        const er = await fetchWithTimeout(api('/api/cost/estimate'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(cp), timeout: 10000 });
if (er.ok){\n          const est = await er.json();\n          const results = document.getElementById('profile-results-content');\n          if (results){\n            const div = document.createElement('div');\n            div.style.cssText = 'margin-top:10px;padding:10px;border:1px solid #2a2a2a;border-radius:6px;background:#0a0a0a;color:#aaa;font-size:12px;';\n            div.innerHTML = `<strong style="color:#00ff88;">Estimated Cost</strong> — Daily: $${Number(est.daily||0).toFixed(4)} • Monthly: $${Number(est.monthly||0).toFixed(2)}`;\n            results.prepend(div);\n          }\n        }\n      }catch{}\n    }catch(err){\n      const results = document.getElementById('profile-results-content');\n      const placeholder = document.getElementById('profile-placeholder');\n      const payloadStr = JSON.stringify(payload, null, 2);\n      if (results){ results.innerHTML = '<div style="padding:20px;">'+\n        '<div style="color:#ff6b6b; font-weight:600; margin-bottom:8px;">Auto‑Profile v2 error</div>'+\n        '<pre style="color:#aaa; white-space:pre-wrap;">'+(err?.message||String(err))+'</pre>'+\n        '<details style="margin-top:12px;"><summary style="cursor:pointer; color:#999;">Payload</summary><pre style="color:#777; white-space:pre-wrap;">'+payloadStr+'</pre></details>'+
'</div>'; results.style.display='block'; }\n      if (placeholder) placeholder.style.display='none';\n    }\n  }\n\n  window.AutoProfileV2 = { run };\n})();
// GUI Tooltips: human-readable help + accurate links\n// Exposes window.Tooltips.{buildTooltipMap, attachTooltips}\n(function(){\n  function L(label, body, links, badges){\n    const linkHtml = (links||[]).map(([txt, href]) => `<a href="${href}" target="_blank" rel="noopener">${txt}</a>`).join(' ');\n    const badgeHtml = (badges||[]).map(([txt, cls]) => `<span class="tt-badge ${cls||''}">${txt}</span>`).join(' ');\n    const badgesBlock = badgeHtml ? `<div class="tt-badges">${badgeHtml}</div>` : '';\n    return `<span class=\"tt-title\">${label}</span>${badgesBlock}<div>${body}</div>` + (links && links.length ? `<div class=\"tt-links\">${linkHtml}</div>` : '');\n  }\n\n  function buildTooltipMap(){\n    return {\n      // Infrastructure & routing\n      QDRANT_URL: L('Qdrant URL', 'HTTP URL for your Qdrant vector database. Used for dense vector queries during retrieval. If unavailable, retrieval still works via BM25 (sparse).', [\n        ['Qdrant Docs: Collections', 'https://qdrant.tech/documentation/concepts/collections/'],\n        ['Qdrant (GitHub)', 'https://github.com/qdrant/qdrant']
]),\n      REDIS_URL: L('Redis URL', 'Connection string for Redis, used for LangGraph checkpoints and optional session memory. The graph runs even if Redis is down (stateless mode).', [\n        ['Redis Docs', 'https://redis.io/docs/latest/']\n      ]),\n      REPO: L('Active Repository', 'Logical repository name for routing and indexing. MCP and CLI use this to scope retrieval.', [\n        ['Docs: MCP Quickstart', '/docs/QUICKSTART_MCP.md']\n      ]),\n      COLLECTION_NAME: L('Collection Name', 'Optional override for the Qdrant collection name. Defaults to code_chunks_{REPO}. Set this if you maintain multiple profiles.', [\n        ['Qdrant Docs: Collections', 'https://qdrant.tech/documentation/concepts/collections/']\n      ]),\n      COLLECTION_SUFFIX: L('Collection Suffix', 'Optional string appended to the default collection name for side-by-side comparisons.'),\n      REPOS_FILE: L('Repos File', 'Path to repos.json that defines repo names, paths, keywords, path boosts, and layer bonuses used for routing.', [\n        ['Local repos.json', '/files/repos.json']\n      ]),\n      REPO_PATH: L('Repo Path (fallback)', 'Absolute path to the active repo if repos.json is not available.'),
OUT_DIR_BASE: L('Out Dir Base', 'Where retrieval looks for indices (chunks.jsonl, bm25_index/). Use ./out.noindex-shared for one index across branches so MCP and local tools stay in sync. Symptom of mismatch: rag_search returns 0 results.', [\n        ['Docs: Shared Index', '/files/README.md']\n      ], [['Requires restart (MCP)','info']]),\n      RAG_OUT_BASE: L('RAG Out Base', 'Optional override for Out Dir Base; used by internal loaders if provided.'),\n      MCP_HTTP_HOST: L('MCP HTTP Host', 'Bind address for the HTTP MCP server (fast transport). Use 0.0.0.0 to listen on all interfaces.', [\n        ['Docs: Remote MCP', '/docs/REMOTE_MCP.md']\n      ]),\n      MCP_HTTP_PORT: L('MCP HTTP Port', 'TCP port for HTTP MCP server (default 8013).', [\n        ['Docs: Remote MCP', '/docs/REMOTE_MCP.md']\n      ]),\n      MCP_HTTP_PATH: L('MCP HTTP Path', 'URL path for the HTTP MCP endpoint (default /mcp).', [\n        ['Docs: Remote MCP', '/docs/REMOTE_MCP.md']\n      ]),\n\n      // Models / Providers\n      GEN_MODEL: L('Generation Model', 'Answer model. Local: qwen3-coder:14b via Ollama. Cloud: gpt-4o-mini, etc. Larger models cost more and can be slower; smaller ones are faster/cheaper.', [
['OpenAI Models', 'https://platform.openai.com/docs/models'],\n        ['Ollama API (GitHub)', 'https://github.com/ollama/ollama/blob/main/docs/api.md']\n      ], [['Affects latency','info']]),\n      OLLAMA_URL: L('Ollama URL', 'Local inference endpoint for Ollama (e.g., http://127.0.0.1:11434/api). Used when GEN_MODEL targets a local model.', [\n        ['Ollama API (GitHub)', 'https://github.com/ollama/ollama/blob/main/docs/api.md']\n      ]),\n      OPENAI_API_KEY: L('OpenAI API Key', 'API key used for OpenAI-based embeddings and/or generation.', [\n        ['OpenAI: API Keys', 'https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key'],\n        ['OpenAI Models', 'https://platform.openai.com/docs/models']\n      ]),\n      EMBEDDING_TYPE: L('Embedding Provider', 'Dense vectors (hybrid).\n• openai — strong quality, paid\n• voyage — strong retrieval, paid\n• mxbai — OSS via SentenceTransformers\n• local — any HF ST model', [\n        ['OpenAI Embeddings', 'https://platform.openai.com/docs/guides/embeddings'],\n        ['Voyage AI Embeddings', 'https://docs.voyageai.com/docs/embeddings'],
['Google Gemini Embeddings', 'https://ai.google.dev/gemini-api/docs/embeddings'],\n        ['SentenceTransformers Docs', 'https://www.sbert.net/']\n      ], [['Requires reindex','reindex']]),\n      VOYAGE_API_KEY: L('Voyage API Key', 'API key for Voyage AI embeddings when EMBEDDING_TYPE=voyage.', [\n        ['Voyage AI Docs', 'https://docs.voyageai.com/']\n      ]),\n      VOYAGE_EMBED_DIM: L('Voyage Embed Dim', 'Embedding vector dimension when using Voyage embeddings (provider‑specific). Larger dims can improve recall but increase Qdrant storage.', [], [['Requires reindex','reindex']]),\n\n      // Reranking\n      RERANK_BACKEND: L('Rerank Backend', 'Reranks fused candidates for better ordering.\n• cohere — best quality, paid (COHERE_API_KEY)\n• local/hf — no cost (ensure model installed)\nDisable only to save cost.', [\n        ['Cohere Docs: Rerank', 'https://docs.cohere.com/reference/rerank'],\n        ['Cohere Python (GitHub)', 'https://github.com/cohere-ai/cohere-python']\n      ]),\n      COHERE_API_KEY: L('Cohere API Key', 'API key for Cohere reranking when RERANK_BACKEND=cohere.', [
['Cohere Dashboard: API Keys', 'https://dashboard.cohere.com/api-keys']\n      ]),\n      COHERE_RERANK_MODEL: L('Cohere Rerank Model', 'Cohere rerank model name (e.g., rerank-3.5). Check the provider docs for the latest list and pricing.', [\n        ['Cohere Docs: Models', 'https://docs.cohere.com/docs/models']\n      ]),\n      RERANKER_MODEL: L('Local Reranker (HF)', 'Name of local/HuggingFace reranker model when RERANK_BACKEND=local or hf.'),\n\n      // Retrieval tuning\n      MQ_REWRITES: L('Multi‑Query Rewrites', 'Rewrite the user query N times to broaden recall; then fuse + rerank. Start at 3–4; raise to 6 for “Where is X implemented?” questions.', [], [['Affects latency','info']]),\n      TOPK_DENSE: L('Top‑K Dense', 'Vector hits before fusion. Higher = better recall, more latency. Typical 60–120; start at 75.', [], [['Affects latency','info']]),\n      TOPK_SPARSE: L('Top‑K Sparse', 'BM25 hits before fusion. Higher = better recall, more latency. Typical 60–120; start at 75.', [\n        ['BM25S (GitHub)', 'https://github.com/xhluca/bm25s']\n      ], [['Affects latency','info']]),
FINAL_K: L('Final Top‑K', 'Results returned after rerank and boosts. Typical 10; increase for browsing, decrease for speed.'),\n      HYDRATION_MODE: L('Hydration Mode', 'Attach code bodies to results.\n• lazy — on‑demand (recommended)\n• none — skip hydration (lowest memory)'),\n      HYDRATION_MAX_CHARS: L('Hydration Max Chars', 'Max characters of code to attach per result. Lower to reduce RAM usage.'),\n\n      // Confidence\n      CONF_TOP1: L('Confidence Top‑1', 'Minimum score to accept top‑1 directly. Recommended ~0.60–0.65. Lower = more answers, more risk.'),\n      CONF_AVG5: L('Confidence Avg‑5', 'Average of top‑5; gate for rewriting loops. Recommended ~0.52–0.58.'),\n      CONF_ANY: L('Confidence Any', 'Proceed if any candidate exceeds this score (fallback).'),\n\n      // Netlify\n      NETLIFY_API_KEY: L('Netlify API Key', 'Key for the netlify_deploy MCP tool to trigger builds.', [\n        ['Netlify: Access Tokens', 'https://docs.netlify.com/api/get-started/#access-tokens']\n      ]),\n      NETLIFY_DOMAINS: L('Netlify Domains', 'Comma‑separated site domains you want to target with the netlify_deploy tool.'),
// Misc\n      THREAD_ID: L('Thread ID', 'Identifier for session state in LangGraph or CLI chat. Use a stable value to preserve memory across runs.', [\n        ['CLI Chat Docs', '/docs/CLI_CHAT.md']\n      ]),\n      TRANSFORMERS_TRUST_REMOTE_CODE: L('Transformers: trust_remote_code', 'Set to true only if you understand the security implications of loading remote model code.', [\n        ['Transformers: Security Notes', 'https://huggingface.co/docs/transformers/installation#security-notes']\n      ]),\n      LANGCHAIN_TRACING_V2: L('LangChain Tracing', 'Enable tracing with LangSmith (Tracing v2).', [\n        ['LangSmith Docs', 'https://docs.smith.langchain.com/']\n      ]),\n\n      GEN_MODEL_HTTP: L('HTTP Channel Model', 'Override generation model when serving via HTTP channel only. Useful to separate prod vs. local dev.'),\n      GEN_MODEL_MCP: L('MCP Channel Model', 'Override generation model when used by MCP tools only (e.g., choose a lighter model to reduce tool costs).'),\n      GEN_MODEL_CLI: L('CLI Channel Model', 'Override generation model for the CLI chat only.'),\n      NETLIFY_API_KEY: L('Netlify API Key', 'Token used by the netlify_deploy MCP tool to trigger builds.', [
['Netlify: Access Tokens', 'https://docs.netlify.com/api/get-started/#access-tokens']\n      ]),\n\n      // Additional providers\n      ANTHROPIC_API_KEY: L('Anthropic API Key', 'API key for Anthropic models (Claude family).', [\n        ['Anthropic: Getting Started', 'https://docs.anthropic.com/en/api/getting-started']\n      ]),\n      GOOGLE_API_KEY: L('Google API Key', 'API key for Google Gemini models and endpoints.', [\n        ['Gemini: API Keys', 'https://ai.google.dev/gemini-api/docs/api-key']\n      ]),\n      OPENAI_BASE_URL: L('OpenAI Base URL', 'Override API base URL for OpenAI‑compatible endpoints (advanced).', [\n        ['OpenAI Models', 'https://platform.openai.com/docs/models']\n      ]),\n\n      // Enrichment / Cards / Indexing\n      ENRICH_BACKEND: L('Enrichment Backend', 'Backend used for optional code/context enrichment (e.g., MLX or local workflows).'),\n      ENRICH_MODEL: L('Enrichment Model', 'Model used for enrichment when enabled (provider‑specific). Use a smaller local model for cost‑free summaries; cloud models improve quality.'),\n      ENRICH_MODEL_OLLAMA: L('Enrichment Model (Ollama)', 'Specific Ollama model to use for enrichment if ENRICH_BACKEND targets Ollama.'),
ENRICH_CODE_CHUNKS: L('Enrich Code Chunks', 'When enabled, stores per‑chunk summaries/keywords during indexing to support features like cards and improved reranking.', [\n        ['Cards Builder (source)', '/files/build_cards.py']\n      ]),\n      CARDS_MAX: L('Cards Max', 'Maximum number of summary cards to consider when boosting retrieval results.', [\n        ['Cards Builder (source)', '/files/build_cards.py']\n      ]),\n      SKIP_DENSE: L('Skip Dense Embeddings', 'When set, indexer skips dense embeddings/Qdrant upsert to build a fast BM25‑only index.'),\n      VENDOR_MODE: L('Vendor Mode', 'Bias for first‑party vs vendor‑origin code in reranking. Options: prefer_first_party | prefer_vendor.'),\n      EMBEDDING_DIM: L('Embedding Dimension', 'Vector length for MXBAI/local embeddings. Typical 384–768. Larger = better recall + larger Qdrant. Changing this requires full reindex.' , [], [['Requires reindex','reindex']]),\n      PORT: L('HTTP Port', 'HTTP server port for the GUI/API when running serve_rag.'),\n      AGRO_EDITION: L('Edition', 'Product edition flag (oss | pro | enterprise) to toggle advanced features in compatible deployments.'),
PORT: L('HTTP Port', 'HTTP server port for serve_rag (GUI/API). Change if port 8012 is in use.'),\n\n      // Repo editor (dynamic inputs)\n      repo_path: L('Repository Path', 'Absolute path to a repository that should be indexed for this logical name.'),\n      repo_keywords: L('Repository Keywords', 'Keywords that help route queries to this repository during retrieval. Add common terms users will ask for.'),\n      repo_pathboosts: L('Path Boosts', 'Directory substrings that should be boosted in ranking for this repository (e.g., app/, api/, server/).'),\n      repo_layerbonuses: L('Layer Bonuses', 'Per‑intent layer bonus map to tilt retrieval toward UI/server/integration code as needed.'),\n\n      // Evaluation\n      GOLDEN_PATH: L('Golden Questions Path', 'Path to your evaluation questions JSON (golden.json by default). Used by eval_loop to measure retrieval quality.', [\n        ['Eval Script', '/files/eval_loop.py'], ['Docs Index', '/docs/README.md']\n      ]),\n      BASELINE_PATH: L('Baseline Path', 'Where eval_loop saves baseline results for regression comparison.', [\n        ['Eval Script', '/files/eval_loop.py']
]),\n      EVAL_MULTI: L('Eval Multi‑Query', 'Whether eval uses multi‑query expansion (1=yes, 0=no). Turning on improves recall; increases latency.'),\n      EVAL_FINAL_K: L('Eval Final‑K', 'How many results eval considers as top‑K when scoring hits. Typical 5–10.'),\n\n      // Repo‑specific env overrides (legacy)\n      agro_PATH: L('agro PATH (legacy)', 'Legacy repo path override. Prefer REPO_PATH or repos.json configuration.' , [\n        ['Local repos.json', '/files/repos.json']\n      ]),\n      agro_PATH_BOOSTS: L('agro Path Boosts (CSV)', 'Comma‑separated path substrings to boost ranking for the agro repo (e.g., app/,lib/,config/). Mirrors per‑repo Path Boosts.'),\n      LANGCHAIN_agro: L('LangChain (agro)', 'Legacy/internal env key for tracing/metadata. Prefer LANGCHAIN_TRACING_V2 + project config.'),\n    };\n  }\n\n  function attachTooltipListeners(icon, bubble, wrap) {\n    function show(){ bubble.classList.add('tooltip-visible'); }\n    function hide(){ bubble.classList.remove('tooltip-visible'); }\n    icon.addEventListener('mouseenter', show);\n    icon.addEventListener('mouseleave', hide);
icon.addEventListener('focus', show);\n    icon.addEventListener('blur', hide);\n    icon.addEventListener('click', (e) => {\n      e.stopPropagation();\n      bubble.classList.toggle('tooltip-visible');\n    });\n    document.addEventListener('click', (evt) => {\n      if (!wrap.contains(evt.target)) bubble.classList.remove('tooltip-visible');\n    });\n  }\n\n  function attachManualTooltips() {\n    // Attach event listeners to any manually-created tooltips in HTML\n    const manualTooltips = document.querySelectorAll('.tooltip-wrap');\n    manualTooltips.forEach((wrap) => {\n      const icon = wrap.querySelector('.help-icon');\n      const bubble = wrap.querySelector('.tooltip-bubble');\n      if (!icon || !bubble) return;\n      // Check if already has listeners (avoid double-attaching)\n      if (icon.dataset.tooltipAttached) return;\n      icon.dataset.tooltipAttached = 'true';\n      attachTooltipListeners(icon, bubble, wrap);\n    });\n  }\n\n  function attachTooltips(){\n    const map = buildTooltipMap();\n    const fields = document.querySelectorAll('[name]');\n    fields.forEach((field) => {\n      const name = field.getAttribute('name');
const parent = field.closest('.input-group');\n      if (!name || !parent) return;\n      const label = parent.querySelector('label');\n      if (!label) return;\n      if (label.querySelector('.help-icon')) return;\n      let key = name;\n      if (name.startsWith('repo_')) {\n        const type = name.split('_')[1];\n        key = 'repo_' + type;\n      }\n      let html = map[key];\n      if (!html) {\n        html = `<span class=\"tt-title\">${name}</span><div>No detailed tooltip available yet. See our docs for related settings.</div><div class=\"tt-links\"><a href=\"/files/README.md\" target=\"_blank\" rel=\"noopener\">Main README</a> <a href=\"/docs/README.md\" target=\"_blank\" rel=\"noopener\">Docs Index</a></div>`;\n      }\n      const spanText = document.createElement('span');\n      spanText.className = 'label-text';\n      spanText.textContent = label.textContent;\n      label.textContent = '';\n      label.appendChild(spanText);\n      const wrap = document.createElement('span');\n      wrap.className = 'tooltip-wrap';\n      const icon = document.createElement('span');\n      icon.className = 'help-icon';\n      icon.setAttribute('tabindex', '0');
icon.setAttribute('aria-label', `Help: ${name}`);\n      icon.textContent = '?';\n      icon.dataset.tooltipAttached = 'true';\n      const bubble = document.createElement('div');\n      bubble.className = 'tooltip-bubble';\n      bubble.setAttribute('role', 'tooltip');\n      bubble.innerHTML = html;\n      wrap.appendChild(icon);\n      wrap.appendChild(bubble);\n      label.appendChild(wrap);\n      attachTooltipListeners(icon, bubble, wrap);\n    });\n\n    // Also attach to manual tooltips in HTML\n    attachManualTooltips();\n  }\n\n  window.Tooltips = { buildTooltipMap, attachTooltips, attachManualTooltips };\n})();
// Enterprise-grade indexing status display\n// Matches storage calculator format with comprehensive metrics\nformatBytes(bytes) {\n    if (!bytes || bytes === 0) return '0 B';\n    const k = 1024;\n    const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];\n    const i = Math.floor(Math.log(bytes) / Math.log(k));\n    return Math.round((bytes / Math.pow(k, i)) * 100) / 100 + ' ' + sizes[i];\n}
formatIndexStatusDisplay(lines, metadata) {\n    if (!metadata) {\n        if (!lines || !lines.length) return '<div style="color:#666;font-size:13px;">Ready to index...</div>';\n        return `<div style="color:#aaa;font-size:12px;">${lines.join('<br>')}</div>`;\n    }\n\n    const html = [];\n    const emb = metadata.embedding_config || {};\n    const storage = metadata.storage_breakdown || {};\n    const costs = metadata.costs || {};\n\n    // HEADER: Repo + Branch\n    html.push(`\n        <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:20px;padding-bottom:16px;border-bottom:2px solid #2a2a2a;">\n            <div style="display:flex;align-items:center;gap:14px;">\n                <div style="width:8px;height:8px;border-radius:50%;background:#00ff88;box-shadow:0 0 12px #00ff88;animation:pulse 2s ease-in-out infinite;"></div>\n                <div>\n                    <div style="font-size:20px;font-weight:700;color:#fff;letter-spacing:-0.5px;">${metadata.current_repo}</div>\n                    <div style="font-size:11px;color:#666;text-transform:uppercase;letter-spacing:0.8px;margin-top:4px;">\n                        <span style="color:#888">Branch:</span> <span style="color:#5b9dff;font-weight:600;">${metadata.current_branch}</span>\n                    </div>\n                </div>\n            </div>\n            <div style="text-align:right;font-size:10px;color:#555;font-family:'SF Mono',monospace;">\n                ${new Date(metadata.timestamp).toLocaleString()}\n            </div>\n        </div>\n    `);\n\n    // EMBEDDING CONFIGURATION\n    html.push(`\n        <div style="background:linear-gradient(135deg,#0a0a0a 0%,#0f0f0f 100%);padding:16px;border-radius:8px;border:1px solid #2a2a2a;margin-bottom:20px;">\n            <div style="font-size:11px;font-weight:700;color:#b794f6;text-transform:uppercase;letter-spacing:1px;margin-bottom:12px;display:flex;align-items:center;gap:8px;">\n                <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="#b794f6" stroke-width="2">\n                    <circle cx="12" cy="12" r="10"></circle>\n                    <path d="M12 6v6l4 2"></path>\n                </svg>\n                Embedding Configuration\n            </div>\n            <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:10px;">\n                <div style="background:#0a0a0a;padding:10px;border-radius:6px;border:1px solid #1a1a1a;">\n                    <div style="font-size:9px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:4px;">Model</div>\n                    <div style="font-size:13px;font-weight:700;color:#b794f6;font-family:'SF Mono',monospace;">${emb.model || 'N/A'}</div>\n                </div>\n                <div style="background:#0a0a0a;padding:10px;border-radius:6px;border:1px solid #1a1a1a;">\n                    <div style="font-size:9px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:4px;">Dimensions</div>\n                    <div style="font-size:13px;font-weight:700;color:#5b9dff;font-family:'SF Mono',monospace;">${emb.dimensions ? emb.dimensions.toLocaleString() : 'N/A'}</div>\n                </div>\n                <div style="background:#0a0a0a;padding:10px;border-radius:6px;border:1px solid #1a1a1a;">\n                    <div style="font-size:9px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:4px;">Precision</div>\n                    <div style="font-size:13px;font-weight:700;color:#ff9b5e;font-family:'SF Mono',monospace;">${emb.precision || 'N/A'}</div>\n                </div>\n            </div>\n        </div>\n    `);\n\n    // COSTS (if available)\n    if (costs.total_tokens > 0) {\n        html.push(`\n            <div style="background:linear-gradient(135deg,#001a0f 0%,#0a0a0a 100%);padding:16px;border-radius:8px;border:1px solid #00442 2;margin-bottom:20px;">\n                <div style="font-size:11px;font-weight:700;color:#00ff88;text-transform:uppercase;letter-spacing:1px;margin-bottom:12px;display:flex;align-items:center;gap:8px;">\n                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="#00ff88" stroke-width="2">\n                        <line x1="12" y1="1" x2="12" y2="23"></line>\n                        <path d="M17 5H9.5a3.5 3.5 0 0 0 0 7h5a3.5 3.5 0 0 1 0 7H6"></path>\n                    </svg>\n                    Indexing Costs\n                </div>\n                <div style="display:grid;grid-template-columns:1fr 1fr;gap:10px;">\n                    <div style="background:#0a0a0a;padding:10px;border-radius:6px;border:1px solid #003311;">\n                        <div style="font-size:9px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:4px;">Total Tokens</div>\n                        <div style="font-size:15px;font-weight:700;color:#00ff88;font-family:'SF Mono',monospace;">${costs.total_tokens.toLocaleString()}</div>\n                    </div>\n                    <div style="background:#0a0a0a;padding:10px;border-radius:6px;border:1px solid #003311;">\n                        <div style="font-size:9px;color:#666;text-transform:uppercase;letter-spacing:0.5px;margin-bottom:4px;">Embedding Cost</div>\n                        <div style="font-size:15px;font-weight:700;color:#00ff88;font-family:'SF Mono',monospace;">$${costs.embedding_cost.toFixed(4)}</div>\n                    </div>\n                </div>\n            </div>\n        `);\n    }\n\n    // STORAGE BREAKDOWN (matching calculator format exactly)\n    html.push(`\n        <div style="background:linear-gradient(135deg,#0f0f0f 0%,#0a0a0a 100%);padding:18px;border-radius:8px;border:1px solid #2a2a2a;margin-bottom:20px;">\n            <div style="font-size:11px;font-weight:700;color:#ff9b5e;text-transform:uppercase;letter-spacing:1px;margin-bottom:16px;display:flex;align-items:center;gap:8px;">\n                <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="#ff9b5e" stroke-width="2">\n                    <rect x="2" y="3" width="20" height="18" rx="2" ry="2"></rect>\n                    <line x1="2" y1="9" x2="22" y2="9"></line>\n                    <line x1="2" y1="15" x2="22" y2="15"></line>\n                </svg>\n                Storage Requirements\n            </div>\n            <div style="display:grid;grid-template-columns:repeat(2,1fr);gap:10px;">\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Chunks JSON</span>\n                    <span style="font-size:13px;font-weight:700;color:#5b9dff;font-family:'SF Mono',monospace;">${formatBytes(storage.chunks_json)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Raw Embeddings</span>\n                    <span style="font-size:13px;font-weight:700;color:#b794f6;font-family:'SF Mono',monospace;">${formatBytes(storage.embeddings_raw)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Qdrant (w/overhead)</span>\n                    <span style="font-size:13px;font-weight:700;color:#ff9b5e;font-family:'SF Mono',monospace;">${formatBytes(storage.embeddings_raw + storage.qdrant_overhead)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">BM25 Index</span>\n                    <span style="font-size:13px;font-weight:700;color:#00ff88;font-family:'SF Mono',monospace;">${formatBytes(storage.bm25_index)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Cards/Summary</span>\n                    <span style="font-size:13px;font-weight:700;color:#ff6b9d;font-family:'SF Mono',monospace;">${formatBytes(storage.cards)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Reranker Cache</span>\n                    <span style="font-size:13px;font-weight:700;color:#ffaa00;font-family:'SF Mono',monospace;">${formatBytes(storage.reranker_cache)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid #1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Redis Cache</span>\n                    <span style="font-size:13px;font-weight:700;color:#7db3ff;font-family:'SF Mono',monospace;">${formatBytes(storage.redis)}</span>\n                </div>\n                <div style="background:#0a0a0a;padding:12px;border-radius:6px;border:1px solid#1a1a1a;display:flex;justify-content:space-between;align-items:center;">\n                    <span style="font-size:10px;color:#888;text-transform:uppercase;letter-spacing:0.5px;">Keywords</span>\n                    <span style="font-size:13px;font-weight:700;color:#ffcf66;font-family:'SF Mono',monospace;">${metadata.keywords_count.toLocaleString()}</span>\n                </div>\n            </div>\n        </div>\n    `);\n\n    // INDEX PROFILES (collapsible)\n    if (metadata.repos && metadata.repos.length > 0) {\n        html.push(`\n            <details style="margin-bottom:20px;">\n                <summary style="cursor:pointer;font-size:11px;font-weight:700;color:#888;text-transform:uppercase;letter-spacing:1px;padding:12px;background:#0a0a0a;border-radius:6px;border:1px solid #2a2a2a;">\n                    <span style="color:#5b9dff;">▸</span> Index Profiles (${metadata.repos.length})\n                </summary>\n                <div style="margin-top:12px;padding:12px;background:#0a0a0a;border-radius:6px;border:1px solid #1a1a1a;">\n        `);\n\n        metadata.repos.forEach(repo => {\n            const totalSize = (repo.sizes.chunks || 0) + (repo.sizes.bm25 || 0) + (repo.sizes.cards || 0);\n            html.push(`\n                <div style="padding:10px;margin-bottom:8px;background:#0f0f0f;border-radius:4px;border:1px solid ${repo.has_cards ? '#003311' : '#1a1a1a'};">\n                    <div style="display:flex;justify-content:space-between;margin-bottom:6px;">\n                        <div style="font-size:12px;font-weight:600;color:#fff;">${repo.name} <span style="color:#666;font-weight:400;">/ ${repo.profile}</span></div>\n                        <div style="font-size:12px;font-weight:700;color:#00ff88;font-family:'SF Mono',monospace;">${formatBytes(totalSize)}</div>\n                    </div>\n                    <div style="font-size:10px;color:#666;">${repo.chunk_count.toLocaleString()} chunks ${repo.has_cards ? '• <span style="color:#00ff88;">✓ Cards</span>' : ''}</div>\n                </div>\n            `);\n        });\n\n        html.push(`</div></details>`);\n    }\n\n    // TOTAL FOOTER\n    html.push(`\n        <div style="display:flex;justify-content:space-between;align-items:center;padding:18px;background:linear-gradient(135deg,#0f1f0f 0%,#0a0a0a 100%);border-radius:8px;border:2px solid #00ff88;">\n            <div style="font-size:13px;font-weight:700;color:#888;text-transform:uppercase;letter-spacing:1px;">Total Index Storage</div>\n            <div style="font-size:24px;font-weight:900;color:#00ff88;font-family:'SF Mono',monospace;text-shadow:0 0 20px rgba(0,255,136,0.3);">\n                ${formatBytes(metadata.total_storage)}\n            </div>\n        </div>\n    `);\n\n    return html.join('');\n}\n\n// Export for use in app.js\nif (typeof window !== 'undefined') {\n    window.formatIndexStatusDisplay = formatIndexStatusDisplay;\n}
// Cost calculator logic. Exported via window.CostLogic\n;(function(){\n  function readInt(id, d){ const el=document.getElementById(id); const v=el?el.value:''; const n=parseInt(v||'',10); return Number.isFinite(n)?n:(d||0); }\n  function readStr(id, d){ const el=document.getElementById(id); const v=el?el.value:''; return (v||d||'').toString(); }\n\n  function buildBase(){\n    return {\n      tokens_in: readInt('cost-in', 500),\n      tokens_out: readInt('cost-out', 800),\n      embeds: readInt('cost-embeds', 0),\n      reranks: readInt('cost-rerank', 0),\n      requests_per_day: readInt('cost-rpd', 100),\n    };\n  }\n\n  function buildPayloadFromUI(){\n    const base = buildBase();\n    const gen_provider = readStr('cost-provider','openai').trim();\n    const gen_model = readStr('cost-model','gpt-4o-mini').trim();\n    const embed_provider = readStr('cost-embed-provider','openai').trim();\n    const embed_model = readStr('cost-embed-model','text-embedding-3-small').trim();\n    const rerank_provider = readStr('cost-rerank-provider','cohere').trim();\n    const rerank_model = readStr('cost-rerank-model','rerank-3.5').trim();
return { gen_provider, gen_model, embed_provider, embed_model, rerank_provider, rerank_model, ...base };\n  }\n\n  async function estimateFromUI(apiBase){\n    try{\n      const payload = buildPayloadFromUI();\n      const base = (apiBase||'').replace(/\/$/,'');\n      let r = await fetch(base + '/api/cost/estimate_pipeline', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });\n      if (!r.ok) r = await fetch(base + '/api/cost/estimate', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });\n      if (!r.ok) throw new Error(await r.text() || 'Cost estimate failed');\n      return await r.json();\n    }catch(e){ throw e; }\n  }\n\n  window.CostLogic = { buildBase, buildPayloadFromUI, estimateFromUI };\n})();
// Profile Renderer - Rich, professional display of auto-generated profiles\n;(function(){\n  \n  // Setting metadata with explanations\n  const SETTING_INFO = {\n    GEN_MODEL: {\n      name: 'Generation Model',\n      description: 'The AI model used to generate answers from retrieved code. This is the "brain" that synthesizes information.',\n      category: 'Generation',\n      icon: '🧠'\n    },\n    EMBEDDING_TYPE: {\n      name: 'Embedding Provider',\n      description: 'Creates vector representations of your code for semantic search. Higher quality embeddings find more relevant results.',\n      category: 'Retrieval',\n      icon: '🔍'\n    },\n    RERANK_BACKEND: {\n      name: 'Reranking Engine',\n      description: 'Re-scores retrieved results for precision. This is your quality filter that ensures the best results rise to the top. Shows backend and model when applicable.',\n      category: 'Retrieval',\n      icon: '⚡'\n    },\n    COHERE_RERANK_MODEL: {\n      name: 'Rerank Model',\n      description: 'Specific Cohere reranker model used when backend = cohere (e.g., rerank-3.5).',\n      category: 'Retrieval',\n      icon: '⚙️'\n    },\n    RERANKER_MODEL: {\n      name: 'Rerank Model',
description: 'Local/HF reranker model used when backend = local or hf (e.g., BAAI/bge-reranker-v2-m3).',\n      category: 'Retrieval',\n      icon: '⚙️'\n    },\n    MQ_REWRITES: {\n      name: 'Multi-Query Expansion',\n      description: 'Number of query variations generated to cast a wider search net. More rewrites = better recall but higher cost.',\n      category: 'Search Strategy',\n      icon: '🎯',\n      valueExplainer: (v) => v + ' variations per query'\n    },\n    TOPK_SPARSE: {\n      name: 'BM25 Candidates',\n      description: 'Number of keyword-based matches to retrieve. BM25 is excellent for exact terms and technical names.',\n      category: 'Search Strategy',\n      icon: '📝',\n      valueExplainer: (v) => 'Top ' + v + ' keyword matches'\n    },\n    TOPK_DENSE: {\n      name: 'Vector Candidates',\n      description: 'Number of semantic matches to retrieve. Vector search excels at conceptual similarity.',\n      category: 'Search Strategy',\n      icon: '🎨',\n      valueExplainer: (v) => 'Top ' + v + ' semantic matches'\n    },\n    FINAL_K: {\n      name: 'Final Results',\n      description: 'After hybrid fusion and reranking, this many results are sent to generation. Balance between context and cost.',
category: 'Search Strategy',\n      icon: '🎁',\n      valueExplainer: (v) => v + ' final results'\n    },\n    HYDRATION_MODE: {\n      name: 'Code Hydration',\n      description: 'How full code is loaded. "Lazy" fetches on-demand for efficiency. "Eager" pre-loads everything.',\n      category: 'Performance',\n      icon: '💧'\n    }\n  };\n\n  const TIER_INFO = {\n    0: { name: 'Free Tier', color: '#4ecdc4', badge: 'LOCAL ONLY' },\n    10: { name: 'Starter', color: '#5b9dff', badge: 'BUDGET FRIENDLY' },\n    50: { name: 'Professional', color: '#b794f6', badge: 'BALANCED' },\n    200: { name: 'Enterprise', color: '#00ff88', badge: 'MAXIMUM PERFORMANCE' }\n  };\n\n  function renderProfileResults(profile, scan, budget) {\n    const tierInfo = TIER_INFO[budget] || { name: 'Custom', color: '#999', badge: 'CUSTOM CONFIG' };\n    \n    let html = '<div style="margin-bottom:24px;padding-bottom:20px;border-bottom:1px solid #2a2a2a;">';\n    html += '<div style="display:flex;align-items:center;justify-content:space-between;margin-bottom:12px;">';\n    html += '<div>';\n    html += '<h4 style="font-size:18px;font-weight:700;color:#fff;margin-bottom:4px;">' + tierInfo.name + ' Profile</h4>';
html += '<span style="font-size:11px;color:' + tierInfo.color + ';font-weight:600;letter-spacing:0.8px;">' + tierInfo.badge + '</span>';\n    html += '</div>';\n    html += '<div style="font-size:28px;font-weight:800;color:' + tierInfo.color + ';">$' + budget + '/mo</div>';\n    html += '</div>';\n    \n    html += '<div style="background:#111;border:1px solid #2a2a2a;border-radius:6px;padding:14px;margin-top:12px;">';\n    html += '<p style="font-size:13px;color:#aaa;line-height:1.6;margin:0;">';\n    html += '<strong style="color:#00ff88;">Baseline Configuration</strong> — ';\n    html += 'This profile gives you a strong starting point optimized for your hardware and budget. ';\n    html += 'You can fine-tune any setting in the Models, Retrieval, or Infrastructure tabs. ';\n    html += 'Consider saving multiple profiles for different use cases (e.g., "dev-fast" vs "prod-quality").';\n    html += '</p></div></div>';\n\n    html += '<div style="display:flex;flex-direction:column;gap:16px;margin-bottom:24px;">';\n\n    // Group settings by category\n    const categories = {};
Object.keys(profile).forEach(key => {\n      const info = SETTING_INFO[key];\n      if (!info) return;\n      \n      const cat = info.category;\n      if (!categories[cat]) categories[cat] = [];\n      categories[cat].push({ key: key, value: profile[key], info: info });\n    });\n\n    // Render each category\n    Object.entries(categories).forEach(([catName, settings]) => {\n      html += '<div style="background:#0a0a0a;border:1px solid #2a2a2a;border-radius:6px;padding:16px;">';\n      html += '<h5 style="font-size:12px;color:#999;text-transform:uppercase;letter-spacing:0.8px;font-weight:600;margin-bottom:14px;">';\n      html += catName + '</h5>';\n      html += '<div style="display:flex;flex-direction:column;gap:12px;">';\n\n      settings.forEach(({ key, value, info }) => {\n        let displayValue = info.valueExplainer ? info.valueExplainer(value) : value;\n        if (key === 'RERANK_BACKEND') {\n          if (String(value) === 'cohere' && profile.COHERE_RERANK_MODEL) {\n            displayValue = `${value}: ${profile.COHERE_RERANK_MODEL}`;\n          } else if ((String(value) === 'hf' || String(value) === 'local') && profile.RERANKER_MODEL) {
displayValue = `${value}: ${profile.RERANKER_MODEL}`;\n          }\n        }\n        html += '<div style="display:flex;gap:12px;">';\n        html += '<div style="font-size:20px;flex-shrink:0;width:32px;height:32px;display:flex;align-items:center;justify-content:center;background:#1a1a1a;border-radius:6px;">';\n        html += info.icon + '</div>';\n        html += '<div style="flex:1;">';\n        html += '<div style="display:flex;align-items:center;justify-content:space-between;margin-bottom:4px;">';\n        html += '<span style="font-size:13px;font-weight:600;color:#fff;">' + info.name + '</span>';\n        html += '<code style="font-size:12px;color:#00ff88;background:#0a0a0a;padding:2px 8px;border-radius:4px;font-family:\'SF Mono\',monospace;">';\n        html += displayValue + '</code></div>';\n        html += '<p style="font-size:12px;color:#888;line-height:1.5;margin:0;">' + info.description + '</p>';\n        html += '</div></div>';\n      });\n\n      html += '</div></div>';\n    });\n\n    html += '</div>';\n\n    html += '<div style="display:flex;gap:12px;padding-top:16px;border-top:1px solid #2a2a2a;">';
html += '<button id="apply-profile-btn" class="small-button" style="flex:1;background:#00ff88;color:#000;border:none;padding:12px;font-weight:700;">';\n    html += 'Apply This Profile</button>';\n    html += '<button id="export-profile-btn" class="small-button" style="background:#1a1a1a;border:1px solid #2a2a2a;color:#aaa;padding:12px;">';\n    html += 'Export JSON</button>';\n    html += '<button id="save-profile-btn" class="small-button" style="background:#1a1a1a;border:1px solid #2a2a2a;color:#aaa;padding:12px;">';\n    html += 'Save As...</button></div>';\n\n    html += '<div style="margin-top:20px;padding:14px;background:#0a0a0a;border:1px solid #2a2a2a;border-radius:6px;">';\n    html += '<div style="font-size:11px;color:#666;line-height:1.6;">';\n    html += '<strong style="color:#888;">Hardware Detected:</strong> ';\n    html += (scan && scan.info && scan.info.os) || 'Unknown';\n    html += ' • ';\n    html += (scan && scan.info && scan.info.arch) || 'Unknown';\n    html += ' • ';\n    html += (scan && scan.info && scan.info.cpu_cores) || '?';
html += ' cores • ';\n    html += (scan && scan.info && scan.info.mem_gb) ? scan.info.mem_gb + 'GB RAM' : 'RAM unknown';\n    if (scan && scan.runtimes && scan.runtimes.ollama) html += ' • Ollama available';\n    if (scan && scan.runtimes && scan.runtimes.cuda) html += ' • CUDA available';\n    html += '</div></div>';\n\n    return html;\n  }\n\n  window.ProfileRenderer = { renderProfileResults: renderProfileResults };\n  window.ProfileRenderer.bindTooltips = function bindTooltips(root){\n    if (!root) return;\n    const icons = root.querySelectorAll('.help-icon');\n    icons.forEach(icon => {\n      const wrap = icon.parentElement;\n      const bubble = wrap && wrap.querySelector('.tooltip-bubble');\n      if (!wrap || !bubble) return;\n      function show(){ bubble.classList.add('tooltip-visible'); }\n      function hide(){ bubble.classList.remove('tooltip-visible'); }\n      icon.addEventListener('mouseenter', show);\n      icon.addEventListener('mouseleave', hide);\n      icon.addEventListener('focus', show);\n      icon.addEventListener('blur', hide);\n      icon.addEventListener('click', (e)=>{ e.stopPropagation(); bubble.classList.toggle('tooltip-visible'); });
document.addEventListener('click', (evt)=>{ if (!wrap.contains(evt.target)) bubble.classList.remove('tooltip-visible'); });\n    });\n  }\n})();
// Chat interface for RAG system\n// Handles sending questions to /answer endpoint and displaying responses\n\n// Default chat settings\nconst DEFAULT_CHAT_SETTINGS = {\n    model: '',  // Empty = use GEN_MODEL\n    temperature: 0.0,\n    maxTokens: 1000,\n    multiQuery: 3,\n    finalK: 20,\n    confidence: 0.55,\n    showCitations: true,\n    showConfidence: false,\n    autoScroll: true,\n    syntaxHighlight: false,\n    systemPrompt: '',\n    // History settings\n    historyEnabled: true,\n    historyLimit: 100,  // Maximum number of messages to store\n    showHistoryOnLoad: true  // Auto-load history when page loads\n};\n\nlet chatMessages = [];\nlet chatSettings = loadChatSettings();\n\n// Load settings from localStorageloadChatSettings() {\n    try {\n        const saved = localStorage.getItem('agro_chat_settings');\n        if (saved) {\n            return { ...DEFAULT_CHAT_SETTINGS, ...JSON.parse(saved) };\n        }\n    } catch (e) {\n        console.warn('Failed to load chat settings:', e);\n    }\n    return { ...DEFAULT_CHAT_SETTINGS };\n}\n\n// Save settings to localStorage
saveChatSettings() {\n    try {\n        const settings = {\n            model: document.getElementById('chat-model').value,\n            temperature: parseFloat(document.getElementById('chat-temperature').value),\n            maxTokens: parseInt(document.getElementById('chat-max-tokens').value),\n            multiQuery: parseInt(document.getElementById('chat-multi-query').value),\n            finalK: parseInt(document.getElementById('chat-final-k').value),\n            confidence: parseFloat(document.getElementById('chat-confidence').value),\n            showCitations: document.getElementById('chat-show-citations').value === '1',\n            showConfidence: document.getElementById('chat-show-confidence').value === '1',\n            autoScroll: document.getElementById('chat-auto-scroll').value === '1',\n            syntaxHighlight: document.getElementById('chat-syntax-highlight').value === '1',\n            systemPrompt: document.getElementById('chat-system-prompt').value,\n            // History settings\n            historyEnabled: document.getElementById('chat-history-enabled').value === '1',\n            historyLimit: Math.min(1000, Math.max(1, parseInt(document.getElementById('chat-history-limit').value) || 100)),\n            showHistoryOnLoad: document.getElementById('chat-show-history-on-load').value === '1'\n        };\n\n        localStorage.setItem('agro_chat_settings', JSON.stringify(settings));\n        chatSettings = settings;\n\n        updateStorageDisplay();\n        showToast('Chat settings saved', 'success');\n    } catch (e) {\n        console.error('Failed to save chat settings:', e);\n        showToast('Failed to save settings: ' + e.message, 'error');\n    }\n}\n\n// Reset settings to defaults
resetChatSettings() {\n    if (!confirm('Reset all chat settings to defaults?')) return;\n\n    chatSettings = { ...DEFAULT_CHAT_SETTINGS };\n    localStorage.removeItem('agro_chat_settings');\n    applyChatSettings();\n    showToast('Chat settings reset to defaults', 'success');\n}\n\n// Apply settings to UI inputs
applyChatSettings() {\n    try {\n        const elements = {\n            'chat-model': chatSettings.model,\n            'chat-temperature': chatSettings.temperature,\n            'chat-max-tokens': chatSettings.maxTokens,\n            'chat-multi-query': chatSettings.multiQuery,\n            'chat-final-k': chatSettings.finalK,\n            'chat-confidence': chatSettings.confidence,\n            'chat-show-citations': chatSettings.showCitations ? '1' : '0',\n            'chat-show-confidence': chatSettings.showConfidence ? '1' : '0',\n            'chat-auto-scroll': chatSettings.autoScroll ? '1' : '0',\n            'chat-syntax-highlight': chatSettings.syntaxHighlight ? '1' : '0',\n            'chat-system-prompt': chatSettings.systemPrompt,\n            // History settings\n            'chat-history-enabled': chatSettings.historyEnabled ? '1' : '0',\n            'chat-history-limit': chatSettings.historyLimit,\n            'chat-show-history-on-load': chatSettings.showHistoryOnLoad ? '1' : '0'\n        };\n\n        for (const [id, value] of Object.entries(elements)) {\n            const el = document.getElementById(id);\n            if (el) {\n                el.value = value;\n            }\n        }\n\n        // Update storage display\n        updateStorageDisplay();\n    } catch (e) {\n        console.warn('Failed to apply chat settings:', e);\n    }\n}\n\n// Send a question to the RAG\nasync function sendMessage() {\n    const input = document.getElementById('chat-input');\n    const sendBtn = document.getElementById('chat-send');\n    const repoSelect = document.getElementById('chat-repo-select');\n\n    const question = input.value.trim();\n    if (!question) return;\n\n    const repo = repoSelect.value || null;\n\n    // Add user message to chat\n    addMessage('user', question);\n    input.value = '';\n    input.style.height = 'auto';\n\n    // Disable input while loading\n    input.disabled = true;\n    sendBtn.disabled = true;\n    sendBtn.textContent = 'Thinking...';\n\n    // Add loading message\n    const loadingId = addMessage('assistant', '...', true);\n\n    try {\n        // Use /api/chat endpoint with full settings support\n        const url = new URL('/api/chat', window.location.origin);\n\n        const payload = {\n            question: question,\n            repo: repo || null,\n            model: chatSettings.model || null,\n            temperature: chatSettings.temperature,\n            max_tokens: chatSettings.maxTokens,\n            multi_query: chatSettings.multiQuery,\n            final_k: chatSettings.finalK,\n            confidence: chatSettings.confidence,\n            system_prompt: chatSettings.systemPrompt || null\n        };\n\n        const response = await fetch(url, {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json'\n            },\n            body: JSON.stringify(payload)\n        });\n\n        const data = await response.json();\n\n        if (!response.ok) {\n            throw new Error(data.detail || 'Failed to get answer');\n        }\n\n        // Remove loading message and add real answer\n        removeMessage(loadingId);\n\n        // Add confidence score if enabled\n        let answerText = data.answer;\n        if (chatSettings.showConfidence && data.confidence) {\n            answerText = `[Confidence: ${(data.confidence * 100).toFixed(1)}%]\n\n${answerText}`;\n        }\n\n        addMessage('assistant', answerText);\n\n    } catch (error) {\n        console.error('Chat error:', error);\n        removeMessage(loadingId);\n        addMessage('assistant', `Error: ${error.message}`, false, true);\n    } finally {\n        input.disabled = false;\n        sendBtn.disabled = false;\n        sendBtn.textContent = 'Send';\n        input.focus();\n    }\n}\n\n// Add a message to the chat
addMessage(role, content, isLoading = false, isError = false, saveToHistory = true) {\n    const messagesContainer = document.getElementById('chat-messages');\n\n    // Remove empty state if present\n    const emptyState = messagesContainer.querySelector('[style*="text-align: center"]');\n    if (emptyState) {\n        emptyState.remove();\n    }\n\n    const messageId = `msg-${Date.now()}-${Math.random()}`;\n    const messageDiv = document.createElement('div');\n    messageDiv.id = messageId;\n    messageDiv.style.cssText = 'margin-bottom: 16px; animation: fadeIn 0.2s;';\n\n    const roleColor = role === 'user' ? '#5b9dff' : '#00ff88';\n    const roleBg = role === 'user' ? '#0f1f2f' : '#0f1f0f';\n    const roleLabel = role === 'user' ? 'You' : 'Assistant';\n\n    // Process content for file links and formatting\n    let processedContent = content;\n    if (role === 'assistant' && !isLoading) {\n        processedContent = formatAssistantMessage(content);\n    } else {\n        processedContent = escapeHtml(content);\n    }\n\n    messageDiv.innerHTML = `\n        <div style="display: flex; gap: 12px;">\n            <div style="flex-shrink: 0; width: 32px; height: 32px; border-radius: 6px; background: ${roleBg}; border: 1px solid ${roleColor}; display: flex; align-items: center; justify-content: center; font-size: 12px; font-weight: 600; color: ${roleColor};">\n                ${roleLabel[0]}\n            </div>\n            <div style="flex: 1;">\n                <div style="font-size: 12px; color: #888; margin-bottom: 4px;">${roleLabel}</div>\n                <div style="color: ${isError ? '#ff6b6b' : '#ddd'}; line-height: 1.6; white-space: pre-wrap; word-break: break-word;">\n                    ${processedContent}\n                </div>\n            </div>\n        </div>\n    `;\n\n    messagesContainer.appendChild(messageDiv);\n\n    // Scroll to bottom if auto-scroll is enabled\n    if (chatSettings.autoScroll) {\n        messagesContainer.scrollTop = messagesContainer.scrollHeight;\n    }\n\n    chatMessages.push({ id: messageId, role, content, isLoading, isError });\n\n    // Save to history if enabled and not a loading message\n    if (saveToHistory && !isLoading && !isError && chatSettings.historyEnabled) {\n        saveMessageToHistory(role, content, messageId);\n    }\n\n    return messageId;\n}\n\n// Remove a message by ID
removeMessage(messageId) {\n    const messageDiv = document.getElementById(messageId);\n    if (messageDiv) {\n        messageDiv.remove();\n    }\n    chatMessages = chatMessages.filter(m => m.id !== messageId);\n}\n\n// Format assistant message with file links and code blocks
formatAssistantMessage(content) {\n    let formatted = escapeHtml(content);\n\n    // Extract and link file paths (e.g., server/app.py:123-145 or just server/app.py)\n    formatted = formatted.replace(\n        /([a-zA-Z0-9_\-\/\.]+\.(py|js|ts|tsx|jsx|rb|go|rs|java|cs|yml|yaml|json|md|txt))(?::(\d+)(?:-(\d+))?)?/g,\n        (match, filePath, ext, startLine, endLine) => {\n            const lineRange = startLine ? `:${startLine}${endLine ? `-${endLine}` : ''}` : '';\n            const displayText = `${filePath}${lineRange}`;\n            // Use vscode:// URL scheme if available, otherwise just show as styled text\n            return `<a href="vscode://file/${filePath}${startLine ? ':' + startLine : ''}" style="color: #5b9dff; text-decoration: none; border-bottom: 1px solid #5b9dff; font-family: 'SF Mono', monospace; font-size: 13px;" title="Open in editor">${displayText}</a>`;\n        }\n    );\n\n    // Extract repo header (e.g., [repo: agro])\n    formatted = formatted.replace(\n        /\[repo:\s*([^\]]+)\]/g,\n        '<span style="background: #1a1a1a; color: #888; padding: 2px 8px; border-radius: 3px; font-size: 11px; font-family: \'SF Mono\', monospace;">repo: $1</span>'\n    );\n\n    // Simple code block formatting (backticks)\n    formatted = formatted.replace(\n        /`([^`]+)`/g,\n        '<code style="background: #1a1a1a; color: #00ff88; padding: 2px 6px; border-radius: 3px; font-family: \'SF Mono\', monospace; font-size: 13px;">$1</code>'\n    );\n\n    // Multi-line code blocks\n    formatted = formatted.replace(\n        /```([^\n]*)\n([\s\S]*?)```/g,\n        (match, lang, code) => {\n            const escapedCode = code.trim();\n            return `<pre style="background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 6px; padding: 12px; overflow-x: auto; margin: 8px 0;"><code style="color: #ddd; font-family: 'SF Mono', monospace; font-size: 13px;">${escapedCode}</code></pre>`;\n        }\n    );\n\n    return formatted;\n}\n\n// Clear all messages
clearChat() {\n    if (!confirm('Clear all messages?')) return;\n\n    const messagesContainer = document.getElementById('chat-messages');\n    messagesContainer.innerHTML = `\n        <div style="text-align: center; color: #666; padding: 40px 20px;">\n            <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" style="opacity: 0.3; margin-bottom: 12px;">\n                <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>\n            </svg>\n            <div>Start a conversation with your codebase</div>\n            <div style="font-size: 11px; margin-top: 8px;">Try: "Where is OAuth token validated?" or "How do we handle API errors?"</div>\n        </div>\n    `;\n    chatMessages = [];\n}\n\n// Helper: escape HTMLescapeHtml(text) {\n    const div = document.createElement('div');\n    div.textContent = text;\n    return div.innerHTML;\n}\n\n// ========== HISTORY MANAGEMENT FUNCTIONS ==========\n\n// Save message to history
saveMessageToHistory(role, content, messageId) {\n    if (!chatSettings.historyEnabled) return;\n\n    try {\n        let history = JSON.parse(localStorage.getItem('agro_chat_history') || '[]');\n\n        // Add new message with metadata\n        history.push({\n            id: messageId,\n            role: role,\n            content: content,\n            timestamp: new Date().toISOString(),\n            repo: document.getElementById('chat-repo-select').value || 'auto'\n        });\n\n        // Enforce history limit\n        if (history.length > chatSettings.historyLimit) {\n            history = history.slice(-chatSettings.historyLimit);\n        }\n\n        localStorage.setItem('agro_chat_history', JSON.stringify(history));\n        updateStorageDisplay();\n    } catch (e) {\n        console.warn('Failed to save message to history:', e);\n    }\n}\n\n// Load chat history from localStorage
loadChatHistory() {\n    if (!chatSettings.historyEnabled || !chatSettings.showHistoryOnLoad) return;\n\n    try {\n        const history = JSON.parse(localStorage.getItem('agro_chat_history') || '[]');\n        const messagesContainer = document.getElementById('chat-messages');\n\n        if (history.length > 0) {\n            // Clear the empty state message\n            messagesContainer.innerHTML = '';\n\n            // Add separator for historical messages\n            const separator = document.createElement('div');\n            separator.style.cssText = 'text-align: center; color: #666; margin: 20px 0; font-size: 11px;';\n            separator.innerHTML = `\n                <div style="display: flex; align-items: center; gap: 12px;">\n                    <div style="flex: 1; height: 1px; background: #2a2a2a;"></div>\n                    <span>Previous conversation (${history.length} messages)</span>\n                    <div style="flex: 1; height: 1px; background: #2a2a2a;"></div>\n                </div>\n            `;\n            messagesContainer.appendChild(separator);\n\n            // Load messages\n            history.forEach(msg => {\n                addMessage(msg.role, msg.content, false, false, false); // Don't save again\n            });\n\n            // Add separator for new session\n            const newSessionSeparator = document.createElement('div');\n            newSessionSeparator.style.cssText = 'text-align: center; color: #666; margin: 20px 0; font-size: 11px;';\n            newSessionSeparator.innerHTML = `\n                <div style="display: flex; align-items: center; gap: 12px;">\n                    <div style="flex: 1; height: 1px; background: #2a2a2a;"></div>\n                    <span>New session started</span>\n                    <div style="flex: 1; height: 1px; background: #2a2a2a;"></div>\n                </div>\n            `;\n            messagesContainer.appendChild(newSessionSeparator);\n        }\n    } catch (e) {\n        console.warn('Failed to load chat history:', e);\n    }\n}\n\n// Clear chat history
clearChatHistory() {\n    if (!confirm('Clear all saved chat history? This cannot be undone.')) return;\n\n    try {\n        localStorage.removeItem('agro_chat_history');\n        updateStorageDisplay();\n        showToast('Chat history cleared', 'success');\n    } catch (e) {\n        console.error('Failed to clear chat history:', e);\n        showToast('Failed to clear history: ' + e.message, 'error');\n    }\n}\n\n// Export chat history as JSON
exportChatHistory() {\n    try {\n        const history = localStorage.getItem('agro_chat_history') || '[]';\n        const blob = new Blob([history], { type: 'application/json' });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement('a');\n        a.href = url;\n        a.download = `chat-history-${new Date().toISOString().split('T')[0]}.json`;\n        document.body.appendChild(a);\n        a.click();\n        document.body.removeChild(a);\n        URL.revokeObjectURL(url);\n        showToast('Chat history exported', 'success');\n    } catch (e) {\n        console.error('Failed to export chat history:', e);\n        showToast('Failed to export history: ' + e.message, 'error');\n    }\n}\n\n// Calculate and display storage usage
updateStorageDisplay() {\n    try {\n        const historyStr = localStorage.getItem('agro_chat_history') || '[]';\n        const sizeInBytes = new Blob([historyStr]).size;\n        const sizeInKB = (sizeInBytes / 1024).toFixed(2);\n        const history = JSON.parse(historyStr);\n\n        const displayElement = document.getElementById('chat-storage-display');\n        if (displayElement) {\n            displayElement.textContent = `${history.length} messages using ${sizeInKB}KB`;\n        }\n    } catch (e) {\n        console.warn('Failed to update storage display:', e);\n    }\n}\n\n// Auto-resize textarea
autoResizeTextarea(textarea) {\n    textarea.style.height = 'auto';\n    const newHeight = Math.min(textarea.scrollHeight, 120);\n    textarea.style.height = newHeight + 'px';\n}\n\n// Initialize chat when DOM is ready\nif (typeof window !== 'undefined') {\n    window.addEventListener('DOMContentLoaded', () => {\n        const input = document.getElementById('chat-input');\n        const sendBtn = document.getElementById('chat-send');\n        const clearBtn = document.getElementById('chat-clear');\n        const historyBtn = document.getElementById('chat-history');\n        const exportHistoryBtn = document.getElementById('chat-export-history');\n        const clearHistoryBtn = document.getElementById('chat-clear-history');\n        const saveSettingsBtn = document.getElementById('chat-save-settings');\n        const resetSettingsBtn = document.getElementById('chat-reset-settings');\n\n        if (input) {\n            // Send on Ctrl+Enter\n            input.addEventListener('keydown', (e) => {\n                if (e.key === 'Enter' && e.ctrlKey) {\n                    e.preventDefault();\n                    sendMessage();\n                }\n            });\n\n            // Auto-resize as user types\n            input.addEventListener('input', () => {\n                autoResizeTextarea(input);\n            });\n        }\n\n        if (sendBtn) {\n            sendBtn.addEventListener('click', sendMessage);\n        }\n\n        if (clearBtn) {\n            clearBtn.addEventListener('click', clearChat);\n        }\n\n        if (historyBtn) {\n            historyBtn.addEventListener('click', () => {\n                const dropdown = document.getElementById('history-dropdown');\n                dropdown.style.display = dropdown.style.display === 'block' ? 'none' : 'block';\n            });\n        }\n\n        if (exportHistoryBtn) {\n            exportHistoryBtn.addEventListener('click', exportChatHistory);\n        }\n\n        if (clearHistoryBtn) {\n            clearHistoryBtn.addEventListener('click', clearChatHistory);\n        }\n\n        if (saveSettingsBtn) {\n            saveSettingsBtn.addEventListener('click', saveChatSettings);\n        }\n\n        if (resetSettingsBtn) {\n            resetSettingsBtn.addEventListener('click', resetChatSettings);\n        }\n\n        // Apply loaded settings on page load\n        applyChatSettings();\n\n        // Load chat history if enabled\n        loadChatHistory();\n\n        // Hide dropdown when clicking outside\n        document.addEventListener('click', (e) => {\n            if (!e.target.closest('#chat-history') && !e.target.closest('#history-dropdown')) {\n                const dropdown = document.getElementById('history-dropdown');\n                if (dropdown) dropdown.style.display = 'none';\n            }\n        });\n    });\n}\n\n// Add fadeIn animation\nif (typeof document !== 'undefined' && !document.querySelector('#chat-animations')) {\n    const style = document.createElement('style');\n    style.id = 'chat-animations';\n    style.textContent = `\n        @keyframes fadeIn {\n            from { opacity: 0; transform: translateY(-4px); }\n            to { opacity: 1; transform: translateY(0); }\n        }\n    `;\n    document.head.appendChild(style);\n}
// AGRO Storage Calculator v1.2 - JavaScript Logic\n// This file contains all the calculation logic for the storage calculator\n\n// Improved formatBytes function with consistent formattingformatBytes(bytes) {\n    if (!isFinite(bytes) || bytes === 0) return '0 B';\n    const abs = Math.abs(bytes);\n    const KB = 1024;\n    const MB = KB * 1024;\n    const GB = MB * 1024;\n    const TB = GB * 1024;\n    const nf = new Intl.NumberFormat('en-US', { maximumFractionDigits: 3 });\n\n    if (abs < KB) return `${bytes.toFixed(0)} B`;\n    if (abs < MB) return `${nf.format(bytes / KB)} KiB`;\n    if (abs < GB) return `${nf.format(bytes / MB)} MiB`;\n    if (abs < TB) return `${nf.format(bytes / GB)} GiB`;\n    return `${nf.format(bytes / TB)} TiB`;\n}\nformatNumber(num) {\n    return new Intl.NumberFormat('en-US').format(num);\n}\n\n// Calculator 1: Full Storage Requirements
calculateStorage1() {\n    const R = parseFloat(document.getElementById('calc1-repoSize').value) *\n             parseFloat(document.getElementById('calc1-repoUnit').value);\n    const C = parseFloat(document.getElementById('calc1-chunkSize').value) *\n             parseFloat(document.getElementById('calc1-chunkUnit').value);\n\n    // Guard against invalid chunk size\n    if (!C || C <= 0) {\n        console.warn("Chunk size must be > 0");\n        return;\n    }\n\n    const D = parseFloat(document.getElementById('calc1-embDim').value);\n    const B = parseFloat(document.getElementById('calc1-precision').value);\n    const Q = parseFloat(document.getElementById('calc1-qdrant').value);\n    const hydrationPct = parseFloat(document.getElementById('calc1-hydration').value) / 100;\n    const redisBytes = parseFloat(document.getElementById('calc1-redis').value) * 1048576;\n    const replFactor = parseFloat(document.getElementById('calc1-replication').value);\n\n    // Calculate\n    const N = Math.ceil(R / C);\n    const E = N * D * B;\n    const Q_bytes = E * Q;\n    const BM25 = 0.20 * R;\n    const CARDS = 0.10 * R;\n    const HYDR = hydrationPct * R;\n    const RER = 0.5 * E;\n\n    // Update display\n    document.getElementById('calc1-chunks').textContent = formatNumber(N);\n    document.getElementById('calc1-embeddings').textContent = formatBytes(E);\n    document.getElementById('calc1-qdrantSize').textContent = formatBytes(Q_bytes);\n    document.getElementById('calc1-bm25').textContent = formatBytes(BM25);\n    document.getElementById('calc1-cards').textContent = formatBytes(CARDS);\n    document.getElementById('calc1-hydr').textContent = formatBytes(HYDR);\n    document.getElementById('calc1-reranker').textContent = formatBytes(RER);\n    document.getElementById('calc1-redisSize').textContent = formatBytes(redisBytes);\n\n    // Totals\n    const singleTotal = E + Q_bytes + BM25 + CARDS + HYDR + RER + redisBytes;\n    const criticalComponents = E + Q_bytes + HYDR + CARDS + RER;\n    const replicatedTotal = singleTotal + (replFactor - 1) * criticalComponents;\n\n    document.getElementById('calc1-single').textContent = formatBytes(singleTotal);\n    document.getElementById('calc1-replicated').textContent = formatBytes(replicatedTotal);\n    document.getElementById('calc1-repFactor').textContent = replFactor;\n}\n\n// Calculator 2: Optimization & Fitting (corrected version)
calculateStorage2() {\n    // Read base values (uses same unit semantics as calc1)\n    const R = parseFloat(document.getElementById('calc2-repoSize').value) *\n              parseFloat(document.getElementById('calc2-repoUnit').value);\n\n    const targetBytes = parseFloat(document.getElementById('calc2-targetSize').value) *\n                        parseFloat(document.getElementById('calc2-targetUnit').value);\n\n    const C = parseFloat(document.getElementById('calc2-chunkSize').value) *\n              parseFloat(document.getElementById('calc2-chunkUnit').value);\n\n    // Guard against invalid chunk size\n    if (!C || C <= 0) {\n        console.warn("Chunk size must be > 0");\n        return;\n    }\n\n    const D = parseFloat(document.getElementById('calc2-embDim').value);\n    const bm25Pct = parseFloat(document.getElementById('calc2-bm25pct').value) / 100;\n    const cardsPct = parseFloat(document.getElementById('calc2-cardspct').value) / 100;\n\n    // Try to reuse calc1 inputs if present (keeps both calculators consistent)\n    const qdrantMultiplier = (document.getElementById('calc1-qdrant') ? parseFloat(document.getElementById('calc1-qdrant').value) : 1.5);\n    const hydrationPct = (document.getElementById('calc1-hydration') ? (parseFloat(document.getElementById('calc1-hydration').value) / 100) : 1.0);\n    const redisBytesInput = (document.getElementById('calc1-redis') ? parseFloat(document.getElementById('calc1-redis').value) * 1048576 : 390 * 1048576);\n    const replicationFactor = (document.getElementById('calc1-replication') ? parseFloat(document.getElementById('calc1-replication').value) : 3);\n\n    // Derived values\n    const N = Math.ceil(R / C);\n    const E_float32 = N * D * 4;\n    const E_float16 = E_float32 / 2;\n    const E_int8 = E_float32 / 4;\n    const E_pq8 = E_float32 / 8;\n\n    const BM25 = bm25Pct * R;\n    const CARDS = cardsPct * R;\n\n    // Update display\n    document.getElementById('calc2-chunks').textContent = formatNumber(N);\n    document.getElementById('calc2-baseStorage').textContent = formatBytes(R);\n    document.getElementById('calc2-float32').textContent = formatBytes(E_float32);\n    document.getElementById('calc2-float16').textContent = formatBytes(E_float16);\n    document.getElementById('calc2-int8').textContent = formatBytes(E_int8);\n    document.getElementById('calc2-pq8').textContent = formatBytes(E_pq8);\n\n    // Aggressive plan: PQ 8x, no local hydration (hydrate = 0)\n    const aggressiveEmbedding = E_pq8;\n    const aggressiveQ = E_pq8 * qdrantMultiplier;\n    const aggressiveRer = 0.5 * E_pq8; // reranker scaled with PQ embedding bytes\n    const aggressiveTotal = aggressiveEmbedding + aggressiveQ + BM25 + CARDS + redisBytesInput + aggressiveRer;\n    const aggressiveCritical = aggressiveEmbedding + aggressiveQ + CARDS + aggressiveRer; // no hydration\n    const aggressiveReplicated = aggressiveTotal + (replicationFactor - 1) * aggressiveCritical;\n    const aggressiveFits = aggressiveTotal <= targetBytes;\n\n    document.getElementById('calc2-aggressive-total').textContent = formatBytes(aggressiveTotal);\n    document.getElementById('calc2-aggressive-replicated').textContent = formatBytes(aggressiveReplicated);\n    document.getElementById('calc2-aggressive-plan').className = 'plan-card ' + (aggressiveFits ? 'fits' : 'exceeds');\n\n    // Conservative plan: float16 precision, full hydration\n    const conservativeEmbedding = E_float16;\n    const conservativeQ = conservativeEmbedding * qdrantMultiplier;\n    const conservativeRer = 0.5 * conservativeEmbedding;\n    const conservativeHydration = hydrationPct * R;\n    const conservativeTotal = conservativeEmbedding + conservativeQ + conservativeHydration + BM25 + CARDS + conservativeRer + redisBytesInput;\n    const conservativeCritical = conservativeEmbedding + conservativeQ + conservativeHydration + CARDS + conservativeRer;\n    const conservativeReplicated = conservativeTotal + (replicationFactor - 1) * conservativeCritical;\n    const conservativeFits = conservativeTotal <= targetBytes;\n\n    document.getElementById('calc2-conservative-total').textContent = formatBytes(conservativeTotal);\n    document.getElementById('calc2-conservative-replicated').textContent = formatBytes(conservativeReplicated);\n    document.getElementById('calc2-conservative-plan').className = 'plan-card ' + (conservativeFits ? 'fits' : 'exceeds');\n\n    // Update replication factor display\n    document.getElementById('calc2-aggRepFactor').textContent = replicationFactor;\n    document.getElementById('calc2-consRepFactor').textContent = replicationFactor;\n\n    // Update hydration info display\n    const hydrationInfoEl = document.getElementById('hydrationInfo');\n    if (hydrationInfoEl) {\n        hydrationInfoEl.textContent = Math.round(hydrationPct * 100) + '%';\n    }\n\n    // Status message\n    const statusEl = document.getElementById('calc2-status');\n    if (aggressiveFits && conservativeFits) {\n        statusEl.className = 'success';\n        statusEl.textContent = '✓ Both configurations fit within your ' + formatBytes(targetBytes) + ' limit';\n    } else if (aggressiveFits) {\n        statusEl.className = 'warning';\n        statusEl.textContent = '⚠ Only Minimal config fits. Low Latency config needs ' + formatBytes(conservativeTotal - targetBytes) + ' more storage.';\n    } else {\n        statusEl.className = 'warning';\n        statusEl.textContent = '⚠ Both exceed limit. Minimal needs ' + formatBytes(aggressiveTotal - targetBytes) + ' more. Consider larger chunks or stronger compression.';\n    }\n}\n\n// Initialize event listeners when DOM is loaded
initStorageCalculator() {\n    // Event listeners for Calculator 1\n    ['calc1-repoSize', 'calc1-repoUnit', 'calc1-chunkSize', 'calc1-chunkUnit',\n     'calc1-embDim', 'calc1-precision', 'calc1-qdrant', 'calc1-hydration',\n     'calc1-redis', 'calc1-replication'].forEach(id => {\n        const element = document.getElementById(id);\n        if (element) {\n            element.addEventListener('input', () => {\n                calculateStorage1();\n                calculateStorage2(); // Recalc calc2 when calc1 shared params change\n            });\n        }\n    });\n\n    // Event listeners for Calculator 2\n    ['calc2-repoSize', 'calc2-repoUnit', 'calc2-targetSize', 'calc2-targetUnit',\n     'calc2-chunkSize', 'calc2-chunkUnit', 'calc2-embDim', 'calc2-bm25pct',\n     'calc2-cardspct'].forEach(id => {\n        const element = document.getElementById(id);\n        if (element) {\n            element.addEventListener('input', calculateStorage2);\n        }\n    });\n\n    // Initial calculations\n    calculateStorage1();\n    calculateStorage2();\n}\n\n// Export functions for external use\nif (typeof module !== 'undefined' && module.exports) {\n    module.exports = {\n        formatBytes,\n        formatNumber,\n        calculateStorage1,\n        calculateStorage2,\n        initStorageCalculator\n    };\n}
// Storage Calculator HTML Template\n// This function generates the HTML structure for the storage calculator
getStorageCalculatorHTML() {\n    return `\n        <div class="storage-calc-wrapper">\n            <div class="storage-calc-header">\n                <h1><span class="brand">AGRO</span> Storage Calculator Suite</h1>\n                <p class="subtitle">Another Good RAG Option • Enterprise Memory Planning</p>\n                <div class="info-box">\n                    <p>\n                        <strong>Left:</strong> Calculate exact storage needs for your configuration.<br>\n                        <strong>Right:</strong> See if your data fits within a target limit using different strategies.\n                    </p>\n                </div>\n            </div>\n\n            <div class="calculators-grid">\n                <!-- Calculator 1: Comprehensive Storage Requirements -->\n                <div class="calculator">\n                    <div class="calculator-title">\n                        Storage Requirements\n                        <span class="calculator-badge">Full Stack</span>\n                    </div>\n\n                    <p style="font-size: 12px; color: #888; margin-bottom: 20px; line-height: 1.5;">\n                        Calculate total storage for your chosen configuration with all components.\n                    </p>\n\n                    <div class="input-section">\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Repository Size\n                                        <span class="tooltip" title="Total size of your data/documents to index">?</span>\n                                    </div>\n                                </label>\n                                <div class="unit-input">\n                                    <input type="number" id="calc1-repoSize" value="5" step="0.1" min="0.1" aria-label="Repository size value">\n                                    <select id="calc1-repoUnit" aria-label="Repository size unit">\n                                        <option value="1073741824" selected>GiB</option>\n                                        <option value="1099511627776">TiB</option>\n                                        <option value="1048576">MiB</option>\n                                    </select>\n                                </div>\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Chunk Size\n                                        <span class="tooltip" title="Size of text chunks for embedding. Typically 1-8 KiB">?</span>\n                                    </div>\n                                </label>\n                                <div class="unit-input">\n                                    <input type="number" id="calc1-chunkSize" value="4" step="1" min="0.001" aria-label="Chunk size value">\n                                    <select id="calc1-chunkUnit" aria-label="Chunk size unit">\n                                        <option value="1024" selected>KiB</option>\n                                        <option value="1048576">MiB</option>\n                                    </select>\n                                </div>\n                            </div>\n                        </div>\n\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Embedding Dimension\n                                        <span class="tooltip" title="Vector size: 512 (small), 768 (BERT), 1536 (OpenAI)">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc1-embDim" value="512" step="1" min="1" aria-label="Embedding dimension">\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Precision\n                                        <span class="tooltip" title="float32: full precision, float16: half size, int8: quarter size">?</span>\n                                    </div>\n                                </label>\n                                <select id="calc1-precision" aria-label="Data precision">\n                                    <option value="4" selected>float32</option>\n                                    <option value="2">float16</option>\n                                    <option value="1">int8</option>\n                                </select>\n                            </div>\n                        </div>\n\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Qdrant Overhead\n                                        <span class="tooltip" title="Vector DB index overhead. Typically 1.5x embedding size">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc1-qdrant" value="1.5" step="0.1" min="1" aria-label="Qdrant overhead multiplier">\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Hydration %\n                                        <span class="tooltip" title="% of raw data kept in RAM for instant retrieval. 0% = fetch from disk, 100% = everything in memory">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc1-hydration" value="100" step="10" min="0" max="100" aria-label="Hydration percentage">\n                            </div>\n                        </div>\n\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Redis Cache (MiB)\n                                        <span class="tooltip" title="Session/chat memory storage">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc1-redis" value="400" step="50" min="0" aria-label="Redis cache size">\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Replication Factor\n                                        <span class="tooltip" title="Number of copies for HA/scaling">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc1-replication" value="3" step="1" min="1" aria-label="Replication factor">\n                            </div>\n                        </div>\n                    </div>\n\n                    <div class="results">\n                        <div class="result-grid">\n                            <div class="result-item">\n                                <span class="result-label">Chunks</span>\n                                <span class="result-value" id="calc1-chunks">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Raw Embeddings</span>\n                                <span class="result-value" id="calc1-embeddings">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Qdrant</span>\n                                <span class="result-value" id="calc1-qdrantSize">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">BM25 Index</span>\n                                <span class="result-value" id="calc1-bm25">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Cards/Summary</span>\n                                <span class="result-value" id="calc1-cards">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Hydration</span>\n                                <span class="result-value" id="calc1-hydr">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Reranker</span>\n                                <span class="result-value" id="calc1-reranker">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Redis</span>\n                                <span class="result-value" id="calc1-redisSize">-</span>\n                            </div>\n                        </div>\n\n                        <div class="total-row">\n                            <div class="result-item">\n                                <span class="result-label">Single Instance</span>\n                                <span class="result-value" id="calc1-single">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Replicated (×<span id="calc1-repFactor">3</span>)</span>\n                                <span class="result-value" id="calc1-replicated">-</span>\n                            </div>\n                        </div>\n                    </div>\n                </div>\n\n                <!-- Calculator 2: Optimization & Fitting -->\n                <div class="calculator">\n                    <div class="calculator-title">\n                        Optimization Planner\n                        <span class="calculator-badge">Fit Analysis</span>\n                    </div>\n\n                    <p style="font-size: 12px; color: #888; margin-bottom: 20px; line-height: 1.5;">\n                        Compare two strategies: <strong>Minimal</strong> (smallest footprint, fetches data on-demand) vs <strong>Low Latency</strong> (everything in RAM for instant access).\n                    </p>\n\n                    <div class="input-section">\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Repository Size\n                                        <span class="tooltip" title="Same as left calculator - your total data">?</span>\n                                    </div>\n                                </label>\n                                <div class="unit-input">\n                                    <input type="number" id="calc2-repoSize" value="5" step="0.1" min="0.1" aria-label="Repository size value">\n                                    <select id="calc2-repoUnit" aria-label="Repository size unit">\n                                        <option value="1073741824" selected>GiB</option>\n                                        <option value="1099511627776">TiB</option>\n                                        <option value="1048576">MiB</option>\n                                    </select>\n                                </div>\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Target Limit\n                                        <span class="tooltip" title="Max storage you want to use">?</span>\n                                    </div>\n                                </label>\n                                <div class="unit-input">\n                                    <input type="number" id="calc2-targetSize" value="5" step="0.5" min="0.1" aria-label="Target storage limit">\n                                    <select id="calc2-targetUnit" aria-label="Target limit unit">\n                                        <option value="1073741824" selected>GiB</option>\n                                        <option value="1099511627776">TiB</option>\n                                    </select>\n                                </div>\n                            </div>\n                        </div>\n\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Chunk Size\n                                        <span class="tooltip" title="Smaller chunks = more vectors = more storage">?</span>\n                                    </div>\n                                </label>\n                                <div class="unit-input">\n                                    <input type="number" id="calc2-chunkSize" value="4" step="1" min="0.001" aria-label="Chunk size value">\n                                    <select id="calc2-chunkUnit" aria-label="Chunk size unit">\n                                        <option value="1024" selected>KiB</option>\n                                        <option value="1048576">MiB</option>\n                                    </select>\n                                </div>\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Embedding Dims\n                                        <span class="tooltip" title="Must match your model choice">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc2-embDim" value="512" step="1" min="1" aria-label="Embedding dimension">\n                            </div>\n                        </div>\n\n                        <div class="input-row">\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        BM25 Overhead %\n                                        <span class="tooltip" title="Text search index, typically 20% of data">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc2-bm25pct" value="20" step="5" min="0" max="100" aria-label="BM25 overhead percentage">\n                            </div>\n                            <div class="input-group">\n                                <label>\n                                    <div class="label-with-tooltip">\n                                        Cards/Summary %\n                                        <span class="tooltip" title="Metadata/summaries, typically 10% of data">?</span>\n                                    </div>\n                                </label>\n                                <input type="number" id="calc2-cardspct" value="10" step="5" min="0" max="100" aria-label="Cards/summary percentage">\n                            </div>\n                        </div>\n                    </div>\n\n                    <div class="results">\n                        <div class="result-grid">\n                            <div class="result-item">\n                                <span class="result-label">Chunks</span>\n                                <span class="result-value" id="calc2-chunks">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">Repository</span>\n                                <span class="result-value" id="calc2-baseStorage">-</span>\n                            </div>\n                        </div>\n\n                        <div class="plan-title">Embedding Size by Precision (raw vectors only)</div>\n                        <div class="result-grid">\n                            <div class="result-item">\n                                <span class="result-label">float32 (baseline)</span>\n                                <span class="result-value" id="calc2-float32">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">float16 (half size)</span>\n                                <span class="result-value" id="calc2-float16">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">int8 (quarter size)</span>\n                                <span class="result-value" id="calc2-int8">-</span>\n                            </div>\n                            <div class="result-item">\n                                <span class="result-label">\n                                    Product Quantization\n                                    <span class="tooltip" title="Aggressive compression: 8× smaller but ~5% accuracy loss" style="margin-left: 4px;">?</span>\n                                </span>\n                                <span class="result-value" id="calc2-pq8">-</span>\n                            </div>\n                        </div>\n\n                        <div class="plans-section">\n                            <div class="plan-title">Configuration Plans</div>\n                            <div class="plan-grid">\n                                <div class="plan-card" id="calc2-aggressive-plan">\n                                    <div class="plan-name">Minimal (No Hydration)</div>\n                                    <div class="plan-details" id="calc2-aggressive-details" style="line-height: 1.8;">\n                                        <strong>Includes:</strong><br>\n                                        • Product Quantized vectors<br>\n                                        • Qdrant index<br>\n                                        • BM25 search<br>\n                                        • Cards/metadata<br>\n                                        • Reranker cache<br>\n                                        • Redis<br>\n                                        <strong>Excludes:</strong><br>\n                                        • Raw data (fetched on-demand)\n                                    </div>\n                                    <div class="plan-total" id="calc2-aggressive-total">-</div>\n                                </div>\n                                <div class="plan-card" id="calc2-conservative-plan">\n                                    <div class="plan-name">Low Latency (Full Cache)</div>\n                                    <div class="plan-details" id="calc2-conservative-details" style="line-height: 1.8;">\n                                        <strong>Includes:</strong><br>\n                                        • float16 vectors<br>\n                                        • Qdrant index<br>\n                                        • BM25 search<br>\n                                        • Cards/metadata<br>\n                                        • Reranker cache<br>\n                                        • Redis<br>\n                                        • <span style="color: #ffaa00;">Data in RAM (per left hydration %)</span>\n                                    </div>\n                                    <div class="plan-total" id="calc2-conservative-total">-</div>\n                                </div>\n                            </div>\n\n                            <p style="font-size: 11px; color: #666; margin: 16px 0 8px; padding: 12px; background: #0a0a0a; border-radius: 4px; line-height: 1.5;">\n                                💡 <strong>Why the big difference?</strong> Low Latency keeps data in RAM based on hydration % from left panel (currently adding <span id="hydrationInfo">100%</span> of repo size). Minimal only stores compressed vectors and indexes, fetching actual data from disk when needed.\n                            </p>\n\n                            <div class="total-row" style="margin-top: 20px;">\n                                <div class="result-item">\n                                    <span class="result-label">Minimal × <span id="calc2-aggRepFactor">3</span> replicas</span>\n                                    <span class="result-value" id="calc2-aggressive-replicated">-</span>\n                                </div>\n                                <div class="result-item">\n                                    <span class="result-label">Low Latency × <span id="calc2-consRepFactor">3</span> replicas</span>\n                                    <span class="result-value" id="calc2-conservative-replicated">-</span>\n                                </div>\n                            </div>\n\n                            <div id="calc2-status" style="margin-top: 12px;"></div>\n                        </div>\n                    </div>\n                </div>\n            </div>\n\n            <div class="storage-calc-footer">\n                <p>AGRO (Another Good RAG Option) • Enterprise Storage Calculator v1.2</p>\n                <p>Precision calculations for vector search infrastructure</p>\n            </div>\n        </div>\n    `;\n}\n\n// Export for use in main app\nif (typeof module !== 'undefined' && module.exports) {\n    module.exports = { getStorageCalculatorHTML };\n}
// Golden Questions Manager\n// Handles CRUD operations for golden questions used in RAG evaluation\n\nlet goldenQuestions = [];\n\n// Recommended questions (baseline for this repo)\nconst RECOMMENDED_GOLDEN = [\n  { q: 'Where is hybrid retrieval implemented?', repo: 'agro', expect_paths: ['retrieval/hybrid_search.py'] },\n  { q: 'Where is keyword generation handled server-side?', repo: 'agro', expect_paths: ['server/app.py','keywords/generate'] },\n  { q: 'Where is the metadata enrichment logic for code/keywords?', repo: 'agro', expect_paths: ['metadata_enricher.py'] },\n  { q: 'Where is the indexing pipeline (BM25 and dense) implemented?', repo: 'agro', expect_paths: ['indexer/index_repo.py'] },\n  { q: 'Where is comprehensive index status computed?', repo: 'agro', expect_paths: ['server/app.py','server/index_stats.py','index/status'] },\n  { q: 'Where are semantic cards built or listed?', repo: 'agro', expect_paths: ['server/app.py','api/cards','indexer/build_cards.py'] },\n  { q: 'Where are golden questions API routes defined?', repo: 'agro', expect_paths: ['server/app.py','api/golden'] },\n  { q: 'Where is the endpoint to test a single golden question?', repo: 'agro', expect_paths: ['server/app.py','api/golden/test'] },\n  { q: 'Where are GUI assets mounted and served?', repo: 'agro', expect_paths: ['server/app.py','/gui','gui/index.html'] },\n  { q: 'Where is repository configuration (repos.json) loaded?', repo: 'agro', expect_paths: ['config_loader.py'] },\n  { q: 'Where are MCP stdio tools implemented (rag_answer, rag_search)?', repo: 'agro', expect_paths: ['server/mcp/server.py'] },\n  { q: 'Where can I list or fetch latest LangGraph traces?', repo: 'agro', expect_paths: ['server/app.py','api/traces'] }\n];\n\n// Load all golden questions\nasync function loadGoldenQuestions() {\n    try {\n        const response = await fetch('/api/golden');\n        const data = await response.json();\n        goldenQuestions = data.questions || [];\n        renderGoldenQuestions();\n    } catch (error) {\n        console.error('Failed to load golden questions:', error);\n        document.getElementById('golden-questions-content').innerHTML =\n            `<div style="color: #ff6b6b;">Error loading questions: ${error.message}</div>`;\n    }\n}\n\n// Render questions list
renderGoldenQuestions() {\n    const container = document.getElementById('golden-questions-content');\n\n    if (goldenQuestions.length === 0) {\n        container.innerHTML = `\n            <div style="text-align: center; padding: 24px; color: #666;">\n                <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" style="opacity: 0.3; margin-bottom: 12px;">\n                    <circle cx="12" cy="12" r="10"></circle>\n                    <line x1="12" y1="16" x2="12" y2="12"></line>\n                    <line x1="12" y1="8" x2="12.01" y2="8"></line>\n                </svg>\n                <div>No golden questions yet. Add one above!</div>\n            </div>\n        `;\n        return;\n    }\n\n    const html = goldenQuestions.map((q, index) => `\n        <div class="golden-question-item" data-index="${index}" style="background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 4px; padding: 12px; margin-bottom: 10px;">\n            <div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 8px;">\n                <div style="flex: 1;">\n                    <div style="font-weight: 600; color: #fff; margin-bottom: 4px; word-break: break-word;">${escapeHtml(q.q)}</div>\n                    <div style="font-size: 11px; color: #888;">\n                        <span style="background: #1a1a1a; padding: 2px 6px; border-radius: 3px; margin-right: 6px;">${q.repo}</span>\n                        ${(q.expect_paths || []).map(p => `<span style="color: #00ff88;">${escapeHtml(p)}</span>`).join(', ')}\n                    </div>\n                </div>\n                <div style="display: flex; gap: 6px; margin-left: 12px;">\n                    <button class="btn-test-question" data-index="${index}" style="background: #1a1a1a; color: #5b9dff; border: 1px solid #5b9dff; padding: 4px 8px; border-radius: 3px; font-size: 11px; cursor: pointer; white-space: nowrap;" title="Test this question">Test</button>\n                    <button class="btn-edit-question" data-index="${index}" style="background: #1a1a1a; color: #ff9b5e; border: 1px solid #ff9b5e; padding: 4px 8px; border-radius: 3px; font-size: 11px; cursor: pointer;" title="Edit">Edit</button>\n                    <button class="btn-delete-question" data-index="${index}" style="background: #1a1a1a; color: #ff6b6b; border: 1px solid #ff6b6b; padding: 4px 8px; border-radius: 3px; font-size: 11px; cursor: pointer;" title="Delete">✗</button>\n                </div>\n            </div>\n            <div class="question-test-results" id="test-results-${index}" style="display: none; margin-top: 8px; padding-top: 8px; border-top: 1px solid #2a2a2a;"></div>\n        </div>\n    `).join('');\n\n    container.innerHTML = html;\n\n    // Attach event listeners\n    document.querySelectorAll('.btn-test-question').forEach(btn => {\n        btn.addEventListener('click', (e) => testQuestion(parseInt(e.target.dataset.index)));\n    });\n    document.querySelectorAll('.btn-edit-question').forEach(btn => {\n        btn.addEventListener('click', (e) => editQuestion(parseInt(e.target.dataset.index)));\n    });\n    document.querySelectorAll('.btn-delete-question').forEach(btn => {\n        btn.addEventListener('click', (e) => deleteQuestion(parseInt(e.target.dataset.index)));\n    });\n}\n\n// Add new question\nasync function addGoldenQuestion() {\n    const q = document.getElementById('golden-new-q').value.trim();\n    const repo = document.getElementById('golden-new-repo').value;\n    const pathsStr = document.getElementById('golden-new-paths').value.trim();\n\n    if (!q) {\n        alert('Please enter a question');\n        return;\n    }\n\n    const expect_paths = pathsStr ? pathsStr.split(',').map(p => p.trim()).filter(p => p) : [];\n\n    try {\n        const response = await fetch('/api/golden', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ q, repo, expect_paths })\n        });\n\n        const data = await response.json();\n        if (data.ok) {\n            // Clear form\n            document.getElementById('golden-new-q').value = '';\n            document.getElementById('golden-new-paths').value = '';\n\n            // Reload questions\n            await loadGoldenQuestions();\n\n            showToast('Question added successfully', 'success');\n        } else {\n            throw new Error(data.error || 'Failed to add question');\n        }\n    } catch (error) {\n        console.error('Failed to add question:', error);\n        alert('Failed to add question: ' + error.message);\n    }\n}\n\n// Test a single question\nasync function testQuestion(index) {\n    const q = goldenQuestions[index];\n    const resultsDiv = document.getElementById(`test-results-${index}`);\n    resultsDiv.style.display = 'block';\n    resultsDiv.innerHTML = '<div style="color: #888; font-size: 12px;">Testing...</div>';\n\n    try {\n        const response = await fetch('/api/golden/test', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({\n                q: q.q,\n                repo: q.repo,\n                expect_paths: q.expect_paths,\n                final_k: 5,\n                use_multi: true\n            })\n        });\n\n        const data = await response.json();\n\n        const top1Color = data.top1_hit ? '#00ff88' : '#ff6b6b';\n        const topkColor = data.topk_hit ? '#00ff88' : '#ff9b5e';\n\n        let html = `\n            <div style="font-size: 12px;">\n                <div style="margin-bottom: 8px;">\n                    <span style="color: ${top1Color}; font-weight: 600;">${data.top1_hit ? '✓' : '✗'} Top-1</span>\n                    <span style="margin-left: 12px; color: ${topkColor}; font-weight: 600;">${data.topk_hit ? '✓' : '✗'} Top-K</span>\n                </div>\n                <div style="font-size: 11px; color: #aaa;">\n                    <div style="margin-bottom: 4px;"><strong>Expected:</strong> ${q.expect_paths.join(', ')}</div>\n                    <div style="margin-bottom: 4px;"><strong>Top Result:</strong></div>\n        `;\n\n        if (data.all_results && data.all_results.length > 0) {\n            data.all_results.slice(0, 3).forEach((r, i) => {\n                const color = i === 0 && data.top1_hit ? '#00ff88' : '#aaa';\n                html += `\n                    <div style="color: ${color}; font-family: 'SF Mono', monospace; font-size: 10px; margin-left: 8px; margin-top: 2px;">\n                        ${r.file_path}:${r.start_line} (score: ${r.rerank_score.toFixed(3)})\n                    </div>\n                `;\n            });\n        } else {\n            html += '<div style="margin-left: 8px; color: #ff6b6b;">No results found</div>';\n        }\n\n        html += `\n                </div>\n            </div>\n        `;\n\n        resultsDiv.innerHTML = html;\n    } catch (error) {\n        console.error('Test failed:', error);\n        resultsDiv.innerHTML = `<div style="color: #ff6b6b; font-size: 12px;">Error: ${error.message}</div>`;\n    }\n}\n\n// Edit question (inline)
editQuestion(index) {\n    const q = goldenQuestions[index];\n    const item = document.querySelector(`[data-index="${index}"]`);\n\n    // Replace with edit form\n    item.innerHTML = `\n        <div style="background: #111; padding: 12px; border-radius: 4px;">\n            <div style="margin-bottom: 8px;">\n                <label style="font-size: 11px; color: #888; display: block; margin-bottom: 4px;">Question</label>\n                <textarea id="edit-q-${index}" style="width: 100%; background: #0a0a0a; border: 1px solid #333; color: #fff; padding: 8px; border-radius: 3px; font-size: 13px; min-height: 60px;">${escapeHtml(q.q)}</textarea>\n            </div>\n            <div style="display: grid; grid-template-columns: 1fr 2fr; gap: 8px; margin-bottom: 8px;">\n                <div>\n                    <label style="font-size: 11px; color: #888; display: block; margin-bottom: 4px;">Repo</label>\n                    <select id="edit-repo-${index}" style="width: 100%; background: #0a0a0a; border: 1px solid #333; color: #fff; padding: 6px; border-radius: 3px;">\n                        <option value="agro" ${q.repo === 'agro' ? 'selected' : ''}>agro</option>\n                    </select>\n                </div>\n                <div>\n                    <label style="font-size: 11px; color: #888; display: block; margin-bottom: 4px;">Expected Paths (comma-separated)</label>\n                    <input type="text" id="edit-paths-${index}" value="${(q.expect_paths || []).join(', ')}" style="width: 100%; background: #0a0a0a; border: 1px solid #333; color: #fff; padding: 6px; border-radius: 3px; font-size: 12px;">\n                </div>\n            </div>\n            <div style="display: flex; gap: 6px;">\n                <button onclick="saveEditQuestion(${index})" style="flex: 1; background: #00ff88; color: #000; border: none; padding: 8px; border-radius: 3px; font-size: 12px; font-weight: 600; cursor: pointer;">Save</button>\n                <button onclick="loadGoldenQuestions()" style="flex: 1; background: #1a1a1a; color: #aaa; border: 1px solid #333; padding: 8px; border-radius: 3px; font-size: 12px; cursor: pointer;">Cancel</button>\n            </div>\n        </div>\n    `;\n}\n\n// Save edited question\nasync function saveEditQuestion(index) {\n    const q = document.getElementById(`edit-q-${index}`).value.trim();\n    const repo = document.getElementById(`edit-repo-${index}`).value;\n    const pathsStr = document.getElementById(`edit-paths-${index}`).value.trim();\n\n    if (!q) {\n        alert('Question cannot be empty');\n        return;\n    }\n\n    const expect_paths = pathsStr ? pathsStr.split(',').map(p => p.trim()).filter(p => p) : [];\n\n    try {\n        const response = await fetch(`/api/golden/${index}`, {\n            method: 'PUT',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ q, repo, expect_paths })\n        });\n\n        const data = await response.json();\n        if (data.ok) {\n            await loadGoldenQuestions();\n            showToast('Question updated', 'success');\n        } else {\n            throw new Error(data.error || 'Failed to update');\n        }\n    } catch (error) {\n        console.error('Failed to update question:', error);\n        alert('Failed to update: ' + error.message);\n    }\n}\n\n// Delete question\nasync function deleteQuestion(index) {\n    if (!confirm('Delete this question?')) return;\n\n    try {\n        const response = await fetch(`/api/golden/${index}`, {\n            method: 'DELETE'\n        });\n\n        const data = await response.json();\n        if (data.ok) {\n            await loadGoldenQuestions();\n            showToast('Question deleted', 'success');\n        } else {\n            throw new Error('Failed to delete');\n        }\n    } catch (error) {\n        console.error('Failed to delete question:', error);\n        alert('Failed to delete: ' + error.message);\n    }\n}\n\n// Export questions as JSON
exportGoldenQuestions() {\n    const dataStr = JSON.stringify(goldenQuestions, null, 2);\n    const blob = new Blob([dataStr], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = 'golden_questions_export.json';\n    a.click();\n    URL.revokeObjectURL(url);\n    showToast('Questions exported', 'success');\n}\n\n// Helper: escape HTMLescapeHtml(text) {\n    const div = document.createElement('div');\n    div.textContent = text;\n    return div.innerHTML;\n}\n\n// Helper: show toast notification
showToast(message, type = 'info') {\n    // Simple toast - you can enhance this\n    const color = type === 'success' ? '#00ff88' : type === 'error' ? '#ff6b6b' : '#5b9dff';\n    const toast = document.createElement('div');\n    toast.style.cssText = `\n        position: fixed;\n        top: 80px;\n        right: 24px;\n        background: #111;\n        color: ${color};\n        border: 1px solid ${color};\n        padding: 12px 20px;\n        border-radius: 6px;\n        font-size: 13px;\n        z-index: 10000;\n        box-shadow: 0 4px 12px rgba(0,0,0,0.5);\n    `;\n    toast.textContent = message;\n    document.body.appendChild(toast);\n    setTimeout(() => toast.remove(), 3000);\n}\n\n// Initialize when DOM is ready\nif (typeof window !== 'undefined') {\n    // Event listeners\n    window.addEventListener('DOMContentLoaded', () => {\n        const btnAdd = document.getElementById('btn-golden-add');\n        const btnRefresh = document.getElementById('btn-golden-refresh');\n        const btnExport = document.getElementById('btn-golden-export');\n        const btnTestNew = document.getElementById('btn-golden-test-new');\n\n    if (btnAdd) btnAdd.addEventListener('click', addGoldenQuestion);\n    if (btnRefresh) btnRefresh.addEventListener('click', loadGoldenQuestions);\n    if (btnExport) btnExport.addEventListener('click', exportGoldenQuestions);\n    if (btnTestNew) {\n            btnTestNew.addEventListener('click', async () => {\n                const q = document.getElementById('golden-new-q').value.trim();\n                const repo = document.getElementById('golden-new-repo').value;\n                const pathsStr = document.getElementById('golden-new-paths').value.trim();\n\n                if (!q) {\n                    alert('Please enter a question');\n                    return;\n                }\n\n                const expect_paths = pathsStr ? pathsStr.split(',').map(p => p.trim()).filter(p => p) : [];\n\n                try {\n                    const response = await fetch('/api/golden/test', {\n                        method: 'POST',\n                        headers: { 'Content-Type': 'application/json' },\n                        body: JSON.stringify({ q, repo, expect_paths, final_k: 5, use_multi: true })\n                    });\n\n                    const data = await response.json();\n                    const result = data.top1_hit ? '✓ Top-1 Hit!' : data.topk_hit ? '✓ Top-K Hit' : '✗ Miss';\n                    const color = data.top1_hit ? '#00ff88' : data.topk_hit ? '#ff9b5e' : '#ff6b6b';\n                    showToast(result, data.top1_hit ? 'success' : 'error');\n                    console.log('Test result:', data);\n                } catch (error) {\n                    showToast('Test failed: ' + error.message, 'error');\n                }\n            });\n        }\n\n        const btnLoad = document.getElementById('btn-golden-load-recommended');\n        if (btnLoad) btnLoad.addEventListener('click', bulkAddRecommended);\n        const btnRunAll = document.getElementById('btn-golden-run-tests');\n        if (btnRunAll) btnRunAll.addEventListener('click', runAllGoldenTests);\n\n        // Auto-load on Tools tab activation\n        const toolsTab = document.querySelector('[data-tab="tools"]');\n        if (toolsTab) {\n            toolsTab.addEventListener('click', () => {\n                setTimeout(loadGoldenQuestions, 100);\n            });\n        }\n    });\n}\n\n// Export for use in edit inline function\nif (typeof window !== 'undefined') {\n    window.saveEditQuestion = saveEditQuestion;\n    window.bulkAddRecommended = bulkAddRecommended;\n    window.runAllGoldenTests = runAllGoldenTests;\n}\n\n// ---- Bulk helpers ----\nasync function bulkAddRecommended() {\n    try {\n        let added = 0;\n        for (const q of RECOMMENDED_GOLDEN) {\n            const r = await fetch('/api/golden', {\n                method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(q)\n            });\n            const d = await r.json();\n            if (d && d.ok) added += 1;\n        }\n        await loadGoldenQuestions();\n        showToast(`Loaded ${added} recommended questions`, added ? 'success' : 'error');\n    } catch (e) {\n        console.error('bulkAddRecommended failed', e);\n        showToast('Failed to load recommended questions: ' + e.message, 'error');\n    }\n}\n\nasync function runAllGoldenTests() {\n    try {\n        const btn = document.getElementById('btn-golden-run-tests');\n        if (btn) { btn.disabled = true; btn.style.opacity = '0.7'; btn.textContent = 'Running…'; }\n        if (typeof showStatus === 'function') showStatus('Running all golden questions…', 'loading');\n        if (!goldenQuestions.length) await loadGoldenQuestions();\n        let top1 = 0, topk = 0, total = goldenQuestions.length;\n        for (let i = 0; i < goldenQuestions.length; i++) {\n            const q = goldenQuestions[i];\n            const resp = await fetch('/api/golden/test', {\n                method: 'POST', headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ q: q.q, repo: q.repo, expect_paths: q.expect_paths || [], final_k: 5, use_multi: true })\n            });\n            const data = await resp.json();\n            if (data.top1_hit) top1 += 1; else if (data.topk_hit) topk += 1;\n            // Paint per-question result under item\n            const slot = document.getElementById(`test-results-${i}`);\n            if (slot) {\n                const color = data.top1_hit ? '#00ff88' : data.topk_hit ? '#ff9b5e' : '#ff6b6b';\n                slot.style.display = 'block';\n                slot.innerHTML = `\n                    <div style="font-size:12px;color:${color};">\n                        ${data.top1_hit ? '✓ Top‑1 Hit' : data.topk_hit ? '✓ Top‑K Hit' : '✗ Miss'}\n                        <span style="color:#666"> — ${escapeHtml(q.q)}</span>\n                    </div>\n                `;\n            }\n        }\n        const msg = `Golden tests: Top‑1 ${top1}/${total}, Top‑K ${topk}/${total}`;\n        showToast(msg, 'success');\n        if (typeof showStatus === 'function') showStatus(msg, 'success');\n    } catch (e) {\n        console.error('runAllGoldenTests failed', e);\n        showToast('Run tests failed: ' + e.message, 'error');\n    } finally {\n        const btn = document.getElementById('btn-golden-run-tests');\n        if (btn) { btn.disabled = false; btn.style.opacity = ''; btn.textContent = 'Run All Tests'; }\n    }\n}\n\n// Defensive binding via event delegation (in case direct bind missed)\ndocument.addEventListener('click', (e) => {\n    const run = e.target && (e.target.id === 'btn-golden-run-tests' || (e.target.closest && e.target.closest('#btn-golden-run-tests')));\n    const load = e.target && (e.target.id === 'btn-golden-load-recommended' || (e.target.closest && e.target.closest('#btn-golden-load-recommended')));\n    if (run) { e.preventDefault(); runAllGoldenTests(); }\n    if (load) { e.preventDefault(); bulkAddRecommended(); }\n}, true);
// Evaluation Runner\n// Handles running full evaluation suite and displaying results\n\nlet evalResults = null;\nlet evalPollingInterval = null;\n\n// Run full evaluation\nasync function runEvaluation() {\n    const useMulti = document.getElementById('eval-use-multi').value === '1';\n    const finalK = parseInt(document.getElementById('eval-final-k').value) || 5;\n\n    const btn = document.getElementById('btn-eval-run');\n    btn.disabled = true;\n    btn.textContent = 'Starting...';\n\n    try {\n        const response = await fetch('/api/eval/run', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ use_multi: useMulti, final_k: finalK })\n        });\n\n        const data = await response.json();\n\n        if (data.ok) {\n            showEvalProgress();\n            startPolling();\n        } else {\n            throw new Error(data.error || 'Failed to start evaluation');\n        }\n    } catch (error) {\n        console.error('Failed to start evaluation:', error);\n        alert('Failed to start evaluation: ' + error.message);\n        btn.disabled = false;\n        btn.textContent = 'Run Full Evaluation';\n    }\n}\n\n// Show progress UI
showEvalProgress() {\n    document.getElementById('eval-progress').style.display = 'block';\n    document.getElementById('eval-results').style.display = 'none';\n    document.getElementById('eval-comparison').style.display = 'none';\n    document.getElementById('eval-status').textContent = 'Initializing...';\n    document.getElementById('eval-progress-bar').style.width = '0%';\n}\n\n// Start polling for status
startPolling() {\n    if (evalPollingInterval) clearInterval(evalPollingInterval);\n\n    evalPollingInterval = setInterval(async () => {\n        try {\n            const response = await fetch('/api/eval/status');\n            const status = await response.json();\n\n            if (status.running) {\n                const progress = status.total > 0 ? (status.progress / status.total * 100) : 10;\n                document.getElementById('eval-progress-bar').style.width = progress + '%';\n                document.getElementById('eval-status').textContent =\n                    `Running... ${status.progress}/${status.total} questions`;\n            } else {\n                // Evaluation finished\n                clearInterval(evalPollingInterval);\n                evalPollingInterval = null;\n                await loadEvalResults();\n            }\n        } catch (error) {\n            console.error('Failed to poll status:', error);\n        }\n    }, 1000);\n}\n\n// Load evaluation results\nasync function loadEvalResults() {\n    try {\n        const response = await fetch('/api/eval/results');\n        const data = await response.json();\n\n        if (data.error) {\n            throw new Error(data.error);\n        }\n\n        evalResults = data;\n        renderEvalResults();\n\n        // Re-enable button\n        const btn = document.getElementById('btn-eval-run');\n        btn.disabled = false;\n        btn.textContent = 'Run Full Evaluation';\n\n        // Hide progress\n        document.getElementById('eval-progress').style.display = 'none';\n    } catch (error) {\n        console.error('Failed to load results:', error);\n        document.getElementById('eval-status').textContent = 'Error: ' + error.message;\n        document.getElementById('eval-status').style.color = '#ff6b6b';\n        const btn = document.getElementById('btn-eval-run');\n        btn.disabled = false;\n        btn.textContent = 'Run Full Evaluation';\n    }\n}\n\n// Render evaluation results
renderEvalResults() {\n    if (!evalResults) return;\n\n    // Show results section\n    document.getElementById('eval-results').style.display = 'block';\n\n    // Overall metrics\n    const top1Pct = (evalResults.top1_accuracy * 100).toFixed(1) + '%';\n    const topkPct = (evalResults.topk_accuracy * 100).toFixed(1) + '%';\n    const duration = evalResults.duration_secs + 's';\n\n    document.getElementById('eval-top1-acc').textContent = top1Pct;\n    document.getElementById('eval-topk-acc').textContent = topkPct;\n    document.getElementById('eval-duration').textContent = duration;\n\n    // Per-question details\n    const detailsContainer = document.getElementById('eval-details');\n    const results = evalResults.results || [];\n    const failures = results.filter(r => !r.topk_hit);\n    const passes = results.filter(r => r.topk_hit);\n\n    let html = `\n        <div style="margin-bottom: 12px;">\n            <div style="font-size: 12px; color: #888; margin-bottom: 8px;">\n                <span style="color: #00ff88;">✓ ${passes.length} passed</span>\n                <span style="margin-left: 16px; color: #ff6b6b;">✗ ${failures.length} failed</span>\n            </div>\n        </div>\n    `;\n\n    // Show failures first\n    if (failures.length > 0) {\n        html += '<div style="margin-bottom: 16px;"><div style="font-size: 12px; font-weight: 600; color: #ff6b6b; margin-bottom: 8px;">FAILURES</div>';\n        failures.forEach((r, i) => {\n            html += renderQuestionResult(r, true);\n        });\n        html += '</div>';\n    }\n\n    // Show passes (collapsed by default)\n    if (passes.length > 0) {\n        html += `\n            <details style="margin-top: 12px;">\n                <summary style="font-size: 12px; font-weight: 600; color: #00ff88; margin-bottom: 8px; cursor: pointer;">\n                    PASSES (${passes.length})\n                </summary>\n                <div style="margin-top: 8px;">\n        `;\n        passes.forEach((r, i) => {\n            html += renderQuestionResult(r, false);\n        });\n        html += '</div></details>';\n    }\n\n    detailsContainer.innerHTML = html;\n}\n\n// Render individual question result
renderQuestionResult(r, isFailure) {\n    const top1Color = r.top1_hit ? '#00ff88' : '#ff6b6b';\n    const topkColor = r.topk_hit ? '#00ff88' : '#ff9b5e';\n\n    return `\n        <div style="background: #0a0a0a; border-left: 3px solid ${isFailure ? '#ff6b6b' : '#00ff88'}; padding: 10px; margin-bottom: 8px; border-radius: 4px;">\n            <div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 6px;">\n                <div style="flex: 1; font-size: 12px; color: #fff; font-weight: 500;">${escapeHtml(r.question)}</div>\n                <div style="font-size: 11px; margin-left: 12px;">\n                    <span style="background: #1a1a1a; padding: 2px 6px; border-radius: 3px;">${r.repo}</span>\n                </div>\n            </div>\n            <div style="font-size: 11px; color: #888; margin-bottom: 4px;">\n                <strong>Expected:</strong> ${(r.expect_paths || []).join(', ')}\n            </div>\n            <div style="font-size: 11px;">\n                <span style="color: ${top1Color}; font-weight: 600;">${r.top1_hit ? '✓' : '✗'} Top-1</span>\n                <span style="margin-left: 12px; color: ${topkColor}; font-weight: 600;">${r.topk_hit ? '✓' : '✗'} Top-K</span>\n            </div>\n            <div style="margin-top: 6px; font-size: 10px; font-family: 'SF Mono', monospace; color: #666;">\n                ${(r.top_paths || []).slice(0, 3).map((p, i) => {\n                    const match = (r.expect_paths || []).some(exp => p.includes(exp));\n                    const color = match ? '#00ff88' : '#666';\n                    return `<div style="color: ${color};">${i + 1}. ${escapeHtml(p)}</div>`;\n                }).join('')}\n            </div>\n        </div>\n    `;\n}\n\n// Save baseline\nasync function saveBaseline() {\n    if (!evalResults) {\n        alert('No evaluation results to save');\n        return;\n    }\n\n    try {\n        const response = await fetch('/api/eval/baseline/save', {\n            method: 'POST'\n        });\n\n        const data = await response.json();\n        if (data.ok) {\n            showToast('Baseline saved successfully', 'success');\n        } else {\n            throw new Error('Failed to save baseline');\n        }\n    } catch (error) {\n        console.error('Failed to save baseline:', error);\n        alert('Failed to save baseline: ' + error.message);\n    }\n}\n\n// Compare with baseline\nasync function compareWithBaseline() {\n    if (!evalResults) {\n        alert('No current evaluation results');\n        return;\n    }\n\n    try {\n        const response = await fetch('/api/eval/baseline/compare');\n        const data = await response.json();\n\n        if (!data.ok) {\n            throw new Error(data.message || 'No baseline found');\n        }\n\n        renderComparison(data);\n    } catch (error) {\n        console.error('Failed to compare:', error);\n        alert(error.message);\n    }\n}\n\n// Render comparison results
renderComparison(data) {\n    const container = document.getElementById('eval-comparison');\n    container.style.display = 'block';\n\n    const deltaTop1 = data.delta.top1;\n    const deltaTopk = data.delta.topk;\n    const deltaTop1Pct = (deltaTop1 * 100).toFixed(1) + '%';\n    const deltaTopkPct = (deltaTopk * 100).toFixed(1) + '%';\n\n    const top1Icon = deltaTop1 >= 0 ? '✓' : '✗';\n    const topkIcon = deltaTopk >= 0 ? '✓' : '✗';\n    const top1Color = deltaTop1 >= 0 ? '#00ff88' : '#ff6b6b';\n    const topkColor = deltaTopk >= 0 ? '#00ff88' : '#ff6b6b';\n\n    let html = `\n        <div style="background: #0f0f0f; border: 1px solid #2a2a2a; border-radius: 6px; padding: 16px;">\n            <h4 style="font-size: 14px; color: #b794f6; margin-bottom: 12px; text-transform: uppercase; letter-spacing: 0.5px;">\n                Baseline Comparison\n            </h4>\n            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; margin-bottom: 16px;">\n                <div style="background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 4px; padding: 12px;">\n                    <div style="font-size: 11px; color: #888; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 4px;">Top-1 Accuracy</div>\n                    <div style="font-size: 14px; color: #aaa; margin-bottom: 4px;">\n                        Baseline: ${(data.baseline.top1_accuracy * 100).toFixed(1)}%\n                    </div>\n                    <div style="font-size: 14px; color: #fff; margin-bottom: 4px;">\n                        Current: ${(data.current.top1_accuracy * 100).toFixed(1)}%\n                    </div>\n                    <div style="font-size: 16px; color: ${top1Color}; font-weight: 700;">\n                        ${top1Icon} ${deltaTop1 >= 0 ? '+' : ''}${deltaTop1Pct}\n                    </div>\n                </div>\n                <div style="background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 4px; padding: 12px;">\n                    <div style="font-size: 11px; color: #888; text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: 4px;">Top-K Accuracy</div>\n                    <div style="font-size: 14px; color: #aaa; margin-bottom: 4px;">\n                        Baseline: ${(data.baseline.topk_accuracy * 100).toFixed(1)}%\n                    </div>\n                    <div style="font-size: 14px; color: #fff; margin-bottom: 4px;">\n                        Current: ${(data.current.topk_accuracy * 100).toFixed(1)}%\n                    </div>\n                    <div style="font-size: 16px; color: ${topkColor}; font-weight: 700;">\n                        ${topkIcon} ${deltaTopk >= 0 ? '+' : ''}${deltaTopkPct}\n                    </div>\n                </div>\n            </div>\n    `;\n\n    if (data.regressions && data.regressions.length > 0) {\n        html += `\n            <div style="background: #1a0000; border: 1px solid #ff6b6b; border-radius: 4px; padding: 12px; margin-bottom: 12px;">\n                <div style="font-size: 12px; font-weight: 600; color: #ff6b6b; margin-bottom: 8px;">\n                    ⚠ REGRESSIONS (${data.regressions.length})\n                </div>\n                ${data.regressions.map(r => `\n                    <div style="font-size: 11px; color: #ffaaaa; margin-bottom: 4px;">\n                        <span style="background: #2a1a1a; padding: 2px 6px; border-radius: 2px; margin-right: 6px;">${r.repo}</span>\n                        ${escapeHtml(r.question)}\n                    </div>\n                `).join('')}\n            </div>\n        `;\n    }\n\n    if (data.improvements && data.improvements.length > 0) {\n        html += `\n            <div style="background: #001a00; border: 1px solid #00ff88; border-radius: 4px; padding: 12px;">\n                <div style="font-size: 12px; font-weight: 600; color: #00ff88; margin-bottom: 8px;">\n                    ✓ IMPROVEMENTS (${data.improvements.length})\n                </div>\n                ${data.improvements.map(r => `\n                    <div style="font-size: 11px; color: #aaffaa; margin-bottom: 4px;">\n                        <span style="background: #1a2a1a; padding: 2px 6px; border-radius: 2px; margin-right: 6px;">${r.repo}</span>\n                        ${escapeHtml(r.question)}\n                    </div>\n                `).join('')}\n            </div>\n        `;\n    }\n\n    if (!data.has_regressions) {\n        html += `\n            <div style="background: #001a00; border: 1px solid #00ff88; border-radius: 4px; padding: 12px; text-align: center; color: #00ff88; font-weight: 600;">\n                ✓ No significant regressions detected\n            </div>\n        `;\n    }\n\n    html += '</div>';\n    container.innerHTML = html;\n}\n\n// Export results
exportEvalResults() {\n    if (!evalResults) {\n        alert('No results to export');\n        return;\n    }\n\n    const dataStr = JSON.stringify(evalResults, null, 2);\n    const blob = new Blob([dataStr], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    const timestamp = new Date().toISOString().replace(/:/g, '-').substring(0, 19);\n    a.download = `eval_results_${timestamp}.json`;\n    a.click();\n    URL.revokeObjectURL(url);\n    showToast('Results exported', 'success');\n}\n\n// Helper functionsescapeHtml(text) {\n    const div = document.createElement('div');\n    div.textContent = text;\n    return div.innerHTML;\n}
showToast(message, type = 'info') {\n    const color = type === 'success' ? '#00ff88' : type === 'error' ? '#ff6b6b' : '#5b9dff';\n    const toast = document.createElement('div');\n    toast.style.cssText = `\n        position: fixed;\n        top: 80px;\n        right: 24px;\n        background: #111;\n        color: ${color};\n        border: 1px solid ${color};\n        padding: 12px 20px;\n        border-radius: 6px;\n        font-size: 13px;\n        z-index: 10000;\n        box-shadow: 0 4px 12px rgba(0,0,0,0.5);\n    `;\n    toast.textContent = message;\n    document.body.appendChild(toast);\n    setTimeout(() => toast.remove(), 3000);\n}\n\n// Initialize\nif (typeof window !== 'undefined') {\n    window.addEventListener('DOMContentLoaded', () => {\n        const btnRun = document.getElementById('btn-eval-run');\n        const btnSaveBaseline = document.getElementById('btn-eval-save-baseline');\n        const btnCompare = document.getElementById('btn-eval-compare');\n        const btnExport = document.getElementById('btn-eval-export');\n\n        if (btnRun) btnRun.addEventListener('click', runEvaluation);\n        if (btnSaveBaseline) btnSaveBaseline.addEventListener('click', saveBaseline);\n        if (btnCompare) btnCompare.addEventListener('click', compareWithBaseline);\n        if (btnExport) btnExport.addEventListener('click', exportEvalResults);\n    });\n}
import os\nimport json\nfrom typing import Dict, Iterator\nfrom dotenv import load_dotenv\nfrom server.env_model import generate_text\nfrom common.config_loader import out_dir\n\nload_dotenv()\nREPO = os.getenv('REPO','project').strip()\nMAX_CHUNKS = int(os.getenv('CARDS_MAX','0') or '10')\nBASE = out_dir(REPO)\nCHUNKS = os.path.join(BASE, 'chunks.jsonl')\nCARDS = os.path.join(BASE, 'cards.jsonl')\nCARDS_TXT = os.path.join(BASE, 'cards.txt')\nINDEX_DIR = os.path.join(BASE, 'bm25_cards')\n\nPROMPT = (\n    "Summarize this code chunk for retrieval as a JSON object with keys: "\n    "symbols (array of names: functions/classes/components/routes), purpose (short sentence), "\n    "routes (array of route paths if any). Respond with only the JSON.\n\n"\n)\niter_chunks() -> Iterator[Dict]:\n    with open(CHUNKS, 'r', encoding='utf-8') as f:\n        for line in f:\n            o = json.loads(line)\n            yield o
main() -> None:\n    os.makedirs(BASE, exist_ok=True)\n    n = 0\n    with open(CARDS, 'w', encoding='utf-8') as out_json, open(CARDS_TXT, 'w', encoding='utf-8') as out_txt:\n        for ch in iter_chunks():\n            code = ch.get('code','')\n            fp = ch.get('file_path','')\n            snippet = code[:2000]\n            msg = PROMPT + snippet\n            try:\n                text, _ = generate_text(user_input=msg, system_instructions=None, reasoning_effort=None, response_format={"type": "json_object"})\n                content = (text or '').strip()\n                card: Dict = json.loads(content) if content else {"symbols": [], "purpose": "", "routes": []}\n            except Exception:\n                card = {"symbols": [], "purpose": "", "routes": []}\n            card['file_path'] = fp\n            card['id'] = ch.get('id')\n            out_json.write(json.dumps(card, ensure_ascii=False) + '\n')\n            text_out = ' '.join(card.get('symbols', [])) + '\n' + card.get('purpose','') + '\n' + ' '.join(card.get('routes', [])) + '\n' + fp\n            out_txt.write(text_out.replace('\n',' ') + '\n')\n            n += 1\n            if MAX_CHUNKS and n >= MAX_CHUNKS:\n                break\n    try:\n        import bm25s  # type: ignore\n        from bm25s.tokenization import Tokenizer  # type: ignore\n        from Stemmer import Stemmer  # type: ignore\n        stemmer = Stemmer('english')\n        tok = Tokenizer(stemmer=stemmer, stopwords='en')\n        with open(CARDS_TXT,'r',encoding='utf-8') as f:\n            docs = [line.strip() for line in f if line.strip()]\n        tokens = tok.tokenize(docs)\n        retriever = bm25s.BM25(method='lucene', k1=1.2, b=0.65)\n        retriever.index(tokens)\n        try:\n            retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}\n        except Exception:\n            pass\n        os.makedirs(INDEX_DIR, exist_ok=True)\n        retriever.save(INDEX_DIR, corpus=docs)\n        tok.save_vocab(save_dir=INDEX_DIR)\n        tok.save_stopwords(save_dir=INDEX_DIR)\n        print(f"Built cards BM25 index with {len(docs)} docs at {INDEX_DIR}")\n    except Exception as e:\n        print('BM25 build failed:', e)\n\nif __name__ == '__main__':\n    main()
"""Indexer package (index building and cards).\n\nRoot-level shims keep backward compatibility for commands like\n`python index_repo.py` while the canonical modules live here.\n"""
import os\nimport json\nimport hashlib\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nfrom common.config_loader import get_repo_paths, out_dir\nfrom common.paths import data_dir\nfrom retrieval.ast_chunker import lang_from_path, collect_files, chunk_code\nimport bm25s  # type: ignore\nfrom bm25s.tokenization import Tokenizer  # type: ignore\nfrom Stemmer import Stemmer  # type: ignore\nfrom qdrant_client import QdrantClient, models\nimport uuid\nfrom openai import OpenAI\nfrom retrieval.embed_cache import EmbeddingCache\nimport tiktoken\nfrom sentence_transformers import SentenceTransformer\nimport fnmatch\nimport pathlib\nimport common.qdrant_utils as qdrant_recreate_fallback  # make recreate_collection 404-safe\nfrom datetime import datetime\n\n# --- global safe filters (avoid indexing junk) ---\nfrom common.filtering import _prune_dirs_in_place, _should_index_file, PRUNE_DIRS\n\n# Patch os.walk to prune noisy dirs and skip junk file types\n_os_walk = os.walk
_filtered_os_walk(top, *args, **kwargs):\n    for root, dirs, files in _os_walk(top, *args, **kwargs):\n        _prune_dirs_in_place(dirs)\n        files[:] = [f for f in files if _should_index_file(f)]\n        yield root, dirs, files\nos.walk = _filtered_os_walk  # type: ignore\n\n# Patch Path.rglob as well (if code uses it)\n_Path_rglob = Path.rglob
_filtered_rglob(self, pattern):\n    for p in _Path_rglob(self, pattern):\n        # skip if any pruned dir appears in the path\n        if any(part in PRUNE_DIRS for part in p.parts):\n            continue\n        if not _should_index_file(p.name):\n            continue\n        yield p\nPath.rglob = _filtered_rglob  # type: ignore\n# --- end filters ---\n\n\n# Load local env and also repo-root .env if present (no hard-coded paths)\ntry:\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / ".env"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nif OPENAI_API_KEY and OPENAI_API_KEY.strip().upper() in {"SK-REPLACE", "REPLACE"}:\n    OPENAI_API_KEY = None\nQDRANT_URL = os.getenv('QDRANT_URL','http://127.0.0.1:6333')\n# Repo scoping\nREPO = os.getenv('REPO', 'project').strip()\n# Resolve repo paths and outdir from config (repos.json or env)\ntry:\n    BASES = get_repo_paths(REPO)\nexcept Exception:\n    # Fallback to current directory when no config present (best-effort)\n    BASES = [str(Path(__file__).resolve().parent)]\nOUTDIR = out_dir(REPO)\n# Allow explicit collection override (for versioned collections per embedding config)\nCOLLECTION = os.getenv('COLLECTION_NAME', f'code_chunks_{REPO}')\n\n\n# Centralized file indexing gate (extensions, excludes, heuristics)\nSOURCE_EXTS = {\n    ".py", ".rb", ".ts", ".tsx", ".js", ".jsx", ".go", ".rs", ".java",\n    ".cs", ".c", ".h", ".cpp", ".hpp", ".m", ".mm", ".kt", ".kts", ".swift",\n    ".sql", ".yml", ".yaml", ".toml", ".ini", ".json", ".md"\n}\nEXCLUDE_GLOBS_FILE = str((data_dir() / "exclude_globs.txt").resolve())
_load_exclude_globs() -> list[str]:\n    p = pathlib.Path(EXCLUDE_GLOBS_FILE)\n    if not p.exists():\n        return []\n    return [ln.strip() for ln in p.read_text().splitlines() if ln.strip() and not ln.startswith("#")]\n\n_EXCLUDE_GLOBS = _load_exclude_globs()\nshould_index_file(path: str) -> bool:\n    p = pathlib.Path(path)\n    # 1) fast deny: extension must look like source\n    if p.suffix.lower() not in SOURCE_EXTS:\n        return False\n    # 2) glob excludes (vendor, caches, images, minified, etc.)\n    as_posix = p.as_posix()\n    for pat in _EXCLUDE_GLOBS:\n        if fnmatch.fnmatch(as_posix, pat):\n            return False\n    # 3) quick heuristic to skip huge/minified one-liners\n    try:\n        text = p.read_text(errors="ignore")\n        if len(text) > 2_000_000:  # ~2MB\n            return False\n        lines = text.splitlines()\n        if lines:\n            avg = sum(len(x) for x in lines) / max(1, len(lines))\n            if avg > 2500:\n                return False\n    except Exception:\n        return False\n    return True\n\n\n# --- Repo-aware layer tagging ---
detect_layer(fp: str) -> str:\n    f = (fp or '').lower()\n    if REPO == 'project':\n        if '/core/admin_ui/' in f or '/site/' in f or '/docs-site/' in f:\n            return 'ui'\n        if '/plugins/' in f or '/core/plugins/' in f or 'notification' in f or 'pushover' in f or 'apprise' in f:\n            return 'plugin'\n        if '/core/api/' in f or '/core/' in f or '/server' in f:\n            return 'kernel'\n        if '/docs/' in f or '/internal_docs/' in f:\n            return 'docs'\n        if '/tests/' in f or '/test_' in f:\n            return 'tests'\n        if '/infra/' in f or '/deploy/' in f or '/scripts/' in f:\n            return 'infra'\n        return 'kernel'\n    else:\n        if '/admin_ui/' in f or '/site/' in f or '/docs-site/' in f:\n            return 'ui'\n        if 'provider' in f or 'providers' in f or 'integration' in f or 'webhook' in f or 'adapter' in f:\n            return 'integration'\n        if '/api/' in f or '/backends/' in f or '/server' in f:\n            return 'server'\n        if '/sdks/' in f or '/python_mcp/' in f or '/node_mcp/' in f or '/plugin-dev-kit/' in f:\n            return 'sdk'\n        if '/docs/' in f or '/internal_docs/' in f:\n            return 'docs'\n        if '/asterisk/' in f or '/config/' in f or '/infra/' in f:\n            return 'infra'\n        return 'server'\n\nVENDOR_MARKERS = (\n    "/vendor/","/third_party/","/external/","/deps/","/node_modules/",\n    "/Pods/","/Godeps/","/.bundle/","/bundle/"\n)
detect_origin(fp: str) -> str:\n    low = (fp or '').lower()\n    for m in VENDOR_MARKERS:\n        if m in low:\n            return 'vendor'\n    try:\n        with open(fp, 'r', encoding='utf-8', errors='ignore') as f:\n            head = ''.join([next(f) for _ in range(12)])\n        if any(k in head.lower() for k in (\n            'apache license','mit license','bsd license','mozilla public license'\n        )):\n            return 'vendor'\n    except Exception:\n        pass\n    return 'first_party'\nos.makedirs(OUTDIR, exist_ok=True)\n_clip_for_openai(text: str, enc, max_tokens: int = 8000) -> str:\n    toks = enc.encode(text)\n    if len(toks) <= max_tokens:\n        return text\n    return enc.decode(toks[:max_tokens])\nembed_texts(client: OpenAI, texts: List[str], batch: int = 64) -> List[List[float]]:\n    embs = []\n    enc = tiktoken.get_encoding('cl100k_base')\n    for i in range(0, len(texts), batch):\n        sub = [_clip_for_openai(t, enc) for t in texts[i:i+batch]]\n        r = client.embeddings.create(model='text-embedding-3-large', input=sub)\n        for d in r.data:\n            embs.append(d.embedding)\n    return embs
embed_texts_local(texts: List[str], model_name: str = 'BAAI/bge-small-en-v1.5', batch: int = 128) -> List[List[float]]:\n    model = SentenceTransformer(model_name)\n    out = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        v = model.encode(sub, normalize_embeddings=True, show_progress_bar=False)\n        out.extend(v.tolist())\n    return out\n_renorm_truncate(vecs: List[List[float]], dim: int) -> List[List[float]]:\n    out: List[List[float]] = []\n    import math as _m\n    for v in vecs:\n        w = v[:dim] if dim and dim < len(v) else v\n        n = _m.sqrt(sum(x*x for x in w)) or 1.0\n        out.append([x / n for x in w])\n    return out\nembed_texts_mxbai(texts: List[str], dim: int = 512, batch: int = 128) -> List[List[float]]:\n    model = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')\n    out: List[List[float]] = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        v = model.encode(sub, normalize_embeddings=True, show_progress_bar=False)\n        out.extend(v.tolist())\n    return _renorm_truncate(out, dim)
embed_texts_voyage(texts: List[str], batch: int = 128, output_dimension: int = 512) -> List[List[float]]:\n    import voyageai  # type: ignore\n    client = voyageai.Client(api_key=os.getenv('VOYAGE_API_KEY'))\n    out: List[List[float]] = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        r = client.embed(sub, model='voyage-code-3', input_type='document', output_dimension=output_dimension)\n        out.extend(r.embeddings)\n    return out
main() -> None:\n    files = collect_files(BASES)\n    print(f'Discovered {len(files)} source files.')\n    all_chunks: List[Dict] = []\n    for fp in files:\n        if not should_index_file(fp):\n            continue\n        lang = lang_from_path(fp)\n        if not lang:\n            continue\n        try:\n            with open(fp, 'r', encoding='utf-8', errors='ignore') as f:\n                src = f.read()\n        except Exception:\n            continue\n        ch = chunk_code(src, fp, lang, target=900)\n        all_chunks.extend(ch)\n\n    seen, chunks = set(), []\n    for c in all_chunks:\n        c['repo'] = REPO\n        try:\n            c['layer'] = detect_layer(c.get('file_path',''))\n        except Exception:\n            c['layer'] = 'server'\n        try:\n            c['origin'] = detect_origin(c.get('file_path',''))\n        except Exception:\n            c['origin'] = 'first_party'\n        h = hashlib.md5(c['code'].encode()).hexdigest()\n        if h in seen:\n            continue\n        seen.add(h)\n        c['hash'] = h\n        chunks.append(c)\n    print(f'Prepared {len(chunks)} chunks.')\n\n    ENRICH = (os.getenv('ENRICH_CODE_CHUNKS', 'false') or 'false').lower() == 'true'\n    enrich = None  # type: ignore[assignment]\n    if ENRICH:\n        try:\n            from common.metadata import enrich  # type: ignore\n        except Exception:\n            pass\n        if enrich is not None:\n            for c in chunks:\n                try:\n                    meta = enrich(c.get('file_path',''), c.get('language',''), c.get('code',''))\n                    c['summary'] = meta.get('summary','')\n                    c['keywords'] = meta.get('keywords', [])\n                except Exception:\n                    c['summary'] = ''\n                    c['keywords'] = []\n\n    corpus: List[str] = []\n    for c in chunks:\n        pre = []\n        if c.get('name'):\n            pre += [c['name']]*2\n        if c.get('imports'):\n            pre += [i[0] or i[1] for i in c['imports'] if isinstance(i, (list, tuple))]\n        body = c['code']\n        corpus.append((' '.join(pre)+'\n'+body).strip())\n\n    stemmer = Stemmer('english')\n    tokenizer = Tokenizer(stemmer=stemmer, stopwords='en')\n    corpus_tokens = tokenizer.tokenize(corpus)\n    retriever = bm25s.BM25(method='lucene', k1=1.2, b=0.65)\n    retriever.index(corpus_tokens)\n    os.makedirs(os.path.join(OUTDIR, 'bm25_index'), exist_ok=True)\n    try:\n        retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}\n    except Exception:\n        pass\n    retriever.save(os.path.join(OUTDIR, 'bm25_index'), corpus=corpus)\n    tokenizer.save_vocab(save_dir=os.path.join(OUTDIR, 'bm25_index'))\n    tokenizer.save_stopwords(save_dir=os.path.join(OUTDIR, 'bm25_index'))\n    with open(os.path.join(OUTDIR, 'bm25_index', 'corpus.txt'), 'w', encoding='utf-8') as f:\n        for doc in corpus:\n            f.write(doc.replace('\n','\\n')+'\n')\n    chunk_ids = [str(c['id']) for c in chunks]\n    with open(os.path.join(OUTDIR, 'bm25_index', 'chunk_ids.txt'), 'w', encoding='utf-8') as f:\n        for cid in chunk_ids:\n            f.write(cid+'\n')\n    import json as _json\n    _json.dump({str(i): cid for i, cid in enumerate(chunk_ids)}, open(os.path.join(OUTDIR,'bm25_index','bm25_map.json'),'w'))\n    with open(os.path.join(OUTDIR,'chunks.jsonl'),'w',encoding='utf-8') as f:\n        for c in chunks:\n            f.write(json.dumps(c, ensure_ascii=False)+'\n')\n    print('BM25 index saved.')\n\n    try:\n        meta = {\n            'repo': REPO,\n            'timestamp': datetime.utcnow().isoformat() + 'Z',\n            'chunks_path': os.path.join(OUTDIR, 'chunks.jsonl'),\n            'bm25_index_dir': os.path.join(OUTDIR, 'bm25_index'),\n            'chunk_count': len(chunks),\n            'collection_name': COLLECTION,\n        }\n        with open(os.path.join(OUTDIR, 'last_index.json'), 'w', encoding='utf-8') as mf:\n            json.dump(meta, mf, indent=2)\n    except Exception:\n        pass\n\n    if (os.getenv('SKIP_DENSE','0') or '0').strip() == '1':\n        print('Skipping dense embeddings and Qdrant upsert (SKIP_DENSE=1).')\n        return\n\n    client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n    texts = []\n    for c in chunks:\n        if c.get('summary') or c.get('keywords'):\n            kw = ' '.join(c.get('keywords', []))\n            texts.append(f"{c.get('file_path','') }\n{c.get('summary','')}\n{kw}\n{c.get('code','')}")\n        else:\n            texts.append(c['code'])\n    embs: List[List[float]] = []\n    et = (os.getenv('EMBEDDING_TYPE','openai') or 'openai').lower()\n    if et == 'voyage':\n        try:\n            embs = embed_texts_voyage(texts, batch=64, output_dimension=int(os.getenv('VOYAGE_EMBED_DIM','512')))\n        except Exception as e:\n            print(f"Voyage embedding failed ({e}); falling back to local embeddings.")\n            embs = []\n        if not embs:\n            embs = embed_texts_local(texts)\n    elif et == 'mxbai':\n        try:\n            dim = int(os.getenv('EMBEDDING_DIM', '512'))\n            embs = embed_texts_mxbai(texts, dim=dim)\n        except Exception as e:\n            print(f"MXBAI embedding failed ({e}); falling back to local embeddings.")\n            embs = embed_texts_local(texts)\n    elif et == 'local':\n        embs = embed_texts_local(texts)\n    else:\n        if client is not None:\n            try:\n                cache = EmbeddingCache(OUTDIR)\n                hashes = [c['hash'] for c in chunks]\n                embs = cache.embed_texts(client, texts, hashes, model='text-embedding-3-large', batch=64)\n                pruned = cache.prune(set(hashes))\n                if pruned > 0:\n                    print(f'Pruned {pruned} orphaned embeddings from cache.')\n                cache.save()\n            except Exception as e:\n                print(f'Embedding via OpenAI failed ({e}); falling back to local embeddings.')\n        if not embs:\n            embs = embed_texts_local(texts)\n    point_ids: List[str] = []\n    try:\n        q = QdrantClient(url=QDRANT_URL)\n        qdrant_recreate_fallback.recreate_collection(\n            q,\n            collection_name=COLLECTION,\n            vectors_config={'dense': models.VectorParams(size=len(embs[0]), distance=models.Distance.COSINE)}\n        )\n        points = []\n        for c, v in zip(chunks, embs):\n            cid = str(c['id'])\n            pid = str(uuid.uuid5(uuid.NAMESPACE_DNS, cid))\n            slim_payload = {\n                'id': c.get('id'),\n                'file_path': c.get('file_path'),\n                'start_line': c.get('start_line'),\n                'end_line': c.get('end_line'),\n                'layer': c.get('layer'),\n                'repo': c.get('repo'),\n                'origin': c.get('origin'),\n                'hash': c.get('hash'),\n                'language': c.get('language')\n            }\n            slim_payload = {k: v for k, v in slim_payload.items() if v is not None}\n            points.append(models.PointStruct(id=pid, vector={'dense': v}, payload=slim_payload))\n            point_ids.append(pid)\n            if len(points) == 64:\n                q.upsert(COLLECTION, points=points)\n                points = []\n        if points:\n            q.upsert(COLLECTION, points=points)\n        import json as _json\n        _json.dump({str(i): pid for i, pid in enumerate(point_ids)}, open(os.path.join(OUTDIR,'bm25_index','bm25_point_ids.json'),'w'))\n        print(f'Indexed {len(chunks)} chunks to Qdrant (embeddings: {len(embs[0])} dims).')\n        try:\n            meta = {\n                'repo': REPO,\n                'timestamp': datetime.utcnow().isoformat() + 'Z',\n                'chunks_path': os.path.join(OUTDIR, 'chunks.jsonl'),\n                'bm25_index_dir': os.path.join(OUTDIR, 'bm25_index'),\n                'chunk_count': len(chunks),\n                'collection_name': COLLECTION,\n                'embedding_type': (os.getenv('EMBEDDING_TYPE','openai') or 'openai').lower(),\n                'embedding_dim': len(embs[0]) if embs and embs[0] else None,\n            }\n            with open(os.path.join(OUTDIR, 'last_index.json'), 'w', encoding='utf-8') as mf:\n                json.dump(meta, mf, indent=2)\n        except Exception:\n            pass\n    except Exception as e:\n        print(f"Qdrant unavailable or failed to index ({e}); continuing with BM25-only index. Dense retrieval will be disabled.")\n\nif __name__ == '__main__':\n    main()
