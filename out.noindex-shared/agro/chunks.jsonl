{"id": "bafcb8bd46b0", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": ["from fastapi import FastAPI, Query, HTTPException", "from pydantic import BaseModel", "from typing import Optional, Dict, Any, List", "from pathlib import Path", "from fastapi.staticfiles import StaticFiles", "from fastapi.responses import FileResponse, JSONResponse", "from langgraph_app import build_graph", "from hybrid_search import search_routed_multi", "from config_loader import load_repos", "import os, json"], "code": "from fastapi import FastAPI, Query, HTTPException\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom pathlib import Path\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse, JSONResponse\nfrom langgraph_app import build_graph\nfrom hybrid_search import search_routed_multi\nfrom config_loader import load_repos\nimport os, json\n\napp = FastAPI(title=\"AGRO RAG + GUI\")\n\n_graph = Noneget_graph():\n    global _graph\n    if _graph is None:\n        _graph = build_graph()\n    return _graph\n\nCFG = {\"configurable\": {\"thread_id\": \"http\"}}\nAnswer(BaseModel):\n    answer: str\n\nROOT = Path(__file__).resolve().parent\nGUI_DIR = ROOT / \"gui\"\n\n# Serve static GUI assets\nif GUI_DIR.exists():\n    app.mount(\"/gui\", StaticFiles(directory=str(GUI_DIR), html=True), name=\"gui\")\n\n@app.get(\"/\", include_in_schema=False)", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f6d2723278b7e0bde43d18d14b445aee"}
{"id": "48366d11b1fe", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 14, "imports": [], "code": "serve_index():\n    idx = GUI_DIR / \"index.html\"\n    if idx.exists():\n        return FileResponse(str(idx))\n    return {\"ok\": True, \"message\": \"GUI assets not found; use /health, /search, /answer\"}\n\n@app.get(\"/health\")health():\n    try:\n        g = get_graph()\n        return {\"status\": \"healthy\", \"graph_loaded\": g is not None, \"ts\": __import__('datetime').datetime.utcnow().isoformat() + 'Z'}\n    except Exception as e:\n        return {\"status\": \"error\", \"detail\": str(e)}\n\n@app.get(\"/answer\", response_model=Answer)", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6fe4696aa7122e4d59f47e64f7c006f7"}
{"id": "462e830c55d4", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 15, "imports": [], "code": "answer(\n    q: str = Query(..., description=\"Question\"),\n    repo: Optional[str] = Query(None, description=\"Repository override: project|project\")\n):\n    \"\"\"Answer a question using strict per-repo routing.\n\n    If `repo` is provided, retrieval and the answer header will use that repo.\n    Otherwise, a lightweight router selects the repo from the query content.\n    \"\"\"\n    g = get_graph()\n    state = {\"question\": q, \"documents\": [], \"generation\":\"\", \"iteration\":0, \"confidence\":0.0, \"repo\": (repo.strip() if repo else None)}\n    res = g.invoke(state, CFG)\n    return {\"answer\": res[\"generation\"]}\n\n@app.get(\"/search\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a457d311f74c03a060903287426cf8be"}
{"id": "eef173b62450", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "search(\n    q: str = Query(..., description=\"Question\"),\n    repo: Optional[str] = Query(None, description=\"Repository override: project|project\"),\n    top_k: int = Query(10, description=\"Number of results to return\")\n):\n    \"\"\"Search for relevant code locations without generation.\n\n    Returns file paths, line ranges, and rerank scores for the most relevant code chunks.\n    \"\"\"\n    docs = search_routed_multi(q, repo_override=repo, m=4, final_k=top_k)\n    results = [\n        {\n            \"file_path\": d.get(\"file_path\", \"\"),\n            \"start_line\": d.get(\"start_line\", 0),\n            \"end_line\": d.get(\"end_line\", 0),\n            \"language\": d.get(\"language\", \"\"),\n            \"rerank_score\": float(d.get(\"rerank_score\", 0.0) or 0.0),\n            \"repo\": d.get(\"repo\", repo),\n        }\n        for d in docs\n    ]\n    return {\"results\": results, \"repo\": repo, \"count\": len(results)}\n\n# ---------------- Minimal GUI API stubs ----------------_read_json(path: Path, default: Any) -> Any:\n    if path.exists():\n        try:\n            return json.loads(path.read_text())\n        except Exception:\n            return default\n    return default\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8c4dd00aab29d293aaeb39d7ca4f4a92"}
{"id": "43f4d15b8ec2", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "_write_json(path: Path, data: Any) -> None:\n    path.parent.mkdir(parents=True, exist_ok=True)\n    path.write_text(json.dumps(data, indent=2))\n\n@app.post(\"/api/env/reload\")api_env_reload() -> Dict[str, Any]:\n    try:\n        from dotenv import load_dotenv as _ld\n        _ld(override=False)\n    except Exception:\n        pass\n    return {\"ok\": True}\n\n@app.get(\"/api/config\")get_config() -> Dict[str, Any]:\n    cfg = load_repos()\n    # return a broad env snapshot for the GUI; rely on client to pick what it needs\n    env: Dict[str, Any] = {}\n    for k, v in os.environ.items():\n        # keep it simple; include strings only\n        env[k] = v\n    repos = cfg.get(\"repos\", [])\n    return {\n        \"env\": env,\n        \"default_repo\": cfg.get(\"default_repo\"),\n        \"repos\": repos,\n    }\n\n@app.get(\"/api/prices\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3d2f555e97c8a4ec15b131082910f1be"}
{"id": "e130fede9410", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "get_prices():\n    default_prices = {\n        \"last_updated\": \"2025-10-10\",\n        \"currency\": \"USD\",\n        \"models\": [\n            {\"provider\": \"openai\", \"family\": \"gpt-4o-mini\", \"model\": \"gpt-4o-mini\",\n             \"unit\": \"1k_tokens\", \"input_per_1k\": 0.005, \"output_per_1k\": 0.015,\n             \"embed_per_1k\": 0.0001, \"rerank_per_1k\": 0.0, \"notes\": \"EXAMPLE\"},\n            {\"provider\": \"cohere\", \"family\": \"rerank-english-v3.0\", \"model\": \"rerank-english-v3.0\",\n             \"unit\": \"1k_tokens\", \"input_per_1k\": 0.0, \"output_per_1k\": 0.0,\n             \"embed_per_1k\": 0.0, \"rerank_per_1k\": 0.30, \"notes\": \"EXAMPLE\"},\n            {\"provider\": \"voyage\", \"family\": \"voyage-3-large\", \"model\": \"voyage-3-large\",\n             \"unit\": \"1k_tokens\", \"input_per_1k\": 0.0, \"output_per_1k\": 0.0,\n             \"embed_per_1k\": 0.12, \"rerank_per_1k\": 0.0, \"notes\": \"EXAMPLE\"},\n            {\"provider\": \"local\", \"family\": \"qwen3-coder\", \"model\": \"qwen3-coder:14b\",\n             \"unit\": \"request\", \"per_request\": 0.0, \"notes\": \"Local inference assumed $0; electricity optional\"}\n        ]\n    }\n    prices_path = GUI_DIR / \"prices.json\"\n    data = _read_json(prices_path, default_prices)\n    return JSONResponse(data)\n\n@app.post(\"/api/prices/upsert\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e279480d4147c09e0084fe815fe158db"}
{"id": "da1f43684220", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 16, "imports": [], "code": "upsert_price(item: Dict[str, Any]) -> Dict[str, Any]:\n    prices_path = GUI_DIR / \"prices.json\"\n    data = _read_json(prices_path, {\"models\": []})\n    models: List[Dict[str, Any]] = list(data.get(\"models\", []))\n    key = (str(item.get(\"provider\")), str(item.get(\"model\")))\n    idx = next((i for i, m in enumerate(models) if (str(m.get(\"provider\")), str(m.get(\"model\"))) == key), None)\n    if idx is None:\n        models.append(item)\n    else:\n        models[idx].update(item)\n    data[\"models\"] = models\n    data[\"last_updated\"] = __import__('datetime').datetime.utcnow().strftime('%Y-%m-%d')\n    _write_json(prices_path, data)\n    return {\"ok\": True, \"count\": len(models)}\n\n@app.get(\"/api/keywords\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "150cef01559f389a327f592f837d051a"}
{"id": "bdd5422ed883", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "get_keywords() -> Dict[str, Any]:\n    discr = _read_json(ROOT / \"discriminative_keywords.json\", [])\n    sema = _read_json(ROOT / \"semantic_keywords.json\", [])\n    repos_cfg = load_repos()\n    repo_k = []\n    for r in repos_cfg.get(\"repos\", []):\n        for k in r.get(\"keywords\", []) or []:\n            if isinstance(k, str):\n                repo_k.append(k)\n    def uniq(xs: List[str]) -> List[str]:\n        seen = set(); out: List[str] = []\n        for k in xs:\n            k2 = str(k)\n            if k2 not in seen:\n                out.append(k2); seen.add(k2)\n        return out\n    discr = uniq(discr)\n    sema = uniq(sema)\n    repo_k = uniq(repo_k)\n    allk = uniq((discr or []) + (sema or []) + (repo_k or []))\n    return {\"discriminative\": discr, \"semantic\": sema, \"repos\": repo_k, \"keywords\": allk}\n\n@app.post(\"/api/scan-hw\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e8c930d453897ec39ae6853137c8fca6"}
{"id": "c8d55d31dc74", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "scan_hw() -> Dict[str, Any]:\n    # Lightweight local scan without new deps\n    import platform, shutil\n    info = {\n        \"os\": platform.system(),\n        \"arch\": platform.machine(),\n        \"cpu_cores\": os.cpu_count() or 0,\n        \"mem_gb\": None,\n    }\n    # Try to get memory (Darwin via sysctl; Linux via /proc/meminfo)\n    try:\n        if info[\"os\"] == \"Darwin\":\n            import subprocess\n            out = subprocess.check_output([\"sysctl\", \"-n\", \"hw.memsize\"], text=True).strip()\n            info[\"mem_gb\"] = round(int(out) / (1024**3), 2)\n        elif Path(\"/proc/meminfo\").exists():\n            txt = Path(\"/proc/meminfo\").read_text()\n            for line in txt.splitlines():\n                if line.startswith(\"MemTotal:\"):\n                    kb = int(line.split()[1]); info[\"mem_gb\"] = round(kb/1024/1024, 2)\n                    break\n    except Exception:\n        pass\n    runtimes = {\n        \"ollama\": bool(os.getenv(\"OLLAMA_URL\") or shutil.which(\"ollama\")),\n        \"coreml\": info[\"os\"] == \"Darwin\",\n        \"cuda\": bool(shutil.which(\"nvidia-smi\")),\n        \"mps\": info[\"os\"] == \"Darwin\",\n    }\n    tools = {\"uvicorn\": bool(shutil.which(\"uvicorn\")), \"docker\": bool(shutil.which(\"docker\"))}\n    return {\"info\": info, \"runtimes\": runtimes, \"tools\": tools}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8dadfc234c19cf6c1c45ed72eb3a916b"}
{"id": "b2cef6812add", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 12, "imports": [], "code": "_find_price(provider: str, model: Optional[str]) -> Optional[Dict[str, Any]]:\n    data = _read_json(GUI_DIR / \"prices.json\", {\"models\": []})\n    models = data.get(\"models\", [])\n    # Prefer exact provider+model, else fallback to first matching provider\n    for m in models:\n        if m.get(\"provider\") == provider and (model is None or m.get(\"model\") == model):\n            return m\n    for m in models:\n        if m.get(\"provider\") == provider:\n            return m\n    return None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b4e1d8d606cfb525135f2853f88bca7c"}
{"id": "4eb6d2361457", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 18, "imports": [], "code": "_estimate_cost(gen_provider: str, gen_model: Optional[str], tokens_in: int, tokens_out: int, embeds: int, reranks: int, requests_per_day: int) -> Dict[str, Any]:\n    price = _find_price(gen_provider, gen_model)\n    if not price:\n        return {\"daily\": 0.0, \"monthly\": 0.0, \"breakdown\": {}}\n    per_1k_in = float(price.get(\"input_per_1k\", 0.0))\n    per_1k_out = float(price.get(\"output_per_1k\", 0.0))\n    embed_per_1k = float(price.get(\"embed_per_1k\", 0.0))\n    rerank_per_1k = float(price.get(\"rerank_per_1k\", 0.0))\n    per_req = float(price.get(\"per_request\", 0.0))\n    daily = 0.0\n    daily += (tokens_in/1000.0) * per_1k_in * max(1, requests_per_day)\n    daily += (tokens_out/1000.0) * per_1k_out * max(1, requests_per_day)\n    daily += (embeds/1000.0) * embed_per_1k\n    daily += (reranks/1000.0) * rerank_per_1k\n    daily += per_req * max(1, requests_per_day)\n    return {\"daily\": round(daily, 6), \"monthly\": round(daily*30.0, 4), \"breakdown\": price}\n\n@app.post(\"/api/cost/estimate\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f576280725eae2b287d8cfd0c83c4f1a"}
{"id": "23ae4c50535e", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "cost_estimate(payload: Dict[str, Any]) -> Dict[str, Any]:\n    gen_provider = str(payload.get(\"gen_provider\") or payload.get(\"provider\") or \"openai\")\n    gen_model = payload.get(\"gen_model\")\n    tokens_in = int(payload.get(\"tokens_in\") or 0)\n    tokens_out = int(payload.get(\"tokens_out\") or 0)\n    embeds = int(payload.get(\"embeds\") or 0)\n    reranks = int(payload.get(\"reranks\") or 0)\n    rpd = int(payload.get(\"requests_per_day\") or 0)\n    return _estimate_cost(gen_provider, gen_model, tokens_in, tokens_out, embeds, reranks, rpd)\n\n@app.post(\"/api/cost/estimate_pipeline\")cost_estimate_pipeline(payload: Dict[str, Any]) -> Dict[str, Any]:\n    # same shape as estimate(), kept for compatibility\n    return cost_estimate(payload)\n\n@app.get(\"/api/profiles\")profiles_list() -> Dict[str, Any]:\n    prof_dir = GUI_DIR / \"profiles\"\n    prof_dir.mkdir(parents=True, exist_ok=True)\n    names = []\n    for p in prof_dir.glob(\"*.json\"):\n        names.append(p.stem)\n    return {\"profiles\": sorted(names), \"default\": None}\n\n@app.post(\"/api/profiles/save\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a8ebf3b38cef96780c3cd91be3c2245a"}
{"id": "58d5d0058bb6", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "profiles_save(payload: Dict[str, Any]) -> Dict[str, Any]:\n    name = str(payload.get(\"name\") or \"\").strip()\n    prof = payload.get(\"profile\") or {}\n    if not name:\n        raise HTTPException(status_code=400, detail=\"missing name\")\n    path = GUI_DIR / \"profiles\" / f\"{name}.json\"\n    _write_json(path, prof)\n    return {\"ok\": True, \"name\": name}\n\n@app.post(\"/api/profiles/apply\")profiles_apply(payload: Dict[str, Any]) -> Dict[str, Any]:\n    prof = payload.get(\"profile\") or {}\n    applied = []\n    for k, v in prof.items():\n        os.environ[str(k)] = str(v)\n        applied.append(str(k))\n    return {\"ok\": True, \"applied_keys\": applied}\n\n# --- Index + Cards: minimal stubs to keep GUI functional ---\n_INDEX_STATUS: List[str] = []\n\n@app.post(\"/api/index/start\")index_start() -> Dict[str, Any]:\n    global _INDEX_STATUS\n    _INDEX_STATUS = [\"Prepared 123 chunks\", \"BM25 index saved\", \"Indexed 123 chunks to Qdrant\"]\n    return {\"ok\": True}\n\n@app.get(\"/api/index/status\")index_status() -> Dict[str, Any]:\n    return {\"lines\": _INDEX_STATUS}\n\n@app.post(\"/api/cards/build\")", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f3c9c14e543db15ca99d23a2c4cf7381"}
{"id": "68e967d22420", "file_path": "/Users/davidmontgomery/agro/serve_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 6, "imports": [], "code": "cards_build() -> Dict[str, Any]:\n    return {\"ok\": True}\n\n@app.get(\"/api/cards\")cards_list() -> Dict[str, Any]:\n    return {\"cards\": []}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "82bbc734c987d83077932bd91a1c33b6"}
{"id": "9e18cfd3ec65", "file_path": "/Users/davidmontgomery/agro/rerank.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": ["import math", "import os", "from typing import List, Dict", "from rerankers import Reranker", "from typing import Optional"], "code": "import math\nimport os\nfrom typing import List, Dict\nfrom rerankers import Reranker\nfrom typing import Optional\n\n# Load .env early so config reads below see the right values\ntry:\n    from dotenv import load_dotenv\n    load_dotenv(override=False)\nexcept Exception:\n    pass\n\n_HF_PIPE = None  # optional transformers pipeline for models that require trust_remote_code\n\n_RERANKER = None\n\n# Default to a strong open-source cross-encoder; allow env override\nDEFAULT_MODEL = os.getenv('RERANKER_MODEL', 'BAAI/bge-reranker-v2-m3')\n# Default backend: local (set RERANK_BACKEND=cohere + COHERE_API_KEY to use Cohere API)\nRERANK_BACKEND = (os.getenv('RERANK_BACKEND', 'local') or 'local').lower()\n# Default Cohere model (override via COHERE_RERANK_MODEL). Accepts 'rerank-3.5' or 'rerank-2.5'.\nCOHERE_MODEL = os.getenv('COHERE_RERANK_MODEL', 'rerank-3.5')\n\n_sigmoid(x: float) -> float:\n    try:\n        return 1.0 / (1.0 + math.exp(-float(x)))\n    except Exception:\n        return 0.0\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "38805057b8c498b65adbf2a321548568"}
{"id": "b1b9f6ef56d1", "file_path": "/Users/davidmontgomery/agro/rerank.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "_normalize(score: float, model_name: str) -> float:\n    if any(k in model_name.lower() for k in ['bge-reranker', 'cross-encoder', 'mxbai', 'jina-reranker']):\n        return _sigmoid(score)\n    return float(score)\n\n_maybe_init_hf_pipeline(model_name: str) -> Optional[object]:\n    global _HF_PIPE\n    if _HF_PIPE is not None:\n        return _HF_PIPE\n    try:\n        if 'jinaai/jina-reranker' in model_name.lower():\n            # Use HF pipeline directly to guarantee trust_remote_code is honored\n            os.environ.setdefault('TRANSFORMERS_TRUST_REMOTE_CODE', '1')\n            from transformers import pipeline\n            _HF_PIPE = pipeline(\n                task='text-classification',\n                model=model_name,\n                tokenizer=model_name,\n                trust_remote_code=True,\n                device_map='auto'\n            )\n            return _HF_PIPE\n    except Exception:\n        _HF_PIPE = None\n    return _HF_PIPE\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9814d31c996705c509e57f0198db99d3"}
{"id": "4cf35d92c992", "file_path": "/Users/davidmontgomery/agro/rerank.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 13, "imports": [], "code": "get_reranker() -> Reranker:\n    global _RERANKER\n    if _RERANKER is None:\n        model_name = DEFAULT_MODEL\n        # First try a direct HF pipeline for models with custom code\n        if _maybe_init_hf_pipeline(model_name):\n            return None  # Signal to use HF pipeline path\n        # Otherwise, fall back to rerankers\n        os.environ.setdefault('TRANSFORMERS_TRUST_REMOTE_CODE', '1')\n        _RERANKER = Reranker(model_name, model_type='cross-encoder', trust_remote_code=True)\n    return _RERANKER\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7106e2e2662d1a209943caf53d60d796"}
{"id": "ec211ed0f410", "file_path": "/Users/davidmontgomery/agro/rerank.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 96, "imports": [], "code": "rerank_results(query: str, results: List[Dict], top_k: int = 10) -> List[Dict]:\n    if not results:\n        return []\n    # Optional hard disable for environments without model/network\n    if RERANK_BACKEND in ('none', 'off', 'disabled'):\n        # Assign neutral scores based on original order\n        for i, r in enumerate(results):\n            r['rerank_score'] = float(1.0 - (i * 0.01))\n        return results[:top_k]\n    model_name = DEFAULT_MODEL\n    # Optional Cohere backend (remote API)\n    if RERANK_BACKEND == 'cohere':\n        try:\n            import cohere  # type: ignore\n            api_key = os.getenv('COHERE_API_KEY')\n            if not api_key:\n                raise RuntimeError('COHERE_API_KEY not set')\n            client = cohere.Client(api_key=api_key)\n            docs = []\n            for r in results:\n                file_ctx = r.get('file_path', '')\n                code_snip = (r.get('code') or r.get('text') or '')[:700]\n                docs.append(f\"{file_ctx}\\n\\n{code_snip}\")\n            rr = client.rerank(model=COHERE_MODEL, query=query, documents=docs, top_n=len(docs))\n            # Normalize scores into 0..1\n            scores = [getattr(x, 'relevance_score', 0.0) for x in rr.results]\n            max_s = max(scores) if scores else 1.0\n            for item in rr.results:\n                idx = int(getattr(item, 'index', 0))\n                score = float(getattr(item, 'relevance_score', 0.0))\n                results[idx]['rerank_score'] = (score / max_s) if max_s else 0.0\n            results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n            return results[:top_k]\n        except Exception:\n            # Fall back to local reranker paths below\n            pass\n    # HF pipeline path (e.g., Jina reranker)\n    pipe = _maybe_init_hf_pipeline(model_name)\n    if pipe is not None:\n        pairs = []\n        for r in results:\n            code_snip = (r.get('code') or r.get('text') or '')[:700]\n            pairs.append({'text': query, 'text_pair': code_snip})\n        try:\n            out = pipe(pairs, truncation=True)\n            raw = []\n            for i, o in enumerate(out):\n                score = float(o.get('score', 0.0))\n                s = _normalize(score, model_name)\n                results[i]['rerank_score'] = s\n                raw.append(s)\n            # Calibrate scores to 0..1 range per request\n            if raw:\n                mn, mx = min(raw), max(raw)\n                rng = (mx - mn)\n                if rng > 1e-9:\n                    for r in results:\n                        r['rerank_score'] = (float(r.get('rerank_score', 0.0)) - mn) / rng\n                elif mx != 0.0:\n                    for r in results:\n                        r['rerank_score'] = float(r.get('rerank_score', 0.0)) / abs(mx)\n            results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n            return results[:top_k]\n        except Exception:\n            # Fall back to rerankers path below\n            pass\n    # rerankers path\n    docs = []\n    for r in results:\n        file_ctx = r.get('file_path', '')\n        code_snip = (r.get('code') or r.get('text') or '')[:600]\n        docs.append(f\"{file_ctx}\\n\\n{code_snip}\")\n    rr = get_reranker()\n    if rr is None and _maybe_init_hf_pipeline(model_name) is not None:\n        # HF pipeline already used above; should not reach here\n        return results[:top_k]\n    ranked = rr.rank(query=query, docs=docs, doc_ids=list(range(len(docs))))\n    raw_scores = []\n    for res in ranked.results:\n        idx = res.document.doc_id\n        s = _normalize(res.score, model_name)\n        results[idx]['rerank_score'] = s\n        raw_scores.append(s)\n    # Calibrate to [0,1] per call for stable gating across backends\n    if raw_scores:\n        mn, mx = min(raw_scores), max(raw_scores)\n        rng = (mx - mn)\n        if rng > 1e-9:\n            for r in results:\n                r['rerank_score'] = (float(r.get('rerank_score', 0.0)) - mn) / rng\n        elif mx != 0.0:\n            for r in results:\n                r['rerank_score'] = float(r.get('rerank_score', 0.0)) / abs(mx)\n    results.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n    return results[:top_k]\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "955091ae67b885ed60de0a49cf7f4330"}
{"id": "bd4e1a73c0f0", "file_path": "/Users/davidmontgomery/agro/runtime_config.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 41, "imports": ["import os", "import json", "from pathlib import Path", "from typing import Any, Dict, Optional, Tuple, List", "from config_loader import layer_bonuses as _layer_bonuses_cfg, path_boosts as _path_boosts_cfg"], "code": "import os\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Tuple, List\n\nfrom config_loader import layer_bonuses as _layer_bonuses_cfg, path_boosts as _path_boosts_cfg\n\n\n_OVERRIDES: Dict[str, Any] | None = None\n\n_overrides_path() -> Path:\n    # Keep with UI assets for simplicity\n    return Path(__file__).parent / \"ui\" / \"runtime_overrides.json\"\n\n_load_overrides() -> Dict[str, Any]:\n    global _OVERRIDES\n    if _OVERRIDES is not None:\n        return _OVERRIDES\n    p = _overrides_path()\n    if p.exists():\n        try:\n            _OVERRIDES = json.loads(p.read_text())\n        except Exception:\n            _OVERRIDES = {}\n    else:\n        _OVERRIDES = {}\n    return _OVERRIDES\n\n_get_override(repo: Optional[str], key: str) -> Any:\n    ov = _load_overrides()\n    # Precedence: per-repo -> _global\n    if repo:\n        rp = ov.get(repo)\n        if isinstance(rp, dict) and key in rp:\n            return rp[key]\n    g = ov.get(\"_global\")\n    if isinstance(g, dict) and key in g:\n        return g[key]\n    return None\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c3c8e09c8c38e45d2e3bc739a33b9af8"}
{"id": "011c2737a6d4", "file_path": "/Users/davidmontgomery/agro/runtime_config.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 38, "imports": [], "code": "_coerce(value: Any, typ: str) -> Any:\n    if value is None:\n        return None\n    try:\n        if typ == \"int\":\n            return int(value)\n        if typ == \"float\":\n            return float(value)\n        if typ == \"bool\":\n            if isinstance(value, bool):\n                return value\n            s = str(value).strip().lower()\n            return s in {\"1\", \"true\", \"yes\", \"on\"}\n        if typ == \"str\":\n            return str(value)\n        if typ == \"list[str]\":\n            if isinstance(value, list):\n                return [str(x) for x in value]\n            return [x.strip() for x in str(value).split(',') if x.strip()]\n    except Exception:\n        return None\n    return value\n\nget_str(repo: Optional[str], key: str, env_key: Optional[str] = None, default: Optional[str] = None) -> Optional[str]:\n    v = _get_override(repo, key)\n    if v is None and env_key:\n        v = os.getenv(env_key)\n    return _coerce(v if v is not None else default, \"str\")\n\nget_int(repo: Optional[str], key: str, env_default: Optional[int] = None, default: Optional[int] = None) -> int:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, \"int\")\n    return int(out) if out is not None else int(default or 0)\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b5b19e4b9ecade79187232014301e925"}
{"id": "f0a164bd4a29", "file_path": "/Users/davidmontgomery/agro/runtime_config.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "get_float(repo: Optional[str], key: str, env_default: Optional[float] = None, default: Optional[float] = None) -> float:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, \"float\")\n    return float(out) if out is not None else float(default or 0.0)\n\nget_bool(repo: Optional[str], key: str, env_default: Optional[bool] = None, default: Optional[bool] = None) -> bool:\n    v = _get_override(repo, key)\n    if v is None:\n        v = env_default\n    v = default if v is None else v\n    out = _coerce(v, \"bool\")\n    return bool(out) if out is not None else bool(default or False)\n\n\n# High-level helpers\nget_conf_thresholds(repo: Optional[str]) -> Tuple[float, float, float]:\n    t1 = get_float(repo, \"CONF_TOP1\", float(os.getenv(\"CONF_TOP1\", \"0.62\")), 0.62)\n    a5 = get_float(repo, \"CONF_AVG5\", float(os.getenv(\"CONF_AVG5\", \"0.55\")), 0.55)\n    anyc = get_float(repo, \"CONF_ANY\", float(os.getenv(\"CONF_ANY\", \"0.55\")), 0.55)\n    return t1, a5, anyc\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b37ba2d1a9203fc818b2260d72e9ef55"}
{"id": "25cd010fcd88", "file_path": "/Users/davidmontgomery/agro/runtime_config.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 17, "imports": [], "code": "get_topk(repo: Optional[str]) -> Tuple[int, int, int]:\n    kd = get_int(repo, \"TOPK_DENSE\", int(os.getenv(\"TOPK_DENSE\", \"75\") or 75), 75)\n    ks = get_int(repo, \"TOPK_SPARSE\", int(os.getenv(\"TOPK_SPARSE\", \"75\") or 75), 75)\n    fk = get_int(repo, \"FINAL_K\", int(os.getenv(\"FINAL_K\", \"10\") or 10), 10)\n    return kd, ks, fk\n\nget_mq_rewrites(repo: Optional[str]) -> int:\n    return get_int(repo, \"MQ_REWRITES\", int(os.getenv(\"MQ_REWRITES\", \"2\") or 2), 2)\n\nget_reranker_config(repo: Optional[str]) -> Dict[str, str]:\n    return {\n        \"backend\": (get_str(repo, \"RERANK_BACKEND\", \"RERANK_BACKEND\", \"local\") or \"local\").lower(),\n        \"model\": get_str(repo, \"RERANKER_MODEL\", \"RERANKER_MODEL\", \"BAAI/bge-reranker-v2-m3\"),\n        \"cohere_model\": get_str(repo, \"COHERE_RERANK_MODEL\", \"COHERE_RERANK_MODEL\", \"rerank-3.5\"),\n    }\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "76293c0a4099c429c10fde7429f55288"}
{"id": "212d0a457061", "file_path": "/Users/davidmontgomery/agro/runtime_config.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 22, "imports": [], "code": "get_path_boosts(repo: Optional[str]) -> List[str]:\n    # Use repos.json, with optional env override per-repo (e.g., PROJECT_PATH_BOOSTS)\n    lst = _path_boosts_cfg(repo or \"\")\n    env_key = f\"{(repo or '').upper()}_PATH_BOOSTS\" if repo else None\n    if env_key:\n        env_val = os.getenv(env_key)\n        if not env_val and (repo or \"\").lower() == \"project\":\n            env_val = os.getenv(\"project_PATH_BOOSTS\")\n        if env_val:\n            lst.extend([t.strip() for t in env_val.split(',') if t.strip()])\n    # De-dup while preserving order\n    seen = set(); out = []\n    for t in lst:\n        tl = t.strip().lower()\n        if tl and tl not in seen:\n            seen.add(tl); out.append(tl)\n    return out\n\nget_layer_bonuses(repo: Optional[str]) -> Dict[str, Dict[str, float]]:\n    return _layer_bonuses_cfg(repo or \"\")\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "25473542312ee78800ceb6c7caa89f45"}
{"id": "53d28ea097dc", "file_path": "/Users/davidmontgomery/agro/config_loader.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 16, "imports": ["import os", "import json", "from pathlib import Path", "from typing import Any, Dict, List, Optional, Tuple"], "code": "import os\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple\n\n\n_CACHE: Dict[str, Any] = {}\n\n_repos_file_path() -> Path:\n    # Allow override via env; default to repos.json in repo root\n    env_path = os.getenv(\"REPOS_FILE\")\n    if env_path:\n        return Path(env_path).expanduser().resolve()\n    return Path(__file__).resolve().parent / \"repos.json\"\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f8051e51a4347cada1f810321db708b2"}
{"id": "ef9819790815", "file_path": "/Users/davidmontgomery/agro/config_loader.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 54, "imports": [], "code": "load_repos() -> Dict[str, Any]:\n    \"\"\"\n    Load repository configuration.\n\n    Format:\n      {\n        \"default_repo\": \"example-1\",\n        \"repos\": [\n          {\"name\": \"example-1\", \"path\": \"/abs/path/example-1\",\n           \"keywords\": [\"auth\", \"backend\"],\n           \"path_boosts\": [\"src/server/\", \"api/\"],\n           \"layer_bonuses\": {\"server\": {\"kernel\": 0.10}, \"ui\": {\"ui\": 0.12}}\n          },\n          {\"name\": \"example-2\", \"path\": [\"/abs/path/example-2\", \"/abs/alt\"]}\n        ]\n      }\n\n    Fallbacks (if repos.json missing):\n      - If REPO and REPO_PATH env set, synthesize a single-repo config.\n      - Else raise a clear error when a function requires config.\n    \"\"\"\n    global _CACHE\n    if \"config\" in _CACHE:\n        return _CACHE[\"config\"]\n\n    p = _repos_file_path()\n    if p.exists():\n        try:\n            data = json.loads(p.read_text())\n            if isinstance(data, dict) and isinstance(data.get(\"repos\"), list):\n                _CACHE[\"config\"] = data\n                return data\n        except Exception:\n            pass\n\n    # Fallback to environment-only single repo\n    env_repo = (os.getenv(\"REPO\") or \"default\").strip()\n    env_path = os.getenv(\"REPO_PATH\") or os.getenv(f\"REPO_{env_repo.upper()}_PATH\")\n    if env_path:\n        cfg = {\n            \"default_repo\": env_repo,\n            \"repos\": [\n                {\"name\": env_repo, \"path\": env_path}\n            ]\n        }\n        _CACHE[\"config\"] = cfg\n        return cfg\n\n    # Last resort minimal placeholder (no repos) to allow help text rendering\n    cfg = {\"default_repo\": None, \"repos\": []}\n    _CACHE[\"config\"] = cfg\n    return cfg\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7699a0f45cab6d1a9f5433aa1fbdeb13"}
{"id": "586ab39bac6a", "file_path": "/Users/davidmontgomery/agro/config_loader.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 37, "imports": [], "code": "list_repos() -> List[str]:\n    cfg = load_repos()\n    return [str(r.get(\"name\")) for r in cfg.get(\"repos\", []) if r.get(\"name\")]\n\nget_default_repo() -> str:\n    cfg = load_repos()\n    # 1) explicit default\n    if cfg.get(\"default_repo\"):\n        return str(cfg[\"default_repo\"]).strip()\n    # 2) first repo\n    repos = cfg.get(\"repos\", [])\n    if repos:\n        return str(repos[0].get(\"name\"))\n    # 3) env REPO or sentinel\n    return (os.getenv(\"REPO\") or \"default\").strip()\n\n_find_repo(name: str) -> Optional[Dict[str, Any]]:\n    name_low = (name or \"\").strip().lower()\n    if not name_low:\n        return None\n    for r in load_repos().get(\"repos\", []):\n        if (r.get(\"name\") or \"\").strip().lower() == name_low:\n            return r\n    return None\n\nget_repo_paths(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        raise ValueError(f\"Unknown repo: {name}. Known: {', '.join(list_repos()) or '[]'}\")\n    p = r.get(\"path\")\n    if isinstance(p, list):\n        return [str(Path(x).expanduser()) for x in p]\n    if isinstance(p, str):\n        return [str(Path(p).expanduser())]\n    raise ValueError(f\"Repo `{name}` missing 'path' in repos.json\")\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ed335d1a351d1452ce56e305eb684860"}
{"id": "632d5b5473c8", "file_path": "/Users/davidmontgomery/agro/config_loader.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 38, "imports": [], "code": "_out_base_dir() -> Path:\n    \"\"\"Resolve the base output directory, preferring out.noindex if present.\n\n    Order of precedence:\n      1) ENV OUT_DIR_BASE or RAG_OUT_BASE (absolute or relative to repo)\n      2) ./out.noindex\n      3) ./out\n    \"\"\"\n    root = Path(__file__).resolve().parent\n    env_base = os.getenv(\"OUT_DIR_BASE\") or os.getenv(\"RAG_OUT_BASE\")\n    if env_base:\n        p = Path(env_base).expanduser()\n        if not p.is_absolute():\n            p = (root / p)\n        return p\n    if (root / \"out.noindex\").exists():\n        return root / \"out.noindex\"\n    return root / \"out\"\n\nout_dir(name: str) -> str:\n    base = _out_base_dir() / name\n    return str(base)\n\nget_repo_keywords(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        return []\n    kws = r.get(\"keywords\") or []\n    return [str(k).lower() for k in kws if isinstance(k, str)]\n\npath_boosts(name: str) -> List[str]:\n    r = _find_repo(name)\n    if not r:\n        return []\n    lst = r.get(\"path_boosts\") or []\n    return [str(x) for x in lst if isinstance(x, str)]\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3beaad50422009c717ca20887c715aac"}
{"id": "8b07e98c07aa", "file_path": "/Users/davidmontgomery/agro/config_loader.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 36, "imports": [], "code": "layer_bonuses(name: str) -> Dict[str, Dict[str, float]]:\n    r = _find_repo(name)\n    if not r:\n        return {}\n    lb = r.get(\"layer_bonuses\") or {}\n    # Normalize numeric values\n    out: Dict[str, Dict[str, float]] = {}\n    for intent, d in (lb.items() if isinstance(lb, dict) else []):\n        if not isinstance(d, dict):\n            continue\n        out[intent] = {k: float(v) for k, v in d.items() if isinstance(v, (int, float))}\n    return out\n\nchoose_repo_from_query(query: str, default: Optional[str] = None) -> str:\n    q = (query or \"\").lower().strip()\n    # Allow explicit prefix: \"<name>: question\"\n    if \":\" in q:\n        cand, _ = q.split(\":\", 1)\n        cand = cand.strip()\n        if cand in [r.lower() for r in list_repos()]:\n            return cand\n    # Keyword voting across repos\n    best = None\n    best_hits = 0\n    for name in list_repos():\n        hits = 0\n        for kw in get_repo_keywords(name):\n            if kw and kw in q:\n                hits += 1\n        if hits > best_hits:\n            best = name\n            best_hits = hits\n    if best:\n        return best\n    return (default or get_default_repo())\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "fc489f4dd6de9ed3bb5ffc45cf935821"}
{"id": "7e5ead94f471", "file_path": "/Users/davidmontgomery/agro/faxbot_rag.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 12, "imports": ["import os", "from dotenv import load_dotenv", "from serve_rag import app"], "code": "import os\nfrom dotenv import load_dotenv\n\nload_dotenv('env/project.env')\nfrom serve_rag import app\n\nif __name__ == '__main__':\n    import uvicorn\n    os.environ['COLLECTION_NAME'] = os.environ.get('COLLECTION_NAME', f\"{os.environ['REPO']}_{os.environ.get('COLLECTION_SUFFIX','default')}\")\n    port = int(os.environ.get('PORT', '8014'))\n    uvicorn.run(app, host='127.0.0.1', port=port)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "50ce60b8cb11dbab33e3f0aefea07100"}
{"id": "a424c9848d79", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 20, "imports": ["import os", "import json", "import collections", "from typing import List, Dict", "from pathlib import Path", "from config_loader import choose_repo_from_query, get_default_repo, out_dir", "from dotenv import load_dotenv, find_dotenv", "from qdrant_client import QdrantClient, models", "import bm25s", "from bm25s.tokenization import Tokenizer", "from Stemmer import Stemmer", "from rerank import rerank_results as ce_rerank", "from env_model import generate_text"], "code": "import os\nimport json\nimport collections\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom config_loader import choose_repo_from_query, get_default_repo, out_dir\nfrom dotenv import load_dotenv, find_dotenv\n# Load any existing env ASAP so downstream imports (e.g., rerank backend) see them\ntry:\n    load_dotenv(override=False)\nexcept Exception:\n    pass\nfrom qdrant_client import QdrantClient, models\nimport bm25s\nfrom bm25s.tokenization import Tokenizer\nfrom Stemmer import Stemmer\nfrom rerank import rerank_results as ce_rerank\nfrom env_model import generate_text\n\n# Query intent → layer preferences", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "068d8f77dfb3311b07c83834cfcc5d1a"}
{"id": "98d3c459903b", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 14, "imports": [], "code": "_classify_query(q:str)->str:\n    ql=(q or '').lower()\n    if any(k in ql for k in ['ui','react','component','tsx','page','frontend','render','css']):\n        return 'ui'\n    if any(k in ql for k in ['notification','pushover','apprise','hubspot','provider','integration','adapter','webhook']):\n        return 'integration'\n    if any(k in ql for k in ['diagnostic','health','event log','phi','mask','hipaa','middleware','auth','token','oauth','hmac']):\n        return 'server'\n    if any(k in ql for k in ['sdk','client library','python sdk','node sdk']):\n        return 'sdk'\n    if any(k in ql for k in ['infra','asterisk','sip','t.38','ami','freeswitch','egress','cloudflared']):\n        return 'infra'\n    return 'server'\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ef9aafb7a212e9d71278c929a92e1fb5"}
{"id": "8cd3973902e9", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 10, "imports": [], "code": "_project_layer_bonus(layer:str,intent:str)->float:\n    layer_lower=(layer or '').lower()\n    intent_lower=(intent or 'server').lower()\n    table={'server':{'kernel':0.10,'plugin':0.04,'ui':0.00,'docs':0.00,'tests':0.00,'infra':0.02},\n           'integration':{'integration':0.12,'kernel':0.04,'ui':0.00,'docs':0.00,'tests':0.00,'infra':0.00},\n           'ui':{'ui':0.12,'docs':0.06,'kernel':0.02,'plugin':0.02,'tests':0.00,'infra':0.00},\n           'sdk':{'kernel':0.04,'docs':0.02},\n           'infra':{'infra':0.12,'kernel':0.04}}\n    return table.get(intent_lower,{}).get(layer_lower,0.0)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "badbb036ebe27117d7162e8dd9526eb2"}
{"id": "b994f1fe46af", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 15, "imports": [], "code": "_project_layer_bonus(layer:str,intent:str)->float:\n    layer_lower=(layer or '').lower()\n    intent_lower=(intent or 'server').lower()\n    table={'server':{'server':0.10,'integration':0.06,'fax':0.30,'admin console':0.10,'sdk':0.00,'infra':0.00,'docs':0.02},\n           'integration':{'provider':0.12,'traits':0.10,'server':0.06,'ui':0.00,'sdk':0.00,'infra':0.02,'docs':0.00},\n           'ui':{'ui':0.12,'docs':0.06,'server':0.02,'hipaa':0.20},\n           'sdk':{'sdk':0.12,'server':0.04,'docs':0.02},\n           'infra':{'infra':0.12,'server':0.04,'provider':0.04}}\n    return table.get(intent_lower,{}).get(layer_lower,0.0)\n_provider_plugin_hint(fp:str, code:str)->float:\n    fp=(fp or '').lower()\n    code=(code or '').lower()\n    keys=['provider','providers','integration','adapter','webhook','pushover','apprise','hubspot']\n    return 0.06 if any(k in fp or k in code for k in keys) else 0.0\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "002b42f3b64bfaabe1fd1200e3d629f7"}
{"id": "83f95bdba62d", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 22, "imports": [], "code": "_origin_bonus(origin:str, mode:str)->float:\n    origin = (origin or '').lower()\n    mode=(mode or 'prefer_first_party').lower()\n    if mode == 'prefer_first_party':\n        return 0.06 if origin=='first_party' else (-0.08 if origin=='vendor' else 0.0)\n    if mode == 'prefer_vendor':\n        return 0.06 if origin=='vendor' else 0.0\n    return 0.0\n_feature_bonus(query:str, fp:str, code:str)->float:\n    ql = (query or '').lower()\n    fp = (fp or '').lower()\n    code=(code or '').lower()\n    bumps = 0.0\n    if any(k in ql for k in ['diagnostic','health','event log','phi','hipaa']):\n        if ('diagnostic' in fp) or ('diagnostic' in code) or ('event' in fp and 'log' in fp):\n            bumps += 0.06\n    return bumps\n_card_bonus(chunk_id: str, card_chunk_ids: set) -> float:\n    \"\"\"Boost chunks that matched via card-based retrieval.\"\"\"\n    return 0.08 if str(chunk_id) in card_chunk_ids else 0.0\n\n# Path-aware bonus to tilt results toward likely server/auth code", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "066bdcd6aab173b7d6f941173314d226"}
{"id": "5f93c47f5bd0", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 15, "imports": [], "code": "_path_bonus(fp: str) -> float:\n    fp = (fp or '').lower()\n    bonus = 0.0\n    for sfx, b in [\n        ('/identity/', 0.12),\n        ('/auth/', 0.12),\n        ('/server', 0.10),\n        ('/backend', 0.10),\n        ('/api/', 0.08),\n    ]:\n        if sfx in fp:\n            bonus += b\n    return bonus\n\n# Additional PROJECT-only path boosts (env-tunable)", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "bc17617323dcee12db58914fb40dbc01"}
{"id": "e83c174823a8", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 33, "imports": [], "code": "_project_path_boost(fp: str, repo_tag: str) -> float:\n    import os as _os\n    if (repo_tag or '').lower() != 'project':\n        return 0.0\n    cfg = _os.getenv('project_PATH_BOOSTS', 'app/,lib/,config/,scripts/,server/,api/,api/app,app/services,app/routers,api/admin_ui,app/plugins')\n    tokens = [t.strip().lower() for t in cfg.split(',') if t.strip()]\n    s = (fp or '').lower()\n    bonus = 0.0\n    for tok in tokens:\n        if tok and tok in s:\n            bonus += 0.06\n    return min(bonus, 0.18)\n\n# Load environment from repo root .env without hard-coded paths\ntry:\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / \".env\"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nQDRANT_URL = os.getenv('QDRANT_URL','http://127.0.0.1:6333')\nREPO = os.getenv('REPO','project')\nVENDOR_MODE = os.getenv('VENDOR_MODE','prefer_first_party')\n# Allow explicit collection override (for versioned collections per embedding config)\nCOLLECTION = os.getenv('COLLECTION_NAME', f'code_chunks_{REPO}')\n\n# --- Embeddings provider (openai | voyage | local) ---", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8ffd301b15d65406b81535a2285eae37"}
{"id": "3d263a367be8", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 9, "imports": [], "code": "_lazy_import_openai():\n    from openai import OpenAI\n    return OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n_lazy_import_voyage():\n    import voyageai\n    return voyageai.Client(api_key=os.getenv(\"VOYAGE_API_KEY\"))\n\n_local_embed_model = None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "eb826631fc9c3c285ffbf30ad7c21c00"}
{"id": "9be740f5e75a", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 17, "imports": [], "code": "_get_embedding(text: str, kind: str = \"query\") -> list[float]:\n    et = (os.getenv(\"EMBEDDING_TYPE\", \"openai\") or \"openai\").lower()\n    if et == \"voyage\":\n        vo = _lazy_import_voyage()\n        out = vo.embed([text], model=\"voyage-code-3\", input_type=kind, output_dimension=512)\n        return out.embeddings[0]\n    if et == \"local\":\n        global _local_embed_model\n        if _local_embed_model is None:\n            from sentence_transformers import SentenceTransformer\n            _local_embed_model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n        # Normalize embeddings for cosine distance\n        return _local_embed_model.encode([text], normalize_embeddings=True, show_progress_bar=False)[0].tolist()\n    # default openai\n    client = _lazy_import_openai()\n    resp = client.embeddings.create(input=text, model=\"text-embedding-3-large\")\n    return resp.data[0].embedding", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "91a903533f645877fc9d33fb856a7a01"}
{"id": "c1498a7fec3d", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "rrf(\n    dense: list,\n    sparse: list,\n    k: int = 10,\n    kdiv: int = 60\n) -> list:\n    \"\"\"\n    Reciprocal Rank Fusion (RRF) for combining dense and sparse retrieval results.\n\n    Args:\n        dense (List): Ranked list of IDs from dense retrieval.\n        sparse (List): Ranked list of IDs from sparse retrieval.\n        k (int, optional): Number of top results to return. Defaults to 10.\n        kdiv (int, optional): RRF constant to dampen rank impact. Defaults to 60.\n\n    Returns:\n        List: Top-k fused IDs by RRF score.\n    \"\"\"\n    score: dict = collections.defaultdict(float)\n    for rank, pid in enumerate(dense, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    for rank, pid in enumerate(sparse, start=1):\n        score[pid] += 1.0 / (kdiv + rank)\n    ranked = sorted(score.items(), key=lambda x: x[1], reverse=True)\n    return [pid for pid, _ in ranked[:k]]", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0e171d7b1306977042317fa785de3e30"}
{"id": "8d28812cb0bb", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "_load_chunks(repo: str) -> List[Dict]:\n    \"\"\"Load minimal chunk metadata (omit code to reduce memory).\"\"\"\n    p = os.path.join(out_dir(repo), 'chunks.jsonl')\n    chunks: List[Dict] = []\n    if os.path.exists(p):\n        with open(p, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                # Drop bulky fields to keep memory bounded\n                o.pop('code', None)\n                o.pop('summary', None)\n                o.pop('keywords', None)\n                chunks.append(o)\n    return chunks\n_load_bm25_map(idx_dir: str):\n    # Prefer point IDs (UUID strings) aligned with Qdrant\n    pid_json = os.path.join(idx_dir, 'bm25_point_ids.json')\n    if os.path.exists(pid_json):\n        m = json.load(open(pid_json))\n        return [m[str(i)] for i in range(len(m))]\n    # Fallback to chunk_ids.txt (string chunk IDs)\n    map_path = os.path.join(idx_dir, 'chunk_ids.txt')\n    if os.path.exists(map_path):\n        with open(map_path, 'r', encoding='utf-8') as f:\n            ids = [line.strip() for line in f if line.strip()]\n        return ids\n    return None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f73b795ca762caa876e0ece6a238f0a6"}
{"id": "8b6ef853d69a", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "_load_cards_bm25(repo: str):\n    idx_dir = os.path.join(out_dir(repo), 'bm25_cards')\n    try:\n        import bm25s\n        retr = bm25s.BM25.load(idx_dir)\n        return retr\n    except Exception:\n        return None\n_load_cards_map(repo: str) -> Dict:\n    \"\"\"Load cards to get chunk ID mapping. Returns dict with card index -> chunk_id and chunk_id -> card data.\"\"\"\n    cards_file = os.path.join(out_dir(repo), 'cards.jsonl')\n    cards_by_idx = {}  # card corpus index -> chunk_id\n    cards_by_chunk_id = {}  # chunk_id -> card metadata\n    try:\n        with open(cards_file, 'r', encoding='utf-8') as f:\n            for idx, line in enumerate(f):\n                card = json.loads(line)\n                chunk_id = str(card.get('id', ''))\n                if chunk_id:\n                    cards_by_idx[idx] = chunk_id\n                    cards_by_chunk_id[chunk_id] = card\n        return {'by_idx': cards_by_idx, 'by_chunk_id': cards_by_chunk_id}\n    except Exception:\n        return {'by_idx': {}, 'by_chunk_id': {}}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6ef978a0c90b0591598f3fdbfad1474d"}
{"id": "1fd7f5b1731f", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 104, "imports": [], "code": "search(query: str, repo: str, topk_dense: int = 75, topk_sparse: int = 75, final_k: int = 10) -> List[Dict]:\n    chunks = _load_chunks(repo)\n    if not chunks:\n        return []\n\n    # ---- Dense (Qdrant) ----\n    dense_pairs = []\n    qc = QdrantClient(url=QDRANT_URL)\n    coll = os.getenv('COLLECTION_NAME', f'code_chunks_{repo}')\n    try:\n        e = _get_embedding(query, kind=\"query\")\n    except Exception:\n        e = []\n    try:\n        dres = qc.query_points(\n            collection_name=coll,\n            query=e,\n            using='dense',\n            limit=topk_dense,\n            with_payload=models.PayloadSelectorInclude(include=['file_path','start_line','end_line','language','layer','repo','hash','id'])\n        )\n        points = getattr(dres, 'points', dres)\n        dense_pairs = [(str(p.id), dict(p.payload)) for p in points]  # type: ignore\n    except Exception:\n        dense_pairs = []\n\n    # ---- Sparse (BM25S) ----\n    idx_dir = os.path.join(out_dir(repo), 'bm25_index')\n    retriever = bm25s.BM25.load(idx_dir)\n    tokenizer = Tokenizer(stemmer=Stemmer('english'), stopwords='en')\n    tokens = tokenizer.tokenize([query])\n    ids, _ = retriever.retrieve(tokens, k=topk_sparse)\n    # ids shaped (1, k)\n    ids = ids.tolist()[0] if hasattr(ids, 'tolist') else list(ids[0])\n    id_map = _load_bm25_map(idx_dir)\n    by_chunk_id = {str(c['id']): c for c in chunks}\n    sparse_pairs = []\n    for i in ids:\n        if id_map is not None:\n            if 0 <= i < len(id_map):\n                pid_or_cid = id_map[i]\n                key = str(pid_or_cid)\n                if key in by_chunk_id:\n                    # id_map contained chunk id\n                    sparse_pairs.append((key, by_chunk_id[key]))\n                else:\n                    # Fallback to corpus order alignment\n                    if 0 <= i < len(chunks):\n                        sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n        else:\n            # fallback to corpus order alignment\n            if 0 <= i < len(chunks):\n                sparse_pairs.append((str(chunks[i]['id']), chunks[i]))\n\n    # Card-based BM25 boosting: retrieve cards and boost matching chunks\n    card_chunk_ids: set = set()\n    cards_retr = _load_cards_bm25(repo)\n    if cards_retr is not None:\n        try:\n            cards_map = _load_cards_map(repo)\n            tokens = tokenizer.tokenize([query])\n            c_ids, _ = cards_retr.retrieve(tokens, k=min(topk_sparse, 30))\n            # Map card indices to chunk IDs\n            c_ids_flat = c_ids[0] if hasattr(c_ids, '__getitem__') else c_ids\n            for card_idx in c_ids_flat:\n                chunk_id = cards_map['by_idx'].get(int(card_idx))\n                if chunk_id:\n                    card_chunk_ids.add(str(chunk_id))\n        except Exception:\n            pass\n\n    # Fuse\n    dense_ids = [pid for pid,_ in dense_pairs]\n    sparse_ids = [pid for pid,_ in sparse_pairs]\n    fused = rrf(dense_ids, sparse_ids, k=max(final_k, 2*final_k)) if dense_pairs else sparse_ids[:final_k]\n    by_id = {pid: p for pid,p in (dense_pairs + sparse_pairs)}\n    docs = [by_id[pid] for pid in fused if pid in by_id]\n    # Hydrate code bodies with a low-memory strategy (lazy, on-demand)\n    HYDRATION_MODE = (os.getenv('HYDRATION_MODE','lazy') or 'lazy').lower()\n    if HYDRATION_MODE != 'none':\n        _hydrate_docs_inplace(repo, docs)\n    docs = ce_rerank(query, docs, top_k=final_k)\n    # Apply path + layer intent + provider + feature + card + (optional) origin bonuses, then resort\n    intent = _classify_query(query)\n    for d in docs:\n        layer_bonus = _project_layer_bonus(d.get('layer',''), intent) if repo=='project' else _project_layer_bonus(d.get('layer',''), intent)\n        origin_bonus = _origin_bonus(d.get('origin',''), VENDOR_MODE) if 'VENDOR_MODE' in os.environ else 0.0\n        repo_tag = d.get('repo', repo)\n        chunk_id = str(d.get('id', ''))\n        d['rerank_score'] = float(\n            d.get('rerank_score', 0.0)\n            + _path_bonus(d.get('file_path', ''))\n            + _project_path_boost(d.get('file_path',''), repo_tag)\n            + layer_bonus\n            + _provider_plugin_hint(d.get('file_path', ''), d.get('code', '')[:1000])\n            + _feature_bonus(query, d.get('file_path',''), d.get('code','')[:800])\n            + _card_bonus(chunk_id, card_chunk_ids)\n            + origin_bonus\n        )\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n    return docs[:final_k]\n\n# Local code cache to hydrate code bodies from chunks.jsonl instead of Qdrant payloads\n_code_cache_by_repo: dict[str, dict] = {}", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "38e8d4a96fe648aa2ae867357f29f552"}
{"id": "2c6d69068811", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "_load_code_cache(repo: str):\n    import json\n    if repo in _code_cache_by_repo:\n        return _code_cache_by_repo[repo]\n    jl = os.path.join(out_dir(repo), 'chunks.jsonl')\n    cache: dict[str, dict[str, str]] = {'by_hash': {}, 'by_id': {}}\n    try:\n        with open(jl, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                h = o.get('hash')\n                cid = str(o.get('id', ''))\n                code = o.get('code', '')\n                if h:\n                    cache['by_hash'][h] = code\n                if cid:\n                    cache['by_id'][cid] = code\n    except FileNotFoundError:\n        pass\n    _code_cache_by_repo[repo] = cache\n    return cache\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8ce0308e90c4514c7729cd27e1538295"}
{"id": "5f6e8d694b16", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 49, "imports": [], "code": "_hydrate_docs_inplace(repo: str, docs: List[Dict]) -> None:\n    \"\"\"Fill missing code for the selected docs by streaming chunks.jsonl once.\n\n    Avoids loading the entire repo into memory. Honors HYDRATION_MAX_CHARS to cap snippet size.\n    \"\"\"\n    needed_ids: set[str] = set()\n    needed_hashes: set[str] = set()\n    for d in docs:\n        if d.get('code'):\n            continue\n        cid = str(d.get('id','') or '')\n        h = d.get('hash')\n        if cid:\n            needed_ids.add(cid)\n        if h:\n            needed_hashes.add(h)\n    if not needed_ids and not needed_hashes:\n        return\n    jl = os.path.join(out_dir(repo), 'chunks.jsonl')\n    max_chars = int(os.getenv('HYDRATION_MAX_CHARS', '2000') or '2000')\n    found_by_id: dict[str, str] = {}\n    found_by_hash: dict[str, str] = {}\n    try:\n        with open(jl, 'r', encoding='utf-8') as f:\n            for line in f:\n                try:\n                    o = json.loads(line)\n                except Exception:\n                    continue\n                cid = str(o.get('id','') or '')\n                h = o.get('hash')\n                code = (o.get('code') or '')\n                if max_chars > 0 and code:\n                    code = code[:max_chars]\n                if cid and cid in needed_ids and cid not in found_by_id:\n                    found_by_id[cid] = code\n                if h and h in needed_hashes and h not in found_by_hash:\n                    found_by_hash[h] = code\n                if len(found_by_id) >= len(needed_ids) and len(found_by_hash) >= len(needed_hashes):\n                    break\n    except FileNotFoundError:\n        return\n    for d in docs:\n        if not d.get('code'):\n            cid = str(d.get('id','') or '')\n            h = d.get('hash')\n            d['code'] = found_by_id.get(cid) or (found_by_hash.get(h) if h else '') or ''\n\n# --- filename/path boosts applied post-rerank ---", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a9bcd6ba833eb812c77066e5e88f9448"}
{"id": "93811afd8153", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 15, "imports": [], "code": "_apply_filename_boosts(docs: list[dict], question: str) -> None:\n    terms = set((question or '').lower().replace('/', ' ').replace('-', ' ').split())\n    for d in docs:\n        fp = (d.get('file_path') or '').lower()\n        fn = os.path.basename(fp)\n        parts = fp.split('/')\n        score = float(d.get('rerank_score', 0.0) or 0.0)\n        if any(t and t in fn for t in terms):\n            score *= 1.5\n        if any(t and t in p for t in terms for p in parts):\n            score *= 1.2\n        d['rerank_score'] = score\n    docs.sort(key=lambda x: x.get('rerank_score', 0.0), reverse=True)\n\n# --- Strict per-repo routing helpers (no fusion) ---", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0fa0fa4f2717d11cb2cd7b16e2acc07d"}
{"id": "1351e64494a0", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 24, "imports": [], "code": "route_repo(query: str, default_repo: str | None = None) -> str:\n    \"\"\"Route to a repo using repos.json config and lightweight prefixing.\n\n    - Supports explicit prefix: \"<name>: question\"\n    - Falls back to keyword voting as configured in repos.json\n    - Defaults to configured default_repo (repos.json) or env REPO\n    \"\"\"\n    try:\n        # Prefer config-driven choice (handles prefixes + keywords)\n        return choose_repo_from_query(query, default=(default_repo or get_default_repo()))\n    except Exception:\n        # Very safe fallback\n        q = (query or '').lower().strip()\n        if ':' in q:\n            cand, _ = q.split(':', 1)\n            cand = cand.strip()\n            if cand:\n                return cand\n        return (default_repo or os.getenv('REPO', 'project') or 'project').strip()\nsearch_routed(query: str, repo_override: str | None = None, final_k: int = 10):\n    repo = (repo_override or route_repo(query, default_repo=os.getenv('REPO', 'project')) or os.getenv('REPO', 'project')).strip()\n    return search(query, repo=repo, final_k=final_k)\n\n# Multi-query expansion (cheap) and routed search", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d3ed337175ee54ea147a77da28757db3"}
{"id": "3a881ffffe2a", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 17, "imports": [], "code": "expand_queries(query: str, m: int = 4) -> list[str]:\n    # Fast path: no expansion requested\n    if m <= 1:\n        return [query]\n    try:\n        sys = \"Rewrite a developer query into multiple search-friendly variants without changing meaning.\"\n        user = f\"Count: {m}\\nQuery: {query}\\nOutput one variant per line, no numbering.\"\n        text, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n        lines = [ln.strip('- ').strip() for ln in (text or '').splitlines() if ln.strip()]\n        uniq = []\n        for ln in lines:\n            if ln and ln not in uniq:\n                uniq.append(ln)\n        return (uniq or [query])[:m]\n    except Exception:\n        return [query]\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "50a8de59d1b9cb7b21067671d9a4830e"}
{"id": "b831f7529ac5", "file_path": "/Users/davidmontgomery/agro/hybrid_search.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "search_routed_multi(query: str, repo_override: str | None = None, m: int = 4, final_k: int = 10):\n    repo = (repo_override or route_repo(query) or os.getenv('REPO','project')).strip()\n    variants = expand_queries(query, m=m)\n    all_docs = []\n    for qv in variants:\n        docs = search(qv, repo=repo, final_k=final_k)\n        all_docs.extend(docs)\n    # Deduplicate by file_path + line span\n    seen = set()\n    uniq = []\n    for d in all_docs:\n        key = (d.get('file_path'), d.get('start_line'), d.get('end_line'))\n        if key in seen:\n            continue\n        seen.add(key)\n        uniq.append(d)\n    # Rerank union\n    try:\n        from rerank import rerank_results as ce_rerank\n        reranked = ce_rerank(query, uniq, top_k=final_k)\n        _apply_filename_boosts(reranked, query)\n        return reranked\n    except Exception:\n        return uniq[:final_k]\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7b2ec11925244e919556873f5fbd0fee"}
{"id": "691d6a6bffb8", "file_path": "/Users/davidmontgomery/agro/watchdog.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 32, "imports": ["from __future__ import annotations", "import json", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"\nEnterprise Compatibility Watchdog (stub)\n\n- Reads compat_rules.json and prints a summary\n- Intended to be extended with collectors (GitHub issues, release notes) and emit rules/alerts\n\"\"\"\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\n\nROOT = Path(__file__).resolve().parent\nRULES = ROOT / \"compat_rules.json\"\n\nmain() -> int:\n    if RULES.exists():\n        try:\n            data = json.loads(RULES.read_text())\n        except Exception:\n            data = []\n    else:\n        data = []\n    print(f\"[watchdog] Loaded {len(data)} compat rule(s) from {RULES}\")\n    for i, r in enumerate(data[:10], start=1):\n        print(f\"  {i}. {r.get('id')} — {r.get('message')}\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(main())\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0b9f33ce8d772d131b6f95e9a6706b2f"}
{"id": "22dee42cce27", "file_path": "/Users/davidmontgomery/agro/filtering.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "# coding: utf-8\n\nPRUNE_DIRS = {\n    '.git', '.worktrees', '.venv', 'venv', 'env', '.venv_ci',\n    'node_modules', 'vendor', 'dist', 'build',\n    '.next', '.turbo', '.svelte-kit', 'coverage',\n    'site', '_site', '__pycache__', '.pytest_cache', '.mypy_cache', '.cache'\n}\n\nVALID_EXTS = (\n    '.py', '.ts', '.tsx', '.js', '.jsx', '.go', '.rs', '.java', '.c', '.cpp',\n    '.md', '.mdx', '.yaml', '.yml', '.toml', '.json'\n)\n\nSKIP_EXTS = ('.map', '.pyc', '.ds_store')\n_should_index_file(name):\n    n = name.lower()\n    if n.endswith(SKIP_EXTS):\n        return False\n    return n.endswith(VALID_EXTS)\n_prune_dirs_in_place(dirs):\n    # remove noisy dirs without descending into them\n    dirs[:] = [d for d in dirs if d not in PRUNE_DIRS]\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "94c4599a5ade63d95c45e2876962f3b3"}
{"id": "1d62ddf4621d", "file_path": "/Users/davidmontgomery/agro/env_model.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 29, "imports": ["import os", "import json", "from typing import Optional, Dict, Any, Tuple"], "code": "import os\nimport json\nfrom typing import Optional, Dict, Any, Tuple\n\ntry:\n    from openai import OpenAI\nexcept Exception as e:\n    raise RuntimeError(\"openai>=1.x is required for Responses API\") from e\n\n# Model pin (Responses API): default to OpenAI gpt-4o-mini\n# Users can override with GEN_MODEL (e.g., gpt-4.1, o4-mini, gpt-4o)\n# Avoid local defaults; prefer OpenAI to reduce confusion.\n_DEFAULT_MODEL = os.getenv(\"GEN_MODEL\", os.getenv(\"ENRICH_MODEL\", \"gpt-4o-mini\"))\n\n_client = None\n\n# MLX backend (lazy-loaded for Apple Silicon)\n_mlx_model = None\n_mlx_tokenizer = None\n_get_mlx_model():\n    \"\"\"Lazy-load MLX model for Apple Silicon generation\"\"\"\n    global _mlx_model, _mlx_tokenizer\n    if _mlx_model is None:\n        from mlx_lm import load\n        model_name = os.getenv(\"GEN_MODEL\", \"mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit\")\n        _mlx_model, _mlx_tokenizer = load(model_name)\n    return _mlx_model, _mlx_tokenizer\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e4dbd875b610ac0b29598094199f21c8"}
{"id": "4b25e84d1015", "file_path": "/Users/davidmontgomery/agro/env_model.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "client() -> OpenAI:\n    global _client\n    if _client is None:\n        # Let OPENAI_API_KEY and OPENAI_BASE_URL (if set) drive the target\n        # This allows using OpenAI-hosted models or an OpenAI-compatible server (e.g., vLLM/Ollama proxy)\n        _client = OpenAI()\n    return _client\n\n_extract_text(resp: Any) -> str:\n    # Prefer .output_text if present (library convenience), else parse the structure\n    txt = \"\"\n    if hasattr(resp, \"output_text\") and isinstance(getattr(resp, \"output_text\"), str):\n        txt = resp.output_text\n        if txt:\n            return txt\n    try:\n        # Fallback path: resp.output[0].content[0].text\n        out = getattr(resp, \"output\", None)\n        if out and len(out) > 0:\n            cont = getattr(out[0], \"content\", None)\n            if cont and len(cont) > 0 and hasattr(cont[0], \"text\"):\n                return cont[0].text or \"\"\n    except Exception:\n        pass\n    return txt or \"\"\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1695b151aa4489d22f2d0defe3da62a0"}
{"id": "d37ec217af36", "file_path": "/Users/davidmontgomery/agro/env_model.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 163, "imports": [], "code": "generate_text(\n    user_input: str,\n    *,\n    system_instructions: Optional[str] = None,\n    model: Optional[str] = None,\n    reasoning_effort: Optional[str] = None,  # e.g., \"low\" | \"medium\" | \"high\"\n    response_format: Optional[Dict[str, Any]] = None,  # e.g., {\"type\":\"json_object\"}\n    store: bool = False,\n    previous_response_id: Optional[str] = None,\n    extra: Optional[Dict[str, Any]] = None,\n) -> Tuple[str, Any]:\n    \"\"\"\n    Minimal wrapper over Responses API:\n      - Uses 'instructions' for system prompt and 'input' for user text\n      - Supports response_format (JSON mode / structured)\n      - Leaves tool-calling to upstream if needed (MCP/file_search handled elsewhere)\n    \"\"\"\n    mdl = model or _DEFAULT_MODEL\n    kwargs: Dict[str, Any] = {\n        \"model\": mdl,\n        \"input\": user_input,\n        \"store\": store,\n    }\n    if system_instructions:\n        kwargs[\"instructions\"] = system_instructions\n    if reasoning_effort:\n        kwargs[\"reasoning\"] = {\"effort\": reasoning_effort}\n    if response_format:\n        kwargs[\"response_format\"] = response_format\n    if previous_response_id:\n        kwargs[\"previous_response_id\"] = previous_response_id\n    if extra:\n        kwargs.update(extra)\n\n    # Check for MLX backend (Apple Silicon, highest priority for local models)\n    ENRICH_BACKEND = os.getenv(\"ENRICH_BACKEND\", \"\").lower()\n    is_mlx_model = mdl.startswith(\"mlx-community/\") if mdl else False\n    prefer_mlx = (ENRICH_BACKEND == \"mlx\") or is_mlx_model\n\n    if prefer_mlx:\n        try:\n            from mlx_lm import generate\n            model, tokenizer = _get_mlx_model()\n\n            # Build prompt with system instructions if provided\n            sys_text = (system_instructions or \"\").strip()\n            prompt = (f\"<system>{sys_text}</system>\\n\" if sys_text else \"\") + user_input\n\n            # Generate with MLX\n            text = generate(\n                model,\n                tokenizer,\n                prompt=prompt,\n                max_tokens=2048,  # More tokens for answer generation\n                verbose=False\n            )\n            return text, {\"response\": text, \"backend\": \"mlx\"}\n        except Exception as e:\n            # Fall through to Ollama/OpenAI on MLX failure\n            pass\n\n    # If using a local model server (Ollama-compatible), prefer its API first when configured\n    OLLAMA_URL = os.getenv(\"OLLAMA_URL\")\n    prefer_ollama = bool(OLLAMA_URL)\n    if prefer_ollama:\n        try:\n            import requests, json as _json, time\n            sys_text = (system_instructions or \"\").strip()\n            prompt = (f\"<system>{sys_text}</system>\\n\" if sys_text else \"\") + user_input\n            url = OLLAMA_URL.rstrip(\"/\") + \"/generate\"\n\n            # Retry configuration (production hardening)\n            max_retries = 2\n            chunk_timeout = 60  # 60s per chunk\n            total_timeout = 300  # 5min hard cap\n\n            for attempt in range(max_retries + 1):\n                start_time = time.time()\n                try:\n                    # Prefer streaming to avoid long blocking on large models\n                    with requests.post(url, json={\n                        \"model\": mdl,\n                        \"prompt\": prompt,\n                        \"stream\": True,\n                        \"options\": {\"temperature\": 0.2, \"num_ctx\": 8192},\n                    }, timeout=chunk_timeout, stream=True) as r:\n                        r.raise_for_status()\n                        buf = []\n                        last = None\n                        for line in r.iter_lines(decode_unicode=True):\n                            # Check total timeout\n                            if time.time() - start_time > total_timeout:\n                                # Return partial output on timeout\n                                partial = (\"\".join(buf) or \"\").strip()\n                                if partial:\n                                    return partial + \" [TIMEOUT]\", {\"response\": partial, \"timeout\": True}\n                                break\n\n                            if not line:\n                                continue\n                            try:\n                                obj = _json.loads(line)\n                            except Exception:\n                                continue\n                            if isinstance(obj, dict):\n                                seg = (obj.get(\"response\") or \"\")\n                                if seg:\n                                    buf.append(seg)\n                                last = obj\n                                if obj.get(\"done\") is True:\n                                    break\n\n                        text = (\"\".join(buf) or \"\").strip()\n                        if text:\n                            return text, (last or {\"response\": text})\n\n                    # Fallback to non-stream if streaming returned empty\n                    resp = requests.post(url, json={\n                        \"model\": mdl,\n                        \"prompt\": prompt,\n                        \"stream\": False,\n                        \"options\": {\"temperature\": 0.2, \"num_ctx\": 8192},\n                    }, timeout=total_timeout)\n                    resp.raise_for_status()\n                    data = resp.json()\n                    text = (data.get(\"response\") or \"\").strip()\n                    if text:\n                        return text, data\n\n                except (requests.Timeout, requests.ConnectionError) as e:\n                    # Retry on network errors\n                    if attempt < max_retries:\n                        backoff = 2 ** attempt  # Exponential backoff: 1s, 2s\n                        time.sleep(backoff)\n                        continue\n                    # Last attempt failed, fall through to OpenAI\n                    pass\n                except Exception:\n                    # Other errors, don't retry\n                    break\n        except Exception:\n            pass\n    # Try OpenAI Responses API\n    try:\n        resp = client().responses.create(**kwargs)\n        text = _extract_text(resp)\n        return text, resp\n    except Exception:\n        # Fallback to Chat Completions for OpenAI-compatible servers that don't expose Responses API\n        try:\n            messages = []\n            if system_instructions:\n                messages.append({\"role\": \"system\", \"content\": system_instructions})\n            messages.append({\"role\": \"user\", \"content\": user_input})\n            ckwargs: Dict[str, Any] = {\"model\": mdl, \"messages\": messages}\n            if response_format and isinstance(response_format, dict):\n                ckwargs[\"response_format\"] = response_format\n            cc = client().chat.completions.create(**ckwargs)\n            text = (cc.choices[0].message.content if getattr(cc, \"choices\", []) else \"\") or \"\"\n            return text, cc\n        except Exception as e:\n            raise RuntimeError(f\"Generation failed for model={mdl}: {e}\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c09791d0348d063cef4638e73ed96ba0"}
{"id": "d33015f6b365", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 29, "imports": ["import os", "import sys", "import json", "import time", "import argparse", "from pathlib import Path", "from typing import Dict, List, Any", "from dotenv import load_dotenv", "from eval_rag import main as run_eval, hit, GOLDEN_PATH, USE_MULTI, FINAL_K", "from hybrid_search import search_routed, search_routed_multi"], "code": "#!/usr/bin/env python3\n\"\"\"\nMinimal eval loop with regression tracking.\n\nUsage:\n  python eval_loop.py                    # Run once\n  python eval_loop.py --watch            # Run on file changes\n  python eval_loop.py --baseline         # Save current results as baseline\n  python eval_loop.py --compare          # Compare against baseline\n\"\"\"\nimport os\nimport sys\nimport json\nimport time\nimport argparse\nfrom pathlib import Path\nfrom typing import Dict, List, Any\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Import eval logic\nfrom eval_rag import main as run_eval, hit, GOLDEN_PATH, USE_MULTI, FINAL_K\nfrom hybrid_search import search_routed, search_routed_multi\n\n\nBASELINE_PATH = os.getenv('BASELINE_PATH', 'eval_baseline.json')\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "682adabb218fe48d9f884f7b6316d8cb"}
{"id": "c456424a8084", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 57, "imports": [], "code": "run_eval_with_results() -> Dict[str, Any]:\n    \"\"\"Run eval and return detailed results.\"\"\"\n    if not os.path.exists(GOLDEN_PATH):\n        return {\"error\": f\"No golden file at {GOLDEN_PATH}\"}\n\n    gold = json.load(open(GOLDEN_PATH))\n    total = len(gold)\n    hits_top1 = 0\n    hits_topk = 0\n    results = []\n\n    t0 = time.time()\n    for i, row in enumerate(gold, 1):\n        q = row['q']\n        repo = row.get('repo') or os.getenv('REPO', 'project')\n        expect = row.get('expect_paths') or []\n\n        if USE_MULTI:\n            docs = search_routed_multi(q, repo_override=repo, m=4, final_k=FINAL_K)\n        else:\n            docs = search_routed(q, repo_override=repo, final_k=FINAL_K)\n\n        paths = [d.get('file_path', '') for d in docs]\n        top1_hit = hit(paths[:1], expect) if paths else False\n        topk_hit = hit(paths, expect) if paths else False\n\n        if top1_hit:\n            hits_top1 += 1\n        if topk_hit:\n            hits_topk += 1\n\n        results.append({\n            \"question\": q,\n            \"repo\": repo,\n            \"expect_paths\": expect,\n            \"top1_path\": paths[:1],\n            \"top1_hit\": top1_hit,\n            \"topk_hit\": topk_hit,\n            \"top_paths\": paths[:FINAL_K]\n        })\n\n    dt = time.time() - t0\n\n    return {\n        \"total\": total,\n        \"top1_hits\": hits_top1,\n        \"topk_hits\": hits_topk,\n        \"top1_accuracy\": round(hits_top1 / max(1, total), 3),\n        \"topk_accuracy\": round(hits_topk / max(1, total), 3),\n        \"final_k\": FINAL_K,\n        \"use_multi\": USE_MULTI,\n        \"duration_secs\": round(dt, 2),\n        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"results\": results\n    }\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ff224a6fd988e0b9c1eabc333f2b1e62"}
{"id": "c8ffeb04436a", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 7, "imports": [], "code": "save_baseline(results: Dict[str, Any]):\n    \"\"\"Save current results as baseline.\"\"\"\n    with open(BASELINE_PATH, 'w') as f:\n        json.dump(results, f, indent=2)\n    print(f\"✓ Baseline saved to {BASELINE_PATH}\")\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1212abb5c49027c0d809694b50b62995"}
{"id": "2f644af27dfe", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 63, "imports": [], "code": "compare_with_baseline(current: Dict[str, Any]):\n    \"\"\"Compare current results with baseline.\"\"\"\n    if not os.path.exists(BASELINE_PATH):\n        print(f\"⚠ No baseline found at {BASELINE_PATH}\")\n        print(f\"  Run with --baseline to create one\")\n        return\n\n    with open(BASELINE_PATH) as f:\n        baseline = json.load(f)\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"REGRESSION CHECK: Current vs Baseline\")\n    print(\"=\"*60)\n\n    curr_top1 = current[\"top1_accuracy\"]\n    base_top1 = baseline[\"top1_accuracy\"]\n    curr_topk = current[\"topk_accuracy\"]\n    base_topk = baseline[\"topk_accuracy\"]\n\n    delta_top1 = curr_top1 - base_top1\n    delta_topk = curr_topk - base_topk\n\n    print(f\"\\nTop-1 Accuracy:\")\n    print(f\"  Baseline: {base_top1:.3f}\")\n    print(f\"  Current:  {curr_top1:.3f}\")\n    print(f\"  Delta:    {delta_top1:+.3f} {'✓' if delta_top1 >= 0 else '✗'}\")\n\n    print(f\"\\nTop-{FINAL_K} Accuracy:\")\n    print(f\"  Baseline: {base_topk:.3f}\")\n    print(f\"  Current:  {curr_topk:.3f}\")\n    print(f\"  Delta:    {delta_topk:+.3f} {'✓' if delta_topk >= 0 else '✗'}\")\n\n    # Check for regressions per-question\n    regressions = []\n    improvements = []\n\n    for i, (curr_res, base_res) in enumerate(zip(current[\"results\"], baseline[\"results\"])):\n        if curr_res[\"question\"] != base_res[\"question\"]:\n            continue  # skip if questions don't align\n\n        if base_res[\"top1_hit\"] and not curr_res[\"top1_hit\"]:\n            regressions.append((i+1, curr_res[\"question\"], curr_res[\"repo\"]))\n        elif not base_res[\"top1_hit\"] and curr_res[\"top1_hit\"]:\n            improvements.append((i+1, curr_res[\"question\"], curr_res[\"repo\"]))\n\n    if regressions:\n        print(f\"\\n⚠ REGRESSIONS ({len(regressions)} questions):\")\n        for idx, q, repo in regressions:\n            print(f\"  [{idx}] {repo}: {q}\")\n\n    if improvements:\n        print(f\"\\n✓ IMPROVEMENTS ({len(improvements)} questions):\")\n        for idx, q, repo in improvements:\n            print(f\"  [{idx}] {repo}: {q}\")\n\n    if not regressions and delta_top1 >= -0.05 and delta_topk >= -0.05:\n        print(\"\\n✓ No significant regressions detected\")\n        return True\n    else:\n        print(\"\\n✗ Regressions detected!\")\n        return False\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b0e9b857ef4dbd80ee983e624ecba5d1"}
{"id": "d05306ee5f56", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 46, "imports": [], "code": "watch_mode():\n    \"\"\"Watch for file changes and re-run eval.\"\"\"\n    print(\"⏱ Watch mode: monitoring for changes...\")\n    print(f\"   Watching: {GOLDEN_PATH}, hybrid_search.py, langgraph_app.py\")\n\n    files_to_watch = [\n        GOLDEN_PATH,\n        \"hybrid_search.py\",\n        \"langgraph_app.py\",\n        \"index_repo.py\",\n        \"rerank.py\"\n    ]\n\n    last_mtimes = {}\n    for fp in files_to_watch:\n        if os.path.exists(fp):\n            last_mtimes[fp] = os.path.getmtime(fp)\n\n    while True:\n        time.sleep(5)\n        changed = False\n        for fp in files_to_watch:\n            if not os.path.exists(fp):\n                continue\n            mtime = os.path.getmtime(fp)\n            if fp not in last_mtimes or mtime > last_mtimes[fp]:\n                print(f\"\\n🔄 Change detected: {fp}\")\n                last_mtimes[fp] = mtime\n                changed = True\n\n        if changed:\n            print(\"\\n\" + \"=\"*60)\n            print(\"Running eval...\")\n            print(\"=\"*60)\n            results = run_eval_with_results()\n            if \"error\" in results:\n                print(f\"Error: {results['error']}\")\n            else:\n                print(json.dumps({\n                    \"top1_accuracy\": results[\"top1_accuracy\"],\n                    \"topk_accuracy\": results[\"topk_accuracy\"],\n                    \"total\": results[\"total\"],\n                    \"duration_secs\": results[\"duration_secs\"]\n                }, indent=2))\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b73166e42ef9d10aa84e06196dd992e3"}
{"id": "904bd7bab8b2", "file_path": "/Users/davidmontgomery/agro/eval_loop.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 50, "imports": [], "code": "main():\n    parser = argparse.ArgumentParser(description=\"RAG eval loop with regression tracking\")\n    parser.add_argument(\"--baseline\", action=\"store_true\", help=\"Save current results as baseline\")\n    parser.add_argument(\"--compare\", action=\"store_true\", help=\"Compare current results with baseline\")\n    parser.add_argument(\"--watch\", action=\"store_true\", help=\"Watch for file changes and re-run\")\n    parser.add_argument(\"--json\", action=\"store_true\", help=\"Output results as JSON\")\n\n    args = parser.parse_args()\n\n    if args.watch:\n        watch_mode()\n        return\n\n    print(\"Running eval...\")\n    results = run_eval_with_results()\n\n    if \"error\" in results:\n        print(f\"Error: {results['error']}\", file=sys.stderr)\n        sys.exit(1)\n\n    if args.json:\n        print(json.dumps(results, indent=2))\n    else:\n        print(\"\\n\" + \"=\"*60)\n        print(\"EVAL RESULTS\")\n        print(\"=\"*60)\n        print(f\"Total questions: {results['total']}\")\n        print(f\"Top-1 accuracy:  {results['top1_accuracy']:.1%} ({results['top1_hits']}/{results['total']})\")\n        print(f\"Top-{FINAL_K} accuracy: {results['topk_accuracy']:.1%} ({results['topk_hits']}/{results['total']})\")\n        print(f\"Duration:        {results['duration_secs']}s\")\n        print(f\"Timestamp:       {results['timestamp']}\")\n\n        # Show failures\n        failures = [r for r in results[\"results\"] if not r[\"topk_hit\"]]\n        if failures:\n            print(f\"\\n⚠ Failures ({len(failures)}):\")\n            for r in failures:\n                print(f\"  [{r['repo']}] {r['question']}\")\n                print(f\"    Expected: {r['expect_paths']}\")\n                print(f\"    Got: {r['top_paths'][:3]}\")\n\n    if args.baseline:\n        save_baseline(results)\n    elif args.compare:\n        compare_with_baseline(results)\n\n\nif __name__ == \"__main__\":\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "110f9fdd7316f3c37936bd160a211878"}
{"id": "d159f79a9c64", "file_path": "/Users/davidmontgomery/agro/build_cards.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": ["import os, json", "from typing import Dict", "from dotenv import load_dotenv", "from env_model import generate_text"], "code": "import os, json\nfrom typing import Dict\nfrom dotenv import load_dotenv\nfrom env_model import generate_text\n\nload_dotenv()\nREPO = os.getenv('REPO','project').strip()\nMAX_CHUNKS = int(os.getenv('CARDS_MAX','0') or '0')\nBASE = os.path.join(os.path.dirname(__file__), 'out.noindex', REPO)\nCHUNKS = os.path.join(BASE, 'chunks.jsonl')\nCARDS = os.path.join(BASE, 'cards.jsonl')\nCARDS_TXT = os.path.join(BASE, 'cards.txt')\nINDEX_DIR = os.path.join(BASE, 'bm25_cards')\n\nPROMPT = (\n    \"Summarize this code chunk for retrieval as a JSON object with keys: \"\n    \"symbols (array of names: functions/classes/components/routes), purpose (short sentence), \"\n    \"routes (array of route paths if any). Respond with only the JSON.\\n\\n\"\n)\niter_chunks():\n    with open(CHUNKS, 'r', encoding='utf-8') as f:\n        for line in f:\n            o = json.loads(line)\n            yield o\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "062e648b059e73bbd16c6c6155bfee67"}
{"id": "15d9f4123028", "file_path": "/Users/davidmontgomery/agro/build_cards.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 52, "imports": [], "code": "main():\n    os.makedirs(BASE, exist_ok=True)\n    # Responses API via env_model.generate_text\n    n = 0\n    with open(CARDS, 'w', encoding='utf-8') as out_json, open(CARDS_TXT, 'w', encoding='utf-8') as out_txt:\n        for ch in iter_chunks():\n            code = ch.get('code','')\n            fp = ch.get('file_path','')\n            snippet = code[:2000]\n            msg = PROMPT + snippet\n            try:\n                text, _ = generate_text(user_input=msg, system_instructions=None, reasoning_effort=None, response_format={\"type\": \"json_object\"})\n                content = (text or '').strip()\n                card: Dict = json.loads(content) if content else {\"symbols\": [], \"purpose\": \"\", \"routes\": []}\n            except Exception:\n                card = {\"symbols\": [], \"purpose\": \"\", \"routes\": []}\n            card['file_path'] = fp\n            card['id'] = ch.get('id')\n            out_json.write(json.dumps(card, ensure_ascii=False) + '\\n')\n            # Text for BM25\n            text = ' '.join(card.get('symbols', [])) + '\\n' + card.get('purpose','') + '\\n' + ' '.join(card.get('routes', [])) + '\\n' + fp\n            out_txt.write(text.replace('\\n',' ') + '\\n')\n            n += 1\n            if MAX_CHUNKS and n >= MAX_CHUNKS:\n                break\n    # Build BM25 over cards text\n    try:\n        import bm25s\n        from bm25s.tokenization import Tokenizer\n        from Stemmer import Stemmer\n        stemmer = Stemmer('english'); tok = Tokenizer(stemmer=stemmer, stopwords='en')\n        with open(CARDS_TXT,'r',encoding='utf-8') as f:\n            docs = [line.strip() for line in f if line.strip()]\n        tokens = tok.tokenize(docs)\n        retriever = bm25s.BM25(method='lucene', k1=1.2, b=0.65)\n        retriever.index(tokens)\n        # Workaround: ensure JSON-serializable vocab keys\n        try:\n            retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}\n        except Exception:\n            pass\n        os.makedirs(INDEX_DIR, exist_ok=True)\n        retriever.save(INDEX_DIR, corpus=docs)\n        tok.save_vocab(save_dir=INDEX_DIR)\n        tok.save_stopwords(save_dir=INDEX_DIR)\n        print(f\"Built cards BM25 index with {len(docs)} docs at {INDEX_DIR}\")\n    except Exception as e:\n        print('BM25 build failed:', e)\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "366b82608fdb56212b95fa06edfdd1a5"}
{"id": "6746069a5ec7", "file_path": "/Users/davidmontgomery/agro/feature_flags.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 38, "imports": ["import os"], "code": "\"\"\"\nFeature gating helpers.\n\n- is_pro(): True if edition/tier is 'pro' or 'enterprise'\n- is_enterprise(): True if edition/tier is 'enterprise'\n\nEnv controls (any of these work):\n- AGRO_EDITION=oss|pro|enterprise  (preferred)\n- TIER=free|pro|enterprise         (back-compat)\n- PRO_ENABLED=true/false           (optional override)\n- ENTERPRISE_ENABLED=true/false    (optional override)\n\"\"\"\nimport os\n\n_truthy(val: str | None) -> bool:\n    if not val:\n        return False\n    return val.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n\nis_pro() -> bool:\n    edition = (os.getenv(\"AGRO_EDITION\") or os.getenv(\"TIER\") or \"\").strip().lower()\n    if edition in {\"pro\", \"enterprise\"}:\n        return True\n    # Optional explicit override\n    if _truthy(os.getenv(\"PRO_ENABLED\")):\n        return True\n    if _truthy(os.getenv(\"ENTERPRISE_ENABLED\")):\n        return True\n    return False\n\nis_enterprise() -> bool:\n    edition = (os.getenv(\"AGRO_EDITION\") or os.getenv(\"TIER\") or \"\").strip().lower()\n    if edition == \"enterprise\":\n        return True\n    if _truthy(os.getenv(\"ENTERPRISE_ENABLED\")):\n        return True\n    return False\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3a0216468aaf7acb73a4f59520995dc6"}
{"id": "26247d120268", "file_path": "/Users/davidmontgomery/agro/mcp_server_http.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": ["from __future__ import annotations", "import os, json", "from typing import Dict, Any", "from fastmcp import FastMCP", "from langgraph_app import build_graph", "from hybrid_search import search_routed_multi", "from config_loader import list_repos"], "code": "from __future__ import annotations\nimport os, json\nfrom typing import Dict, Any\n\nfrom fastmcp import FastMCP\n\n# Reuse internal pipeline\nfrom langgraph_app import build_graph\nfrom hybrid_search import search_routed_multi\nfrom config_loader import list_repos\n\n\nmcp = FastMCP(\"rag-service\")\n_graph = None\n\n_get_graph():\n    global _graph\n    if _graph is None:\n        _graph = build_graph()\n    return _graph\n\n\n@mcp.tool()", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5f9278cc412bea4e709e9cc42394f62a"}
{"id": "8b02c1207761", "file_path": "/Users/davidmontgomery/agro/mcp_server_http.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "answer(repo: str, question: str) -> Dict[str, Any]:\n    \"\"\"Answer a codebase question using local LangGraph (retrieval+generation). Returns text + citations.\"\"\"\n    g = _get_graph()\n    allowed = set(list_repos())\n    if repo not in allowed:\n        return {\"error\": f\"invalid repo '{repo}', allowed={sorted(allowed)}\"}\n    cfg = {\"configurable\": {\"thread_id\": f\"http-{repo}\"}}\n    state = {\n        \"question\": question,\n        \"documents\": [],\n        \"generation\": \"\",\n        \"iteration\": 0,\n        \"confidence\": 0.0,\n        \"repo\": repo,\n    }\n    res = g.invoke(state, cfg)\n    docs = res.get(\"documents\", [])[:5]\n    citations = [f\"{d['file_path']}:{d['start_line']}-{d['end_line']}\" for d in docs]\n    return {\n        \"answer\": res.get(\"generation\", \"\"),\n        \"citations\": citations,\n        \"repo\": res.get(\"repo\", repo),\n        \"confidence\": float(res.get(\"confidence\", 0.0) or 0.0),\n    }\n\n\n@mcp.tool()", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "573264825742bff4d1aaec46d98eaaa6"}
{"id": "37fe581856fd", "file_path": "/Users/davidmontgomery/agro/mcp_server_http.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "search(repo: str, question: str, top_k: int = 10) -> Dict[str, Any]:\n    \"\"\"Retrieve relevant code locations without generation.\"\"\"\n    allowed = set(list_repos())\n    if repo not in allowed:\n        return {\"error\": f\"invalid repo '{repo}', allowed={sorted(allowed)}\"}\n    docs = search_routed_multi(question, repo_override=repo, m=4, final_k=top_k)\n    results = [\n        {\n            \"file_path\": d.get(\"file_path\", \"\"),\n            \"start_line\": d.get(\"start_line\", 0),\n            \"end_line\": d.get(\"end_line\", 0),\n            \"language\": d.get(\"language\", \"\"),\n            \"rerank_score\": float(d.get(\"rerank_score\", 0.0) or 0.0),\n            \"repo\": d.get(\"repo\", repo),\n        }\n        for d in docs\n    ]\n    return {\"results\": results, \"repo\": repo, \"count\": len(results)}\n\n\nif __name__ == \"__main__\":\n    # Serve over HTTP for remote MCP (platform evals). Use env overrides for host/port/path.\n    host = os.getenv(\"MCP_HTTP_HOST\", \"0.0.0.0\")\n    port = int(os.getenv(\"MCP_HTTP_PORT\", \"8013\"))\n    path = os.getenv(\"MCP_HTTP_PATH\", \"/mcp\")\n    mcp.run(transport=\"http\", host=host, port=port, path=path)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "63383791a40eef785a5db56a09190f1b"}
{"id": "c89da96a1a74", "file_path": "/Users/davidmontgomery/agro/sitecustomize.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "# Python auto-imports sitecustomize at startup if present in sys.path.\n# We use it to block legacy Chat Completions usage at runtime.\ntry:\n    import openai  # type: ignore\n\n    def _blocked(*_args, **_kwargs):  # noqa: D401\n        raise RuntimeError(\n            \"Legacy Chat Completions API is disabled. Use Responses API via env_model.generate_text().\\n\"\n            \"Docs: https://openai.com/index/new-tools-and-features-in-the-responses-api/\"\n        )\n\n    # Block classic patterns if present on this installed version\n    if hasattr(openai, \"ChatCompletion\"):\n        try:\n            openai.ChatCompletion.create = staticmethod(_blocked)  # type: ignore[attr-defined]\n        except Exception:\n            pass\n    # Some older clients expose nested chat.completions\n    if hasattr(openai, \"chat\"):\n        chat = getattr(openai, \"chat\")\n        if hasattr(chat, \"completions\"):\n            try:\n                chat.completions.create = _blocked  # type: ignore[attr-defined]\n            except Exception:\n                pass\nexcept Exception:\n    # If openai not installed yet, do nothing.\n    pass\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "011ffe557ccbf1dfacd0db9c1731bf3f"}
{"id": "62850620ab5a", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 33, "imports": ["import os, operator", "from typing import List, Dict, TypedDict, Annotated", "from pathlib import Path", "from dotenv import load_dotenv, find_dotenv", "from langgraph.graph import END, StateGraph", "from langgraph.checkpoint.redis import RedisSaver", "from hybrid_search import search_routed_multi as hybrid_search_routed_multi", "from env_model import generate_text"], "code": "import os, operator\nfrom typing import List, Dict, TypedDict, Annotated\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nfrom langgraph.graph import END, StateGraph\nfrom langgraph.checkpoint.redis import RedisSaver\nfrom hybrid_search import search_routed_multi as hybrid_search_routed_multi\nfrom env_model import generate_text\n\n# Load environment from repo root .env without hard-coded paths\ntry:\n    # Load any existing env first\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / \".env\"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nRAGState(TypedDict):\n    question: str\n    documents: Annotated[List[Dict], operator.add]\n    generation: str\n    iteration: int\n    confidence: float\n    repo: str\n\n# Responses API shim used via generate_text()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a1a78952c348519cce89d6d318617960"}
{"id": "c0a33ef05f94", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 20, "imports": [], "code": "should_use_multi_query(question: str) -> bool:\n    q = (question or '').lower().strip()\n    if len(q.split()) <= 3:\n        return False\n    for w in (\"how\", \"why\", \"explain\", \"compare\", \"tradeoff\"):\n        if w in q:\n            return True\n    return False\nretrieve_node(state: RAGState) -> Dict:\n    q = state['question']\n    repo = state.get('repo') if isinstance(state, dict) else None\n    mq = int(os.getenv('MQ_REWRITES','2')) if should_use_multi_query(q) else 1\n    docs = hybrid_search_routed_multi(q, repo_override=repo, m=mq, final_k=20)\n    conf = float(sum(d.get('rerank_score',0.0) for d in docs)/max(1,len(docs)))\n    # Propagate the routed repo into state so downstream nodes build correct headers\n    repo_used = (repo or (docs[0].get('repo') if docs else os.getenv('REPO','project')))\n    return {'documents': docs, 'confidence': conf, 'iteration': state.get('iteration',0)+1, 'repo': repo_used}\n\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d5eaa9308826785f6c2bee7f80eb1326"}
{"id": "9dbdc7cf5640", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 20, "imports": [], "code": "route_after_retrieval(state:RAGState)->str:\n    conf = float(state.get(\"confidence\", 0.0) or 0.0)\n    it = int(state.get(\"iteration\", 0) or 0)\n    docs = state.get(\"documents\", []) or []\n    scores = sorted([float(d.get(\"rerank_score\",0.0) or 0.0) for d in docs], reverse=True)\n    top1 = scores[0] if scores else 0.0\n    avg5 = (sum(scores[:5])/min(5, len(scores))) if scores else 0.0\n    # Allow env overrides so teams can tighten gates without code changes\n    try:\n        CONF_TOP1 = float(os.getenv('CONF_TOP1', '0.62'))\n        CONF_AVG5 = float(os.getenv('CONF_AVG5', '0.55'))\n        CONF_ANY = float(os.getenv('CONF_ANY', '0.55'))\n    except Exception:\n        CONF_TOP1, CONF_AVG5, CONF_ANY = 0.62, 0.55, 0.55\n    if top1 >= CONF_TOP1 or avg5 >= CONF_AVG5 or conf >= CONF_ANY:\n        return \"generate\"\n    if it >= 3:\n        return \"fallback\"\n    return \"rewrite_query\"\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6e8e186dd6b367ef798c50953e033b58"}
{"id": "c0ef74bc24d2", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 8, "imports": [], "code": "rewrite_query(state: RAGState) -> Dict:\n    q = state['question']\n    sys = \"You rewrite developer questions into search-optimized queries without changing meaning.\"\n    user = f\"Rewrite this for code search (expand CamelCase, include API nouns), one line.\\n\\n{q}\"\n    newq, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n    newq = (newq or '').strip()\n    return {'question': newq}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "81f11513a05aecc9309a0ceb2f6bf973"}
{"id": "7bc53ce5ac2c", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 24, "imports": [], "code": "generate_node(state: RAGState) -> Dict:\n    q = state['question']; ctx = state['documents'][:5]\n    citations = \"\\n\".join([f\"- {d['file_path']}:{d['start_line']}-{d['end_line']}\" for d in ctx])\n    context_text = \"\\n\\n\".join([d.get('code','') for d in ctx])\n    sys = 'You answer strictly from the provided code context. Always cite file paths and line ranges you used.'\n    user = f\"Question:\\n{q}\\n\\nContext:\\n{context_text}\\n\\nCitations (paths and line ranges):\\n{citations}\\n\\nAnswer:\"\n    content, _ = generate_text(user_input=user, system_instructions=sys, reasoning_effort=None)\n    content = content or ''\n    # Lightweight verifier: if confidence low, try multi-query retrieval and regenerate once\n    conf = float(state.get('confidence', 0.0) or 0.0)\n    if conf < 0.55:\n        repo = state.get('repo') or os.getenv('REPO','project')\n        alt_docs = hybrid_search_routed_multi(q, repo_override=repo, m=4, final_k=10)\n        if alt_docs:\n            ctx2 = alt_docs[:5]\n            citations2 = \"\\n\".join([f\"- {d['file_path']}:{d['start_line']}-{d['end_line']}\" for d in ctx2])\n            context_text2 = \"\\n\\n\".join([d.get('code','') for d in ctx2])\n            user2 = f\"Question:\\n{q}\\n\\nContext:\\n{context_text2}\\n\\nCitations (paths and line ranges):\\n{citations2}\\n\\nAnswer:\"\n            content2, _ = generate_text(user_input=user2, system_instructions=sys, reasoning_effort=None)\n            content = (content2 or content or '')\n    repo_hdr = state.get('repo') or (ctx[0].get('repo') if ctx else None) or os.getenv('REPO','project')\n    header = f\"[repo: {repo_hdr}]\"\n    return {'generation': header + \"\\n\" + content}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0228d79c34422f7329dfaf87d7168778"}
{"id": "d1d5fd4f012c", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 6, "imports": [], "code": "fallback_node(state: RAGState) -> Dict:\n    repo_hdr = state.get('repo') or (state.get('documents')[0].get('repo') if state.get('documents') else None) or os.getenv('REPO','project')\n    header = f\"[repo: {repo_hdr}]\"\n    msg = \"I don't have high confidence from local code. Try refining the question or expanding the context.\"\n    return {'generation': header + \"\\n\" + msg}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d7e995e03b2d44664759431f8fd8c3d9"}
{"id": "97e276ecacd7", "file_path": "/Users/davidmontgomery/agro/langgraph_app.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "build_graph():\n    builder = StateGraph(RAGState)\n    builder.add_node('retrieve', retrieve_node)\n    builder.add_node('rewrite_query', rewrite_query)\n    builder.add_node('generate', generate_node)\n    builder.add_node('fallback', fallback_node)\n    builder.set_entry_point('retrieve')\n    builder.add_conditional_edges('retrieve', route_after_retrieval, {\n        'generate': 'generate', 'rewrite_query': 'rewrite_query', 'fallback': 'fallback'\n    })\n    builder.add_edge('rewrite_query', 'retrieve')\n    builder.add_edge('generate', END)\n    builder.add_edge('fallback', END)\n    DB_URI = os.getenv('REDIS_URL','redis://127.0.0.1:6379/0')\n    # Prefer Redis checkpointer, but do not fail hard if unavailable\n    try:\n        checkpointer = RedisSaver(redis_url=DB_URI)\n        graph = builder.compile(checkpointer=checkpointer)\n    except Exception:\n        graph = builder.compile()\n    return graph\n\nif __name__ == '__main__':\n    import sys\n    q = ' '.join(sys.argv[1:]) if len(sys.argv)>1 else 'Where is OAuth token validated?'\n    graph = build_graph(); cfg = {'configurable': {'thread_id': 'dev'}}\n    res = graph.invoke({'question': q, 'documents': [], 'generation':'', 'iteration':0, 'confidence':0.0}, cfg)\n    print(res['generation'])\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3bd07a37aa67e0b03091fb167e1c3fc1"}
{"id": "68eb0d2f4f2f", "file_path": "/Users/davidmontgomery/agro/eval_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 21, "imports": ["import os, json, time", "from typing import List, Dict", "from dotenv import load_dotenv", "from hybrid_search import search_routed, search_routed_multi"], "code": "import os, json, time\nfrom typing import List, Dict\nfrom dotenv import load_dotenv\nfrom hybrid_search import search_routed, search_routed_multi\n\nload_dotenv()\n\nGOLDEN_PATH = os.getenv('GOLDEN_PATH', 'golden.json')\nUSE_MULTI = os.getenv('EVAL_MULTI','1') == '1'\nFINAL_K = int(os.getenv('EVAL_FINAL_K','5'))\n\n\"\"\"\nGolden file format (golden.json):\n[\n  {\"q\": \"Where is ProviderSetupWizard rendered?\", \"repo\": \"project\", \"expect_paths\": [\"core/admin_ui/src/components/ProviderSetupWizard.tsx\"]},\n  {\"q\": \"Where do we mask PHI in events?\", \"repo\": \"project\", \"expect_paths\": [\"app/...\"]}\n]\n\"\"\"\nhit(paths: List[str], expect: List[str]) -> bool:\n    return any(any(exp in p for p in paths) for exp in expect)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1f7539a2361c1df2ab7c4ddcd97978f7"}
{"id": "b906008aecad", "file_path": "/Users/davidmontgomery/agro/eval_rag.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "main():\n    if not os.path.exists(GOLDEN_PATH):\n        print('No golden file found at', GOLDEN_PATH)\n        return\n    gold = json.load(open(GOLDEN_PATH))\n    total = len(gold); hits_top1 = 0; hits_topk = 0\n    t0 = time.time()\n    for i, row in enumerate(gold, 1):\n        q = row['q']; repo = row.get('repo') or os.getenv('REPO','project')\n        expect = row.get('expect_paths') or []\n        if USE_MULTI:\n            docs = search_routed_multi(q, repo_override=repo, m=4, final_k=FINAL_K)\n        else:\n            docs = search_routed(q, repo_override=repo, final_k=FINAL_K)\n        paths = [d.get('file_path','') for d in docs]\n        if paths:\n            if hit(paths[:1], expect): hits_top1 += 1\n            if hit(paths, expect): hits_topk += 1\n        print(f\"[{i}/{total}] repo={repo} q={q}\\n  top1={paths[:1]}\\n  top{FINAL_K} hit={hit(paths, expect)}\")\n    dt = time.time() - t0\n    print(json.dumps({\n        'total': total,\n        'top1': hits_top1,\n        'topk': hits_topk,\n        'final_k': FINAL_K,\n        'use_multi': USE_MULTI,\n        'secs': round(dt,2)\n    }, indent=2))\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a4eaee5deae228a57cc887baa5dadbbd"}
{"id": "fac7e47e3cea", "file_path": "/Users/davidmontgomery/agro/autoscaler.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 39, "imports": ["from __future__ import annotations", "import argparse", "import json", "import os", "import sys", "import time", "from dataclasses import dataclass", "from pathlib import Path", "from typing import Any, Dict, Optional", "import requests  # type: ignore"], "code": "#!/usr/bin/env python3\n\"\"\"\nAutotune autoscaler (stub):\n- Samples local CPU/RAM (and GPU later) via psutil\n- Reads gui/autotune_policy.json\n- During off hours, POSTs /api/autotune/status with a suggested mode (ECO/BALANCED/TURBO)\n\nDefaults:\n- Does not change env or persist profiles; only signals current_mode to the server stub\n- Business hours gate: leaves user settings untouched during business hours\n\"\"\"\nfrom __future__ import annotations\nimport argparse\nimport json\nimport os\nimport sys\nimport time\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\n\ntry:\n    import psutil  # type: ignore\nexcept Exception:\n    psutil = None  # type: ignore\n\nimport requests  # type: ignore\n\nROOT = Path(__file__).resolve().parent\nGUI = ROOT / \"gui\"\nPOLICY_PATH = GUI / \"autotune_policy.json\"\n\n\n@dataclassMetrics:\n    cpu: float\n    mem: float\n    gpu: Optional[float] = None\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7081f46fb685c274ac8448a837b6d3ca"}
{"id": "7f7c002c8673", "file_path": "/Users/davidmontgomery/agro/autoscaler.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 19, "imports": [], "code": "load_policy(path: Path) -> Dict[str, Any]:\n    try:\n        return json.loads(path.read_text())\n    except Exception:\n        return {\n            \"business_hours\": {\"start\": \"09:00\", \"end\": \"18:00\", \"days\": [1, 2, 3, 4, 5]},\n            \"thresholds\": {\"cpu_hot\": 0.8, \"mem_hot\": 0.85, \"gpu_hot\": 0.85},\n            \"modes\": {\n                \"ECO\": {\"when\": {\"cpu_util_max\": 0.25, \"mem_util_max\": 0.50, \"gpu_util_max\": 0.30}},\n                \"BALANCED\": {\"when\": {\"cpu_util_max\": 0.55, \"mem_util_max\": 0.70, \"gpu_util_max\": 0.60}},\n                \"TURBO\": {\"when\": {\"cpu_util_max\": 0.90, \"mem_util_max\": 0.90, \"gpu_util_max\": 0.90}},\n            },\n        }\n\nparse_hhmm(s: str) -> tuple[int, int]:\n    h, m = s.split(\":\")\n    return int(h), int(m)\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4a22f1f6a3e666d2f8e31401ca3cddc2"}
{"id": "bbd858cc1e06", "file_path": "/Users/davidmontgomery/agro/autoscaler.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 24, "imports": [], "code": "is_business_hours(now: Optional[time.struct_time], policy: Dict[str, Any]) -> bool:\n    if now is None:\n        now = time.localtime()\n    days = set(policy.get(\"business_hours\", {}).get(\"days\", [1, 2, 3, 4, 5]))\n    if now.tm_wday + 1 not in days:\n        return False\n    start_s = policy.get(\"business_hours\", {}).get(\"start\", \"09:00\")\n    end_s = policy.get(\"business_hours\", {}).get(\"end\", \"18:00\")\n    sh, sm = parse_hhmm(start_s)\n    eh, em = parse_hhmm(end_s)\n    tmin = now.tm_hour * 60 + now.tm_min\n    start_m = sh * 60 + sm\n    end_m = eh * 60 + em\n    return start_m <= tmin <= end_m\n\nsample_metrics() -> Metrics:\n    if psutil is None:\n        return Metrics(cpu=0.0, mem=0.0, gpu=None)\n    cpu = psutil.cpu_percent(interval=0.3) / 100.0\n    mem = psutil.virtual_memory().percent / 100.0\n    # TODO: GPU (Metal/CUDA) sampling in future\n    return Metrics(cpu=cpu, mem=mem, gpu=None)\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f95f1061bb185b6f78b23f61b853ecd1"}
{"id": "bd5b68f4a91e", "file_path": "/Users/davidmontgomery/agro/autoscaler.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "pick_mode(m: Metrics, policy: Dict[str, Any]) -> Optional[str]:\n    # Simple rule: choose the first mode whose 'when' limits are not exceeded\n    modes = policy.get(\"modes\", {})\n    order = [\"ECO\", \"BALANCED\", \"TURBO\"]\n    for name in order:\n        spec = modes.get(name, {}).get(\"when\", {})\n        cpu_ok = m.cpu <= float(spec.get(\"cpu_util_max\", 1.0))\n        mem_ok = m.mem <= float(spec.get(\"mem_util_max\", 1.0))\n        gpu_lim = spec.get(\"gpu_util_max\")\n        gpu_ok = True if gpu_lim is None or m.gpu is None else m.gpu <= float(gpu_lim)\n        if cpu_ok and mem_ok and gpu_ok:\n            return name\n    return None\n\npost_status(host: str, enabled: bool, mode: Optional[str]) -> None:\n    try:\n        requests.post(\n            f\"{host}/api/autotune/status\",\n            json={\"enabled\": enabled, \"current_mode\": mode},\n            timeout=3,\n        )\n    except Exception:\n        pass\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b1b55c539bd52efb0ee0e598ae87f9f9"}
{"id": "2abc94bab93a", "file_path": "/Users/davidmontgomery/agro/autoscaler.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 26, "imports": [], "code": "main(argv: list[str]) -> int:\n    p = argparse.ArgumentParser(description=\"Autotune autoscaler (stub)\")\n    p.add_argument(\"--host\", default=os.getenv(\"AUTOTUNE_HOST\", \"http://127.0.0.1:8012\"))\n    p.add_argument(\"--interval\", type=int, default=int(os.getenv(\"AUTOTUNE_INTERVAL\", \"15\")))\n    args = p.parse_args(argv)\n\n    policy = load_policy(POLICY_PATH)\n    print(f\"[autoscaler] Using policy {POLICY_PATH}\")\n    print(f\"[autoscaler] Posting to {args.host} every {args.interval}s (off-hours only)\")\n\n    while True:\n        now = time.localtime()\n        bh = is_business_hours(now, policy)\n        m = sample_metrics()\n        if not bh:\n            mode = pick_mode(m, policy)\n            post_status(args.host, enabled=True, mode=mode)\n        time.sleep(max(3, args.interval))\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(main(sys.argv[1:]))\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4982e4bc11275be3a22f9c3bb9ddd973"}
{"id": "93ef259872ea", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 40, "imports": ["import os, re, hashlib", "from typing import Dict, List, Optional"], "code": "import os, re, hashlib\nfrom typing import Dict, List, Optional\n\n# Optional import: tree_sitter_languages may be unavailable on newer Python versions.\ntry:\n    from tree_sitter_languages import get_parser as _ts_get_parser\nexcept Exception:\n    _ts_get_parser = None\n\nLANG_MAP = {\n    \".py\": \"python\", \".js\": \"javascript\", \".jsx\": \"javascript\",\n    \".ts\": \"typescript\", \".tsx\": \"typescript\",\n    \".go\": \"go\", \".java\": \"java\", \".rs\": \"rust\",\n    \".c\": \"c\", \".h\": \"c\", \".cpp\": \"cpp\", \".cc\": \"cpp\", \".hpp\": \"cpp\",\n}\n\n# Optional overlap to provide additional local context when chunk boundaries split logical units\nOVERLAP_LINES = 20\n\nFUNC_NODES = {\n    \"python\": {\"function_definition\", \"class_definition\"},\n    \"javascript\": {\"function_declaration\", \"class_declaration\", \"method_definition\", \"arrow_function\"},\n    \"typescript\": {\"function_declaration\", \"class_declaration\", \"method_signature\", \"method_definition\", \"arrow_function\"},\n    \"go\": {\"function_declaration\", \"method_declaration\"},\n    \"java\": {\"class_declaration\", \"method_declaration\"},\n    \"rust\": {\"function_item\", \"impl_item\"},\n    \"c\": {\"function_definition\"},\n    \"cpp\": {\"function_definition\", \"class_specifier\"},\n}\n\nIMPORT_NODES = {\n    \"python\": {\"import_statement\", \"import_from_statement\"},\n    \"javascript\": {\"import_declaration\"},\n    \"typescript\": {\"import_declaration\"},\n    \"go\": {\"import_declaration\"},\n    \"java\": {\"import_declaration\"},\n    \"rust\": {\"use_declaration\"},\n    \"c\": set(), \"cpp\": set(),\n}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ac1695852347afad75edde75c6997341"}
{"id": "e23fb9d2bab7", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 26, "imports": [], "code": "lang_from_path(path:str)->Optional[str]:\n    _, ext = os.path.splitext(path)\n    return LANG_MAP.get(ext.lower())\nnonws_len(s:str)->int:\n    return len(re.sub(r\"\\s+\", \"\", s))\nextract_imports(src:str, lang:str)->List[str]:\n    try:\n        if _ts_get_parser is None:\n            raise RuntimeError(\"tree_sitter_languages not available\")\n        parser = _ts_get_parser(lang)\n        tree = parser.parse(bytes(src, \"utf-8\"))\n        imports = []\n        def walk(n):\n            if n.type in IMPORT_NODES.get(lang, set()):\n                imports.append(src[n.start_byte:n.end_byte])\n            for c in n.children:\n                walk(c)\n        walk(tree.root_node)\n        return imports\n    except Exception:\n        if lang == \"python\":\n            return re.findall(r\"^(?:from\\s+[^\\n]+|import\\s+[^\\n]+)$\", src, flags=re.M)\n        if lang in {\"javascript\",\"typescript\"}:\n            return re.findall(r\"^import\\s+[^\\n]+;$\", src, flags=re.M)\n        return []\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f100d01bbb2964a89e17a322a5bcc6f5"}
{"id": "590b4e1cb60f", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 28, "imports": [], "code": "greedy_fallback(src:str, fpath:str, lang:str, target:int)->List[Dict]:\n    sep = r\"(?:\\nclass\\s+|\\ndef\\s+)\" if lang==\"python\" else r\"(?:\\nclass\\s+|\\nfunction\\s+)\"\n    parts = re.split(sep, src)\n    if len(parts) < 2:\n        out, cur, acc = [], [], 0\n        for line in src.splitlines(True):\n            cur.append(line); acc += nonws_len(line)\n            if acc >= target:\n                out.append(\"\".join(cur)); cur, acc = [], 0\n        if cur: out.append(\"\".join(cur))\n        return [{\n            \"id\": hashlib.md5((fpath+str(i)+s[:80]).encode()).hexdigest()[:12],\n            \"file_path\": fpath, \"language\": lang, \"type\":\"blob\",\"name\":None,\n            \"start_line\": 1, \"end_line\": s.count(\"\\n\")+1, \"imports\": extract_imports(src, lang), \"code\": s\n        } for i,s in enumerate(out)]\n    else:\n        rejoined, buf, acc = [], [], 0\n        for p in parts:\n            if acc + nonws_len(p) > target and buf:\n                s = \"\".join(buf); rejoined.append(s); buf, acc = [], 0\n            buf.append(p); acc += nonws_len(p)\n        if buf: rejoined.append(\"\".join(buf))\n        return [{\n            \"id\": hashlib.md5((fpath+str(i)+s[:80]).encode()).hexdigest()[:12],\n            \"file_path\": fpath, \"language\": lang, \"type\":\"section\",\"name\":None,\n            \"start_line\": 1, \"end_line\": s.count(\"\\n\")+1, \"imports\": extract_imports(s, lang), \"code\": s\n        } for i,s in enumerate(rejoined)]\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4e3f0e605ea96df15ae5a643774ea3a1"}
{"id": "1f00e58622cf", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 39, "imports": [], "code": "collect_files(roots:List[str])->List[str]:\n    import fnmatch\n    out=[]\n    # Hardcoded skip dirs for safety\n    skip_dirs = {\".git\",\"node_modules\",\".venv\",\"venv\",\"dist\",\"build\",\"__pycache__\",\".next\",\".turbo\",\".parcel-cache\",\".pytest_cache\",\"vendor\",\"third_party\",\".bundle\",\"Pods\"}\n\n    # Try to load exclusion patterns from file\n    exclude_patterns = []\n    for root in roots:\n        # Check for exclude_globs.txt in data/ directory\n        parent_dir = os.path.dirname(root) if os.path.isfile(root) else root\n        exclude_file = os.path.join(parent_dir, 'data', 'exclude_globs.txt')\n        if os.path.exists(exclude_file):\n            try:\n                with open(exclude_file, 'r') as f:\n                    patterns = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n                    exclude_patterns.extend(patterns)\n            except Exception:\n                pass\n\n    for root in roots:\n        for dp, dns, fns in os.walk(root):\n            # Skip directories that match our exclusion rules\n            dns[:] = [d for d in dns if d not in skip_dirs and not d.startswith('.venv') and not d.startswith('venv')]\n\n            for fn in fns:\n                p = os.path.join(dp, fn)\n\n                # Check if file matches any exclusion pattern\n                skip = False\n                for pattern in exclude_patterns:\n                    if fnmatch.fnmatch(p, pattern) or fnmatch.fnmatch(os.path.relpath(p, root), pattern):\n                        skip = True\n                        break\n\n                if not skip and lang_from_path(p):\n                    out.append(p)\n    return out\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "cab2360ce7100a1a0e613a9bdd68be03"}
{"id": "aa7d519e0f0a", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 9, "imports": [], "code": "_guess_name(lang:str, text:str)->Optional[str]:\n    if lang==\"python\":\n        m = re.search(r\"^(?:def|class)\\s+([A-Za-z_][A-Za-z0-9_]*)\", text, flags=re.M)\n        return m.group(1) if m else None\n    if lang in {\"javascript\",\"typescript\"}:\n        m = re.search(r\"^(?:function|class)\\s+([A-Za-z_$][A-Za-z0-9_$]*)\", text, flags=re.M)\n        return m.group(1) if m else None\n    return None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "fb9ab905ee37b606a1e64ccf602f1ac4"}
{"id": "51a7d2f84839", "file_path": "/Users/davidmontgomery/agro/ast_chunker.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 49, "imports": [], "code": "chunk_code(src:str, fpath:str, lang:str, target:int=900)->List[Dict]:\n    \"\"\"AST-aware chunking around functions/classes; falls back if no nodes.\"\"\"\n    try:\n        if _ts_get_parser is None:\n            raise RuntimeError(\"tree_sitter_languages not available\")\n        parser = _ts_get_parser(lang)\n        tree = parser.parse(bytes(src, \"utf-8\"))\n        wanted = FUNC_NODES.get(lang, set())\n        nodes = []\n        stack = [tree.root_node]\n        while stack:\n            n = stack.pop()\n            if n.type in wanted:\n                nodes.append(n)\n            stack.extend(n.children)\n        if not nodes:\n            return greedy_fallback(src, fpath, lang, target)\n        chunks: List[Dict] = []\n        all_lines = src.splitlines()\n        for i, n in enumerate(nodes):\n            text = src[n.start_byte:n.end_byte]\n            if nonws_len(text) > target:\n                for j, sub in enumerate(greedy_fallback(text, fpath, lang, target)):\n                    sub[\"id\"] = hashlib.md5((fpath+f\"/{i}:{j}\"+sub[\"code\"][:80]).encode()).hexdigest()[:12]\n                    sub[\"start_line\"] = n.start_point[0]+1\n                    sub[\"end_line\"] = sub[\"start_line\"] + sub[\"code\"].count(\"\\n\")\n                    chunks.append(sub)\n            else:\n                name = _guess_name(lang, text)\n                start_line = n.start_point[0] + 1\n                end_line = n.end_point[0] + 1\n                actual_start = max(1, start_line - OVERLAP_LINES) if OVERLAP_LINES > 0 else start_line\n                # Slice lines with 1-based indexing\n                chunk_text = \"\\n\".join(all_lines[actual_start-1:end_line])\n                chunks.append({\n                    \"id\": hashlib.md5((fpath+str(i)+text[:80]).encode()).hexdigest()[:12],\n                    \"file_path\": fpath,\n                    \"language\": lang,\n                    \"type\": \"unit\",\n                    \"name\": name,\n                    \"start_line\": actual_start,\n                    \"end_line\": end_line,\n                    \"imports\": extract_imports(src, lang),\n                    \"code\": chunk_text,\n                })\n        return chunks\n    except Exception:\n        return greedy_fallback(src, fpath, lang, target)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c568720743b92b60162319df2a26baa0"}
{"id": "972bd53ea2e2", "file_path": "/Users/davidmontgomery/agro/metadata_enricher.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": ["import os", "import json"], "code": "import os\nimport json\n\n# MLX backend (default for Apple Silicon)\nENRICH_BACKEND = os.getenv(\"ENRICH_BACKEND\", \"mlx\").lower()  # mlx | ollama\nMLX_MODEL = os.getenv(\"ENRICH_MODEL\", \"mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit\")\nOLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://127.0.0.1:11434/api/generate\")\nOLLAMA_MODEL = os.getenv(\"ENRICH_MODEL_OLLAMA\", \"qwen3-coder:30b\")\n\nSYSTEM = (\n    \"You are a senior code analyst. Extract: 1) concise summary of purpose, \"\n    \"2) key APIs/classes/functions referenced, 3) inputs/outputs/side-effects, \"\n    \"4) 8-15 retrieval keywords (snake_case). Keep under 120 tokens.\"\n)\n\nPROMPT_TMPL = (\n    \"<system>\" + SYSTEM + \"</system>\\n\"\n    \"<analyze file='{file}' lang='{lang}'>\\n{code}\\n</analyze>\\n\"\n    \"<format>JSON with keys: summary, keywords</format>\"\n)\n\n# Lazy-load MLX model (only once)\n_mlx_model = None\n_mlx_tokenizer = None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "348f34cf27aa805adb4c283c65f6973f"}
{"id": "2d2b6661e48c", "file_path": "/Users/davidmontgomery/agro/metadata_enricher.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 7, "imports": [], "code": "_get_mlx_model():\n    global _mlx_model, _mlx_tokenizer\n    if _mlx_model is None:\n        from mlx_lm import load\n        _mlx_model, _mlx_tokenizer = load(MLX_MODEL)\n    return _mlx_model, _mlx_tokenizer\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5108ea854a408413ef09dc0d04c3b019"}
{"id": "c85d0500bc80", "file_path": "/Users/davidmontgomery/agro/metadata_enricher.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 40, "imports": [], "code": "enrich(file_path: str, lang: str, code: str) -> dict:\n    prompt = PROMPT_TMPL.format(file=file_path, lang=lang, code=(code or '')[:4000])\n\n    if ENRICH_BACKEND == \"mlx\":\n        # MLX backend (Apple Silicon, fast)\n        try:\n            from mlx_lm import generate\n            model, tokenizer = _get_mlx_model()\n            txt = generate(model, tokenizer, prompt=prompt, max_tokens=150, verbose=False)\n        except Exception as e:\n            return {\"summary\": f\"MLX error: {str(e)[:100]}\", \"keywords\": []}\n    else:\n        # Ollama backend (fallback)\n        import requests\n        try:\n            resp = requests.post(\n                OLLAMA_URL,\n                json={\n                    \"model\": OLLAMA_MODEL,\n                    \"prompt\": prompt,\n                    \"stream\": False,\n                    \"options\": {\"temperature\": 0.1, \"num_ctx\": 4096},\n                },\n                timeout=10,\n            )\n            resp.raise_for_status()\n            txt = resp.json().get(\"response\", \"{}\")\n        except Exception as e:\n            return {\"summary\": f\"Ollama error: {str(e)[:100]}\", \"keywords\": []}\n\n    # Parse JSON response\n    try:\n        data = json.loads(txt)\n        if isinstance(data, dict):\n            return {\"summary\": data.get(\"summary\", \"\"), \"keywords\": data.get(\"keywords\", [])}\n    except Exception:\n        pass\n    return {\"summary\": txt[:300], \"keywords\": []}\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "58e0137460e4bc6f95574a63c6b120cd"}
{"id": "ae1d68926e80", "file_path": "/Users/davidmontgomery/agro/vivified_rag.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 12, "imports": ["import os", "from dotenv import load_dotenv", "from serve_rag import app"], "code": "import os\nfrom dotenv import load_dotenv\n\nload_dotenv('env/project.env')\nfrom serve_rag import app\n\nif __name__ == '__main__':\n    import uvicorn\n    os.environ['COLLECTION_NAME'] = os.environ.get('COLLECTION_NAME', f\"{os.environ['REPO']}_{os.environ.get('COLLECTION_SUFFIX','default')}\")\n    port = int(os.environ.get('PORT', '8012'))\n    uvicorn.run(app, host='127.0.0.1', port=port)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "25ce3168f34426c2412c92e5d4cb2dc7"}
{"id": "f632312b7cbb", "file_path": "/Users/davidmontgomery/agro/chat_cli.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 44, "imports": ["import os", "import sys", "from pathlib import Path", "from langgraph_app import build_graph", "from config_loader import list_repos", "from rich.console import Console", "from rich.markdown import Markdown", "from rich.panel import Panel", "from rich.prompt import Prompt"], "code": "#!/usr/bin/env python3\n\"\"\"\nInteractive CLI chat interface for RAG service.\nUses LangGraph with Redis checkpoints for conversation memory.\n\nUsage:\n    export REPO=agro\n    export THREAD_ID=my-session-1\n    python chat_cli.py\n\nCommands:\n    /repo <name>    - Switch repository (from repos.json)\n    /save           - Save conversation checkpoint\n    /clear          - Clear conversation history\n    /help           - Show commands\n    /exit, /quit    - Exit chat\n\"\"\"\nimport os\nimport sys\nfrom pathlib import Path\ntry:\n    from dotenv import load_dotenv\nexcept Exception:\n    # Graceful fallback if python-dotenv is not installed yet\n    def load_dotenv(*args, **kwargs):\n        return False\n\n# Load environment\nload_dotenv(Path(__file__).parent / \".env\")\n\nfrom langgraph_app import build_graph\nfrom config_loader import list_repos\nfrom rich.console import Console\nfrom rich.markdown import Markdown\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\n\nconsole = Console()\n\n# Configuration\nREPO = os.getenv('REPO', 'agro')\nTHREAD_ID = os.getenv('THREAD_ID', 'cli-chat')\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "59eeaaf8bbdce5e00cde7674ec3b29c9"}
{"id": "c7f90c570390", "file_path": "/Users/davidmontgomery/agro/chat_cli.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 185, "imports": [], "code": "ChatCLI:\n    \"\"\"Interactive CLI chat with RAG.\"\"\"\n\n    def __init__(self, repo: str = 'agro', thread_id: str = 'cli-chat'):\n        self.repo = repo\n        self.thread_id = thread_id\n        self.graph = None\n        self._init_graph()\n\n    def _init_graph(self):\n        \"\"\"Initialize LangGraph with Redis checkpoints.\"\"\"\n        try:\n            self.graph = build_graph()\n            console.print(f\"[green]✓[/green] Graph initialized with Redis checkpoints\")\n        except Exception as e:\n            console.print(f\"[red]✗[/red] Failed to initialize graph: {e}\")\n            sys.exit(1)\n\n    def _get_config(self):\n        \"\"\"Get config for current thread.\"\"\"\n        return {\"configurable\": {\"thread_id\": self.thread_id}}\n\n    def _format_answer(self, generation: str) -> str:\n        \"\"\"Format answer, removing repo header if present.\"\"\"\n        lines = generation.split('\\n')\n        # Remove [repo: ...] header if present\n        if lines and lines[0].startswith('[repo:'):\n            return '\\n'.join(lines[1:]).strip()\n        return generation\n\n    def ask(self, question: str) -> dict:\n        \"\"\"Ask a question and get answer.\"\"\"\n        try:\n            state = {\n                \"question\": question,\n                \"documents\": [],\n                \"generation\": \"\",\n                \"iteration\": 0,\n                \"confidence\": 0.0,\n                \"repo\": self.repo\n            }\n\n            result = self.graph.invoke(state, self._get_config())\n            return result\n        except Exception as e:\n            console.print(f\"[red]Error:[/red] {e}\")\n            return {\"generation\": f\"Error: {e}\", \"documents\": [], \"confidence\": 0.0}\n\n    def switch_repo(self, new_repo: str):\n        \"\"\"Switch to a different repository.\"\"\"\n        allowed = set(list_repos())\n        if new_repo not in allowed:\n            console.print(f\"[red]✗[/red] Invalid repo. Allowed: {sorted(allowed)}\")\n            return\n\n        self.repo = new_repo\n        console.print(f\"[green]✓[/green] Switched to repo: [bold]{new_repo}[/bold]\")\n\n    def show_help(self):\n        \"\"\"Show available commands.\"\"\"\n        help_text = \"\"\"\n## Commands\n\n- `/repo <name>` - Switch repository (from repos.json)\n- `/save` - Save conversation checkpoint\n- `/clear` - Clear conversation history\n- `/help` - Show this help\n- `/exit`, `/quit` - Exit chat\n\n## Examples\n\nAsk a question:\n```\n> Where is OAuth token validated?\n```\n\nSwitch repo:\n```\n> /repo agro\n> How do we handle inbound faxes?\n```\n        \"\"\"\n        console.print(Markdown(help_text))\n\n    def show_welcome(self):\n        \"\"\"Show welcome message.\"\"\"\n        welcome = f\"\"\"\n# 🤖 RAG CLI Chat\n\nConnected to: [bold cyan]{self.repo}[/bold cyan]\nThread ID: [bold]{self.thread_id}[/bold]\n\nType your question or use `/help` for commands.\n        \"\"\"\n        console.print(Panel(Markdown(welcome), border_style=\"cyan\"))\n\n    def run(self):\n        \"\"\"Main chat loop.\"\"\"\n        self.show_welcome()\n\n        while True:\n            try:\n                # Get user input\n                user_input = Prompt.ask(\n                    f\"\\n[bold cyan]{self.repo}[/bold cyan] >\",\n                    default=\"\"\n                )\n\n                if not user_input.strip():\n                    continue\n\n                # Handle commands\n                if user_input.startswith('/'):\n                    cmd = user_input.lower().split()[0]\n\n                    if cmd in ['/exit', '/quit']:\n                        console.print(\"[yellow]Goodbye![/yellow]\")\n                        break\n\n                    elif cmd == '/help':\n                        self.show_help()\n                        continue\n\n                    elif cmd == '/repo':\n                        parts = user_input.split(maxsplit=1)\n                        if len(parts) > 1:\n                            self.switch_repo(parts[1].strip())\n                        else:\n                            console.print(\"[red]Usage:[/red] /repo <project|project>\")\n                        continue\n\n                    elif cmd == '/save':\n                        console.print(f\"[green]✓[/green] Checkpoint saved (thread: {self.thread_id})\")\n                        continue\n\n                    elif cmd == '/clear':\n                        # Create new thread ID to start fresh\n                        import time\n                        self.thread_id = f\"cli-chat-{int(time.time())}\"\n                        console.print(f\"[green]✓[/green] Cleared history (new thread: {self.thread_id})\")\n                        continue\n\n                    else:\n                        console.print(f\"[red]Unknown command:[/red] {cmd}\")\n                        console.print(\"Type [bold]/help[/bold] for available commands\")\n                        continue\n\n                # Ask question\n                console.print(\"[dim]Thinking...[/dim]\")\n                result = self.ask(user_input)\n\n                # Show answer\n                answer = self._format_answer(result.get('generation', ''))\n                confidence = result.get('confidence', 0.0)\n                docs = result.get('documents', [])\n\n                # Display answer in panel\n                console.print(\"\\n\")\n                console.print(Panel(\n                    Markdown(answer),\n                    title=f\"Answer (confidence: {confidence:.2f})\",\n                    border_style=\"green\" if confidence > 0.6 else \"yellow\"\n                ))\n\n                # Show top citations\n                if docs:\n                    console.print(\"\\n[dim]Top sources:[/dim]\")\n                    for i, doc in enumerate(docs[:3], 1):\n                        fp = doc.get('file_path', 'unknown')\n                        start = doc.get('start_line', 0)\n                        end = doc.get('end_line', 0)\n                        score = doc.get('rerank_score', 0.0)\n                        console.print(f\"  [dim]{i}.[/dim] {fp}:{start}-{end} [dim](score: {score:.3f})[/dim]\")\n\n            except KeyboardInterrupt:\n                console.print(\"\\n[yellow]Use /exit to quit[/yellow]\")\n                continue\n            except EOFError:\n                console.print(\"\\n[yellow]Goodbye![/yellow]\")\n                break\n            except Exception as e:\n                console.print(f\"[red]Error:[/red] {e}\")\n                continue\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d3f830719d3986c400bc60616e3c2b0f"}
{"id": "7143ebcab84e", "file_path": "/Users/davidmontgomery/agro/chat_cli.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 24, "imports": [], "code": "main():\n    \"\"\"Entry point.\"\"\"\n    # Check dependencies\n    try:\n        from rich.console import Console\n        from rich.markdown import Markdown\n        from rich.panel import Panel\n        from rich.prompt import Prompt\n    except ImportError:\n        print(\"Error: Missing 'rich' library. Install with: pip install rich\")\n        sys.exit(1)\n\n    # Get config from environment\n    repo = os.getenv('REPO', 'agro')\n    thread_id = os.getenv('THREAD_ID', 'cli-chat')\n\n    # Create and run chat\n    chat = ChatCLI(repo=repo, thread_id=thread_id)\n    chat.run()\n\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "cda91f9a52cb05baa59f55f4d6945229"}
{"id": "2f43010f64b7", "file_path": "/Users/davidmontgomery/agro/qdrant_recreate_fallback.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 16, "imports": ["from qdrant_client import QdrantClient", "from qdrant_client.http.exceptions import UnexpectedResponse"], "code": "# coding: utf-8\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http.exceptions import UnexpectedResponse\n\n_orig_recreate = QdrantClient.recreate_collection\n\n_extract_args(*args, **kwargs):\n    name = kwargs.get(\"collection_name\")\n    vectors_config = kwargs.get(\"vectors_config\")\n    if name is None and args:\n        name = args[0]\n    if vectors_config is None and len(args) > 1:\n        vectors_config = args[1]\n    return name, vectors_config\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "397e04f10a1a1ef41c0c6f44b350c740"}
{"id": "6da142d62811", "file_path": "/Users/davidmontgomery/agro/qdrant_recreate_fallback.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "recreate_collection_safe(self, *args, **kwargs):\n    try:\n        return _orig_recreate(self, *args, **kwargs)\n    except UnexpectedResponse as e:\n        # Some servers return 404 on delete step inside recreate\n        if getattr(e, \"status_code\", None) == 404:\n            name, vectors_config = _extract_args(*args, **kwargs)\n            return self.create_collection(collection_name=name, vectors_config=vectors_config)\n        raise\n    except Exception:\n        # Very defensive fallback: try delete (ignore errors), then create\n        name, vectors_config = _extract_args(*args, **kwargs)\n        try:\n            try:\n                self.delete_collection(name)\n            except Exception:\n                pass\n            return self.create_collection(collection_name=name, vectors_config=vectors_config)\n        except Exception:\n            raise\n\n\nQdrantClient.recreate_collection = recreate_collection_safe\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9608032c89fc6796434fe64d194f5072"}
{"id": "46ee738d1f2f", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 27, "imports": ["import os", "import json", "import hashlib", "from typing import List, Dict", "from pathlib import Path", "from dotenv import load_dotenv, find_dotenv", "from config_loader import get_repo_paths, out_dir", "from ast_chunker import lang_from_path, collect_files, chunk_code", "import bm25s", "from bm25s.tokenization import Tokenizer", "from Stemmer import Stemmer", "from qdrant_client import QdrantClient, models", "import uuid", "from openai import OpenAI", "from embed_cache import EmbeddingCache", "import tiktoken", "from sentence_transformers import SentenceTransformer", "import fnmatch, pathlib", "import qdrant_recreate_fallback  # make recreate_collection 404-safe", "from filtering import _prune_dirs_in_place, _should_index_file, PRUNE_DIRS", "import os", "from pathlib import Path"], "code": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nfrom config_loader import get_repo_paths, out_dir\nfrom ast_chunker import lang_from_path, collect_files, chunk_code\nimport bm25s\nfrom bm25s.tokenization import Tokenizer\nfrom Stemmer import Stemmer\nfrom qdrant_client import QdrantClient, models\nimport uuid\nfrom openai import OpenAI\nfrom embed_cache import EmbeddingCache\nimport tiktoken\nfrom sentence_transformers import SentenceTransformer\nimport fnmatch, pathlib\nimport qdrant_recreate_fallback  # make recreate_collection 404-safe\n\n# --- global safe filters (avoid indexing junk) ---\nfrom filtering import _prune_dirs_in_place, _should_index_file, PRUNE_DIRS\nimport os\nfrom pathlib import Path\n\n# Patch os.walk to prune noisy dirs and skip junk file types\n_os_walk = os.walk", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ce94c35286e070c12937162924222ed8"}
{"id": "a871a505b111", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 9, "imports": [], "code": "_filtered_os_walk(top, *args, **kwargs):\n    for root, dirs, files in _os_walk(top, *args, **kwargs):\n        _prune_dirs_in_place(dirs)\n        files[:] = [f for f in files if _should_index_file(f)]\n        yield root, dirs, files\nos.walk = _filtered_os_walk\n\n# Patch Path.rglob as well (if code uses it)\n_Path_rglob = Path.rglob", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "33a755b5f444e3b57344b83e5cbc2f53"}
{"id": "dd1bbebec6f3", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 50, "imports": [], "code": "_filtered_rglob(self, pattern):\n    for p in _Path_rglob(self, pattern):\n        # skip if any pruned dir appears in the path\n        if any(part in PRUNE_DIRS for part in p.parts):\n            continue\n        if not _should_index_file(p.name):\n            continue\n        yield p\nPath.rglob = _filtered_rglob\n# --- end filters ---\n\n\n# Load local env and also repo-root .env if present (no hard-coded paths)\ntry:\n    load_dotenv(override=False)\n    repo_root = Path(__file__).resolve().parent\n    env_path = repo_root / \".env\"\n    if env_path.exists():\n        load_dotenv(dotenv_path=env_path, override=False)\n    else:\n        alt = find_dotenv(usecwd=True)\n        if alt:\n            load_dotenv(dotenv_path=alt, override=False)\nexcept Exception:\n    pass\nOPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\nif OPENAI_API_KEY and OPENAI_API_KEY.strip().upper() in {\"SK-REPLACE\", \"REPLACE\"}:\n    OPENAI_API_KEY = None\nQDRANT_URL = os.getenv('QDRANT_URL','http://127.0.0.1:6333')\n# Repo scoping\nREPO = os.getenv('REPO', 'project').strip()\n# Resolve repo paths and outdir from config (repos.json or env)\ntry:\n    BASES = get_repo_paths(REPO)\nexcept Exception:\n    # Fallback to current directory when no config present (best-effort)\n    BASES = [str(Path(__file__).resolve().parent)]\nOUTDIR = out_dir(REPO)\n# Allow explicit collection override (for versioned collections per embedding config)\nCOLLECTION = os.getenv('COLLECTION_NAME', f'code_chunks_{REPO}')\n\n\n# Centralized file indexing gate (extensions, excludes, heuristics)\nSOURCE_EXTS = {\n    \".py\", \".rb\", \".ts\", \".tsx\", \".js\", \".jsx\", \".go\", \".rs\", \".java\",\n    \".cs\", \".c\", \".h\", \".cpp\", \".hpp\", \".m\", \".mm\", \".kt\", \".kts\", \".swift\",\n    \".sql\", \".yml\", \".yaml\", \".toml\", \".ini\", \".json\", \".md\"\n}\nEXCLUDE_GLOBS_FILE = \"data/exclude_globs.txt\"\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8f138d4905d83b4ae2f2827bfbcbceb9"}
{"id": "0e6b8ccbf5d4", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 34, "imports": [], "code": "_load_exclude_globs() -> list[str]:\n    p = pathlib.Path(EXCLUDE_GLOBS_FILE)\n    if not p.exists():\n        return []\n    return [ln.strip() for ln in p.read_text().splitlines() if ln.strip() and not ln.startswith(\"#\")]\n\n_EXCLUDE_GLOBS = _load_exclude_globs()\nshould_index_file(path: str) -> bool:\n    p = pathlib.Path(path)\n    # 1) fast deny: extension must look like source\n    if p.suffix.lower() not in SOURCE_EXTS:\n        return False\n    # 2) glob excludes (vendor, caches, images, minified, etc.)\n    as_posix = p.as_posix()\n    for pat in _EXCLUDE_GLOBS:\n        if fnmatch.fnmatch(as_posix, pat):\n            return False\n    # 3) quick heuristic to skip huge/minified one-liners\n    try:\n        text = p.read_text(errors=\"ignore\")\n        if len(text) > 2_000_000:  # ~2MB\n            return False\n        # suspect minified if average line length is enormous\n        lines = text.splitlines()\n        if lines:\n            avg = sum(len(x) for x in lines) / max(1, len(lines))\n            if avg > 2500:\n                return False\n    except Exception:\n        return False\n    return True\n\n\n# --- Repo-aware layer tagging ---", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "2303c164635f4226317db20ba444873a"}
{"id": "ef0c51d4a59d", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 35, "imports": [], "code": "detect_layer(fp: str) -> str:\n    f = (fp or '').lower()\n    if REPO == 'project':\n        if '/core/admin_ui/' in f or '/site/' in f or '/docs-site/' in f:\n            return 'ui'\n        if '/plugins/' in f or '/core/plugins/' in f or 'notification' in f or 'pushover' in f or 'apprise' in f:\n            return 'plugin'\n        if '/core/api/' in f or '/core/' in f or '/server' in f:\n            return 'kernel'\n        if '/docs/' in f or '/internal_docs/' in f:\n            return 'docs'\n        if '/tests/' in f or '/test_' in f:\n            return 'tests'\n        if '/infra/' in f or '/deploy/' in f or '/scripts/' in f:\n            return 'infra'\n        return 'kernel'\n    else:\n        if '/admin_ui/' in f or '/site/' in f or '/docs-site/' in f:\n            return 'ui'\n        if 'provider' in f or 'providers' in f or 'integration' in f or 'webhook' in f or 'adapter' in f:\n            return 'integration'\n        if '/api/' in f or '/backends/' in f or '/server' in f:\n            return 'server'\n        if '/sdks/' in f or '/python_mcp/' in f or '/node_mcp/' in f or '/plugin-dev-kit/' in f:\n            return 'sdk'\n        if '/docs/' in f or '/internal_docs/' in f:\n            return 'docs'\n        if '/asterisk/' in f or '/config/' in f or '/infra/' in f:\n            return 'infra'\n        return 'server'\n\nVENDOR_MARKERS = (\n    \"/vendor/\",\"/third_party/\",\"/external/\",\"/deps/\",\"/node_modules/\",\n    \"/Pods/\",\"/Godeps/\",\"/.bundle/\",\"/bundle/\"\n)", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c2ca7df6372a5868beee7cfa21abd2f0"}
{"id": "49303bfc8884", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "detect_origin(fp: str) -> str:\n    low = (fp or '').lower()\n    for m in VENDOR_MARKERS:\n        if m in low:\n            return 'vendor'\n    try:\n        with open(fp, 'r', encoding='utf-8', errors='ignore') as f:\n            head = ''.join([next(f) for _ in range(12)])\n        if any(k in head.lower() for k in (\n            'apache license','mit license','bsd license','mozilla public license'\n        )):\n            return 'vendor'\n    except Exception:\n        pass\n    return 'first_party'\nos.makedirs(OUTDIR, exist_ok=True)\n_clip_for_openai(text: str, enc, max_tokens: int = 8000) -> str:\n    toks = enc.encode(text)\n    if len(toks) <= max_tokens:\n        return text\n    return enc.decode(toks[:max_tokens])\nembed_texts(client: OpenAI, texts: List[str], batch: int = 64) -> List[List[float]]:\n    # Legacy non-cached embedder (kept for compatibility if needed)\n    embs = []\n    enc = tiktoken.get_encoding('cl100k_base')\n    for i in range(0, len(texts), batch):\n        sub = [_clip_for_openai(t, enc) for t in texts[i:i+batch]]\n        r = client.embeddings.create(model='text-embedding-3-large', input=sub)\n        for d in r.data:\n            embs.append(d.embedding)\n    return embs\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d0ab0ee612bc7cf9ab6152403dd2eb22"}
{"id": "9c90244f329b", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 26, "imports": [], "code": "embed_texts_local(texts: List[str], model_name: str = 'BAAI/bge-small-en-v1.5', batch: int = 128) -> List[List[float]]:\n    model = SentenceTransformer(model_name)\n    out = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        v = model.encode(sub, normalize_embeddings=True, show_progress_bar=False)\n        out.extend(v.tolist())\n    return out\n_renorm_truncate(vecs: List[List[float]], dim: int) -> List[List[float]]:\n    out: List[List[float]] = []\n    import math as _m\n    for v in vecs:\n        w = v[:dim] if dim and dim < len(v) else v\n        # renormalize\n        n = _m.sqrt(sum(x*x for x in w)) or 1.0\n        out.append([x / n for x in w])\n    return out\nembed_texts_mxbai(texts: List[str], dim: int = 512, batch: int = 128) -> List[List[float]]:\n    model = SentenceTransformer('mixedbread-ai/mxbai-embed-large-v1')\n    out: List[List[float]] = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        v = model.encode(sub, normalize_embeddings=True, show_progress_bar=False)\n        out.extend(v.tolist())\n    return _renorm_truncate(out, dim)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "2aa09ec6b96d63118c7760ef093f3a22"}
{"id": "6cc8784f05b3", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 10, "imports": [], "code": "embed_texts_voyage(texts: List[str], batch: int = 128, output_dimension: int = 512) -> List[List[float]]:\n    import voyageai\n    client = voyageai.Client(api_key=os.getenv('VOYAGE_API_KEY'))\n    out: List[List[float]] = []\n    for i in range(0, len(texts), batch):\n        sub = texts[i:i+batch]\n        r = client.embed(sub, model='voyage-code-3', input_type='document', output_dimension=output_dimension)\n        out.extend(r.embeddings)\n    return out\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "776fc141c72b548425390c7f2d319c75"}
{"id": "7e1eed7b0926", "file_path": "/Users/davidmontgomery/agro/index_repo.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 188, "imports": [], "code": "main() -> None:\n    files = collect_files(BASES)\n    print(f'Discovered {len(files)} source files.')\n    all_chunks: List[Dict] = []\n    for fp in files:\n        if not should_index_file(fp):\n            continue\n        lang = lang_from_path(fp)\n        if not lang:\n            continue\n        try:\n            with open(fp, 'r', encoding='utf-8', errors='ignore') as f:\n                src = f.read()\n        except Exception:\n            continue\n        ch = chunk_code(src, fp, lang, target=900)\n        all_chunks.extend(ch)\n\n    seen, chunks = set(), []\n    for c in all_chunks:\n        c['repo'] = REPO\n        try:\n            c['layer'] = detect_layer(c.get('file_path',''))\n        except Exception:\n            c['layer'] = 'server'\n        try:\n            c['origin'] = detect_origin(c.get('file_path',''))\n        except Exception:\n            c['origin'] = 'first_party'\n        h = hashlib.md5(c['code'].encode()).hexdigest()\n        if h in seen:\n            continue\n        seen.add(h)\n        c['hash'] = h\n        chunks.append(c)\n    print(f'Prepared {len(chunks)} chunks.')\n\n    # Optional enrichment using a local code LLM via Ollama\n    ENRICH = (os.getenv('ENRICH_CODE_CHUNKS', 'false') or 'false').lower() == 'true'\n    if ENRICH:\n        try:\n            from metadata_enricher import enrich  # type: ignore\n        except Exception:\n            enrich = None\n        if enrich is not None:\n            for c in chunks:\n                try:\n                    meta = enrich(c.get('file_path',''), c.get('language',''), c.get('code',''))\n                    c['summary'] = meta.get('summary','')\n                    c['keywords'] = meta.get('keywords', [])\n                except Exception:\n                    c['summary'] = ''\n                    c['keywords'] = []\n\n    # BM25S index\n    corpus: List[str] = []\n    for c in chunks:\n        pre = []\n        if c.get('name'):\n            pre += [c['name']]*2\n        if c.get('imports'):\n            pre += [i[0] or i[1] for i in c['imports'] if isinstance(i, (list, tuple))]\n        body = c['code']\n        corpus.append((' '.join(pre)+'\\n'+body).strip())\n\n    stemmer = Stemmer('english')\n    tokenizer = Tokenizer(stemmer=stemmer, stopwords='en')\n    corpus_tokens = tokenizer.tokenize(corpus)\n    retriever = bm25s.BM25(method='lucene', k1=1.2, b=0.65)\n    retriever.index(corpus_tokens)\n    os.makedirs(os.path.join(OUTDIR, 'bm25_index'), exist_ok=True)\n    # Workaround: ensure JSON-serializable vocab keys\n    try:\n        retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}\n    except Exception:\n        pass\n    retriever.save(os.path.join(OUTDIR, 'bm25_index'), corpus=corpus)\n    tokenizer.save_vocab(save_dir=os.path.join(OUTDIR, 'bm25_index'))\n    tokenizer.save_stopwords(save_dir=os.path.join(OUTDIR, 'bm25_index'))\n    with open(os.path.join(OUTDIR, 'bm25_index', 'corpus.txt'), 'w', encoding='utf-8') as f:\n        for doc in corpus:\n            f.write(doc.replace('\\n','\\\\n')+'\\n')\n    # Persist a stable mapping from BM25 doc index -> chunk id\n    # Persist mapping from BM25 doc index -> chunk id (string)\n    chunk_ids = [str(c['id']) for c in chunks]\n    with open(os.path.join(OUTDIR, 'bm25_index', 'chunk_ids.txt'), 'w', encoding='utf-8') as f:\n        for cid in chunk_ids:\n            f.write(cid+'\\n')\n    # Also write a JSON map for convenience\n    import json as _json\n    _json.dump({str(i): cid for i, cid in enumerate(chunk_ids)}, open(os.path.join(OUTDIR,'bm25_index','bm25_map.json'),'w'))\n    with open(os.path.join(OUTDIR,'chunks.jsonl'),'w',encoding='utf-8') as f:\n        for c in chunks:\n            f.write(json.dumps(c, ensure_ascii=False)+'\\n')\n    print('BM25 index saved.')\n\n    # Optionally skip dense embeddings/Qdrant for fast local-only BM25 indexing\n    if (os.getenv('SKIP_DENSE','0') or '0').strip() == '1':\n        print('Skipping dense embeddings and Qdrant upsert (SKIP_DENSE=1).')\n        return\n\n    client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n    # Choose text for embedding (optionally enriched)\n    texts = []\n    for c in chunks:\n        if c.get('summary') or c.get('keywords'):\n            kw = ' '.join(c.get('keywords', []))\n            texts.append(f\"{c.get('file_path','') }\\n{c.get('summary','')}\\n{kw}\\n{c.get('code','')}\")\n        else:\n            texts.append(c['code'])\n    embs: List[List[float]] = []\n    et = (os.getenv('EMBEDDING_TYPE','openai') or 'openai').lower()\n    if et == 'voyage':\n        try:\n            embs = embed_texts_voyage(texts, batch=64, output_dimension=int(os.getenv('VOYAGE_EMBED_DIM','512')))\n        except Exception as e:\n            print(f\"Voyage embedding failed ({e}); falling back to local embeddings.\")\n            embs = []\n        if not embs:\n            embs = embed_texts_local(texts)\n    elif et == 'mxbai':\n        try:\n            dim = int(os.getenv('EMBEDDING_DIM', '512'))\n            embs = embed_texts_mxbai(texts, dim=dim)\n        except Exception as e:\n            print(f\"MXBAI embedding failed ({e}); falling back to local embeddings.\")\n            embs = embed_texts_local(texts)\n    elif et == 'local':\n        embs = embed_texts_local(texts)\n    else:\n        if client is not None:\n            try:\n                cache = EmbeddingCache(OUTDIR)\n                hashes = [c['hash'] for c in chunks]\n                embs = cache.embed_texts(client, texts, hashes, model='text-embedding-3-large', batch=64)\n                # Prune orphaned embeddings from deleted/changed files\n                pruned = cache.prune(set(hashes))\n                if pruned > 0:\n                    print(f'Pruned {pruned} orphaned embeddings from cache.')\n                cache.save()\n            except Exception as e:\n                print(f'Embedding via OpenAI failed ({e}); falling back to local embeddings.')\n        if not embs:\n            embs = embed_texts_local(texts)\n    point_ids: List[str] = []\n    try:\n        q = QdrantClient(url=QDRANT_URL)\n        q.recreate_collection(\n            collection_name=COLLECTION,\n            vectors_config={'dense': models.VectorParams(size=len(embs[0]), distance=models.Distance.COSINE)}\n        )\n        points = []\n        for c, v in zip(chunks, embs):\n            # Derive a stable UUID from the chunk id string to satisfy Qdrant (expects int or UUID)\n            cid = str(c['id'])\n            pid = str(uuid.uuid5(uuid.NAMESPACE_DNS, cid))\n            # Create slim payload without code (code is stored locally in chunks.jsonl)\n            slim_payload = {\n                'id': c.get('id'),\n                'file_path': c.get('file_path'),\n                'start_line': c.get('start_line'),\n                'end_line': c.get('end_line'),\n                'layer': c.get('layer'),\n                'repo': c.get('repo'),\n                'origin': c.get('origin'),\n                'hash': c.get('hash'),\n                'language': c.get('language')\n            }\n            # Remove None values to keep payload minimal\n            slim_payload = {k: v for k, v in slim_payload.items() if v is not None}\n            points.append(models.PointStruct(id=pid, vector={'dense': v}, payload=slim_payload))\n            point_ids.append(pid)\n            if len(points) == 64:\n                q.upsert(COLLECTION, points=points)\n                points = []\n        if points:\n            q.upsert(COLLECTION, points=points)\n        # Persist point id mapping aligned to BM25 corpus order\n        import json as _json\n        _json.dump({str(i): pid for i, pid in enumerate(point_ids)}, open(os.path.join(OUTDIR,'bm25_index','bm25_point_ids.json'),'w'))\n        print(f'Indexed {len(chunks)} chunks to Qdrant (embeddings: {len(embs[0])} dims).')\n    except Exception as e:\n        # Allow offline usage (BM25-only search) when Qdrant is unavailable\n        print(f\"Qdrant unavailable or failed to index ({e}); continuing with BM25-only index. Dense retrieval will be disabled.\")\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6dc9cd60c55beb60583fc7bdc0119739"}
{"id": "b0884cab15cc", "file_path": "/Users/davidmontgomery/agro/embed_cache.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 3, "imports": ["import os, json", "import tiktoken"], "code": "import os, json\nimport tiktoken\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0ef50c49b537aa279335f6a7c4c0d20a"}
{"id": "2c5ebf388812", "file_path": "/Users/davidmontgomery/agro/embed_cache.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 68, "imports": [], "code": "EmbeddingCache:\n    def __init__(self, outdir: str):\n        os.makedirs(outdir, exist_ok=True)\n        self.path = os.path.join(outdir, \"embed_cache.jsonl\")\n        self.cache = {}\n        if os.path.exists(self.path):\n            with open(self.path, \"r\", encoding=\"utf-8\") as f:\n                for line in f:\n                    try:\n                        o = json.loads(line)\n                        self.cache[o[\"hash\"]] = o[\"vec\"]\n                    except Exception:\n                        pass\n\n    def get(self, h: str):\n        return self.cache.get(h)\n\n    def put(self, h: str, v):\n        self.cache[h] = v\n\n    def save(self):\n        with open(self.path, \"w\", encoding=\"utf-8\") as f:\n            for h, v in self.cache.items():\n                f.write(json.dumps({\"hash\": h, \"vec\": v}) + \"\\n\")\n\n    def prune(self, valid_hashes: set):\n        \"\"\"Remove cached embeddings for chunks that no longer exist.\n\n        Args:\n            valid_hashes: Set of hashes for chunks that currently exist\n\n        Returns:\n            Number of entries pruned\n        \"\"\"\n        before = len(self.cache)\n        self.cache = {h: v for h, v in self.cache.items() if h in valid_hashes}\n        after = len(self.cache)\n        pruned = before - after\n        if pruned > 0:\n            self.save()\n        return pruned\n\n    def embed_texts(self, client, texts, hashes, model=\"text-embedding-3-large\", batch=64):\n        embs = [None] * len(texts)\n        to_embed, idx_map = [], []\n        for i, (t, h) in enumerate(zip(texts, hashes)):\n            v = self.get(h)\n            if v is None:\n                idx_map.append(i)\n                to_embed.append(t)\n            else:\n                embs[i] = v\n        enc = tiktoken.get_encoding('cl100k_base')\n        def _clip_for_openai(text: str, max_tokens: int = 8000) -> str:\n            toks = enc.encode(text)\n            if len(toks) <= max_tokens:\n                return text\n            return enc.decode(toks[:max_tokens])\n        for i in range(0, len(to_embed), batch):\n            sub = [_clip_for_openai(t) for t in to_embed[i:i+batch]]\n            r = client.embeddings.create(model=model, input=sub)\n            for j, d in enumerate(r.data):\n                orig = idx_map[i + j]\n                vec = d.embedding\n                embs[orig] = vec\n                self.put(hashes[orig], vec)\n        return embs\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "32dea01bdec3bd025bda2c08cda0ee9d"}
{"id": "43816d92dc2d", "file_path": "/Users/davidmontgomery/agro/mcp_server.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 26, "imports": ["import sys", "import json", "import os", "from pathlib import Path", "from typing import Dict, Any, List", "from langgraph_app import build_graph", "from hybrid_search import search_routed_multi", "import urllib.request, urllib.error, urllib.parse", "import json as _json", "from config_loader import list_repos"], "code": "#!/usr/bin/env python3\n\"\"\"\nMCP server exposing RAG tools for Codex/Claude integration.\nImplements Model Context Protocol via stdio.\n\nTools (sanitized names for OpenAI tool spec):\n  - rag_answer(repo, question) → full LangGraph answer + citations\n  - rag_search(repo, question) → retrieval-only (for debugging)\nCompatibility: accepts legacy names \"rag.answer\" and \"rag.search\" on tools/call.\n\"\"\"\nimport sys\nimport json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, List\n\n# Ensure we can import from the same directory\nsys.path.insert(0, str(Path(__file__).parent))\n\nfrom langgraph_app import build_graph\nfrom hybrid_search import search_routed_multi\nimport urllib.request, urllib.error, urllib.parse\nimport json as _json\nfrom config_loader import list_repos\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6bbf52eb6b1a7fe629d66a6095de7da3"}
{"id": "e3c9436283f5", "file_path": "/Users/davidmontgomery/agro/mcp_server.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 440, "imports": [], "code": "MCPServer:\n    \"\"\"Minimal MCP server over stdio.\"\"\"\n\n    def __init__(self):\n        self.graph = None\n        self._init_graph()\n\n    def _init_graph(self):\n        \"\"\"Lazy-load the LangGraph.\"\"\"\n        try:\n            self.graph = build_graph()\n        except Exception as e:\n            self._error(f\"Failed to initialize graph: {e}\")\n\n    def _error(self, msg: str):\n        \"\"\"Write error to stderr (MCP uses stdout for protocol).\"\"\"\n        print(f\"ERROR: {msg}\", file=sys.stderr)\n\n    def _log(self, msg: str):\n        \"\"\"Write log to stderr.\"\"\"\n        print(f\"LOG: {msg}\", file=sys.stderr)\n\n    def handle_rag_answer(self, repo: str, question: str) -> Dict[str, Any]:\n        \"\"\"\n        Execute full LangGraph pipeline: retrieval → generation → answer.\n        Returns: {answer: str, citations: List[str], repo: str}\n        \"\"\"\n        if not self.graph:\n            self._init_graph()\n\n        if not self.graph:\n            return {\n                \"error\": \"Graph not initialized\",\n                \"answer\": \"\",\n                \"citations\": [],\n                \"repo\": repo or \"unknown\"\n            }\n\n        try:\n            allowed = set(list_repos())\n            if repo not in allowed:\n                return {\"error\": f\"invalid repo '{repo}', allowed={sorted(allowed)}\", \"answer\": \"\", \"citations\": [], \"repo\": repo or \"unknown\"}\n            cfg = {\"configurable\": {\"thread_id\": f\"mcp-{repo or 'default'}\"}}\n            state = {\n                \"question\": question,\n                \"documents\": [],\n                \"generation\": \"\",\n                \"iteration\": 0,\n                \"confidence\": 0.0,\n                \"repo\": repo\n            }\n\n            result = self.graph.invoke(state, cfg)\n\n            # Extract citations from documents\n            docs = result.get(\"documents\", [])[:5]\n            citations = [\n                f\"{d['file_path']}:{d['start_line']}-{d['end_line']}\"\n                for d in docs\n            ]\n\n            return {\n                \"answer\": result.get(\"generation\", \"\"),\n                \"citations\": citations,\n                \"repo\": result.get(\"repo\", repo or \"unknown\"),\n                \"confidence\": float(result.get(\"confidence\", 0.0))\n            }\n        except Exception as e:\n            self._error(f\"rag.answer error: {e}\")\n            return {\n                \"error\": str(e),\n                \"answer\": \"\",\n                \"citations\": [],\n                \"repo\": repo or \"unknown\"\n            }\n\n    def handle_rag_search(self, repo: str, question: str, top_k: int = 10) -> Dict[str, Any]:\n        \"\"\"\n        Retrieval-only path for debugging.\n        Returns: {results: List[Dict], repo: str, count: int}\n        \"\"\"\n        try:\n            allowed = set(list_repos())\n            if repo not in allowed:\n                return {\"error\": f\"invalid repo '{repo}', allowed={sorted(allowed)}\", \"results\": [], \"repo\": repo or \"unknown\", \"count\": 0}\n            docs = search_routed_multi(\n                question,\n                repo_override=repo,\n                m=4,\n                final_k=top_k\n            )\n\n            # Return slim results (no code bodies for MCP transport)\n            results = [\n                {\n                    \"file_path\": d.get(\"file_path\", \"\"),\n                    \"start_line\": d.get(\"start_line\", 0),\n                    \"end_line\": d.get(\"end_line\", 0),\n                    \"language\": d.get(\"language\", \"\"),\n                    \"rerank_score\": float(d.get(\"rerank_score\", 0.0)),\n                    \"repo\": d.get(\"repo\", repo or \"unknown\")\n                }\n                for d in docs\n            ]\n\n            return {\n                \"results\": results,\n                \"repo\": repo or (results[0][\"repo\"] if results else \"unknown\"),\n                \"count\": len(results)\n            }\n        except Exception as e:\n            self._error(f\"rag.search error: {e}\")\n            return {\n                \"error\": str(e),\n                \"results\": [],\n                \"repo\": repo or \"unknown\",\n                \"count\": 0\n            }\n\n    # --- Netlify helpers ---\n    def _netlify_api(self, path: str, method: str = \"GET\", data: dict | None = None) -> dict:\n        api_key = os.getenv(\"NETLIFY_API_KEY\")\n        if not api_key:\n            raise RuntimeError(\"NETLIFY_API_KEY not set in environment\")\n        url = f\"https://api.netlify.com/api/v1{path}\"\n        req = urllib.request.Request(url, method=method)\n        req.add_header(\"Authorization\", f\"Bearer {api_key}\")\n        req.add_header(\"Content-Type\", \"application/json\")\n        body = None\n        if data is not None:\n            body = _json.dumps(data).encode(\"utf-8\")\n        try:\n            with urllib.request.urlopen(req, data=body, timeout=30) as resp:\n                raw = resp.read().decode(\"utf-8\")\n                return _json.loads(raw) if raw else {}\n        except urllib.error.HTTPError as he:\n            err_body = he.read().decode(\"utf-8\", errors=\"ignore\")\n            raise RuntimeError(f\"Netlify HTTP {he.code}: {err_body}\")\n\n    def _netlify_find_site_by_domain(self, domain: str) -> dict | None:\n        sites = self._netlify_api(\"/sites\", method=\"GET\")\n        if isinstance(sites, list):\n            domain_low = (domain or \"\").strip().lower()\n            for s in sites:\n                for key in (\"custom_domain\", \"url\", \"ssl_url\"):\n                    val = (s.get(key) or \"\").lower()\n                    if val and domain_low in val:\n                        return s\n        return None\n\n    def handle_netlify_deploy(self, domain: str) -> Dict[str, Any]:\n        targets: list[str]\n        if domain == \"both\":\n            targets = [\"project.net\", \"project.dev\"]\n        else:\n            targets = [domain]\n        results = []\n        for d in targets:\n            site = self._netlify_find_site_by_domain(d)\n            if not site:\n                results.append({\"domain\": d, \"status\": \"not_found\"})\n                continue\n            site_id = site.get(\"id\")\n            if not site_id:\n                results.append({\"domain\": d, \"status\": \"no_site_id\"})\n                continue\n            try:\n                build = self._netlify_api(f\"/sites/{site_id}/builds\", method=\"POST\", data={})\n                results.append({\n                    \"domain\": d,\n                    \"status\": \"triggered\",\n                    \"site_id\": site_id,\n                    \"build_id\": build.get(\"id\"),\n                })\n            except Exception as e:\n                results.append({\"domain\": d, \"status\": \"error\", \"error\": str(e)})\n        return {\"results\": results}\n\n    # --- Web tools (allowlisted) ---\n    _WEB_ALLOWED = {\"openai.com\", \"platform.openai.com\", \"github.com\", \"openai.github.io\"}\n\n    def _is_allowed_url(self, url: str) -> bool:\n        try:\n            u = urllib.parse.urlparse(url)\n            host = (u.netloc or \"\").lower()\n            # allow subdomains of allowed hosts\n            return any(host == h or host.endswith(\".\" + h) for h in self._WEB_ALLOWED)\n        except Exception:\n            return False\n\n    def handle_web_get(self, url: str, max_bytes: int = 20000) -> Dict[str, Any]:\n        if not (url or \"\").startswith(\"http\"):\n            return {\"error\": \"url must start with http(s)\"}\n        if not self._is_allowed_url(url):\n            return {\"error\": \"host not allowlisted\"}\n        req = urllib.request.Request(url, method=\"GET\", headers={\"User-Agent\": \"project-rag-mcp/1.0\"})\n        try:\n            with urllib.request.urlopen(req, timeout=20) as resp:\n                raw = resp.read(max_bytes + 1)\n                clipped = raw[:max_bytes]\n                return {\n                    \"url\": url,\n                    \"status\": resp.status,\n                    \"length\": len(raw),\n                    \"clipped\": len(raw) > len(clipped),\n                    \"content_preview\": clipped.decode(\"utf-8\", errors=\"ignore\")\n                }\n        except urllib.error.HTTPError as he:\n            body = he.read().decode(\"utf-8\", errors=\"ignore\")\n            return {\"url\": url, \"status\": he.code, \"error\": body[:1000]}\n        except Exception as e:\n            return {\"url\": url, \"error\": str(e)}\n\n    def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Handle MCP tool call request.\n\n        Request format:\n        {\n          \"jsonrpc\": \"2.0\",\n          \"id\": <request_id>,\n          \"method\": \"tools/call\",\n          \"params\": {\n            \"name\": \"rag.answer\" | \"rag.search\",\n            \"arguments\": {\n              \"repo\": \"project\" | \"project\",\n              \"question\": \"...\",\n              \"top_k\": 10  # optional, search only\n            }\n          }\n        }\n        \"\"\"\n        method = request.get(\"method\")\n        req_id = request.get(\"id\")\n\n        if method == \"tools/list\":\n            # Return available tools\n            repos = list_repos()\n            return {\n                \"jsonrpc\": \"2.0\",\n                \"id\": req_id,\n                \"result\": {\n                    \"tools\": [\n                        {\n                            \"name\": \"rag_answer\",\n                            \"description\": \"Get RAG answer with citations for a configured repo\",\n                            \"inputSchema\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"repo\": {\n                                        \"type\": \"string\",\n                                        \"description\": \"Repository name\",\n                                        \"enum\": repos\n                                    },\n                                    \"question\": {\n                                        \"type\": \"string\",\n                                        \"description\": \"Developer question to answer from codebase\"\n                                    }\n                                },\n                                \"required\": [\"repo\", \"question\"]\n                            }\n                        },\n                        {\n                            \"name\": \"rag_search\",\n                            \"description\": \"Retrieval-only search (debugging) - returns relevant code locations without generation\",\n                            \"inputSchema\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"repo\": {\n                                        \"type\": \"string\",\n                                        \"description\": \"Repository name\",\n                                        \"enum\": repos\n                                    },\n                                    \"question\": {\n                                        \"type\": \"string\",\n                                        \"description\": \"Search query for code retrieval\"\n                                    },\n                                    \"top_k\": {\n                                        \"type\": \"integer\",\n                                        \"description\": \"Number of results to return (default: 10)\",\n                                        \"default\": 10\n                                    }\n                                },\n                                \"required\": [\"repo\", \"question\"]\n                            }\n                        },\n                        {\n                            \"name\": \"netlify_deploy\",\n                            \"description\": \"Trigger a Netlify build for project.net, project.dev, or both (uses NETLIFY_API_KEY)\",\n                            \"inputSchema\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"domain\": {\n                                        \"type\": \"string\",\n                                        \"description\": \"Target domain\",\n                                        \"enum\": [\"project.net\", \"project.dev\", \"both\"],\n                                        \"default\": \"both\"\n                                    }\n                                }\n                            }\n                        },\n                        {\n                            \"name\": \"web_get\",\n                            \"description\": \"HTTP GET (allowlisted hosts only: openai.com, platform.openai.com, github.com, openai.github.io)\",\n                            \"inputSchema\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"url\": {\"type\": \"string\", \"description\": \"Absolute URL to fetch\"},\n                                    \"max_bytes\": {\"type\": \"integer\", \"description\": \"Max bytes to return\", \"default\": 20000}\n                                },\n                                \"required\": [\"url\"]\n                            }\n                        }\n                    ]\n                }\n            }\n\n        elif method == \"tools/call\":\n            params = request.get(\"params\", {})\n            tool_name = params.get(\"name\")\n            args = params.get(\"arguments\", {})\n\n            # Backward-compat: accept legacy dotted names\n            if tool_name in (\"rag.answer\", \"rag_answer\"):\n                result = self.handle_rag_answer(\n                    repo=args.get(\"repo\"),\n                    question=args.get(\"question\", \"\")\n                )\n                return {\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": req_id,\n                    \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(result, indent=2)}]}\n                }\n\n            elif tool_name in (\"rag.search\", \"rag_search\"):\n                result = self.handle_rag_search(\n                    repo=args.get(\"repo\"),\n                    question=args.get(\"question\", \"\"),\n                    top_k=args.get(\"top_k\", 10)\n                )\n                return {\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": req_id,\n                    \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(result, indent=2)}]}\n                }\n\n            elif tool_name in (\"netlify.deploy\", \"netlify_deploy\"):\n                domain = args.get(\"domain\", \"both\")\n                result = self.handle_netlify_deploy(domain)\n                return {\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": req_id,\n                    \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(result, indent=2)}]}\n                }\n\n            elif tool_name in (\"web.get\", \"web_get\"):\n                url = args.get(\"url\", \"\")\n                max_bytes = args.get(\"max_bytes\", 20000)\n                result = self.handle_web_get(url, max_bytes=max_bytes)\n                return {\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": req_id,\n                    \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(result, indent=2)}]}\n                }\n\n            else:\n                return {\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": req_id,\n                    \"error\": {\n                        \"code\": -32601,\n                        \"message\": f\"Unknown tool: {tool_name}\"\n                    }\n                }\n\n        elif method == \"initialize\":\n            return {\n                \"jsonrpc\": \"2.0\",\n                \"id\": req_id,\n                \"result\": {\n                    \"protocolVersion\": \"2024-11-05\",\n                    \"capabilities\": {\n                        \"tools\": {}\n                    },\n                    \"serverInfo\": {\n                        \"name\": \"project-rag-mcp\",\n                        \"version\": \"1.0.0\"\n                    }\n                }\n            }\n\n        else:\n            return {\n                \"jsonrpc\": \"2.0\",\n                \"id\": req_id,\n                \"error\": {\n                    \"code\": -32601,\n                    \"message\": f\"Method not found: {method}\"\n                }\n            }\n\n    def run(self):\n        \"\"\"Main stdio loop.\"\"\"\n        self._log(\"MCP server starting (stdio mode)...\")\n\n        for line in sys.stdin:\n            line = line.strip()\n            if not line:\n                continue\n\n            try:\n                request = json.loads(line)\n                response = self.handle_request(request)\n                print(json.dumps(response), flush=True)\n            except json.JSONDecodeError as e:\n                self._error(f\"Invalid JSON: {e}\")\n                print(json.dumps({\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": None,\n                    \"error\": {\n                        \"code\": -32700,\n                        \"message\": \"Parse error\"\n                    }\n                }), flush=True)\n            except Exception as e:\n                self._error(f\"Unexpected error: {e}\")\n                print(json.dumps({\n                    \"jsonrpc\": \"2.0\",\n                    \"id\": None,\n                    \"error\": {\n                        \"code\": -32603,\n                        \"message\": f\"Internal error: {e}\"\n                    }\n                }), flush=True)\n\n\nif __name__ == \"__main__\":\n    server = MCPServer()\n    server.run()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1933bb4d72a1e153c9b8c601dcdc3c8d"}
{"id": "bfbd77bc84be", "file_path": "/Users/davidmontgomery/agro/node_mcp/server.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 36, "imports": ["import express from 'express';", "import fetch from 'node-fetch';"], "code": "import express from 'express';\nimport fetch from 'node-fetch';\n\nconst app = express();\nconst PORT = process.env.PORT || 8014;\nconst RAG_API_URL = process.env.RAG_API_URL || 'http://127.0.0.1:8012';\n\napp.get('/health', (req, res) => {\n  res.json({ status: 'ok', proxy: true, target: RAG_API_URL });\n});\n\n// JSON answer proxy\napp.get('/mcp/answer', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// JSON search proxy\napp.get('/mcp/search', async (req, res) => {\n  try {\n    const { q, repo, top_k, token } = req.query;\n    const u = new URL('/search', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    if (top_k) u.searchParams.set('top_k', String(top_k));\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ee1480fbc93b89437e3ba2fa8ed4e377"}
{"id": "ac1ff05db109", "file_path": "/Users/davidmontgomery/agro/node_mcp/server.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 36, "imports": ["import express from 'express';", "import fetch from 'node-fetch';"], "code": "    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// SSE proxy for streaming answer\napp.get('/mcp/answer_stream', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer_stream', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.searchParams.set('repo', repo);\n    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n\n    const r = await fetch(u.toString(), { headers });\n    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');\n    res.setHeader('Cache-Control', 'no-cache');\n    res.setHeader('X-Accel-Buffering', 'no');\n\n    if (!r.ok || !r.body) {\n      res.write(`data: [ERROR] upstream ${r.status}\\n\\n`);\n      return res.end();\n    }\n\n    const reader = r.body.getReader();\n    const decoder = new TextDecoder();\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n      res.write(decoder.decode(value));\n      // flush\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4f6e37f5c41bb7d8ccc0ed5fc0781051"}
{"id": "4ce2af0fac71", "file_path": "/Users/davidmontgomery/agro/node_mcp/server.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 14, "imports": ["import express from 'express';", "import fetch from 'node-fetch';"], "code": "    }\n    res.end();\n  } catch (e) {\n    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');\n    res.write(`data: [ERROR] ${String(e)}\\n\\n`);\n    res.end();\n  }\n});\n\napp.listen(PORT, () => {\n  console.log(`Node proxy listening on :${PORT}, targeting ${RAG_API_URL}`);\n});\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e26c702caa984b43003a438b52aae4a8"}
{"id": "503413cd86a9", "file_path": "/Users/davidmontgomery/agro/scripts/test_backend.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 20, "imports": ["from __future__ import annotations", "from fastapi.testclient import TestClient", "import io", "from pathlib import Path", "import json, sys", "import types as _types", "import serve_rag"], "code": "#!/usr/bin/env python3\nfrom __future__ import annotations\nfrom fastapi.testclient import TestClient\nimport io\nfrom pathlib import Path\nimport json, sys\nROOT = Path(__file__).resolve().parents[1]\nsys.path.insert(0, str(ROOT))\n# Provide a lightweight stub for rerankers to avoid import-time type errors\nimport types as _types\nif 'rerankers' not in sys.modules:\n    m = _types.ModuleType('rerankers')\n    class Reranker:  # minimal placeholder\n        def __init__(self, *a, **k):\n            pass\n    m.Reranker = Reranker\n    sys.modules['rerankers'] = m\nimport serve_rag\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f55adb4f1aadd6018d749f9d27c318de"}
{"id": "04f4d8b30b3d", "file_path": "/Users/davidmontgomery/agro/scripts/test_backend.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 41, "imports": [], "code": "main() -> int:\n    app = serve_rag.app\n    c = TestClient(app)\n\n    # Prices\n    r = c.get('/api/prices')\n    assert r.status_code == 200, r.text\n    models = r.json().get('models', [])\n    print('prices models:', len(models))\n\n    # Upsert a model\n    r = c.post('/api/prices/upsert', json={\"provider\":\"local\",\"model\":\"qwen3-coder:14b\",\"unit\":\"request\"})\n    assert r.status_code == 200 and r.json().get('ok'), r.text\n\n    # Cost estimate\n    r = c.post('/api/cost/estimate', json={\"provider\":\"openai\",\"model\":\"gpt-4o-mini\",\"tokens_in\":500,\"tokens_out\":800,\"embeds\":0,\"reranks\":0,\"requests_per_day\":100})\n    assert r.status_code == 200, r.text\n    print('cost:', r.json().get('daily'), r.json().get('monthly'))\n\n    # Secrets ingest\n    buf = io.BytesIO(b\"OPENAI_API_KEY=sk-test-xyz\\nREPO=agro\\n\")\n    files = {\"file\": (\"tmp.env\", buf, \"text/plain\")}\n    data = {\"persist\": \"true\"}\n    r = c.post('/api/secrets/ingest', files=files, data=data)\n    assert r.status_code == 200, r.text\n    r = c.get('/api/config')\n    env = r.json().get('env', {})\n    assert env.get('OPENAI_API_KEY') == 'sk-test-xyz', env\n    print('env OPENAI_API_KEY:', env.get('OPENAI_API_KEY'))\n\n    # Autotune\n    r = c.get('/api/autotune/status')\n    assert r.status_code == 200\n    print('autotune:', r.json())\n\n    return 0\n\n\nif __name__ == '__main__':\n    raise SystemExit(main())\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "27d7aa0dfc5768797a94c9f1aee70d8e"}
{"id": "f3ee80787ece", "file_path": "/Users/davidmontgomery/agro/scripts/quick_token_test.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 35, "imports": ["import os", "import sys", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"Quick token test for docs - measure actual usage\"\"\"\nimport os\nos.environ[\"OLLAMA_URL\"] = \"http://127.0.0.1:11434/api\"\nos.environ[\"GEN_MODEL\"] = \"qwen3-coder:30b\"\n\nimport sys\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model(\"gpt-4o\")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\n# Test 1: Claude Alone (read full files)\nfrom pathlib import Path\nquestion = \"How are fax jobs created and dispatched\"\nkeywords = [\"fax\", \"jobs\", \"created\", \"dispatched\"]\nrepo_path = os.getenv('project_PATH', '/abs/path/to/project')\n\nfull_content = \"\"\nfor py_file in list(Path(repo_path).rglob('*.py'))[:10]:\n    try:\n        content = py_file.read_text(errors='ignore')\n        if any(kw in content.lower() for kw in keywords):\n            full_content += f\"\\n{'='*70}\\n{content}\\n\"\n    except:\n        pass\n\ntokens_claude_alone = count_tokens(full_content)\nprint(f\"1. Claude Alone: {tokens_claude_alone:,} tokens\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "63ed2f7fc40d8a55d20890bd76f802cf"}
{"id": "f3db3ef4c517", "file_path": "/Users/davidmontgomery/agro/scripts/quick_token_test.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 26, "imports": ["import os", "import sys", "from pathlib import Path"], "code": "\n# Test 2: MCP metadata only (simulate what Claude Code gets)\nmcp_response = \"\"\"{\"results\": [\n  {\"file_path\": \"server.py\", \"start_line\": 120, \"end_line\": 145, \"score\": 0.89},\n  {\"file_path\": \"tasks.py\", \"start_line\": 67, \"end_line\": 89, \"score\": 0.85},\n  {\"file_path\": \"models.py\", \"start_line\": 234, \"end_line\": 267, \"score\": 0.78}\n], \"count\": 3}\"\"\"\n\n# Tool schema (sent with every request)\ntool_schema = \"\"\"{\"tools\": [{\"name\": \"rag_search\", \"description\": \"Search codebase\", \"inputSchema\": {...}}]}\"\"\"\n\ntokens_mcp = count_tokens(mcp_response + tool_schema)\nprint(f\"2. Claude + RAG via MCP: {tokens_mcp:,} tokens\")\n\n# Calculate savings\nsaved = tokens_claude_alone - tokens_mcp\npct = (saved / tokens_claude_alone * 100) if tokens_claude_alone > 0 else 0\nreduction = tokens_claude_alone / tokens_mcp if tokens_mcp > 0 else 0\n\nprint(f\"\\nSavings: {saved:,} tokens ({pct:.1f}%)\")\nprint(f\"Reduction: {reduction:.1f}x\")\n\n# Cost (gpt-4o: $2.50/1M input)\ncost_alone = tokens_claude_alone * (2.50 / 1_000_000)\ncost_mcp = tokens_mcp * (2.50 / 1_000_000)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3dd72edef1cb48ee8233ad1fb219bec3"}
{"id": "4d2bf174aa8e", "file_path": "/Users/davidmontgomery/agro/scripts/quick_token_test.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 6, "imports": ["import os", "import sys", "from pathlib import Path"], "code": "cost_saved = cost_alone - cost_mcp\n\nprint(f\"\\nPer query: ${cost_saved:.6f} saved\")\nprint(f\"Per 100 queries: ${cost_saved * 100:.2f} saved\")\nprint(f\"Per month (100/day): ${cost_saved * 3000:.2f} saved\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "74bb71cc0ae453ba0bacc9eff6f30137"}
{"id": "7a36a5116717", "file_path": "/Users/davidmontgomery/agro/scripts/netlify_deploy.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 28, "imports": ["import os, sys, json, urllib.request, urllib.error"], "code": "#!/usr/bin/env python3\nimport os, sys, json, urllib.request, urllib.error\n\nAPI = \"https://api.netlify.com/api/v1\"\napi(path: str, method: str = \"GET\", data: dict | None = None) -> dict:\n    token = os.getenv(\"NETLIFY_API_KEY\")\n    if not token:\n        print(\"NETLIFY_API_KEY not set\", file=sys.stderr)\n        sys.exit(2)\n    url = f\"{API}{path}\"\n    req = urllib.request.Request(url, method=method)\n    req.add_header(\"Authorization\", f\"Bearer {token}\")\n    req.add_header(\"Content-Type\", \"application/json\")\n    body = json.dumps(data).encode(\"utf-8\") if data is not None else None\n    with urllib.request.urlopen(req, data=body, timeout=30) as resp:\n        raw = resp.read().decode(\"utf-8\")\n        return json.loads(raw) if raw else {}\nfind_site(domain: str) -> dict | None:\n    sites = api(\"/sites\", \"GET\")\n    dom = (domain or \"\").strip().lower()\n    if isinstance(sites, list):\n        for s in sites:\n            for key in (\"custom_domain\", \"url\", \"ssl_url\"):\n                val = (s.get(key) or \"\").lower()\n                if val and dom in val:\n                    return s\n    return None\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "31668c3a7051ca3c58abaa0c9532f375"}
{"id": "c4b9afcb2a74", "file_path": "/Users/davidmontgomery/agro/scripts/netlify_deploy.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 13, "imports": [], "code": "trigger(domain: str) -> dict:\n    s = find_site(domain)\n    if not s:\n        return {\"domain\": domain, \"status\": \"not_found\"}\n    sid = s.get(\"id\")\n    if not sid:\n        return {\"domain\": domain, \"status\": \"no_site_id\"}\n    try:\n        b = api(f\"/sites/{sid}/builds\", \"POST\", {})\n        return {\"domain\": domain, \"status\": \"triggered\", \"site_id\": sid, \"build_id\": b.get(\"id\")}\n    except Exception as e:\n        return {\"domain\": domain, \"status\": \"error\", \"error\": str(e)}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4d84597fbd9a9cb3f5c1fd2cd8c79855"}
{"id": "4c5ab77428eb", "file_path": "/Users/davidmontgomery/agro/scripts/netlify_deploy.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 20, "imports": [], "code": "main():\n    if len(sys.argv) < 2:\n        print(\"Usage: netlify_deploy.py [project.net|project.dev|both|list]\", file=sys.stderr)\n        sys.exit(2)\n    cmd = sys.argv[1].strip().lower()\n    if cmd == \"list\":\n        sites = api(\"/sites\", \"GET\")\n        out = []\n        for s in sites if isinstance(sites, list) else []:\n            out.append({\"id\": s.get(\"id\"), \"name\": s.get(\"name\"), \"url\": s.get(\"url\"), \"custom_domain\": s.get(\"custom_domain\")})\n        print(json.dumps(out, indent=2))\n        return\n    domains = [\"project.net\", \"project.dev\"] if cmd == \"both\" else [cmd]\n    results = [trigger(d) for d in domains]\n    print(json.dumps(results, indent=2))\n\nif __name__ == \"__main__\":\n    main()\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1154ac4e777f87e0189052b9ccf2e8aa"}
{"id": "b9280c3f4707", "file_path": "/Users/davidmontgomery/agro/scripts/guard_legacy_api.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 40, "imports": ["import os, sys, re"], "code": "#!/usr/bin/env python3\nimport os, sys, re\n\nSCAN_ALL = os.getenv(\"SCAN_ALL\", \"0\").lower() in {\"1\",\"true\",\"yes\"}\nROOTS = [os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))]\nif SCAN_ALL:\n    ROOTS += [\n        os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        os.getenv('project_PATH', '/abs/path/to/project'),\n    ]\n\nBAD_PATTERNS = [\n    r\"\\bChatCompletion\\b\",\n    r\"\\bclient\\.chat\\.completions\\b\",\n    r\"\\bassistants?\\.v1\\b\",\n    r\"\\bgpt-3\\.5\\b\",\n    r\"\\bgpt-4(?!\\.1|o)\\b\",\n    r\"\\bgpt-4o(-mini)?\\b\",\n    r\"\\btext-embedding-ada\\b\",\n    r\"\\btext-embedding-00[23]\\b\",\n]\nALLOWLIST_FILES = {\n    # add filenames you want ignored (e.g., historical docs)\n}\n\nSKIP_DIRS = {\".git\", \".venv\", \"venv\", \"node_modules\", \"dist\", \"build\", \"vendor\", \"third_party\", \"site-packages\", \"__pycache__\"}\n\nscan_file(path: str) -> list[str]:\n    try:\n        with open(path, \"r\", errors=\"ignore\") as f:\n            s = f.read()\n    except Exception:\n        return []\n    hits = []\n    for pat in BAD_PATTERNS:\n        if re.search(pat, s):\n            hits.append(pat)\n    return hits\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e711f9e243bb5a6f3487c18b568ee56a"}
{"id": "3dfc561113da", "file_path": "/Users/davidmontgomery/agro/scripts/guard_legacy_api.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 39, "imports": [], "code": "main() -> int:\n    offenders = []\n    for root in ROOTS:\n        if not os.path.isdir(root):\n            continue\n        for base, dirs, files in os.walk(root):\n            # prune skip dirs\n            dirs[:] = [d for d in dirs if d not in SKIP_DIRS and not d.startswith('.')]\n            for name in files:\n                if name in ALLOWLIST_FILES:\n                    continue\n                # Scan code files only (skip docs like .md)\n                if not any(name.endswith(ext) for ext in (\".py\", \".ts\", \".tsx\", \".js\", \".rb\")):\n                    continue\n                path = os.path.join(base, name)\n                # skip this guard file and sitecustomize self-detection\n                if path.endswith(\"scripts/guard_legacy_api.py\") or path.endswith(\"sitecustomize.py\"):\n                    continue\n                hits = scan_file(path)\n                if hits:\n                    offenders.append((path, hits))\n    if offenders:\n        print(\"\\u274c Legacy APIs/models detected:\")\n        for p, pats in offenders:\n            print(f\"- {p}\")\n            for pat in pats:\n                print(f\"    \\u21b3 {pat}\")\n        print(\"\\nAction: replace Chat Completions with Responses API calls; update model pins (e.g., gpt-4o-mini-latest or a dated pin).\")\n        print(\"Docs:\")\n        print(\"  https://openai.com/index/new-tools-and-features-in-the-responses-api/\")\n        print(\"  https://openai.com/index/introducing-upgrades-to-codex/\")\n        return 2\n    print(\"\\u2713 No legacy APIs/models detected.\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    raise SystemExit(main())\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7737bc343c039ff70c36ad06625e0a42"}
{"id": "5ab43e06d005", "file_path": "/Users/davidmontgomery/agro/scripts/measure_overhead.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 31, "imports": ["import sys, os", "import json", "from mcp_server import MCPServer"], "code": "#!/usr/bin/env python3\n\"\"\"Measure MCP tool schema overhead - the part sent on EVERY request\"\"\"\nimport sys, os\nimport json\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model(\"gpt-4o\")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\n# Get tool schemas\nfrom mcp_server import MCPServer\nserver = MCPServer()\ntools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\ntools_resp = server.handle_request(tools_req)\ntools_json = json.dumps(tools_resp['result']['tools'], indent=2)\n\nschema_tokens = count_tokens(tools_json)\n\nprint(\"=\" * 80)\nprint(\"MCP TOOL SCHEMA OVERHEAD (sent with EVERY Claude Code request)\")\nprint(\"=\" * 80)\nprint(f\"Schema tokens: {schema_tokens:,}\")\nprint(f\"Schema size: {len(tools_json):,} bytes\")\nprint(f\"\\nThis overhead is ADDED to every single request.\")\nprint(f\"Even if MCP response is small, you always pay for the tool schemas.\\n\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5c34d13fb4a3a0249eabaea2c1d003ed"}
{"id": "d8dfba881bd2", "file_path": "/Users/davidmontgomery/agro/scripts/measure_overhead.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 10, "imports": ["import sys, os", "import json", "from mcp_server import MCPServer"], "code": "\n# Show the actual schema\nprint(\"Tool schemas:\")\nfor tool in tools_resp['result']['tools']:\n    print(f\"  - {tool['name']}: {len(json.dumps(tool)):,} bytes\")\n\nwith open('/tmp/mcp_schema.json', 'w') as f:\n    f.write(tools_json)\nprint(f\"\\nFull schema saved to: /tmp/mcp_schema.json\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5777626a73c22803cc3421f000302207"}
{"id": "9fbbfaf90282", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 40, "imports": ["import sys", "import os", "import json", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"\nCompare token usage across three approaches:\n1. Claude alone (no RAG) - reads full files\n2. RAG via direct Python calls (hybrid_search.py)\n3. RAG via MCP tools (what Claude Code uses)\n\nThis shows actual token savings from using RAG.\n\"\"\"\n\nimport sys\nimport os\nimport json\nfrom pathlib import Path\n\n# Try tiktoken for precise counts\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\n    print(\"✓ Using tiktoken for precise token counts\\n\")\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print(\"⚠️  tiktoken not installed - using estimates (1 token ≈ 4 chars)\")\n    print(\"   Install: pip install tiktoken\\n\")\n\ncount_tokens(text: str, model: str = \"gpt-4o\") -> int:\n    \"\"\"Count tokens precisely or estimate\"\"\"\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    return len(text) // 4\n\n\n# ============================================================\n# Approach 1: Claude Alone (Traditional - NO RAG)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "224927dfd6d01ab8480997132f82ae4e"}
{"id": "3c4c00611bd8", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 56, "imports": [], "code": "measure_claude_alone(question: str, repo: str):\n    \"\"\"\n    Simulate what Claude would do WITHOUT RAG:\n    - Extract keywords from question\n    - Grep files for those keywords\n    - Read 5-10 full files\n    \"\"\"\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'error': f'Repo not found: {repo}'}\n\n    # Extract keywords (what Claude would search for)\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find matching files\n    matched_files = []\n    combined_text = \"\"\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        # Skip vendor/node_modules\n        if any(skip in str(py_file) for skip in ['node_modules', '.venv', 'vendor', '.git']):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n\n            # If keywords match, Claude would read this ENTIRE file\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                combined_text += f\"\\n{'='*70}\\n{py_file}\\n{'='*70}\\n{content}\\n\"\n\n                if len(matched_files) >= 10:  # Limit to 10 files\n                    break\n        except:\n            pass\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'Claude Alone (no RAG)',\n        'files_read': len(matched_files),\n        'chars': len(combined_text),\n        'tokens': tokens,\n        'files': matched_files[:5]  # Show first 5\n    }\n\n\n# ============================================================\n# Approach 2: RAG via Direct Python\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d40ce0314bd93660970a4233af19c3d8"}
{"id": "912f771f3c37", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "measure_rag_python(question: str, repo: str, top_k: int = 10):\n    \"\"\"Use hybrid_search.py directly (local Python calls)\"\"\"\n    try:\n        from hybrid_search import search_routed_multi\n\n        results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n        # Combine retrieved chunks\n        combined_text = \"\"\n        for r in results:\n            combined_text += f\"{r['file_path']}:{r['start_line']}-{r['end_line']}\\n\"\n            combined_text += r.get('code', '') + \"\\n\\n\"\n\n        tokens = count_tokens(combined_text)\n\n        return {\n            'approach': 'RAG (direct Python)',\n            'chunks': len(results),\n            'chars': len(combined_text),\n            'tokens': tokens,\n            'files_touched': len(set(r['file_path'] for r in results)),\n            'top_scores': [r['rerank_score'] for r in results[:3]]\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 3: RAG via MCP (What Claude Code Uses)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f26c3758188977e7e474fcc13c15f79d"}
{"id": "fbe0a3e8db54", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 51, "imports": [], "code": "measure_rag_mcp(question: str, repo: str, top_k: int = 10):\n    \"\"\"\n    Simulate MCP tool call (what Claude Code actually uses).\n    This calls the same backend as direct Python but through MCP layer.\n    \"\"\"\n    try:\n        from mcp_server import MCPServer\n\n        # Call rag_search tool\n        req = {\n            'jsonrpc': '2.0',\n            'id': 1,\n            'method': 'tools/call',\n            'params': {\n                'name': 'rag_search',\n                'arguments': {\n                    'repo': repo,\n                    'question': question,\n                    'top_k': top_k\n                }\n            }\n        }\n\n        server = MCPServer()\n        resp = server.handle_request(req)\n\n        # Extract results\n        result_text = resp['result']['content'][0]['text']\n        result_data = json.loads(result_text)\n\n        # MCP returns file paths + line ranges (no full code in the response)\n        # But we need to count what gets sent to Claude\n        combined_text = result_text  # This is what Claude receives\n\n        tokens = count_tokens(combined_text)\n\n        return {\n            'approach': 'RAG (via MCP tools)',\n            'chunks': result_data.get('count', 0),\n            'chars': len(combined_text),\n            'tokens': tokens,\n            'mcp_result_size': len(result_text)\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Run Comparison\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "2cbf3945a5e80f0c217f8ee226a81613"}
{"id": "f763a4589d77", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 133, "imports": [], "code": "run_test(question: str, repo: str):\n    \"\"\"Run all three approaches and compare\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"TEST: {question}\")\n    print(f\"REPO: {repo}\")\n    print(f\"{'='*70}\\n\")\n\n    # Method 1: Claude alone\n    print(\"⏳ Measuring: Claude Alone (traditional grep + read files)...\")\n    claude_alone = measure_claude_alone(question, repo)\n\n    # Method 2: RAG Python\n    print(\"⏳ Measuring: RAG via Direct Python...\")\n    rag_python = measure_rag_python(question, repo, top_k=10)\n\n    # Method 3: RAG MCP\n    print(\"⏳ Measuring: RAG via MCP tools...\")\n    rag_mcp = measure_rag_mcp(question, repo, top_k=10)\n\n    # Print results\n    print(f\"\\n{'='*70}\")\n    print(\"RESULTS:\")\n    print(f\"{'='*70}\\n\")\n\n    # Claude Alone\n    if 'error' not in claude_alone:\n        print(f\"1️⃣  CLAUDE ALONE (no RAG):\")\n        print(f\"   Files read: {claude_alone['files_read']}\")\n        print(f\"   Total tokens: {claude_alone['tokens']:,}\")\n        print(f\"   Characters: {claude_alone['chars']:,}\")\n\n    # RAG Python\n    if 'error' not in rag_python:\n        print(f\"\\n2️⃣  RAG (Direct Python):\")\n        print(f\"   Chunks retrieved: {rag_python['chunks']}\")\n        print(f\"   Files touched: {rag_python['files_touched']}\")\n        print(f\"   Total tokens: {rag_python['tokens']:,}\")\n        print(f\"   Top scores: {[f'{s:.3f}' for s in rag_python.get('top_scores', [])]}\")\n\n    # RAG MCP\n    if 'error' not in rag_mcp:\n        print(f\"\\n3️⃣  RAG (via MCP - what Claude Code uses):\")\n        print(f\"   Chunks retrieved: {rag_mcp['chunks']}\")\n        print(f\"   Total tokens: {rag_mcp['tokens']:,}\")\n\n    # Calculate savings\n    if all('error' not in r for r in [claude_alone, rag_python, rag_mcp]):\n        alone_tokens = claude_alone['tokens']\n        python_tokens = rag_python['tokens']\n        mcp_tokens = rag_mcp['tokens']\n\n        print(f\"\\n{'='*70}\")\n        print(\"💰 TOKEN SAVINGS:\")\n        print(f\"{'='*70}\")\n\n        # Python vs Alone\n        saved_python = alone_tokens - python_tokens\n        pct_python = (saved_python / alone_tokens * 100) if alone_tokens > 0 else 0\n\n        print(f\"\\nRAG Python vs Claude Alone:\")\n        print(f\"   Tokens saved: {saved_python:,}\")\n        print(f\"   Percentage: {pct_python:.1f}%\")\n        print(f\"   Reduction: {alone_tokens / max(python_tokens, 1):.1f}x smaller\")\n\n        # MCP vs Alone\n        saved_mcp = alone_tokens - mcp_tokens\n        pct_mcp = (saved_mcp / alone_tokens * 100) if alone_tokens > 0 else 0\n\n        print(f\"\\nRAG MCP vs Claude Alone:\")\n        print(f\"   Tokens saved: {saved_mcp:,}\")\n        print(f\"   Percentage: {pct_mcp:.1f}%\")\n        print(f\"   Reduction: {alone_tokens / max(mcp_tokens, 1):.1f}x smaller\")\n\n        # Cost estimate (gpt-4o: $2.50/1M input tokens)\n        cost_per_token = 2.50 / 1_000_000\n\n        print(f\"\\n💵 COST SAVINGS (gpt-4o @ $2.50/1M input tokens):\")\n        print(f\"   Per query (Python): ${saved_python * cost_per_token:.6f}\")\n        print(f\"   Per 1000 queries (Python): ${saved_python * cost_per_token * 1000:.2f}\")\n        print(f\"   Per query (MCP): ${saved_mcp * cost_per_token:.6f}\")\n        print(f\"   Per 1000 queries (MCP): ${saved_mcp * cost_per_token * 1000:.2f}\")\n\n    return {\n        'question': question,\n        'repo': repo,\n        'claude_alone': claude_alone.get('tokens', 0),\n        'rag_python': rag_python.get('tokens', 0),\n        'rag_mcp': rag_mcp.get('tokens', 0)\n    }\n\n\nif __name__ == '__main__':\n    # Test cases\n    tests = [\n        (\"Where is OAuth token validated\", \"project\"),\n        (\"How are fax jobs created and dispatched\", \"project\"),\n        (\"EventStream component event types in dropdown\", \"project\"),\n    ]\n\n    results = []\n\n    for question, repo in tests:\n        try:\n            result = run_test(question, repo)\n            results.append(result)\n        except Exception as e:\n            print(f\"\\n❌ Error: {e}\")\n\n    # Overall summary\n    if results:\n        print(f\"\\n\\n{'='*70}\")\n        print(\"📊 OVERALL SUMMARY\")\n        print(f\"{'='*70}\\n\")\n\n        total_alone = sum(r['claude_alone'] for r in results)\n        total_python = sum(r['rag_python'] for r in results)\n        total_mcp = sum(r['rag_mcp'] for r in results)\n\n        print(f\"Total queries: {len(results)}\")\n        print(f\"\\nClaude Alone: {total_alone:,} tokens\")\n        print(f\"RAG Python: {total_python:,} tokens\")\n        print(f\"RAG MCP: {total_mcp:,} tokens\")\n\n        if total_alone > 0:\n            print(f\"\\nAverage reduction (Python): {total_alone / max(total_python, 1):.1f}x\")\n            print(f\"Average reduction (MCP): {total_alone / max(total_mcp, 1):.1f}x\")\n\n            saved_python = total_alone - total_python\n            saved_mcp = total_alone - total_mcp\n\n            print(f\"\\nTotal saved (Python): {saved_python:,} tokens ({saved_python/total_alone*100:.1f}%)\")\n            print(f\"Total saved (MCP): {saved_mcp:,} tokens ({saved_mcp/total_alone*100:.1f}%)\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b2154e2dcedb6c3e440892451a4c8768"}
{"id": "b305893973e9", "file_path": "/Users/davidmontgomery/agro/scripts/eval_gate_guard.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": ["import sys, json, re"], "code": "#!/usr/bin/env python3\nimport sys, json, re\n\n\"\"\"\nUsage:\n  python scripts/eval_gate_guard.py <answers.jsonl>\n\nWhere each line is a JSON object containing:\n  {\"q\": \"...\", \"repo\": \"project\", \"answer\": \"...\"}\nThis fails if the answer lacks a [repo: ...] header or no file path-like citation.\n\"\"\"\n\nHEADER_RE = re.compile(r\"^\\[repo:\\s*(project|project)\\]\", re.I | re.M)\nPATH_RE = re.compile(r\"[A-Za-z0-9_\\-./]+?\\.[A-Za-z0-9_]+:\\d+-\\d+\")\n\nok(answer: str) -> bool:\n    if not HEADER_RE.search(answer or \"\"):\n        return False\n    if not PATH_RE.search(answer or \"\"):\n        return False\n    return True\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7268e3295d4ac77d96c473360106b28b"}
{"id": "fbc91c8f506e", "file_path": "/Users/davidmontgomery/agro/scripts/eval_gate_guard.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "main():\n    if len(sys.argv) < 2:\n        print(\"usage: python scripts/eval_gate_guard.py <answers.jsonl>\")\n        sys.exit(2)\n    bad = 0\n    with open(sys.argv[1], \"r\", errors=\"ignore\") as f:\n        for i, line in enumerate(f, 1):\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                obj = json.loads(line)\n            except Exception:\n                print(f\"line {i}: not json\")\n                bad += 1\n                continue\n            ans = obj.get(\"answer\", \"\")\n            if not ok(ans):\n                print(f\"line {i}: FAIL (missing repo header or file citation)\")\n                bad += 1\n    if bad:\n        print(f\"\\u274c guard failed: {bad} bad answer(s)\")\n        sys.exit(3)\n    print(\"\\u2713 guard passed\")\n    sys.exit(0)\n\n\nif __name__ == \"__main__\":\n    main()\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "665c75985371b48bb5ad3d605b52d9d6"}
{"id": "53317487cfd0", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords_v2.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 17, "imports": ["import json", "import os", "import re", "from collections import Counter, defaultdict", "from pathlib import Path"], "code": "import json\nimport os\nimport re\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\nshould_skip_directory(path):\n    \"\"\"Skip vendor/dependency directories\"\"\"\n    skip_patterns = [\n        'node_modules', '.venv', 'venv', '__pycache__', \n        '.git', 'dist', 'build', 'vendor', 'tmp',\n        'test', 'tests', 'spec', 'specs',  # test files\n        'migrations', 'db/migrate',  # migrations\n        'locale', 'locales', 'i18n',  # translations\n        '.bundle', 'coverage', '.pytest_cache'\n    ]\n    return any(skip in path for skip in skip_patterns)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7b6593ba783cd9a329e5cda3b425944b"}
{"id": "4fea66b567ce", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords_v2.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 52, "imports": [], "code": "extract_semantic_terms(file_path, code):\n    \"\"\"Extract meaningful business/domain terms\"\"\"\n    terms = set()\n    \n    # 1. Extract from file/directory names (most semantic!)\n    path_parts = file_path.split('/')\n    for part in path_parts:\n        # Clean up: UserController.rb -> user, controller\n        cleaned = re.sub(r'[._-]', ' ', part)\n        words = re.findall(r'[A-Z][a-z]+|[a-z]+', cleaned)\n        terms.update(w.lower() for w in words if len(w) > 3)\n    \n    # 2. Extract class names (PascalCase)\n    class_names = re.findall(r'\\bclass ([A-Z][a-zA-Z0-9_]+)', code)\n    for name in class_names:\n        # Split camelCase: AIStudioComponent -> ai, studio, component\n        words = re.findall(r'[A-Z][a-z]+|[A-Z]+(?=[A-Z]|$)', name)\n        terms.update(w.lower() for w in words if len(w) > 2)\n    \n    # 3. Extract function names (meaningful ones only)\n    func_names = re.findall(r'\\b(?:def|function|const)\\s+([a-z][a-zA-Z0-9_]+)', code)\n    for name in func_names:\n        # Only keep multi-word functions: validate_oauth not just get\n        if '_' in name:\n            words = name.split('_')\n            terms.update(w for w in words if len(w) > 3)\n    \n    # 4. Extract from comments (gold mine!)\n    comments = re.findall(r'(?:#|//|/\\*|\\*)\\s*(.+)', code)\n    for comment in comments:\n        # Extract capitalized words (likely domain terms)\n        words = re.findall(r'\\b[A-Z][a-z]{2,}\\b', comment)\n        terms.update(w.lower() for w in words)\n    \n    # 5. Extract string literals (API endpoints, routes, etc)\n    strings = re.findall(r'[\"\\']([^\"\\']{5,50})[\"\\']', code)\n    for s in strings:\n        if '/' in s:  # likely a route\n            parts = s.split('/')\n            terms.update(p.lower() for p in parts if p.isalpha() and len(p) > 3)\n    \n    # Filter out programming keywords\n    stop_words = {\n        'return', 'function', 'class', 'const', 'import', 'export',\n        'from', 'self', 'this', 'super', 'none', 'null', 'true', 'false',\n        'async', 'await', 'yield', 'raise', 'assert', 'break', 'continue',\n        'string', 'number', 'boolean', 'object', 'array', 'type', 'interface',\n        'params', 'args', 'kwargs', 'options', 'config', 'props', 'state'\n    }\n    \n    return {t for t in terms if t not in stop_words and t.isalpha()}\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "da0e6fb4b1fb4f217d9e7acd5c43f377"}
{"id": "d7fe2144db2a", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords_v2.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 151, "imports": [], "code": "analyze_repo_semantic(repo_path, repo_name):\n    \"\"\"Find meaningful business domain terms\"\"\"\n    term_counts = Counter()\n    term_files = defaultdict(set)\n    directory_terms = Counter()\n    \n    total_files = 0\n    \n    for root, dirs, files in os.walk(repo_path):\n        # Skip vendor directories\n        if should_skip_directory(root):\n            continue\n        \n        # Remove skippable dirs from traversal\n        dirs[:] = [d for d in dirs if not should_skip_directory(os.path.join(root, d))]\n        \n        # Analyze directory name itself\n        dir_name = os.path.basename(root)\n        if dir_name and len(dir_name) > 3:\n            directory_terms[dir_name.lower()] += 1\n        \n        for file in files:\n            # Only source code files\n            if not any(file.endswith(ext) for ext in ['.py', '.js', '.ts', '.tsx', '.rb', '.yml', '.java']):\n                continue\n            \n            file_path = os.path.join(root, file)\n            rel_path = os.path.relpath(file_path, repo_path)\n            \n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    code = f.read()\n                    \n                terms = extract_semantic_terms(rel_path, code)\n                \n                for term in terms:\n                    term_counts[term] += 1\n                    term_files[term].add(rel_path)\n                \n                total_files += 1\n            except:\n                continue\n    \n    # Calculate relevance scores\n    scored_terms = []\n    for term, count in term_counts.items():\n        file_count = len(term_files[term])\n        \n        # Score formula:\n        # - Appears in multiple files (2-20% of codebase) = domain term\n        # - Too rare (1 file) = noise\n        # - Too common (>20% files) = generic utility\n        if file_count >= 2 and file_count <= total_files * 0.2:\n            # Boost if term appears in directory names (very semantic)\n            dir_boost = 2.0 if term in directory_terms else 1.0\n            \n            # Calculate domain specificity score\n            score = (count * file_count * dir_boost) / (total_files + 1)\n            \n            scored_terms.append({\n                'term': term,\n                'score': score,\n                'files': file_count,\n                'mentions': count,\n                'in_directories': term in directory_terms,\n                'sample_files': list(term_files[term])[:3]\n            })\n    \n    # Sort by score\n    scored_terms.sort(key=lambda x: x['score'], reverse=True)\n    \n    return scored_terms, total_files, directory_terms\n\nif __name__ == '__main__':\n    repos = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n    \n    all_results = {}\n    \n    for repo_name, repo_path in repos.items():\n        print(f'\\n{\"=\"*80}')\n        print(f'SEMANTIC ANALYSIS: {repo_name}')\n        print(f'{\"=\"*80}')\n        \n        terms, total_files, directories = analyze_repo_semantic(repo_path, repo_name)\n        all_results[repo_name] = terms[:50]\n        \n        print(f'\\nAnalyzed {total_files} files')\n        print(f'Found {len(terms)} meaningful domain terms')\n        print(f'\\nTop 30 Business/Domain Keywords:\\n')\n        \n        for i, t in enumerate(terms[:30], 1):\n            dir_marker = '📁' if t['in_directories'] else '  '\n            print(f'{i:2}. {dir_marker} {t[\"term\"]:20} | Score: {t[\"score\"]:8.1f} | {t[\"files\"]:3} files | {t[\"mentions\"]:4} mentions')\n        \n        # Show sample context\n        print(f'\\n📄 Sample file locations for top terms:')\n        for t in terms[:5]:\n            print(f'\\n  {t[\"term\"]}:')\n            for f in t['sample_files']:\n                print(f'    - {f}')\n    \n    # Cross-analysis\n    print(f'\\n{\"=\"*80}')\n    print('CROSS-REPO COMPARISON')\n    print(f'{\"=\"*80}')\n    \n    viv_terms = {t['term'] for t in all_results['project'][:30]}\n    fax_terms = {t['term'] for t in all_results['project'][:30]}\n    \n    shared = viv_terms & fax_terms\n    viv_only = viv_terms - fax_terms\n    fax_only = fax_terms - viv_terms\n    \n    print(f'\\n🔄 Shared terms ({len(shared)}):')\n    if shared:\n        print(f'   {\", \".join(sorted(shared)[:10])}')\n    \n    print(f'\\n💊 PROJECT-specific ({len(viv_only)}):')\n    print(f'   {\", \".join(sorted(list(viv_only)[:15]))}')\n    \n    print(f'\\n📠 PROJECT-specific ({len(fax_only)}):')\n    print(f'   {\", \".join(sorted(list(fax_only)[:15]))}')\n    \n    # Generate suggested queries\n    print(f'\\n{\"=\"*80}')\n    print('SUGGESTED EVAL QUERIES (based on actual terms)')\n    print(f'{\"=\"*80}')\n    \n    for repo_name, terms in all_results.items():\n        print(f'\\n{repo_name.upper()}:')\n        top_terms = terms[:10]\n        \n        # Generate natural queries\n        queries = []\n        for t in top_terms[:5]:\n            queries.append(f'  - \"Where is {t[\"term\"]} implemented?\"')\n            if t['in_directories']:\n                queries.append(f'  - \"How does {t[\"term\"]} work?\"')\n        \n        for q in queries[:8]:\n            print(q)\n    \n    # Save\n    with open('semantic_keywords.json', 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    print(f'\\n✓ Saved to semantic_keywords.json')\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a5d752e2afdb939de693211fcfa73327"}
{"id": "d4520ec569a6", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 28, "imports": ["import sys", "import os", "import json", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"\nCompare token usage across FOUR approaches:\n\n1. Claude Alone (no RAG) - reads full files via grep\n2. RAG CLI Standalone - RAG answers directly (no Claude)\n3. Claude + RAG Direct - Claude gets full code chunks from RAG\n4. Claude + RAG via MCP - Claude gets MCP metadata responses\n\nShows actual tokens sent to LLM in each scenario.\n\"\"\"\n\nimport sys\nimport os\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\nimport json\nfrom pathlib import Path\n\n# Try tiktoken for precise counts\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print(\"⚠️  Install tiktoken for precise counts: pip install tiktoken\\n\")\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d12914bf0feba36a1b13bf4a1b81842b"}
{"id": "d1e198a94e6d", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 15, "imports": [], "code": "count_tokens(text: str, model: str = \"gpt-4o\") -> int:\n    \"\"\"Count tokens precisely or estimate\"\"\"\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    return len(text) // 4\n\n\n# ============================================================\n# Approach 1: Claude Alone (Traditional - NO RAG)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e679be3b2f73cb87d46e2a0099c587f2"}
{"id": "e7f3c46b4d53", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 53, "imports": [], "code": "approach1_claude_alone(question: str, repo: str):\n    \"\"\"\n    Claude without RAG:\n    - Extract keywords\n    - Grep files\n    - Read 5-10 FULL files\n    \"\"\"\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'project': os.getenv('project_PATH', '/abs/path/to/project')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'error': f'Repo not found: {repo_path}'}\n\n    # Keywords from question\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find files\n    matched_files = []\n    full_content = \"\"\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        if any(skip in str(py_file) for skip in ['node_modules', '.venv', 'vendor', '.git', '__pycache__']):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                full_content += f\"\\n{'='*70}\\nFile: {py_file}\\n{'='*70}\\n{content}\\n\"\n\n                if len(matched_files) >= 10:\n                    break\n        except:\n            pass\n\n    tokens = count_tokens(full_content)\n\n    return {\n        'method': '1. Claude Alone (no RAG)',\n        'description': 'Reads full files matching keywords',\n        'files_read': len(matched_files),\n        'tokens': tokens,\n        'sample_files': [Path(f).name for f in matched_files[:3]]\n    }\n\n\n# ============================================================\n# Approach 2: RAG CLI Standalone (no Claude)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a2893def46cd650b9e35f6d54558faf1"}
{"id": "663c5cf09c61", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 43, "imports": [], "code": "approach2_rag_standalone(question: str, repo: str):\n    \"\"\"\n    RAG CLI standalone - full answer generation without Claude.\n    Counts the generated answer + citations.\n    \"\"\"\n    try:\n        from langgraph_app import build_graph\n\n        # Build graph and run (with required thread_id config)\n        graph = build_graph()\n        result = graph.invoke(\n            {\n                \"question\": question,\n                \"repo\": repo,\n            },\n            config={\"configurable\": {\"thread_id\": \"test-comparison\"}}\n        )\n\n        # What gets generated\n        answer_text = result.get('answer', '')\n        citations_text = '\\n'.join([\n            f\"{c.get('file_path', '')}:{c.get('start_line', '')}-{c.get('end_line', '')}\"\n            for c in result.get('citations', [])\n        ])\n\n        full_output = f\"Answer:\\n{answer_text}\\n\\nCitations:\\n{citations_text}\"\n        tokens = count_tokens(full_output)\n\n        return {\n            'method': '2. RAG CLI Standalone',\n            'description': 'RAG generates answer directly (no Claude)',\n            'tokens': tokens,\n            'answer_length': len(answer_text),\n            'citations_count': len(result.get('citations', []))\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 3: Claude + RAG Direct (full chunks)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6120e341c830999e3f89a9f59d5d3c73"}
{"id": "4327503b477c", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 34, "imports": [], "code": "approach3_claude_plus_rag_direct(question: str, repo: str, top_k: int = 10):\n    \"\"\"\n    Claude gets full code chunks from RAG.\n    This is what would happen if Claude called hybrid_search directly.\n    \"\"\"\n    try:\n        from hybrid_search import search_routed_multi\n\n        results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n        # Build what gets sent to Claude\n        context = \"Retrieved code chunks:\\n\\n\"\n        for r in results:\n            context += f\"File: {r['file_path']}:{r['start_line']}-{r['end_line']}\\n\"\n            context += f\"Score: {r['rerank_score']:.3f}\\n\"\n            context += f\"Code:\\n{r.get('code', '')}\\n\\n\"\n\n        tokens = count_tokens(context)\n\n        return {\n            'method': '3. Claude + RAG Direct',\n            'description': 'Claude gets full code chunks from RAG',\n            'chunks': len(results),\n            'tokens': tokens,\n            'files_touched': len(set(r['file_path'] for r in results))\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Approach 4: Claude + RAG via MCP (metadata only)\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4a1676c5f54c6381f162ffabd853ae4c"}
{"id": "e2f0f9c0d44c", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 62, "imports": [], "code": "approach4_claude_plus_rag_mcp(question: str, repo: str, top_k: int = 10):\n    \"\"\"\n    Claude gets MCP tool response (metadata, no full code).\n    This is what I (Claude Code) actually receive.\n\n    IMPORTANT: MCP tool schemas are sent with EVERY request!\n    \"\"\"\n    try:\n        from mcp_server import MCPServer\n\n        server = MCPServer()\n\n        # Get tool schemas (sent with every request)\n        tools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\n        tools_resp = server.handle_request(tools_req)\n        tools_json = json.dumps(tools_resp['result']['tools'])\n        schema_tokens = count_tokens(tools_json)\n\n        # Get the actual search response\n        search_req = {\n            'jsonrpc': '2.0',\n            'id': 1,\n            'method': 'tools/call',\n            'params': {\n                'name': 'rag_search',\n                'arguments': {\n                    'repo': repo,\n                    'question': question,\n                    'top_k': top_k\n                }\n            }\n        }\n\n        search_resp = server.handle_request(search_req)\n\n        # The MCP response is what Claude receives\n        mcp_response = search_resp['result']['content'][0]['text']\n        response_tokens = count_tokens(mcp_response)\n\n        # Total = schemas + response\n        total_tokens = schema_tokens + response_tokens\n\n        # Parse to get metadata\n        result_data = json.loads(mcp_response)\n\n        return {\n            'method': '4. Claude + RAG via MCP',\n            'description': 'Claude gets MCP metadata (paths + scores only) + tool schemas',\n            'chunks': result_data.get('count', 0),\n            'tokens': total_tokens,\n            'schema_tokens': schema_tokens,\n            'response_tokens': response_tokens,\n            'breakdown': f'{schema_tokens} (schemas) + {response_tokens} (response)'\n        }\n    except Exception as e:\n        return {'error': str(e)}\n\n\n# ============================================================\n# Run Comparison\n# ============================================================\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "90cb4e3881a60da717bb8919743c614e"}
{"id": "c1c5680df452", "file_path": "/Users/davidmontgomery/agro/scripts/test_token_comparison.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 146, "imports": [], "code": "run_comparison(question: str, repo: str):\n    \"\"\"Run all four approaches and compare\"\"\"\n    print(f\"\\n{'='*75}\")\n    print(f\"QUESTION: {question}\")\n    print(f\"REPO: {repo}\")\n    print(f\"{'='*75}\\n\")\n\n    results = []\n\n    # Run each approach\n    approaches = [\n        (\"Claude Alone\", approach1_claude_alone),\n        (\"RAG CLI Standalone\", approach2_rag_standalone),\n        (\"Claude + RAG Direct\", approach3_claude_plus_rag_direct),\n        (\"Claude + RAG via MCP\", approach4_claude_plus_rag_mcp),\n    ]\n\n    for name, func in approaches:\n        print(f\"⏳ Testing: {name}...\")\n        result = func(question, repo)\n        results.append(result)\n\n    # Print results\n    print(f\"\\n{'='*75}\")\n    print(\"RESULTS (tokens sent to LLM):\")\n    print(f\"{'='*75}\\n\")\n\n    for i, result in enumerate(results, 1):\n        if 'error' in result:\n            print(f\"{i}. {result.get('method', 'Unknown')}: ERROR - {result['error']}\")\n            continue\n\n        print(f\"{i}. {result['method']}\")\n        print(f\"   {result['description']}\")\n        print(f\"   Tokens: {result['tokens']:,}\")\n\n        # Show method-specific details\n        if 'files_read' in result:\n            print(f\"   Files read: {result['files_read']}\")\n            if result.get('sample_files'):\n                print(f\"   Sample: {', '.join(result['sample_files'])}\")\n\n        if 'chunks' in result:\n            print(f\"   Chunks: {result['chunks']}\")\n\n        if 'files_touched' in result:\n            print(f\"   Files: {result['files_touched']}\")\n\n        if 'citations_count' in result:\n            print(f\"   Citations: {result['citations_count']}\")\n\n        if 'breakdown' in result:\n            print(f\"   Breakdown: {result['breakdown']}\")\n\n        print()\n\n    # Calculate savings\n    valid_results = [r for r in results if 'error' not in r and 'tokens' in r]\n\n    if len(valid_results) >= 2:\n        baseline = valid_results[0]['tokens']  # Claude alone\n\n        print(f\"{'='*75}\")\n        print(\"💰 SAVINGS vs Claude Alone:\")\n        print(f\"{'='*75}\\n\")\n\n        for result in valid_results[1:]:\n            tokens = result['tokens']\n            saved = baseline - tokens\n            pct = (saved / baseline * 100) if baseline > 0 else 0\n            reduction = baseline / tokens if tokens > 0 else 0\n\n            print(f\"{result['method']}:\")\n            print(f\"   Tokens saved: {saved:,}\")\n            print(f\"   Percentage: {pct:.1f}%\")\n            print(f\"   Reduction: {reduction:.1f}x\")\n\n            # Cost (gpt-4o: $2.50/1M input)\n            cost_saved = saved * (2.50 / 1_000_000)\n            print(f\"   $ saved/query: ${cost_saved:.6f}\")\n            print(f\"   $ saved/1000: ${cost_saved * 1000:.2f}\\n\")\n\n    return results\n\n\n# ============================================================\n# Main\n# ============================================================\n\nif __name__ == '__main__':\n    if not HAS_TIKTOKEN:\n        print(\"Installing tiktoken for accurate counts...\")\n        os.system(\"pip install -q tiktoken\")\n        try:\n            import tiktoken\n            HAS_TIKTOKEN = True\n            print(\"✓ tiktoken installed\\n\")\n        except:\n            print(\"⚠️  Using estimates (1 token ≈ 4 chars)\\n\")\n\n    # Test cases\n    tests = [\n        (\"Where is OAuth token validated\", \"project\"),\n        (\"How are fax jobs created and dispatched\", \"project\"),\n    ]\n\n    all_results = []\n\n    for question, repo in tests:\n        try:\n            results = run_comparison(question, repo)\n            all_results.append({\n                'question': question,\n                'repo': repo,\n                'results': results\n            })\n        except Exception as e:\n            print(f\"\\n❌ Error: {e}\\n\")\n\n    # Overall summary\n    if all_results:\n        print(f\"\\n{'='*75}\")\n        print(\"📊 SUMMARY\")\n        print(f\"{'='*75}\\n\")\n\n        print(f\"Total queries tested: {len(all_results)}\\n\")\n\n        # Average by method\n        methods = ['Claude Alone', 'RAG CLI Standalone', 'Claude + RAG Direct', 'Claude + RAG via MCP']\n\n        for method in methods:\n            tokens = []\n            for test in all_results:\n                for r in test['results']:\n                    if r.get('method', '').startswith(method.split()[0]) and 'tokens' in r:\n                        tokens.append(r['tokens'])\n\n            if tokens:\n                avg = sum(tokens) / len(tokens)\n                print(f\"{method}: {avg:,.0f} avg tokens\")\n\n        print(f\"\\n🎯 Recommendation:\")\n        print(f\"   Use MCP tools for maximum token efficiency\")\n        print(f\"   Use RAG CLI for standalone Q&A without Claude\")\n        print(f\"   Use Direct calls for custom integrations\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f5fa42b89134f0f3761accce39b3e753"}
{"id": "82f77b42a866", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 38, "imports": ["import os", "import sys", "import json", "import time", "import platform", "import shutil", "import subprocess", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"\nInteractive quick setup to:\n  1) Add the current working directory as a repo (repos.json)\n  2) Optionally index it\n  3) Ensure venv + deps\n  4) Optionally start infra (Qdrant/Redis via docker compose)\n  5) Register MCP servers with Codex CLI and Claude Code\n\nRun this from the ROOT of the repo you want to index:\n  python /path/to/rag-service/scripts/quick_setup.py\n\nNotes:\n  - Never writes secrets without confirmation\n  - Creates timestamped backups of modified config files\n  - Uses Rich spinners/progress so users always see activity\n\"\"\"\nimport os\nimport sys\nimport json\nimport time\nimport platform\nimport shutil\nimport subprocess\nfrom pathlib import Path\n\ntry:\n    from rich.console import Console\n    from rich.panel import Panel\n    from rich.prompt import Confirm, Prompt\n    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn\nexcept Exception:\n    print(\"This setup requires 'rich'. Install with: pip install rich\", file=sys.stderr)\n    sys.exit(1)\n\nconsole = Console()\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "39de47ff06462f2ede592009328792bd"}
{"id": "eec51915f517", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "write_repos_json(rag_root: Path, name: str, code_path: Path) -> Path:\n    p = os.getenv('REPOS_FILE') or str(rag_root / 'repos.json')\n    repos_path = Path(p)\n    cfg = {'default_repo': name, 'repos': []}\n    if repos_path.exists():\n        try:\n            cfg = json.loads(repos_path.read_text())\n            if not isinstance(cfg, dict):\n                cfg = {'default_repo': name, 'repos': []}\n        except Exception:\n            cfg = {'default_repo': name, 'repos': []}\n    # Update or append\n    repos = cfg.get('repos') or []\n    found = False\n    for r in repos:\n        if (r.get('name') or '').strip().lower() == name.lower():\n            r['path'] = str(code_path)\n            found = True\n            break\n    if not found:\n        repos.append({'name': name, 'path': str(code_path), 'keywords': [], 'path_boosts': [], 'layer_bonuses': {}})\n    cfg['repos'] = repos\n    # Ask to set default\n    if Confirm.ask(f\"Make [bold]{name}[/bold] the default repo?\", default=True):\n        cfg['default_repo'] = name\n    repos_path.write_text(json.dumps(cfg, indent=2))\n    return repos_path\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "28df6614ef6b8cc395e391859f8d00e3"}
{"id": "d319b064659a", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 6, "imports": [], "code": "_venv_python(repo_root: Path) -> Path:\n    if platform.system().lower().startswith('win'):\n        return repo_root / '.venv' / 'Scripts' / 'python.exe'\n    return repo_root / '.venv' / 'bin' / 'python'\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6ee4fcf48509df539c7f62be98fb5e8f"}
{"id": "ca3105f2495d", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 26, "imports": [], "code": "ensure_venv_and_deps(rag_root: Path, progress: Progress, task_id) -> bool:\n    \"\"\"Create .venv and install deps if needed.\"\"\"\n    py = _venv_python(rag_root)\n    # Create venv if missing\n    if not py.exists():\n        progress.update(task_id, description='Creating virtualenv (.venv)')\n        try:\n            subprocess.check_call([sys.executable, '-m', 'venv', str(rag_root / '.venv')])\n        except subprocess.CalledProcessError as e:\n            console.print(f\"[red]Failed to create venv:[/red] {e}\")\n            return False\n    # Install deps\n    progress.update(task_id, description='Installing dependencies')\n    try:\n        reqs = [str(rag_root / 'requirements-rag.txt'), str(rag_root / 'requirements.txt')]\n        for req in reqs:\n            if Path(req).exists():\n                subprocess.check_call([str(py), '-m', 'pip', 'install', '--disable-pip-version-check', '-r', req])\n        # quick sanity imports\n        subprocess.check_call([str(py), '-c', 'import fastapi,qdrant_client,bm25s,langgraph;print(\"ok\")'])\n        return True\n    except subprocess.CalledProcessError as e:\n        console.print(f\"[red]Dependency install failed:[/red] {e}\")\n        return False\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "88f73fdff44e2400fb24d420070bcb31"}
{"id": "8249f349b865", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "start_infra(rag_root: Path, progress: Progress, task_id) -> None:\n    progress.update(task_id, description='Starting Qdrant/Redis (docker compose)')\n    up = rag_root / 'scripts' / 'up.sh'\n    if not up.exists():\n        progress.update(task_id, description='Infra script not found (skipping)')\n        time.sleep(0.3)\n        return\n    try:\n        subprocess.check_call(['bash', str(up)])\n    except Exception as e:\n        console.print(f\"[yellow]Infra start skipped/failed:[/yellow] {e}\")\n    # quick qdrant ping\n    progress.update(task_id, description='Verifying Qdrant/Redis health')\n    try:\n        subprocess.check_call(['bash', '-lc', 'curl -s http://127.0.0.1:6333/collections >/dev/null || true'])\n    except Exception:\n        pass\n\ndetect_codex() -> str | None:\n    path = shutil.which('codex')\n    return path\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9bad20e6827cbd3dc00c1342d7c05672"}
{"id": "5a622d0be39c", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 18, "imports": [], "code": "codex_register(rag_root: Path, progress: Progress, task_id) -> None:\n    path = detect_codex()\n    if not path:\n        progress.update(task_id, description='Codex CLI not found (skip)')\n        time.sleep(0.3)\n        return\n    py = _venv_python(rag_root)\n    server = rag_root / 'mcp_server.py'\n    name = 'rag-service'\n    progress.update(task_id, description='Registering MCP with Codex')\n    try:\n        # remove existing silently\n        subprocess.run(['codex', 'mcp', 'remove', name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        subprocess.check_call(['codex', 'mcp', 'add', name, '--', str(py), str(server)])\n    except subprocess.CalledProcessError as e:\n        console.print(f\"[yellow]Codex registration failed:[/yellow] {e}\")\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d14346cfe24f533762f56be5792ba3f4"}
{"id": "16e9cde4e8ce", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 14, "imports": [], "code": "_claude_config_path() -> Path | None:\n    sysname = platform.system().lower()\n    home = Path.home()\n    if 'darwin' in sysname or 'mac' in sysname:\n        return (home / 'Library' / 'Application Support' / 'Claude' / 'claude_desktop_config.json')\n    if 'linux' in sysname:\n        return (home / '.config' / 'Claude' / 'claude_desktop_config.json')\n    if 'windows' in sysname or 'win' in sysname:\n        appdata = os.getenv('APPDATA')\n        if appdata:\n            return Path(appdata) / 'Claude' / 'claude_desktop_config.json'\n    return None\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "30cfb26ef23e81d1a814ca33fa8ae27d"}
{"id": "7d96f2f18da1", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 33, "imports": [], "code": "claude_register(rag_root: Path, progress: Progress, task_id) -> None:\n    cfgp = _claude_config_path()\n    if not cfgp:\n        progress.update(task_id, description='Claude config path not found (skip)')\n        time.sleep(0.3)\n        return\n    cfgp.parent.mkdir(parents=True, exist_ok=True)\n    py = _venv_python(rag_root)\n    server = rag_root / 'mcp_server.py'\n    # Load existing\n    data = {}\n    if cfgp.exists():\n        try:\n            data = json.loads(cfgp.read_text())\n        except Exception:\n            data = {}\n        # backup\n        bak = cfgp.with_suffix(cfgp.suffix + f'.bak.{time.strftime(\"%Y%m%d-%H%M%S\")}')\n        bak.write_text(json.dumps(data, indent=2))\n    # Merge entry\n    ms = data.get('mcpServers') or {}\n    ms['rag-service'] = {\n        'command': str(py),\n        'args': [str(server)],\n        'env': {\n            'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY', '')\n        }\n    }\n    data['mcpServers'] = ms\n    progress.update(task_id, description='Writing Claude config')\n    cfgp.write_text(json.dumps(data, indent=2))\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0ce22c8c430283c99b3811b575aefc0c"}
{"id": "4dca88ee0e0e", "file_path": "/Users/davidmontgomery/agro/scripts/quick_setup.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 93, "imports": [], "code": "main():\n    rag_root = Path(__file__).resolve().parents[1]\n    # Allow explicit path override for code repo\n    forced_path = None\n    forced_name = None\n    argv = sys.argv[1:]\n    for i, a in enumerate(argv):\n        if a.startswith('--path='):\n            forced_path = a.split('=', 1)[1].strip()\n        elif a == '--path' and i+1 < len(argv):\n            forced_path = argv[i+1].strip()\n        elif a.startswith('--name='):\n            forced_name = a.split('=', 1)[1].strip()\n        elif a == '--name' and i+1 < len(argv):\n            forced_name = argv[i+1].strip()\n\n    code_root = Path(forced_path or os.getcwd()).resolve()\n    suggested = (forced_name or code_root.name.lower().replace(' ', '-').replace('_', '-'))\n    title = \"RAG Service — Quick Setup\"\n    msg = (\n        f\"Detected current directory:\\n[bold]{code_root}[/bold]\\n\\n\"\n        \"Create or update repos.json to include this path?\\n\"\n    )\n    console.print(Panel(msg, title=title, border_style=\"cyan\"))\n    if not Confirm.ask(\"Add this repo?\", default=True):\n        console.print(\"[yellow]Canceled.[/yellow]\")\n        return\n    name = forced_name or Prompt.ask(\"Repository name\", default=suggested)\n    repos_path = write_repos_json(rag_root, name, code_root)\n    console.print(f\"[green]✓[/green] Updated {repos_path}\")\n\n    # Offer to index\n    console.print(Panel(\n        \"Index now? This builds BM25 and embeddings; it may take time and bill your provider if configured.\",\n        title=\"Index Repository\", border_style=\"yellow\"\n    ))\n    do_index = Confirm.ask(\"Start indexing now?\", default=False)\n\n    console.print(Panel(\"Setup environment and agents?\", title=\"Agents & Infra\", border_style=\"cyan\"))\n    do_env = Confirm.ask(\"Ensure virtualenv + dependencies?\", default=True)\n    do_infra = Confirm.ask(\"Start Qdrant/Redis (docker compose)?\", default=True)\n    do_codex = Confirm.ask(\"Register Codex MCP?\", default=True)\n    do_claude = Confirm.ask(\"Register Claude MCP?\", default=True)\n\n    with Progress(\n        SpinnerColumn(style='cyan'),\n        TextColumn(\"{task.description}\"),\n        BarColumn(bar_width=None),\n        TimeElapsedColumn(),\n        transient=True,\n    ) as progress:\n        if do_env:\n            t = progress.add_task(\"Preparing environment\", total=None)\n            ok = ensure_venv_and_deps(rag_root, progress, t)\n            progress.remove_task(t)\n            if not ok:\n                console.print(\"[red]Environment setup failed; continuing without guarantees.[/red]\")\n        if do_infra:\n            t = progress.add_task(\"Starting infra\", total=None)\n            start_infra(rag_root, progress, t)\n            progress.remove_task(t)\n        if do_index:\n            t = progress.add_task(\"Indexing repository\", total=None)\n            env = os.environ.copy()\n            env['REPO'] = name\n            try:\n                subprocess.check_call([str(_venv_python(rag_root)), str(rag_root / 'index_repo.py')], env=env, cwd=str(rag_root))\n                console.print(f\"[green]✓[/green] Indexed repo: [bold]{name}[/bold]\")\n            except subprocess.CalledProcessError as e:\n                console.print(f\"[red]Indexing failed:[/red] {e}\")\n            progress.remove_task(t)\n        if do_codex:\n            t = progress.add_task(\"Registering Codex\", total=None)\n            codex_register(rag_root, progress, t)\n            progress.remove_task(t)\n        if do_claude:\n            t = progress.add_task(\"Registering Claude\", total=None)\n            claude_register(rag_root, progress, t)\n            progress.remove_task(t)\n\n    # Friendly next-steps banner\n    console.print(Panel(\n        \"Setup complete. Next steps:\\n\"\n        \" • Type 'codex' and try: Use rag_search to find OAuth in your repo\\n\"\n        f\" • Or run API: uvicorn serve_rag:app --host 127.0.0.1 --port 8012\\n\"\n        f\" • CLI streaming: python chat_cli.py --stream --api-url http://127.0.0.1:8012\\n\",\n        title=\"You're ready!\", border_style=\"green\"\n    ))\n\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "258858144ab8ce2c20a9e1fef23b4cd4"}
{"id": "fd957eb4eeec", "file_path": "/Users/davidmontgomery/agro/scripts/gui_smoke.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 22, "imports": ["from __future__ import annotations", "import os, time, json, tempfile, signal, subprocess", "from pathlib import Path", "from playwright.sync_api import sync_playwright, expect"], "code": "#!/usr/bin/env python3\nfrom __future__ import annotations\nimport os, time, json, tempfile, signal, subprocess\nfrom pathlib import Path\nfrom playwright.sync_api import sync_playwright, expect\n\nROOT = Path(__file__).resolve().parents[1]\nBASE = \"http://127.0.0.1:8012\"\n\nwait_health(timeout=20):\n    import urllib.request, urllib.error\n    start = time.time()\n    while time.time() - start < timeout:\n        try:\n            with urllib.request.urlopen(f\"{BASE}/health\", timeout=2) as resp:\n                if resp.status == 200:\n                    return True\n        except Exception:\n            time.sleep(0.5)\n    return False\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "0fa81a1d6fa9bf2c8bd54ea6998e1e4b"}
{"id": "df30152635ea", "file_path": "/Users/davidmontgomery/agro/scripts/gui_smoke.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 64, "imports": [], "code": "main() -> int:\n    # Use existing server\n    assert wait_health(5), \"server not running on 8012\"\n\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=False)\n        ctx = browser.new_context()\n        page = ctx.new_page()\n        page.goto(f\"{BASE}/gui/\", wait_until=\"domcontentloaded\")\n        page.wait_for_timeout(1000)\n\n        # Test Health button\n        print(\"Testing health button...\")\n        page.click('#btn-health')\n        page.wait_for_timeout(1000)\n        hs = page.locator('#health-status').text_content()\n        print(f\"  health: {hs}\")\n\n        # Test Overview section load\n        print(\"\\nTesting overview section...\")\n        overview_text = page.locator('#overview-section').text_content()\n        print(f\"  overview contains {len(overview_text)} chars\")\n        if \"—\" in overview_text or not overview_text.strip():\n            print(\"  ❌ Overview appears empty/placeholder\")\n        else:\n            print(\"  ✓ Overview has content\")\n\n        # Test Configure button (wizard)\n        print(\"\\nTesting configure button...\")\n        page.click('#btn-wizard')\n        page.wait_for_timeout(2000)\n        wizard_out = page.locator('#wizard-output').text_content()\n        print(f\"  wizard output: {wizard_out[:200] if wizard_out else '(empty)'}\")\n        if not wizard_out or wizard_out.strip() == \"\":\n            print(\"  ❌ Wizard produced no output\")\n        else:\n            print(\"  ✓ Wizard generated output\")\n\n        # Test Cost calc with select_option\n        print(\"\\nTesting cost calculator...\")\n        page.select_option('#cost-provider', 'openai')\n        page.select_option('#cost-model', 'gpt-4o-mini')\n        page.fill('#cost-in', '500')\n        page.fill('#cost-out', '800')\n        page.fill('#cost-rpd', '100')\n        page.click('#btn-estimate')\n        page.wait_for_timeout(1000)\n        daily = page.locator('#cost-daily').text_content()\n        print(f\"  cost daily: {daily}\")\n        if daily == \"—\":\n            print(\"  ❌ Cost calc not working\")\n        else:\n            print(\"  ✓ Cost calc working\")\n\n        print(\"\\n\\nPress Enter to close browser...\")\n        input()\n        browser.close()\n    return 0\n\n\nif __name__ == '__main__':\n    raise SystemExit(main())\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9c57f043766101e6020e12eff7f349e9"}
{"id": "d34457d6d99c", "file_path": "/Users/davidmontgomery/agro/scripts/measure_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 31, "imports": ["import sys", "import os", "from pathlib import Path", "from hybrid_search import search_routed_multi"], "code": "#!/usr/bin/env python3\n\"\"\"\nMeasure actual token savings from RAG vs traditional file reading.\nCompares targeted RAG retrieval against reading full files.\n\"\"\"\n\nimport sys\nimport os\nfrom pathlib import Path\nfrom hybrid_search import search_routed_multi\n\ntry:\n    import tiktoken\n    HAS_TIKTOKEN = True\nexcept ImportError:\n    HAS_TIKTOKEN = False\n    print(\"⚠️  tiktoken not installed - using rough estimates (1 token ≈ 4 chars)\")\n    print(\"   Install with: pip install tiktoken\\n\")\n\ncount_tokens(text: str, model: str = \"gpt-4o\") -> int:\n    \"\"\"Count tokens precisely if tiktoken available, else estimate\"\"\"\n    if HAS_TIKTOKEN:\n        try:\n            encoding = tiktoken.encoding_for_model(model)\n            return len(encoding.encode(text))\n        except:\n            pass\n    # Fallback: rough estimate\n    return len(text) // 4\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "681246ae9ad9f191690ce86536224ede"}
{"id": "07637b7c8506", "file_path": "/Users/davidmontgomery/agro/scripts/measure_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 21, "imports": [], "code": "measure_rag_tokens(question: str, repo: str, top_k: int = 10):\n    \"\"\"Measure tokens using RAG hybrid search\"\"\"\n    results = search_routed_multi(question, repo_override=repo, final_k=top_k)\n\n    # Combine all retrieved code\n    combined_text = \"\"\n    for r in results:\n        combined_text += f\"File: {r['file_path']}:{r['start_line']}-{r['end_line']}\\n\"\n        combined_text += r.get('code', '') + \"\\n\\n\"\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'RAG (hybrid search)',\n        'chunks': len(results),\n        'text': combined_text,\n        'tokens': tokens,\n        'files_touched': len(set(r['file_path'] for r in results))\n    }\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f0639fd31548df696b4b851f1c8d8bc9"}
{"id": "c7566fc89871", "file_path": "/Users/davidmontgomery/agro/scripts/measure_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 49, "imports": [], "code": "measure_traditional_tokens(question: str, repo: str, max_files: int = 10):\n    \"\"\"\n    Simulate traditional approach: grep for keywords, read full files.\n    This is what you'd do WITHOUT RAG.\n    \"\"\"\n    repo_paths = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'faxbot': os.getenv('FAXBOT_PATH', '/abs/path/to/faxbot')\n    }\n\n    repo_path = repo_paths.get(repo)\n    if not repo_path or not os.path.exists(repo_path):\n        return {'approach': 'Traditional', 'error': f'Repo not found: {repo_path}'}\n\n    # Extract keywords from question (simulate what a human would grep for)\n    keywords = [w.lower() for w in question.split() if len(w) > 3][:5]\n\n    # Find files containing keywords\n    combined_text = \"\"\n    matched_files = []\n\n    for py_file in Path(repo_path).rglob('*.py'):\n        if 'node_modules' in str(py_file) or '.venv' in str(py_file):\n            continue\n\n        try:\n            content = py_file.read_text(errors='ignore')\n\n            # If any keyword appears, a human would likely read this whole file\n            if any(kw in content.lower() for kw in keywords):\n                matched_files.append(str(py_file))\n                combined_text += f\"\\n{'='*60}\\nFile: {py_file}\\n{'='*60}\\n\"\n                combined_text += content + \"\\n\"\n\n                if len(matched_files) >= max_files:\n                    break\n        except Exception as e:\n            pass\n\n    tokens = count_tokens(combined_text)\n\n    return {\n        'approach': 'Traditional (grep + read full files)',\n        'files_read': len(matched_files),\n        'text': combined_text,\n        'tokens': tokens\n    }\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e64009455295ec1c7cf870049aeea95e"}
{"id": "2b97c3fd6ab9", "file_path": "/Users/davidmontgomery/agro/scripts/measure_token_savings.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 91, "imports": [], "code": "run_comparison(question: str, repo: str):\n    \"\"\"Run both approaches and compare\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"Question: {question}\")\n    print(f\"Repository: {repo}\")\n    print(f\"{'='*70}\\n\")\n\n    # Measure RAG\n    print(\"⏳ Running RAG hybrid search...\")\n    rag = measure_rag_tokens(question, repo, top_k=10)\n\n    # Measure traditional\n    print(\"⏳ Simulating traditional grep + file reading...\")\n    trad = measure_traditional_tokens(question, repo, max_files=10)\n\n    # Print results\n    print(f\"\\n{'='*70}\")\n    print(\"📊 RESULTS:\")\n    print(f\"{'='*70}\")\n\n    print(f\"\\n🔍 RAG Approach:\")\n    print(f\"   Chunks retrieved: {rag['chunks']}\")\n    print(f\"   Files touched: {rag['files_touched']}\")\n    print(f\"   Total tokens: {rag['tokens']:,}\")\n\n    print(f\"\\n📁 Traditional Approach (grep + read full files):\")\n    print(f\"   Files read: {trad['files_read']}\")\n    print(f\"   Total tokens: {trad['tokens']:,}\")\n\n    # Calculate savings\n    if trad['tokens'] > 0 and rag['tokens'] > 0:\n        saved = trad['tokens'] - rag['tokens']\n        saved_pct = (saved / trad['tokens']) * 100\n        reduction = trad['tokens'] / rag['tokens']\n\n        print(f\"\\n{'='*70}\")\n        print(\"💰 TOKEN SAVINGS:\")\n        print(f\"{'='*70}\")\n        print(f\"   Tokens saved: {saved:,} tokens\")\n        print(f\"   Percentage saved: {saved_pct:.1f}%\")\n        print(f\"   Reduction factor: {reduction:.1f}x smaller\")\n\n        # Cost estimate (rough: $15/1M input tokens for gpt-4o)\n        cost_per_token = 15 / 1_000_000\n        cost_saved = saved * cost_per_token\n        print(f\"   Cost saved per query: ${cost_saved:.6f}\")\n        print(f\"   Cost saved per 1000 queries: ${cost_saved * 1000:.2f}\")\n\n    return rag, trad\n\n\nif __name__ == '__main__':\n    # Test queries\n    test_cases = [\n        (\"Where is OAuth token validated\", \"project\"),\n        (\"How are fax jobs created and dispatched\", \"project\"),\n        (\"EventStream component event types\", \"project\"),\n        (\"provider health status implementation\", \"project\"),\n    ]\n\n    results = []\n\n    for question, repo in test_cases:\n        try:\n            rag, trad = run_comparison(question, repo)\n            results.append({\n                'question': question,\n                'repo': repo,\n                'rag_tokens': rag['tokens'],\n                'trad_tokens': trad['tokens'],\n                'savings': trad['tokens'] - rag['tokens']\n            })\n        except Exception as e:\n            print(f\"\\n❌ Error testing '{question}': {e}\")\n\n    # Summary\n    if results:\n        print(f\"\\n\\n{'='*70}\")\n        print(\"📈 OVERALL SUMMARY\")\n        print(f\"{'='*70}\")\n\n        total_rag = sum(r['rag_tokens'] for r in results)\n        total_trad = sum(r['trad_tokens'] for r in results)\n        total_saved = total_trad - total_rag\n\n        print(f\"\\nTotal queries tested: {len(results)}\")\n        print(f\"Total RAG tokens: {total_rag:,}\")\n        print(f\"Total traditional tokens: {total_trad:,}\")\n        print(f\"Total saved: {total_saved:,} tokens ({(total_saved/total_trad*100):.1f}%)\")\n        print(f\"Average reduction: {total_trad/total_rag:.1f}x\\n\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "10d5f4b392bfe2b8f0c79c8c44ee2748"}
{"id": "098bf861efd1", "file_path": "/Users/davidmontgomery/agro/scripts/make_repos_json.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 45, "imports": ["import os, sys, json, time", "from pathlib import Path"], "code": "#!/usr/bin/env python3\n\"\"\"\nMake a repos.json from simple CLI args.\n\nUsage examples:\n  python scripts/make_repos_json.py repo-a=/abs/path/a repo-b=/abs/path/b --default repo-a\n\nEnvironment fallbacks:\n  REPO and REPO_PATH if provided (single repo).\n\nBehavior:\n  - Writes repos.json in repo root (or REPOS_FILE location if set)\n  - If repos.json exists, writes a timestamped backup next to it\n\"\"\"\nimport os, sys, json, time\nfrom pathlib import Path\n\nparse_args(argv):\n    pairs = []\n    default_repo = None\n    for arg in argv:\n        if arg == '--help' or arg == '-h':\n            print(__doc__)\n            sys.exit(0)\n        if arg.startswith('--default='):\n            default_repo = arg.split('=',1)[1].strip()\n            continue\n        if arg == '--default':\n            # next token is default\n            # handled in caller for simplicity\n            continue\n        if '=' in arg:\n            name, path = arg.split('=',1)\n            name = name.strip()\n            path = path.strip()\n            if name and path:\n                pairs.append((name, path))\n    # Handle \"--default name\" form\n    if '--default' in argv:\n        i = argv.index('--default')\n        if i+1 < len(argv):\n            default_repo = argv[i+1].strip()\n    return pairs, default_repo\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c8cc61ca8aa293439cafa9a12d096d8c"}
{"id": "ba313fb2f4d8", "file_path": "/Users/davidmontgomery/agro/scripts/make_repos_json.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 53, "imports": [], "code": "main():\n    args = sys.argv[1:]\n    pairs, default_repo = parse_args(args)\n\n    # Fallback to env for single-repo if no pairs passed\n    if not pairs:\n        env_repo = (os.getenv('REPO') or '').strip()\n        env_path = (os.getenv('REPO_PATH') or '').strip()\n        if env_repo and env_path:\n            pairs = [(env_repo, env_path)]\n            if not default_repo:\n                default_repo = env_repo\n        else:\n            print('No repo arguments provided and REPO/REPO_PATH not set. Example: repo-a=/abs/path/a')\n            sys.exit(2)\n\n    # Build config structure\n    repos = []\n    for name, path in pairs:\n        repos.append({\n            'name': name,\n            'path': str(Path(path).expanduser()),\n            'keywords': [],\n            'path_boosts': [],\n            'layer_bonuses': {}\n        })\n\n    if not default_repo:\n        default_repo = repos[0]['name']\n\n    cfg = {'default_repo': default_repo, 'repos': repos}\n\n    # Output path\n    out = os.getenv('REPOS_FILE') or str(Path(__file__).resolve().parents[1] / 'repos.json')\n    outp = Path(out)\n    outp_parent = outp.parent\n    outp_parent.mkdir(parents=True, exist_ok=True)\n\n    # Backup existing\n    if outp.exists():\n        ts = time.strftime('%Y%m%d-%H%M%S')\n        bak = outp.with_suffix(outp.suffix + f'.bak.{ts}')\n        bak.write_text(outp.read_text())\n        print(f'Backed up existing {outp} -> {bak}')\n\n    outp.write_text(json.dumps(cfg, indent=2))\n    print(f'Wrote {outp} with {len(repos)} repo(s); default_repo={default_repo}')\n\n\nif __name__ == '__main__':\n    main()\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "30aded64922ae24837e51c5d69c25e2e"}
{"id": "4ccc0007e183", "file_path": "/Users/davidmontgomery/agro/scripts/benchmark_improvements.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 34, "imports": ["import os", "from hybrid_search import search_routed_multi"], "code": "import os\nfrom hybrid_search import search_routed_multi\n\nTESTS = [\n    ('project','ai studio','easy'),\n    ('project','TBAC trait system','easy'),\n    ('project','plugin builder','easy'),\n    ('project','webhook verification','easy'),\n    ('project','three lane gateway','medium'),\n    ('project','plugin sandbox isolation','medium'),\n    ('project','provider adapter traits','medium'),\n    ('project','canonical event normalization','medium'),\n    ('project','how does TBAC prevent PHI access','hard'),\n    ('project','what is the general purpose of project','hard'),\n    ('project','how do different providers interact','hard'),\n]\n\nos.environ.setdefault('EMBEDDING_TYPE', 'local')\n\nby_diff = {}\nfor repo, q, d in TESTS:\n    docs = search_routed_multi(q, repo_override=repo, final_k=5)\n    s = (docs or [{}])[0].get('rerank_score', 0.0)\n    by_diff.setdefault(d, []).append(s)\n\nprint('\\n' + '='*80)\nprint('FINAL PERFORMANCE METRICS')\nprint('='*80)\n\nTARGET = {'easy':0.80, 'medium':0.70, 'hard':0.65}\nall_scores = []\nfor d, arr in by_diff.items():\n    avg = sum(arr)/max(1,len(arr))\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "15595ea6578a8ccaf5a5c60d6f7664b5"}
{"id": "85aad3eb2f9e", "file_path": "/Users/davidmontgomery/agro/scripts/benchmark_improvements.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 9, "imports": ["import os", "from hybrid_search import search_routed_multi"], "code": "    all_scores.extend(arr)\n    status = '✓' if avg >= TARGET[d] else '✗'\n    print(f\"{status} {d.upper():7} | Avg: {avg:.3f} | Target: {TARGET[d]:.3f}\")\n\noverall = sum(all_scores)/max(1,len(all_scores))\nprint(f\"\\n{'Overall Average:':20} {overall:.3f}\")\nprint('='*80)\n\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c7e305147d7b5952aa35b7a083934900"}
{"id": "e0e30331cdf7", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 16, "imports": ["import json", "import os", "from collections import Counter, defaultdict", "from pathlib import Path", "import re"], "code": "import json\nimport os\nfrom collections import Counter, defaultdict\nfrom pathlib import Path\nimport re\nextract_tokens(code):\n    \"\"\"Extract meaningful tokens from code\"\"\"\n    # Remove strings and comments\n    code = re.sub(r'[\"\\'].*?[\"\\']', '', code)\n    code = re.sub(r'#.*?\\n', '', code)\n    code = re.sub(r'//.*?\\n', '', code)\n    \n    # Extract identifiers (camelCase, snake_case, etc)\n    tokens = re.findall(r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b', code)\n    return [t.lower() for t in tokens if len(t) > 2]\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "57943bae11ee464e7d6a813f1cf06fd3"}
{"id": "a4f31c2fab06", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 43, "imports": [], "code": "analyze_repo(repo_path):\n    \"\"\"Analyze a repo for discriminative keywords\"\"\"\n    file_tokens = defaultdict(set)  # file -> set of tokens\n    global_counts = Counter()  # token -> total count\n    \n    for root, dirs, files in os.walk(repo_path):\n        # Skip common ignore patterns\n        dirs[:] = [d for d in dirs if d not in {'.git', 'node_modules', '__pycache__', '.venv', 'dist', 'build'}]\n        \n        for file in files:\n            if not any(file.endswith(ext) for ext in ['.py', '.js', '.ts', '.tsx', '.rb', '.java', '.go']):\n                continue\n                \n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                    code = f.read()\n                    tokens = extract_tokens(code)\n                    file_tokens[file_path].update(tokens)\n                    global_counts.update(tokens)\n            except:\n                continue\n    \n    # Calculate TF-IDF style scores\n    num_files = len(file_tokens)\n    doc_freq = Counter()  # how many files contain each token\n    \n    for tokens in file_tokens.values():\n        doc_freq.update(tokens)\n    \n    # Score = term frequency * inverse document frequency\n    keyword_scores = {}\n    for token, total_count in global_counts.items():\n        df = doc_freq[token]\n        idf = num_files / df if df > 0 else 0\n        \n        # High score = appears often but in few files (discriminative)\n        # Low score = appears everywhere (stop word) or rarely (noise)\n        if df > 1 and df < num_files * 0.05:  # in 2+ files but <5% of files\n            keyword_scores[token] = total_count * idf\n    \n    return keyword_scores, doc_freq, num_files\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5a0044281f442450fd79d84349e76a78"}
{"id": "37f506876d01", "file_path": "/Users/davidmontgomery/agro/scripts/analyze_keywords.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 63, "imports": [], "code": "find_discriminative_keywords(repo_path, top_n=50):\n    \"\"\"Find the most discriminative keywords in a repo\"\"\"\n    keyword_scores, doc_freq, num_files = analyze_repo(repo_path)\n    \n    # Sort by score\n    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n    \n    results = []\n    for token, score in sorted_keywords[:top_n]:\n        results.append({\n            'keyword': token,\n            'score': round(score, 2),\n            'appears_in_files': doc_freq[token],\n            'file_percentage': round(100 * doc_freq[token] / num_files, 1)\n        })\n    \n    return results\n\nif __name__ == '__main__':\n    repos = {\n        'project': os.getenv('PROJECT_PATH', '/abs/path/to/project'),\n        'project': os.getenv('project_PATH', '/abs/path/to/project')\n    }\n    \n    all_results = {}\n    \n    for repo_name, repo_path in repos.items():\n        print(f'\\n{\"=\"*80}')\n        print(f'ANALYZING: {repo_name}')\n        print(f'{\"=\"*80}')\n        \n        keywords = find_discriminative_keywords(repo_path, top_n=30)\n        all_results[repo_name] = keywords\n        \n        print(f'\\nTop 30 Discriminative Keywords (best for queries):\\n')\n        for i, kw in enumerate(keywords, 1):\n            print(f'{i:2}. {kw[\"keyword\"]:20} | Score: {kw[\"score\"]:8.1f} | In {kw[\"appears_in_files\"]:3} files ({kw[\"file_percentage\"]:4.1f}%)')\n    \n    # Find cross-contamination terms\n    print(f'\\n{\"=\"*80}')\n    print('CROSS-CONTAMINATION ANALYSIS')\n    print(f'{\"=\"*80}')\n    \n    viv_keywords = {k['keyword'] for k in all_results['project'][:30]}\n    fax_keywords = {k['keyword'] for k in all_results['project'][:30]}\n    \n    overlap = viv_keywords & fax_keywords\n    print(f'\\nShared keywords (cause confusion): {len(overlap)}')\n    if overlap:\n        print(f'  {\", \".join(sorted(overlap))}')\n    \n    print(f'\\nPROJECT-only keywords (use these!): {len(viv_keywords - fax_keywords)}')\n    print(f'  {\", \".join(sorted(list(viv_keywords - fax_keywords)[:10]))}')\n    \n    print(f'\\nPROJECT-only keywords (use these!): {len(fax_keywords - viv_keywords)}')\n    print(f'  {\", \".join(sorted(list(fax_keywords - viv_keywords)[:10]))}')\n    \n    # Save to file\n    with open('discriminative_keywords.json', 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    print(f'\\n✓ Results saved to discriminative_keywords.json')\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5f190aa715d8ec6cdc10415ac5d4959d"}
{"id": "3857a1a049e9", "file_path": "/Users/davidmontgomery/agro/scripts/gui_debug.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 8, "imports": ["from __future__ import annotations", "import time", "from playwright.sync_api import sync_playwright"], "code": "#!/usr/bin/env python3\n\"\"\"Debug GUI by opening it and printing console errors\"\"\"\nfrom __future__ import annotations\nimport time\nfrom playwright.sync_api import sync_playwright\n\nBASE = \"http://127.0.0.1:8012\"\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7181e5742d46b9363d723d3294b0c060"}
{"id": "05347b06d75c", "file_path": "/Users/davidmontgomery/agro/scripts/gui_debug.py", "language": "python", "type": "section", "name": null, "start_line": 1, "end_line": 96, "imports": [], "code": "main():\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=False)\n        ctx = browser.new_context()\n        page = ctx.new_page()\n\n        # Capture console messages\n        console_msgs = []\n        page.on(\"console\", lambda msg: console_msgs.append(f\"[{msg.type}] {msg.text}\"))\n        page.on(\"pageerror\", lambda err: print(f\"❌ PAGE ERROR: {err}\"))\n\n        print(f\"Opening {BASE}/gui/...\")\n        page.goto(f\"{BASE}/gui/\", wait_until=\"domcontentloaded\")\n        page.wait_for_timeout(2000)\n\n        # Check overview populated\n        print(\"\\n=== Overview Section ===\")\n        try:\n            health = page.locator('#dash-health').text_content()\n            repo = page.locator('#dash-repo').text_content()\n            autotune = page.locator('#dash-autotune').text_content()\n            cards = page.locator('#dash-cards').text_content()\n            print(f\"Health: {health}\")\n            print(f\"Repo: {repo}\")\n            print(f\"Autotune: {autotune}\")\n            print(f\"Cards: {cards}\")\n            if all(x != \"—\" for x in [health, repo, autotune, cards]):\n                print(\"✓ Overview populated\")\n            else:\n                print(\"❌ Overview still has placeholders\")\n        except Exception as e:\n            print(f\"❌ Error reading overview: {e}\")\n\n        # Test wizard button\n        print(\"\\n=== Testing Wizard Button ===\")\n        try:\n            page.fill('#budget', '10')\n            page.click('#btn-wizard-oneclick')\n            page.wait_for_timeout(3000)\n            tri_out = page.locator('#tri-out').text_content()\n            print(\"Full tri-output:\")\n            print(tri_out)\n            if \"Press button\" in tri_out or len(tri_out) < 20:\n                print(\"❌ Wizard didn't generate output\")\n            else:\n                print(\"✓ Wizard generated output\")\n        except Exception as e:\n            print(f\"❌ Wizard error: {e}\")\n\n        # Test cost calculator with blur events\n        print(\"\\n=== Testing Cost Calculator ===\")\n        try:\n            print(\"Typing 500 into cost-in and blurring...\")\n            page.fill('#cost-in', '500')\n            page.locator('#cost-in').blur()\n            page.wait_for_timeout(300)\n            val = page.input_value('#cost-in')\n            print(f\"  Value after blur: '{val}'\")\n\n            print(\"Typing 800 into cost-out and blurring...\")\n            page.fill('#cost-out', '800')\n            page.locator('#cost-out').blur()\n            page.wait_for_timeout(300)\n            val2 = page.input_value('#cost-out')\n            print(f\"  Value after blur: '{val2}'\")\n\n            if not val or not val2:\n                print(\"❌ Cost inputs being cleared\")\n            else:\n                print(f\"✓ Cost inputs retained (values: {val}, {val2})\")\n\n            # Test with larger number (comma formatting disabled for type=\"number\" inputs)\n            print(\"Testing with 5000 (no comma formatting expected for number inputs)...\")\n            page.fill('#cost-in', '5000')\n            page.locator('#cost-in').blur()\n            page.wait_for_timeout(300)\n            val3 = page.input_value('#cost-in')\n            print(f\"  5000 after blur: '{val3}'\")\n            if val3 == '5000':\n                print(\"✓ Number input retains value\")\n            else:\n                print(f\"❌ Unexpected value: {val3}\")\n        except Exception as e:\n            print(f\"❌ Cost calculator error: {e}\")\n\n        # Print console\n        print(\"\\n=== Console Messages ===\")\n        for msg in console_msgs:\n            print(msg)\n\n        browser.close()\n        return 0\n\nif __name__ == '__main__':\n    main()\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7eac19835cb7fd08fb40332ba3d0e739"}
{"id": "98e849194ede", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 41, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "#!/usr/bin/env python3\n\"\"\"\nComplete, transparent comparison:\n- Qwen 3 vs OpenAI gpt-4o\n- Actual MCP tool schema overhead\n- Real latency measurements\n- Quality comparison\n\"\"\"\nimport sys\nimport os\nimport json\nimport time\nROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\nsys.path.insert(0, ROOT_DIR)\n\ntry:\n    import tiktoken\n    enc = tiktoken.encoding_for_model(\"gpt-4o\")\n    def count_tokens(text): return len(enc.encode(text))\nexcept:\n    def count_tokens(text): return len(text) // 4\n\nprint(\"=\" * 80)\nprint(\"COMPLETE MODEL COMPARISON - TRANSPARENT MEASUREMENTS\")\nprint(\"=\" * 80)\n\n# Test query\nquestion = \"How are fax jobs created and dispatched\"\nrepo = \"project\"\n\nprint(f\"\\nTest query: '{question}'\")\nprint(f\"Repo: {repo}\\n\")\n\n# ==================================================================\n# 1. MEASURE MCP TOOL SCHEMA OVERHEAD (sent on EVERY request)\n# ==================================================================\nprint(\"1. MCP Tool Schema Overhead\")\nprint(\"-\" * 80)\n\nfrom mcp_server import MCPServer\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "705d83e68c764b278c124a169dde07b7"}
{"id": "1aec8cfcd49b", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 33, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "server = MCPServer()\ntools_req = {'jsonrpc': '2.0', 'id': 1, 'method': 'tools/list', 'params': {}}\ntools_resp = server.handle_request(tools_req)\ntools_json = json.dumps(tools_resp['result']['tools'])\nschema_tokens = count_tokens(tools_json)\n\nprint(f\"Tool schemas (sent with EVERY request): {schema_tokens:,} tokens\")\nprint(f\"Schema size: {len(tools_json):,} bytes\\n\")\n\n# ==================================================================\n# 2. MCP SEARCH RESPONSE SIZE\n# ==================================================================\nprint(\"2. MCP Search Response\")\nprint(\"-\" * 80)\n\nsearch_req = {\n    'jsonrpc': '2.0',\n    'id': 1,\n    'method': 'tools/call',\n    'params': {\n        'name': 'rag_search',\n        'arguments': {'repo': repo, 'question': question, 'top_k': 10}\n    }\n}\n\nstart = time.time()\nsearch_resp = server.handle_request(search_req)\nsearch_latency = time.time() - start\n\nmcp_response = search_resp['result']['content'][0]['text']\nresponse_tokens = count_tokens(mcp_response)\ntotal_mcp_tokens = schema_tokens + response_tokens\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a2c0748722d0e96e000e56cbe4ec6c7a"}
{"id": "fd522c8bdec3", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 28, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "\nprint(f\"Response tokens: {response_tokens:,}\")\nprint(f\"Total MCP tokens: {total_mcp_tokens:,} ({schema_tokens} schema + {response_tokens} response)\")\nprint(f\"Search latency: {search_latency:.2f}s\\n\")\n\n# ==================================================================\n# 3. QWEN 3 GENERATION\n# ==================================================================\nprint(\"3. Qwen 3 Generation (Local)\")\nprint(\"-\" * 80)\n\nos.environ[\"OLLAMA_URL\"] = \"http://127.0.0.1:11434/api\"\nos.environ[\"GEN_MODEL\"] = \"qwen3-coder:30b\"\n\nfrom env_model import generate_text\n\n# Parse MCP response to get context\nresult_data = json.loads(mcp_response)\ncontext = f\"Retrieved {result_data['count']} code locations:\\n\"\nfor r in result_data['results'][:5]:\n    context += f\"- {r['file_path']}:{r['start_line']}-{r['end_line']} (score: {r['rerank_score']:.3f})\\n\"\n\nprompt = f\"{context}\\n\\nQuestion: {question}\\nAnswer:\"\n\nstart = time.time()\nqwen_answer, _ = generate_text(prompt, model=\"qwen3-coder:30b\")\nqwen_latency = time.time() - start\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "7ec2b745b4e621329de34928516b352e"}
{"id": "fa941cb376ba", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 33, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "\nqwen_output_tokens = count_tokens(qwen_answer)\nqwen_total_tokens = total_mcp_tokens + qwen_output_tokens\n\nprint(f\"Answer length: {len(qwen_answer)} chars\")\nprint(f\"Output tokens: {qwen_output_tokens:,}\")\nprint(f\"Total tokens (MCP + generation): {qwen_total_tokens:,}\")\nprint(f\"Generation latency: {qwen_latency:.2f}s\")\nprint(f\"Cost: $0.00 (local)\")\nprint(f\"\\nAnswer preview: {qwen_answer[:200]}...\\n\")\n\n# ==================================================================\n# 4. OPENAI GPT-4O GENERATION\n# ==================================================================\nprint(\"4. OpenAI gpt-4o Generation (API)\")\nprint(\"-\" * 80)\n\n# Use OpenAI for generation\nfrom openai import OpenAI\nclient = OpenAI()\n\nstart = time.time()\ntry:\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        max_tokens=500\n    )\n    openai_answer = response.choices[0].message.content\n    openai_latency = time.time() - start\n    \n    openai_output_tokens = count_tokens(openai_answer)\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "556c66cd47dfee410a9bcc0c6ad47ec6"}
{"id": "45cebc59c242", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 27, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "    openai_total_tokens = total_mcp_tokens + openai_output_tokens\n    \n    # gpt-4o pricing (as of Oct 2025): $2.50/1M input, $10/1M output\n    input_cost = total_mcp_tokens * (2.50 / 1_000_000)\n    output_cost = openai_output_tokens * (10.00 / 1_000_000)\n    total_cost = input_cost + output_cost\n    \n    print(f\"Answer length: {len(openai_answer)} chars\")\n    print(f\"Output tokens: {openai_output_tokens:,}\")\n    print(f\"Total tokens (MCP + generation): {openai_total_tokens:,}\")\n    print(f\"Generation latency: {openai_latency:.2f}s\")\n    print(f\"Cost: ${total_cost:.6f} (${input_cost:.6f} input + ${output_cost:.6f} output)\")\n    print(f\"\\nAnswer preview: {openai_answer[:200]}...\\n\")\nexcept Exception as e:\n    print(f\"ERROR: {e}\\n\")\n    openai_answer = None\n\n# ==================================================================\n# 5. COMPARISON TABLE\n# ==================================================================\nprint(\"=\" * 80)\nprint(\"SUMMARY COMPARISON\")\nprint(\"=\" * 80)\n\nprint(\"\\nTOKEN BREAKDOWN:\")\nprint(f\"  MCP tool schemas:     {schema_tokens:,} tokens (sent on EVERY request)\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "52ff0e278751512b5034de345d1d14b8"}
{"id": "89fbe356a4d1", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 37, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "print(f\"  MCP search response:  {response_tokens:,} tokens\")\nprint(f\"  Qwen 3 output:        {qwen_output_tokens:,} tokens\")\nif openai_answer:\n    print(f\"  gpt-4o output:        {openai_output_tokens:,} tokens\")\n\nprint(f\"\\nTOTAL TOKENS:\")\nprint(f\"  Qwen 3:   {qwen_total_tokens:,} tokens\")\nif openai_answer:\n    print(f\"  gpt-4o:   {openai_total_tokens:,} tokens\")\n\nprint(f\"\\nLATENCY:\")\nprint(f\"  MCP search:       {search_latency:.2f}s\")\nprint(f\"  Qwen 3 generate:  {qwen_latency:.2f}s\")\nif openai_answer:\n    print(f\"  gpt-4o generate:  {openai_latency:.2f}s\")\n\nprint(f\"\\nCOST PER QUERY:\")\nprint(f\"  Qwen 3:   $0.00 (local)\")\nif openai_answer:\n    print(f\"  gpt-4o:   ${total_cost:.6f}\")\n\nprint(f\"\\nANSWER QUALITY:\")\nprint(f\"  Qwen 3:   {len(qwen_answer)} chars - {qwen_answer[:100]}...\")\nif openai_answer:\n    print(f\"  gpt-4o:   {len(openai_answer)} chars - {openai_answer[:100]}...\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"SAVED TO: /tmp/full_comparison_results.json\")\nprint(\"=\" * 80)\n\n# Save results\nresults = {\n    \"query\": question,\n    \"repo\": repo,\n    \"mcp\": {\n        \"schema_tokens\": schema_tokens,\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5291bbe227ecb1693fe3a837abd6c700"}
{"id": "e50fda3a7a30", "file_path": "/Users/davidmontgomery/agro/scripts/full_comparison.py", "language": "python", "type": "blob", "name": null, "start_line": 1, "end_line": 27, "imports": ["import sys", "import os", "import json", "import time", "from mcp_server import MCPServer", "from env_model import generate_text", "from openai import OpenAI"], "code": "        \"response_tokens\": response_tokens,\n        \"total_tokens\": total_mcp_tokens,\n        \"latency_s\": search_latency\n    },\n    \"qwen3\": {\n        \"output_tokens\": qwen_output_tokens,\n        \"total_tokens\": qwen_total_tokens,\n        \"latency_s\": qwen_latency,\n        \"cost_usd\": 0.0,\n        \"answer\": qwen_answer\n    }\n}\n\nif openai_answer:\n    results[\"gpt4o\"] = {\n        \"output_tokens\": openai_output_tokens,\n        \"total_tokens\": openai_total_tokens,\n        \"latency_s\": openai_latency,\n        \"cost_usd\": total_cost,\n        \"answer\": openai_answer\n    }\n\nwith open('/tmp/full_comparison_results.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint(\"\\nDone!\")\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "da27cccac00d996afcc859ff0765ab0d"}
{"id": "da4f8fd176f2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 36, "imports": [], "code": "// AGRO GUI app.js (complete with all handlers)\n(function () {\n    // Backend API base: respects ?api= override; defaults to local FastAPI\n    const API_BASE = (() => {\n        try {\n            const u = new URL(window.location.href);\n            const q = new URLSearchParams(u.search);\n            const override = q.get('api');\n            if (override) return override.replace(/\\/$/, '');\n            if (u.port === '8012') return u.origin;\n            return 'http://127.0.0.1:8012';\n        } catch { return 'http://127.0.0.1:8012'; }\n    })();\n    const api = (p) => `${API_BASE}${p}`;\n    const $ = (sel) => document.querySelector(sel);\n    const $$ = (sel) => Array.from(document.querySelectorAll(sel));\n\n    const state = {\n        prices: null,\n        config: null,\n        profiles: [],\n        defaultProfile: null,\n    };\n\n    // ---------------- Tabs ----------------\n    function switchTab(tabName) {\n        const groups = {\n            models: ['generation','embeddings','reranking'],\n            retrieval: ['retrieval','confidence','cards'],\n            repos: ['repos','indexing'],\n            tools: ['calculator','eval','misc'],\n            infra: ['infra'],\n            dashboard: ['dashboard']\n        };\n        const show = groups[tabName] || [tabName];\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "e0822772218a9b4edb05712a8adb513f"}
{"id": "8b07c19e18be", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "        $$('.tab-content').forEach(el => el.classList.remove('active'));\n        show.forEach(id => { const el = document.getElementById(`tab-${id}`); if (el) el.classList.add('active'); });\n        $$('.tab-bar button').forEach(el => el.classList.remove('active'));\n        const btn = document.querySelector(`.tab-bar button[data-tab=\"${tabName}\"]`);\n        if (btn) btn.classList.add('active');\n    }\n\n    function bindTabs() {\n        $$('.tab-bar button').forEach(btn => {\n            btn.addEventListener('click', () => {\n                const tab = btn.getAttribute('data-tab');\n                switchTab(tab);\n            });\n        });\n    }\n\n    // ---------------- Global Search ----------------\n    function clearHighlights() { $$('.hl').forEach(m => { const t=document.createTextNode(m.textContent); m.replaceWith(t); }); }\n    function highlightMatches(root, q) {\n        if (!q) return; const rx = new RegExp(q.replace(/[.*+?^${}()|[\\]\\\\]/g,'\\\\$&'), 'ig');\n        const walker = document.createTreeWalker(root, NodeFilter.SHOW_TEXT, null);\n        const hits = [];\n        while (walker.nextNode()) {\n            const n = walker.currentNode; if (!n.nodeValue || !n.parentElement) continue;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "a069ad0e332274af98e5bceb99bd7952"}
{"id": "3f806a42a2b4", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "            if (/SCRIPT|STYLE|IFRAME/.test(n.parentElement.tagName)) continue;\n            const m = n.nodeValue.match(rx); if (!m) continue;\n            const span = document.createElement('mark'); span.className='hl'; span.textContent = n.nodeValue;\n            const html = n.nodeValue.replace(rx, s => `<mark class=\"hl\">${s}</mark>`);\n            const frag = document.createElement('span'); frag.innerHTML = html;\n            n.parentElement.replaceChild(frag, n);\n            hits.push(frag.querySelector('mark.hl'));\n        }\n        return hits;\n    }\n\n    function bindGlobalSearch() {\n        const box = document.getElementById('global-search');\n        if (!box) return;\n        function run(q, jump=false) {\n            clearHighlights();\n            if (!q) return;\n            const hits = highlightMatches(document.querySelector('.content'), q);\n            if (jump && hits && hits.length) hits[0].scrollIntoView({behavior:'smooth', block:'center'});\n        }\n        box.addEventListener('keydown', (e)=>{ if ((e.ctrlKey||e.metaKey) && e.key.toLowerCase()==='k'){ e.preventDefault(); box.focus(); box.select(); }});\n        box.addEventListener('input', ()=> run(box.value.trim()));\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "132cde3ff7575c92fb80418b4ac988ec"}
{"id": "4e31d770eacd", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 38, "imports": [], "code": "        box.addEventListener('keydown', (e)=>{ if (e.key==='Enter') run(box.value.trim(), true); });\n    }\n\n    // ---------------- Health ----------------\n    async function checkHealth() {\n        try {\n            const r = await fetch(api('/health'));\n            const d = await r.json();\n            $('#health-status').textContent = d.ok || d.status === 'healthy' ? `OK @ ${d.ts || new Date().toISOString()}` : 'Not OK';\n        } catch (e) {\n            $('#health-status').textContent = 'Error';\n        }\n    }\n\n    // ---------------- Config ----------------\n    async function loadConfig() {\n        try {\n            try { await fetch(api('/api/env/reload'), { method: 'POST' }); } catch {}\n            const r = await fetch(api('/api/config'));\n            const d = await r.json();\n            state.config = d;\n            populateConfigForm(d);\n        } catch (e) {\n            console.error('Failed to load config:', e);\n        }\n    }\n\n    function populateConfigForm(data) {\n        const env = data.env || {};\n\n        // Fill all env variable fields\n        Object.entries(env).forEach(([k, v]) => {\n            const field = document.querySelector(`[name=\"${k}\"]`);\n            if (!field) return;\n\n            if (field.type === 'checkbox') {\n                field.checked = String(v).toLowerCase() === 'true' || v === '1' || v === true;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "26be9734627bcb8315240efa969bdc6c"}
{"id": "d03aeea58449", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 37, "imports": [], "code": "            } else if (field.tagName === 'SELECT') {\n                field.value = v;\n            } else {\n                field.value = v;\n            }\n        });\n\n        // Populate repo select\n        const repoSelect = $('#repo-select');\n        if (repoSelect) {\n            repoSelect.innerHTML = '';\n            (data.repos || []).forEach((repo) => {\n                const opt = document.createElement('option');\n                opt.value = repo.name;\n                opt.textContent = repo.name;\n                repoSelect.appendChild(opt);\n            });\n            if (env.REPO) {\n                repoSelect.value = env.REPO;\n            } else if (data.default_repo) {\n                repoSelect.value = data.default_repo;\n            }\n        }\n\n        // Seed cost panel defaults from pricing if fields are empty\n        if (state.prices && Array.isArray(state.prices.models) && state.prices.models.length) {\n            if (!$('#cost-provider').value) $('#cost-provider').value = state.prices.models[0].provider || '';\n            if (!$('#cost-model').value) $('#cost-model').value = state.prices.models[0].model || '';\n        }\n\n        // Cost panel autopopulate from env\n        try {\n            // Generation provider heuristic: use GEN_MODEL hint if present; otherwise env keys\n            let provGuess = '';\n            const gm = env.GEN_MODEL || '';\n            if (/^gpt-|^o\\w+:/i.test(gm)) provGuess = 'openai';\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5f392513ba12265267297865e83954a5"}
{"id": "311f18c09e3d", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 19, "imports": [], "code": "            else if (/^claude/i.test(gm)) provGuess = 'anthropic';\n            else if (/^gemini/i.test(gm)) provGuess = 'google';\n            else if (env.OLLAMA_URL) provGuess = 'local';\n            else if (env.OPENAI_API_KEY) provGuess = 'openai';\n            else if (env.ANTHROPIC_API_KEY) provGuess = 'anthropic';\n            else if (env.GOOGLE_API_KEY) provGuess = 'google';\n            if (provGuess) $('#cost-provider').value = provGuess;\n            if (env.GEN_MODEL) $('#cost-model').value = env.GEN_MODEL;\n\n            // Embeddings\n            if (env.EMBEDDING_TYPE) {\n                const ep = document.getElementById('cost-embed-provider'); if (ep) ep.value = env.EMBEDDING_TYPE;\n                if (env.EMBEDDING_TYPE === 'openai' && document.getElementById('cost-embed-model') && !$('#cost-embed-model').value) $('#cost-embed-model').value = 'text-embedding-3-small';\n                if (env.EMBEDDING_TYPE === 'voyage' && document.getElementById('cost-embed-model') && !$('#cost-embed-model').value) $('#cost-embed-model').value = 'voyage-3-large-embed';\n            }\n            // Reranker\n            if (env.RERANK_BACKEND) {\n                const rp = document.getElementById('cost-rerank-provider'); if (rp) rp.value = env.RERANK_BACKEND;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f3f66867f6c890fae2edf9b64f3dc44d"}
{"id": "c59a1565de00", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "            }\n            if (env.COHERE_RERANK_MODEL && document.getElementById('cost-rerank-model')) $('#cost-rerank-model').value = env.COHERE_RERANK_MODEL;\n            if (env.RERANKER_MODEL && document.getElementById('cost-rerank-model') && !$('#cost-rerank-model').value) $('#cost-rerank-model').value = env.RERANKER_MODEL;\n        } catch {}\n\n        // Wizard defaults: seed from env\n        try { seedWizardFromEnv(env); } catch {}\n        updateWizardSummary();\n\n        // Populate repos metadata editor\n        const reposSection = $('#repos-section');\n        if (reposSection) {\n            reposSection.innerHTML = '';\n            (data.repos || []).forEach((repo) => {\n                const div = document.createElement('div');\n                div.style.cssText = 'background: #0a0a0a; border: 1px solid #2a2a2a; border-radius: 6px; padding: 16px; margin-bottom: 16px;';\n                const rname = repo.name;\n                div.innerHTML = `\n                    <h4 style=\\\"color: #00ff88; font-size: 14px; margin-bottom: 12px;\\\">Repo: ${repo.name}</h4>\n                    <div class=\\\"input-group\\\" style=\\\"margin-bottom: 12px;\\\">\n                        <label>Path</label>\n                        <input type=\\\"text\\\" name=\\\"repo_path_${repo.name}\\\" value=\\\"${repo.path || ''}\\\" />\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f29c2c7d9471bf79c40f2dd038d2f9ca"}
{"id": "fd15f1c4af97", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 19, "imports": [], "code": "                    </div>\n                    <div class=\\\"input-group\\\" style=\\\"margin-bottom: 12px;\\\">\n                        <label>Keywords (comma-separated)</label>\n                        <input type=\\\"text\\\" name=\\\"repo_keywords_${repo.name}\\\" value=\\\"${(repo.keywords||[]).join(',')}\\\" list=\\\"keywords-list\\\" placeholder=\\\"search or type to add\\\" />\n                    </div>\n                    <div class=\\\"input-group\\\" style=\\\"margin-bottom: 12px;\\\">\n                        <label>Path Boosts (comma-separated)</label>\n                        <input type=\\\"text\\\" name=\\\"repo_pathboosts_${repo.name}\\\" value=\\\"${(repo.path_boosts||[]).join(',')}\\\" />\n                    </div>\n                    <div class=\\\"input-group\\\">\n                        <label>Layer Bonuses (JSON)</label>\n                        <textarea name=\\\"repo_layerbonuses_${repo.name}\\\" rows=\\\"3\\\">${repo.layer_bonuses ? JSON.stringify(repo.layer_bonuses, null, 2) : ''}</textarea>\n                    </div>\n                    <div class=\\\"input-group full-width\\\" style=\\\"margin-top:12px;\\\">\n                        <label>Keyword Manager</label>\n                        <div style=\\\"display:grid; grid-template-columns: 1fr auto 1fr; gap:8px; align-items:center;\\\">\n                            <div>\n                                <div style=\\\"display:flex; gap:6px; margin-bottom:6px;\\\">\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9e8d4a155cdc2290589503b3369b791a"}
{"id": "cd2e919607b8", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "                                    <input type=\\\"text\\\" id=\\\"kw-filter-${rname}\\\" placeholder=\\\"filter...\\\" style=\\\"width:60%;\\\">\n                                    <select id=\\\"kw-src-${rname}\\\">\n                                        <option value=\\\"all\\\">All</option>\n                                        <option value=\\\"discriminative\\\">Discriminative</option>\n                                        <option value=\\\"semantic\\\">Semantic</option>\n                                        <option value=\\\"repos\\\">Repo</option>\n                                    </select>\n                                </div>\n                                <select id=\\\"kw-all-${rname}\\\" multiple size=\\\"8\\\" style=\\\"width:100%;\\\"></select>\n                            </div>\n                            <div style=\\\"display:flex; flex-direction:column; gap:8px;\\\">\n                                <button class=\\\"small-button\\\" id=\\\"kw-add-${rname}\\\">&gt;&gt;</button>\n                                <button class=\\\"small-button\\\" id=\\\"kw-rem-${rname}\\\">&lt;&lt;</button>\n                            </div>\n                            <div>\n                                <div class=\\\"small\\\" style=\\\"margin-bottom:6px;\\\">Repo Keywords</div>\n                                <select id=\\\"kw-repo-${rname}\\\" multiple size=\\\"8\\\" style=\\\"width:100%;\\\"></select>\n                            </div>\n                        </div>\n                    </div>\n                `;\n                reposSection.appendChild(div);\n\n                // Hook keyword manager events\n                const fld = div.querySelector(`[name=\\\"repo_keywords_${rname}\\\"]`);\n                const allSel = div.querySelector(`#kw-all-${rname}`);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "dad4747b7cedbb85192a9079bd625167"}
{"id": "c66d04bf0394", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 27, "imports": [], "code": "                const repoSel = div.querySelector(`#kw-repo-${rname}`);\n                const srcSel = div.querySelector(`#kw-src-${rname}`);\n                const filter = div.querySelector(`#kw-filter-${rname}`);\n                const addBtn = div.querySelector(`#kw-add-${rname}`);\n                const remBtn = div.querySelector(`#kw-rem-${rname}`);\n\n                function currentRepoKws() {\n                    return (fld.value || '').split(',').map(s => s.trim()).filter(Boolean);\n                }\n                function setRepoKws(arr) {\n                    fld.value = arr.join(',');\n                    // repaint repo list\n                    repoSel.innerHTML = '';\n                    arr.forEach(k => { const o=document.createElement('option'); o.value=k; o.textContent=k; repoSel.appendChild(o); });\n                }\n                function sourceList() {\n                    const cat = (srcSel.value||'all');\n                    const catMap = (state.keywordsCatalog||{});\n                    let base = [];\n                    if (cat === 'all') base = catMap.keywords||[]; else base = catMap[cat]||[];\n                    const f = (filter.value||'').toLowerCase();\n                    const inRepo = new Set(currentRepoKws());\n                    return base.filter(k => !inRepo.has(k) && (!f || k.toLowerCase().includes(f)));\n                }\n                function paintSource() {\n                    allSel.innerHTML = '';\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8a043ee847b5215f7c6bdf406e479758"}
{"id": "0c5c89d3759d", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "                    sourceList().slice(0,500).forEach(k => { const o=document.createElement('option'); o.value=k; o.textContent=k; allSel.appendChild(o); });\n                }\n                addBtn.addEventListener('click', () => {\n                    const cur = currentRepoKws();\n                    const selected = Array.from(allSel.selectedOptions).map(o=>o.value);\n                    const next = Array.from(new Set([...cur, ...selected]));\n                    setRepoKws(next); paintSource();\n                });\n                remBtn.addEventListener('click', () => {\n                    const cur = currentRepoKws();\n                    const remove = new Set(Array.from(repoSel.selectedOptions).map(o=>o.value));\n                    const next = cur.filter(k => !remove.has(k));\n                    setRepoKws(next); paintSource();\n                });\n                srcSel.addEventListener('change', paintSource);\n                filter.addEventListener('input', paintSource);\n\n                // initial fill using existing values + catalog (if loaded later, loadKeywords will repaint)\n                setRepoKws((repo.keywords||[]));\n                if (state.keywordsCatalog) paintSource();\n            });\n        }\n    }\n\n    function gatherConfigForm() {\n        const update = { env: {}, repos: [] };\n\n        // Gather all env vars from form\n        const envFields = $$('[name]').filter(f => !f.name.startsWith('repo_'));\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "fe6ed8b081028b85f9be3621fa06296a"}
{"id": "79938c977092", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 39, "imports": [], "code": "        envFields.forEach(field => {\n            const key = field.name;\n            let val;\n\n            if (field.type === 'checkbox') {\n                val = field.checked;\n            } else if (field.type === 'number') {\n                val = field.value;\n            } else {\n                val = field.value;\n            }\n\n            if (val !== '' && val !== null && val !== undefined) {\n                update.env[key] = val;\n            }\n        });\n\n        // Gather repo-specific fields\n        const repoFields = $$('[name^=\"repo_\"]');\n        const repoMap = {};\n\n        repoFields.forEach(field => {\n            const parts = field.name.split('_');\n            const fieldType = parts[1]; // path, keywords, pathboosts, layerbonuses\n            const repoName = parts.slice(2).join('_');\n\n            if (!repoMap[repoName]) {\n                repoMap[repoName] = { name: repoName };\n            }\n\n            if (fieldType === 'keywords' || fieldType === 'pathboosts') {\n                const key = fieldType === 'pathboosts' ? 'path_boosts' : 'keywords';\n                repoMap[repoName][key] = field.value.split(',').map(s => s.trim()).filter(Boolean);\n            } else if (fieldType === 'layerbonuses') {\n                try {\n                    repoMap[repoName]['layer_bonuses'] = field.value ? JSON.parse(field.value) : {};\n                } catch (e) {\n                    alert(`Invalid JSON for ${repoName} layer_bonuses: ${e.message}`);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "de4a97b777c691da4b8d1f00242bd91c"}
{"id": "866ac123e137", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 53, "imports": [], "code": "                    return null;\n                }\n            } else if (fieldType === 'path') {\n                repoMap[repoName]['path'] = field.value;\n            }\n        });\n\n        update.repos = Object.values(repoMap);\n        return update;\n    }\n\n    async function saveConfig() {\n        const body = gatherConfigForm();\n        if (!body) return;\n\n        try {\n            const r = await fetch(api('/api/config'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(body)\n            });\n\n            if (!r.ok) {\n                alert('Save failed');\n                return;\n            }\n\n            const result = await r.json();\n            if (result.status === 'success') {\n                alert('Configuration updated successfully!');\n                await loadConfig(); // Reload to confirm\n            }\n        } catch (e) {\n            alert('Error saving config: ' + e.message);\n        }\n    }\n\n    // ---------------- Prices & Cost ----------------\n    async function loadPrices() {\n        try {\n            const r = await fetch(api('/api/prices'));\n            state.prices = await r.json();\n            populatePriceDatalists();\n        } catch (e) {\n            console.error('Failed to load prices:', e);\n        }\n    }\n\n    function unique(xs) { return Array.from(new Set(xs)); }\n\n    function populatePriceDatalists() {\n        if (!state.prices || !Array.isArray(state.prices.models)) return;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4c1b1fe9b4c9cf07a194afed099e0c7b"}
{"id": "85c14225ca4d", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "\n        const models = state.prices.models;\n        const providers = unique(models.map(m => (m.provider || '').trim()).filter(Boolean));\n        const allModels = unique(models.map(m => (m.model || '').trim()).filter(Boolean));\n\n        const providerSelect = document.getElementById('cost-provider');\n        const modelList = document.getElementById('model-list');\n        const genList = document.getElementById('gen-model-list');\n        const rrList = document.getElementById('rerank-model-list');\n        const embList = document.getElementById('embed-model-list');\n\n        function setOpts(el, vals) {\n            if (!el) return;\n            el.innerHTML = '';\n            vals.forEach(v => {\n                const opt = document.createElement('option');\n                opt.value = v;\n                if (el.tagName === 'SELECT') opt.textContent = v;\n                el.appendChild(opt);\n            });\n        }\n\n        if (providerSelect && providerSelect.tagName === 'SELECT') {\n            // refill provider select only if empty, preserve user choice\n            if (providerSelect.options.length <= 1) setOpts(providerSelect, providers);\n        }\n        setOpts(modelList, allModels);\n        const genModels = unique(models\n            .filter(m => (m.family||'').includes('gen') || ['openai','anthropic','google','local','mistral','meta'].includes((m.provider||'').toLowerCase()))\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "38b02b2c86a27929d92d63652ef8daa5"}
{"id": "0f9dfb964356", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 23, "imports": [], "code": "            .map(m => m.model));\n        const rrModels = unique(models\n            .filter(m => (m.family||'').includes('rerank') || ['cohere'].includes((m.provider||'').toLowerCase()) || (m.model||'').toLowerCase().includes('rerank'))\n            .map(m => m.model));\n        const embModels = unique(models\n            .filter(m => (m.family||'').includes('embed') || (m.embed_per_1k||0) > 0)\n            .map(m => m.model));\n        setOpts(genList, genModels);\n        setOpts(rrList, rrModels);\n        setOpts(embList, embModels);\n\n        if (!$('#cost-provider').value && providers.length) $('#cost-provider').value = providers[0];\n        if (!$('#cost-model').value && allModels.length) $('#cost-model').value = allModels[0];\n\n        // Filter model options when provider changes AND update the input value\n        const onProv = () => {\n            const modelInput = $('#cost-model');\n            if (!modelInput) return;\n\n            const p = $('#cost-provider').value.trim().toLowerCase();\n            const provModels = unique(models.filter(m => (m.provider||'').toLowerCase()===p).map(m => m.model));\n            const filtered = provModels.length ? provModels : allModels;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "f51513974aa0dd18ca60e465ad3174bd"}
{"id": "441afa3118d2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "\n            setOpts(modelList, filtered);\n\n            // Auto-select first model from this provider if current model doesn't match\n            if (!filtered.includes(modelInput.value)) {\n                modelInput.value = filtered[0] || '';\n            }\n        };\n\n        if (providerSelect) providerSelect.addEventListener('change', onProv);\n        onProv(); // Initialize\n    }\n\n    function buildCostPayload() {\n        const payload = {\n            provider: $('#cost-provider').value.trim(),\n            model: $('#cost-model').value.trim(),\n            tokens_in: parseInt($('#cost-in').value, 10) || 0,\n            tokens_out: parseInt($('#cost-out').value, 10) || 0,\n            embeds: parseInt($('#cost-embeds').value, 10) || 0,\n            reranks: parseInt($('#cost-rerank').value, 10) || 0,\n            requests_per_day: parseInt($('#cost-rpd').value, 10) || 0,\n        };\n        // Optional per-component providers/models for full pipeline costing\n        const ep = document.getElementById('cost-embed-provider');\n        const em = document.getElementById('cost-embed-model');\n        const rp = document.getElementById('cost-rerank-provider');\n        const rm = document.getElementById('cost-rerank-model');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "8e321a3a7e189a08e2c5fa6047ab0554"}
{"id": "45c94ae173da", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "        if (ep && ep.value) payload.embed_provider = ep.value.trim();\n        if (em && em.value) payload.embed_model = em.value.trim();\n        if (rp && rp.value) payload.rerank_provider = rp.value.trim();\n        if (rm && rm.value) payload.rerank_model = rm.value.trim();\n        // MQ rewrites from current config (affects per-request embed/rerank cost)\n        const mq = parseInt((state.config?.env?.MQ_REWRITES)||'1', 10) || 1;\n        payload.mq_rewrites = mq;\n        return payload;\n    }\n\n    async function estimateCost() {\n        const basic = buildCostPayload();\n        // Pipeline payload includes gen model+provider and uses env to resolve embed/rerank (cohere/openai etc.)\n        const pipeline = {\n            gen_provider: basic.provider,\n            gen_model: basic.model,\n            tokens_in: basic.tokens_in,\n            tokens_out: basic.tokens_out,\n            embeds: basic.embeds,\n            reranks: basic.reranks,\n            requests_per_day: basic.requests_per_day,\n        };\n\n        try {\n            let r = await fetch(api('/api/cost/estimate_pipeline'), {\n                method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(pipeline)\n            });\n            if (!r.ok) {\n                // Fallback to legacy single‑row estimator\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "108095bff37cf7c405599dc814ba2d86"}
{"id": "03169d4352d0", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 21, "imports": [], "code": "                r = await fetch(api('/api/cost/estimate'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(basic) });\n            }\n            const d = await r.json();\n            $('#cost-daily').textContent = `$${Number(d.daily||0).toFixed(4)}`;\n            $('#cost-monthly').textContent = `$${Number(d.monthly||0).toFixed(2)}`;\n        } catch (e) {\n            alert('Cost estimation failed: ' + e.message);\n        }\n    }\n\n    // ---------------- Hardware Scan & Profiles ----------------\n    function formatHardwareScan(data) {\n        if (!data || typeof data !== 'object') return 'No scan data';\n        const info = data.info || {};\n        const rt = data.runtimes || {};\n        const parts = [];\n\n        if (info.os) parts.push(`<div class=\"section\"><span class=\"key\">OS:</span> <span class=\"value\">${info.os}</span></div>`);\n        if (info.cpu_cores) parts.push(`<div class=\"section\"><span class=\"key\">CPU Cores:</span> <span class=\"value\">${info.cpu_cores}</span></div>`);\n        if (info.mem_gb) parts.push(`<div class=\"section\"><span class=\"key\">Memory:</span> <span class=\"value\">${info.mem_gb} GB</span></div>`);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "350b557d21e0ccfbd74f9fe0745bc19c"}
{"id": "fe425dead984", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "        if (info.gpu) parts.push(`<div class=\"section\"><span class=\"key\">GPU:</span> <span class=\"value\">${info.gpu}</span></div>`);\n\n        const activeRuntimes = Object.keys(rt).filter(k => rt[k]);\n        if (activeRuntimes.length) {\n            parts.push(`<div class=\"section\"><span class=\"key\">Runtimes:</span> <span class=\"value\">${activeRuntimes.join(', ')}</span></div>`);\n        }\n\n        return parts.join('');\n    }\n\n    async function scanHardware() {\n        try {\n            const r = await fetch(api('/api/scan-hw'), { method: 'POST' });\n            const d = await r.json();\n            const scanOut = $('#scan-out');\n            scanOut.innerHTML = formatHardwareScan(d);\n            scanOut.dataset.scanData = JSON.stringify(d);\n            updateWizardSummary();\n            return d;\n        } catch (e) {\n            alert('Hardware scan failed: ' + e.message);\n            return null;\n        }\n    }\n\n    function proposeProfile(scan, budget) {\n        // Budget-aware defaults (avoid paid providers at $0)\n        const hasLocal = scan?.runtimes?.ollama || scan?.runtimes?.coreml;\n        const rprov = (Number(budget) === 0) ? (hasLocal ? 'local' : 'none') : 'cohere';\n        const prof = {\n            GEN_MODEL: hasLocal && Number(budget) === 0 ? 'qwen3-coder:14b' : 'gpt-4o-mini',\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "70313e326b7cf73f8541897d016fc314"}
{"id": "8dfdd274a300", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "            EMBEDDING_TYPE: (Number(budget) === 0) ? (hasLocal ? 'local' : 'mxbai') : 'openai',\n            RERANK_BACKEND: rprov,\n            MQ_REWRITES: Number(budget) > 50 ? '6' : '3',\n            TOPK_SPARSE: '75',\n            TOPK_DENSE: '75',\n            FINAL_K: Number(budget) > 50 ? '20' : '10',\n            HYDRATION_MODE: 'lazy',\n        };\n        return prof;\n    }\n\n    function formatProfile(prof) {\n        if (!prof || typeof prof !== 'object') return '(Preview will appear here)';\n        const parts = [];\n\n        const keyGroups = {\n            'Generation': ['GEN_MODEL', 'ENRICH_MODEL', 'ENRICH_MODEL_OLLAMA'],\n            'Embeddings': ['EMBEDDING_TYPE', 'VOYAGE_EMBED_DIM', 'EMBEDDING_DIM'],\n            'Reranking': ['RERANK_BACKEND', 'COHERE_RERANK_MODEL', 'RERANKER_MODEL'],\n            'Retrieval': ['MQ_REWRITES', 'FINAL_K', 'TOPK_SPARSE', 'TOPK_DENSE', 'HYDRATION_MODE'],\n        };\n\n        for (const [group, keys] of Object.entries(keyGroups)) {\n            const groupItems = keys.filter(k => prof[k] !== undefined).map(k =>\n                `<div><span class=\"key\">${k}:</span> <span class=\"value\">${prof[k]}</span></div>`\n            );\n            if (groupItems.length) {\n                parts.push(`<div class=\"section\"><strong style=\"color:#5b9dff;\">${group}</strong>${groupItems.join('')}</div>`);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b099d3d2358c08d1fc3ba1108c8065aa"}
{"id": "3455ad31c7df", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 28, "imports": [], "code": "            }\n        }\n\n        if (prof.__estimate__) {\n            const est = prof.__estimate__;\n            parts.push(`<div class=\"section\"><strong style=\"color:#b794f6;\">Cost Estimate</strong><div><span class=\"key\">Daily:</span> <span class=\"value\">$${Number(est.daily||0).toFixed(4)}</span></div><div><span class=\"key\">Monthly:</span> <span class=\"value\">$${Number(est.monthly||0).toFixed(2)}</span></div></div>`);\n        }\n\n        return parts.join('');\n    }\n\n    async function generateProfileWizard() {\n        let scan = null;\n        const scanOut = $('#scan-out');\n        // Try to extract scan from data attribute or re-scan\n        if (scanOut.dataset.scanData) {\n            try { scan = JSON.parse(scanOut.dataset.scanData); } catch {}\n        }\n        if (!scan) scan = await scanHardware();\n        const budget = parseFloat($('#budget').value || '0');\n        const prof = buildWizardProfile(scan, budget);\n\n        // Try a pipeline cost preview\n        const payload = {\n            gen_provider: ($('#cost-provider')?.value || 'openai').trim(),\n            gen_model: ($('#cost-model')?.value || ($('#wizard-gen-model')?.value || 'gpt-4o-mini')).trim(),\n            tokens_in: parseInt($('#cost-in').value || '0', 10) || 0,\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "47cc5493750947d3c274ef6b40397c92"}
{"id": "9f8ff3d9d6c9", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 28, "imports": [], "code": "            tokens_out: parseInt($('#cost-out').value || '0', 10) || 0,\n            embeds: parseInt($('#cost-embeds').value || '0', 10) || 0,\n            reranks: parseInt($('#cost-rerank').value || '0', 10) || 0,\n            requests_per_day: parseInt($('#cost-rpd').value || '0', 10) || 0,\n        };\n        try {\n            const r = await fetch(api('/api/cost/estimate_pipeline'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });\n            const d = await r.json();\n            prof.__estimate__ = d;\n        } catch {}\n        $('#profile-preview').innerHTML = formatProfile(prof);\n        $('#profile-preview').dataset.profileData = JSON.stringify(prof);\n        updateWizardSummary();\n        return prof;\n    }\n\n    async function applyProfileWizard() {\n        let prof = null;\n        const preview = $('#profile-preview');\n        if (preview.dataset.profileData) {\n            try { prof = JSON.parse(preview.dataset.profileData); } catch {}\n        }\n        if (!prof || typeof prof !== 'object') prof = await generateProfileWizard();\n        // Remove cost estimate from applied profile\n        if (prof.__estimate__) delete prof.__estimate__;\n        try {\n            const r = await fetch(api('/api/profiles/apply'), { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ profile: prof }) });\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "2c2b6bcad6918da9a797b761cb2a6cd3"}
{"id": "8956f66078d5", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 36, "imports": [], "code": "            const d = await r.json();\n            alert(`Profile applied: ${d.applied_keys?.join(', ') || 'ok'}`);\n            await loadConfig();\n        } catch (e) { alert('Failed to apply profile: ' + e.message); }\n    }\n\n    // Tri-Candidate Generation (from docs)\n    function generateCandidates(scan, budget) {\n        const hasLocal = !!(scan?.runtimes?.ollama || scan?.runtimes?.coreml);\n        const mem = (scan?.info?.mem_gb || 8);\n        const budgetNum = Number(budget) || 0;\n\n        // Three baseline candidates\n        const local = {\n            name: 'local',\n            env: {\n                GEN_MODEL: hasLocal ? 'qwen3-coder:14b' : 'gpt-4o-mini',\n                EMBEDDING_TYPE: hasLocal ? 'local' : 'mxbai',\n                RERANK_BACKEND: hasLocal ? 'local' : 'none',\n                MQ_REWRITES: mem >= 32 ? '4' : '3',\n                FINAL_K: mem >= 32 ? '10' : '8',\n                TOPK_DENSE: '60', TOPK_SPARSE: '60', HYDRATION_MODE: 'lazy'\n            }\n        };\n        const cheapCloud = {\n            name: 'cheap_cloud',\n            env: {\n                GEN_MODEL: 'gpt-4o-mini', EMBEDDING_TYPE: 'openai', RERANK_BACKEND: 'local',\n                MQ_REWRITES: budgetNum > 25 ? '4' : '3',\n                FINAL_K: budgetNum > 25 ? '10' : '8',\n                TOPK_DENSE: '75', TOPK_SPARSE: '75', HYDRATION_MODE: 'lazy'\n            }\n        };\n        const premium = {\n            name: 'premium',\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "965783364dcfdb371d58338e51257e54"}
{"id": "a62bb26da79a", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 33, "imports": [], "code": "            env: {\n                GEN_MODEL: 'gpt-4o-mini', EMBEDDING_TYPE: 'openai', RERANK_BACKEND: 'cohere',\n                MQ_REWRITES: budgetNum > 100 ? '6' : '4',\n                FINAL_K: budgetNum > 100 ? '20' : '12',\n                TOPK_DENSE: '120', TOPK_SPARSE: '120', HYDRATION_MODE: 'lazy'\n            }\n        };\n        return [local, cheapCloud, premium];\n    }\n\n    async function triCostSelect() {\n        // Use current Cost panel inputs for tokens and rpd\n        const base = {\n            tokens_in: parseInt($('#cost-in').value || '500', 10),\n            tokens_out: parseInt($('#cost-out').value || '800', 10),\n            embeds: parseInt($('#cost-embeds').value || '0', 10),\n            reranks: parseInt($('#cost-rerank').value || '0', 10),\n            requests_per_day: parseInt($('#cost-rpd').value || '100', 10)\n        };\n        const budget = parseFloat($('#budget').value || '0');\n        const scanOut = $('#scan-out');\n        let scan = null;\n        if (scanOut && scanOut.dataset.scanData) {\n            try { scan = JSON.parse(scanOut.dataset.scanData); } catch {}\n        }\n        if (!scan) scan = await scanHardware();\n\n        const cands = generateCandidates(scan, budget);\n\n        const rows = [];\n        for (const c of cands) {\n            // Decide provider/model from env for cost call\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d004c8e66ea2eb2eac51bb4ec81a01dc"}
{"id": "1903f7200f85", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 37, "imports": [], "code": "            const provider = (c.env.GEN_MODEL || '').match(/:/) ? 'local' : 'openai';\n            const model = c.env.GEN_MODEL || 'gpt-4o-mini';\n            const payload = { provider, model, ...base };\n\n            // local electricity optional if provider==local\n            if (provider === 'local') {\n                const kwh = $('#cost-kwh')?.value;\n                const watts = $('#cost-watts')?.value;\n                const hours = $('#cost-hours')?.value;\n                if (kwh) payload.kwh_rate = parseFloat(kwh);\n                if (watts) payload.watts = parseInt(watts, 10);\n                if (hours) payload.hours_per_day = parseFloat(hours);\n            }\n            // Call cost API\n            const r = await fetch(api('/api/cost/estimate'), {\n                method: 'POST',\n                headers: {'Content-Type':'application/json'},\n                body: JSON.stringify(payload)\n            });\n            const d = await r.json();\n            rows.push({\n                name: c.name,\n                env: c.env,\n                provider,\n                model,\n                daily: d.daily,\n                monthly: d.monthly,\n                breakdown: d.breakdown\n            });\n        }\n\n        // Rank by monthly (ascending), then prefer cheaper that meet budget if budget>0\n        const ranked = rows.sort((a,b) => a.monthly - b.monthly);\n        let winner = ranked[0];\n        if (budget > 0) {\n            const within = ranked.filter(r => r.monthly <= budget);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "1e55a61d5400bc9671c9c4941b238cbf"}
{"id": "a5ded058d6f1", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "            if (within.length) winner = within[within.length - 1]; // Pick most expensive within budget\n        }\n\n        const triOut = $('#tri-out');\n        if (triOut) {\n            const lines = [];\n            ranked.forEach(r => {\n                const mark = r.name === winner.name ? '✓' : ' ';\n                const header = `${mark} ${r.name.toUpperCase().padEnd(15)} $${r.monthly.toFixed(2)}/mo`;\n                lines.push(header);\n                lines.push(`  Inference:  ${r.env.GEN_MODEL || '—'}`);\n                lines.push(`  Embedding:  ${r.env.EMBEDDING_TYPE || '—'}`);\n                lines.push(`  Rerank:     ${r.env.RERANK_BACKEND || 'none'}`);\n                lines.push(`  MQ:${r.env.MQ_REWRITES||'3'}  Final-K:${r.env.FINAL_K||'10'}  Sparse:${r.env.TOPK_SPARSE||'75'}  Dense:${r.env.TOPK_DENSE||'75'}`);\n                lines.push('');\n            });\n            triOut.textContent = lines.join('\\n').trim();\n        }\n\n        return { winner, ranked };\n    }\n\n    async function triChooseAndApply() {\n        const { winner } = await triCostSelect();\n        const r = await fetch(api('/api/profiles/apply'), {\n            method: 'POST',\n            headers: { 'Content-Type':'application/json' },\n            body: JSON.stringify({ profile: winner.env })\n        });\n        if (!r.ok) { alert('Apply failed'); return; }\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6c25f6ad2d5d2f6f8132990ce52606a8"}
{"id": "9b27f61e6ae2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "        alert(`Applied: ${winner.name} ($${winner.monthly.toFixed(2)}/mo)`);\n\n        // Show applied profile in preview\n        $('#profile-preview').innerHTML = formatProfile(winner.env);\n        await loadConfig();\n    }\n\n    // Wizard helpers\n    function buildWizardProfile(scan, budget) {\n        // Legacy single-profile builder (kept for compatibility)\n        const hasLocal = scan?.runtimes?.ollama || scan?.runtimes?.coreml;\n        const budgetNum = Number(budget) || 0;\n        const defaultGen = hasLocal && budgetNum === 0 ? 'qwen3-coder:14b' : 'gpt-4o-mini';\n        const defaultEmb = budgetNum === 0 ? (hasLocal ? 'local' : 'mxbai') : 'openai';\n        const defaultRprov = budgetNum === 0 ? (hasLocal ? 'local' : 'none') : 'cohere';\n\n        const profile = {\n            GEN_MODEL: defaultGen,\n            EMBEDDING_TYPE: defaultEmb,\n            RERANK_BACKEND: defaultRprov,\n            MQ_REWRITES: budgetNum > 50 ? '6' : '3',\n            FINAL_K: budgetNum > 50 ? '20' : '10',\n            TOPK_SPARSE: budgetNum > 50 ? '120' : '75',\n            TOPK_DENSE: budgetNum > 50 ? '120' : '75',\n            HYDRATION_MODE: 'lazy',\n        };\n        return profile;\n    }\n\n    function seedWizardFromEnv(env) {\n        const wzGen = $('#wizard-gen-model');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "79d080aa0f2bb960f425e56066b0a343"}
{"id": "52622a151f2d", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 28, "imports": [], "code": "        if (wzGen && env.GEN_MODEL) wzGen.value = env.GEN_MODEL;\n        const wzEmb = $('#wizard-embed-provider');\n        if (wzEmb && env.EMBEDDING_TYPE) wzEmb.value = env.EMBEDDING_TYPE;\n        const wzRprov = $('#wizard-rerank-provider');\n        if (wzRprov && env.RERANK_BACKEND) wzRprov.value = env.RERANK_BACKEND;\n        const wzRmod = $('#wizard-rerank-model');\n        if (wzRmod && (env.COHERE_RERANK_MODEL || env.RERANKER_MODEL)) wzRmod.value = env.COHERE_RERANK_MODEL || env.RERANKER_MODEL;\n    }\n\n    function loadWizardFromEnv() {\n        const env = (state.config && state.config.env) || {};\n        seedWizardFromEnv(env);\n        updateWizardSummary();\n    }\n\n    function updateWizardSummary() {\n        const scanOut = $('#scan-out');\n        let hw = '';\n        if (scanOut && scanOut.dataset.scanData) {\n            try {\n                const s = JSON.parse(scanOut.dataset.scanData);\n                hw = `${s.info?.cpu_cores||'?'} cores, ${s.info?.mem_gb||'?'} GB RAM, runtimes: ${Object.keys(s.runtimes||{}).filter(k=>s.runtimes[k]).join(', ')||'none'}`;\n            } catch { hw = '(hardware not scanned)'; }\n        } else {\n            hw = '(hardware not scanned)';\n        }\n        const gen = ($('#wizard-gen-model')?.value || '(GEN_MODEL not set)');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "efedd8573729d6364d7a52c46f3e1552"}
{"id": "f4e59979bd14", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 19, "imports": [], "code": "        const emb = ($('#wizard-embed-provider')?.value || (state.config?.env?.EMBEDDING_TYPE || '(use current)'));\n        const rprov = ($('#wizard-rerank-provider')?.value || (state.config?.env?.RERANK_BACKEND || '(use current)'));\n        const rmod = ($('#wizard-rerank-model')?.value || state.config?.env?.COHERE_RERANK_MODEL || state.config?.env?.RERANKER_MODEL || '');\n        const budget = $('#budget')?.value || '0';\n        const line = `Hardware: ${hw}\\nModels: gen=${gen}, emb=${emb}, rerank=${rprov}${rmod?`:${rmod}`:''}\\nBudget: $${budget}/mo`;\n        const el = $('#wizard-summary'); if (el) el.textContent = line;\n    }\n\n    // Keep summary in sync\n    ;['wizard-gen-model','wizard-embed-provider','wizard-rerank-provider','wizard-rerank-model','budget'].forEach(id => {\n        const el = document.getElementById(id); if (el) el.addEventListener('input', updateWizardSummary);\n    });\n\n    async function applyProfile() {\n        const scanText = $('#scan-out').textContent;\n        if (!scanText || scanText === '') {\n            alert('Please scan hardware first');\n            return;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "875d2a2cbd409f37f3644922990909bc"}
{"id": "9b8aabf03519", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 46, "imports": [], "code": "        }\n\n        const scan = JSON.parse(scanText);\n        const budget = parseFloat($('#budget').value || '0');\n        const prof = proposeProfile(scan, budget);\n\n        try {\n            const r = await fetch(api('/api/profiles/apply'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ profile: prof })\n            });\n\n            const d = await r.json();\n            alert(`Profile applied: ${d.applied_keys.join(', ')}`);\n            await loadConfig();\n        } catch (e) {\n            alert('Failed to apply profile: ' + e.message);\n        }\n    }\n\n    async function loadProfiles() {\n        try {\n            const r = await fetch(api('/api/profiles'));\n            const d = await r.json();\n            state.profiles = d.profiles || [];\n            state.defaultProfile = d.default || null;\n\n            const ul = $('#profiles-ul');\n            ul.innerHTML = '';\n            state.profiles.forEach((name) => {\n                const li = document.createElement('li');\n                li.textContent = name;\n                li.style.cssText = 'padding: 4px 0; color: #888;';\n                ul.appendChild(li);\n            });\n        } catch (e) {\n            console.error('Failed to load profiles:', e);\n        }\n    }\n\n    async function saveProfile() {\n        const name = $('#profile-name').value.trim();\n        if (!name) {\n            alert('Enter a profile name');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "05d1048cfa3c1959a22c5362657a5f15"}
{"id": "aacb3e8383bb", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 42, "imports": [], "code": "            return;\n        }\n\n        // Prefer wizard preview if present; otherwise build from scan\n        let prof = null;\n        const preview = $('#profile-preview');\n        if (preview.dataset.profileData) {\n            try { prof = JSON.parse(preview.dataset.profileData); } catch {}\n        }\n        if (!prof) {\n            const scanOut = $('#scan-out');\n            if (!scanOut.dataset.scanData) { alert('Please scan hardware first'); return; }\n            const scan = JSON.parse(scanOut.dataset.scanData);\n            const budget = parseFloat($('#budget').value || '0');\n            prof = proposeProfile(scan, budget);\n        }\n        // Remove cost estimate before saving\n        if (prof.__estimate__) delete prof.__estimate__;\n\n        try {\n            const r = await fetch(api('/api/profiles/save'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ name, profile: prof })\n            });\n\n            if (!r.ok) {\n                alert('Save failed');\n                return;\n            }\n\n            await loadProfiles();\n            alert(`Saved profile: ${name}`);\n        } catch (e) {\n            alert('Failed to save profile: ' + e.message);\n        }\n    }\n\n    // ---------------- Secrets Ingest (Drag & Drop) ----------------\n    function bindDropzone() {\n        const dz = $('#dropzone');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "9c51bb533bf827ac50098a98914659ce"}
{"id": "770b6dde1744", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 53, "imports": [], "code": "        const fi = $('#file-input');\n\n        function openPicker() {\n            fi.click();\n        }\n\n        dz.addEventListener('click', openPicker);\n\n        dz.addEventListener('dragover', (e) => {\n            e.preventDefault();\n            dz.style.background = '#111111';\n        });\n\n        dz.addEventListener('dragleave', (e) => {\n            dz.style.background = '';\n        });\n\n        dz.addEventListener('drop', async (e) => {\n            e.preventDefault();\n            dz.style.background = '';\n            const file = e.dataTransfer.files?.[0];\n            if (file) await ingestFile(file);\n        });\n\n        fi.addEventListener('change', async (e) => {\n            const file = e.target.files?.[0];\n            if (file) await ingestFile(file);\n            fi.value = '';\n        });\n    }\n\n    async function ingestFile(file) {\n        const persist = $('#persist-secrets').checked;\n        const fd = new FormData();\n        fd.append('file', file);\n        fd.append('persist', String(persist));\n\n        try {\n            const r = await fetch(api('/api/secrets/ingest'), {\n                method: 'POST',\n                body: fd\n            });\n\n            const d = await r.json();\n            $('#ingest-out').textContent = JSON.stringify(d, null, 2);\n            await loadConfig();\n        } catch (e) {\n            alert('Secrets ingest failed: ' + e.message);\n        }\n    }\n\n    // ---------------- Bindings ----------------\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "92b5a33619aba43e9b1fadd2bc63f7b3"}
{"id": "bd4973c6a117", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 14, "imports": [], "code": "    function bindActions() {\n        const btnHealth = $('#btn-health'); if (btnHealth) btnHealth.addEventListener('click', checkHealth);\n        const saveBtn = $('#save-btn'); if (saveBtn) saveBtn.addEventListener('click', saveConfig);\n        const btnEstimate = $('#btn-estimate'); if (btnEstimate) btnEstimate.addEventListener('click', estimateCost);\n        const btnScanHw = $('#btn-scan-hw'); if (btnScanHw) btnScanHw.addEventListener('click', scanHardware);\n        const legacyApply = document.getElementById('btn-apply-profile');\n        if (legacyApply) legacyApply.addEventListener('click', applyProfile);\n        const btnSaveProfile = $('#btn-save-profile'); if (btnSaveProfile) btnSaveProfile.addEventListener('click', saveProfile);\n        const genBtn = document.getElementById('btn-generate-profile');\n        if (genBtn) genBtn.addEventListener('click', generateProfileWizard);\n        const applyWizard = document.getElementById('btn-apply-wizard');\n        if (applyWizard) applyWizard.addEventListener('click', applyProfileWizard);\n        const oneClick = document.getElementById('btn-wizard-oneclick');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "bf643407b718df38d33d5d65ebfcf526"}
{"id": "3d534f2c4281", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 18, "imports": [], "code": "        if (oneClick) oneClick.addEventListener('click', triChooseAndApply);\n        const loadCur = document.getElementById('btn-wizard-load-cur');\n        if (loadCur) loadCur.addEventListener('click', loadWizardFromEnv);\n\n        const addGen = document.getElementById('btn-add-gen-model');\n        if (addGen) addGen.addEventListener('click', addGenModelFlow);\n        const addEmb = document.getElementById('btn-add-embed-model');\n        if (addEmb) addEmb.addEventListener('click', addEmbedModelFlow);\n        const addRr = document.getElementById('btn-add-rerank-model');\n        if (addRr) addRr.addEventListener('click', addRerankModelFlow);\n        const addCost = document.getElementById('btn-add-cost-model');\n        if (addCost) addCost.addEventListener('click', addCostModelFlow);\n\n        const btnAuto = document.getElementById('btn-autotune-refresh');\n        if (btnAuto) btnAuto.addEventListener('click', refreshAutotune);\n        const cbAuto = document.getElementById('autotune-enabled');\n        if (cbAuto) cbAuto.addEventListener('change', setAutotuneEnabled);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ff2bfbd0c2458d526ae5bf1cf177616d"}
{"id": "24d0c9c6613c", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 19, "imports": [], "code": "\n        const btnIndex = document.getElementById('btn-index-start');\n        if (btnIndex) btnIndex.addEventListener('click', startIndexing);\n        const btnCardsBuild = document.getElementById('btn-cards-build');\n        if (btnCardsBuild) btnCardsBuild.addEventListener('click', buildCards);\n        const btnCardsRefresh = document.getElementById('btn-cards-refresh');\n        if (btnCardsRefresh) btnCardsRefresh.addEventListener('click', refreshCards);\n        // Dashboard button bindings\n        const dashIndex = document.getElementById('dash-index-start');\n        if (dashIndex) dashIndex.addEventListener('click', startIndexing);\n        const dashCardsBuild = document.getElementById('dash-cards-build');\n        if (dashCardsBuild) dashCardsBuild.addEventListener('click', buildCards);\n        const dashCardsRefresh = document.getElementById('dash-cards-refresh');\n        if (dashCardsRefresh) dashCardsRefresh.addEventListener('click', refreshCards);\n        // Keep cost panel in sync with wizard selections\n        const map = [\n            ['wizard-gen-model','cost-model'],\n            ['wizard-embed-provider','cost-embed-provider'],\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6517b4ad2d63edaef8f199212c37c45d"}
{"id": "36aa924091c6", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 38, "imports": [], "code": "            ['wizard-rerank-provider','cost-rerank-provider'],\n            ['wizard-rerank-model','cost-rerank-model'],\n        ];\n        map.forEach(([a,b]) => { const elA = document.getElementById(a), elB = document.getElementById(b); if (elA && elB) elA.addEventListener('input', () => { elB.value = elA.value; }); });\n    }\n\n    // ---------------- Init ----------------\n    async function init() {\n        bindTabs();\n        bindActions();\n        bindGlobalSearchLive();\n        bindDropzone();\n\n        await Promise.all([\n            loadPrices(),\n            loadConfig(),\n            loadProfiles(),\n            loadKeywords()\n        ]);\n\n        await checkHealth();\n        await refreshAutotune();\n        await refreshDashboard();\n        addHelpTooltips();\n        // Note: comma formatting removed for cost-* fields since they are type=\"number\" inputs\n        wireDayConverters();\n    }\n\n    window.addEventListener('DOMContentLoaded', init);\n\n    // ---------------- Global Search (live) ----------------\n    function bindGlobalSearchLive() {\n        const box = document.getElementById('global-search');\n        if (!box) return;\n        const pop = document.getElementById('search-results');\n        let index = [];\n        let items = []; let cursor = -1;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c50a71ff9850753f851c62bb4200a700"}
{"id": "eb0ec49c1303", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 21, "imports": [], "code": "        function ensureIndex(){\n            if (index.length) return index;\n            const idx=[];\n            $$('.settings-section').forEach(sec=>{\n                const title = (sec.querySelector('h3')?.textContent||'').toLowerCase();\n                sec.querySelectorAll('.input-group').forEach(g=>{\n                    const label=(g.querySelector('label')?.textContent||'').trim();\n                    const input=g.querySelector('input,select,textarea');\n                    if (!input) return;\n                    const name=input.name||input.id||''; const ph=input.getAttribute('placeholder')||'';\n                    const content=(title+' '+label+' '+name+' '+ph).toLowerCase();\n                    idx.push({label: `${label||name} — ${title}`, el: input, content});\n                });\n            });\n            index = idx; return idx;\n        }\n        function sectionGroupFor(el){\n            const tc = el.closest('.tab-content'); if (!tc) return 'dashboard';\n            const id = tc.id.replace('tab-','');\n            const map = { generation:'models', embeddings:'models', reranking:'models', retrieval:'retrieval', confidence:'retrieval', cards:'retrieval', repos:'repos', indexing:'repos', infra:'infra', calculator:'tools', eval:'tools', misc:'tools', dashboard:'dashboard' };\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d50e54c52bd9af5db771f73f297d4069"}
{"id": "64d279fd5c90", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 24, "imports": [], "code": "            return map[id] || id;\n        }\n        function go(item){\n            const tab = sectionGroupFor(item.el); switchTab(tab);\n            item.el.classList.add('search-hit'); item.el.scrollIntoView({behavior:'smooth', block:'center'});\n            setTimeout(()=> item.el.classList.remove('search-hit'), 1200);\n            if (pop) pop.style.display='none';\n        }\n        function render(){\n            if (!pop) return; pop.innerHTML='';\n            if (!items.length){ pop.style.display='none'; return; }\n            items.slice(0,12).forEach((r,i)=>{\n                const div=document.createElement('div'); div.className='item'+(i===cursor?' active':'');\n                div.textContent=r.label; div.addEventListener('click',()=>go(r)); pop.appendChild(div);\n            });\n            pop.style.display='block';\n        }\n        function search(q){\n            const s=q.trim().toLowerCase(); if(!s){ items=[]; render(); return; }\n            ensureIndex(); items = index.filter(x=> x.content.includes(s)); cursor=0; render();\n        }\n        document.addEventListener('click', (e)=>{ if (pop && !pop.contains(e.target) && e.target!==box) pop.style.display='none'; });\n        box.addEventListener('keydown', (e)=>{ if ((e.ctrlKey||e.metaKey) && e.key.toLowerCase()==='k'){ e.preventDefault(); box.focus(); box.select(); }});\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "44bc63b37c11cd1d3242a077d3502203"}
{"id": "9513040d86fc", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "        box.addEventListener('input', ()=> search(box.value));\n        box.addEventListener('keydown', (e)=>{\n            if (!pop || pop.style.display!=='block') return;\n            if (e.key==='ArrowDown'){ e.preventDefault(); cursor=Math.min(cursor+1, items.length-1); render(); }\n            else if (e.key==='ArrowUp'){ e.preventDefault(); cursor=Math.max(cursor-1,0); render(); }\n            else if (e.key==='Enter'){ e.preventDefault(); if(items[cursor]) go(items[cursor]); }\n        });\n    }\n\n    // ---------------- Autotune ----------------\n    async function refreshAutotune() {\n        try {\n            const r = await fetch(api('/api/autotune/status'));\n            if (!r.ok) {\n                if (r.status === 403 || r.status === 402) {\n                    $('#autotune-mode').textContent = 'Pro required (set Edition to pro)';\n                } else {\n                    $('#autotune-mode').textContent = '—';\n                }\n                $('#autotune-enabled').checked = false;\n                return;\n            }\n            const d = await r.json();\n            $('#autotune-enabled').checked = !!d.enabled;\n            $('#autotune-mode').textContent = d.current_mode || '—';\n        } catch (e) {\n            $('#autotune-mode').textContent = '—';\n        }\n    }\n\n    // ---------------- Dashboard Summary ----------------\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b3b86f42540be43c972e921907de525d"}
{"id": "e5e8dbad55c3", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 22, "imports": [], "code": "    async function refreshDashboard() {\n        try {\n            const c = state.config || (await (await fetch(api('/api/config'))).json());\n            const repo = (c.env && (c.env.REPO || c.default_repo)) || '(none)';\n            const reposCount = (c.repos || []).length;\n            const dr = document.getElementById('dash-repo'); if (dr) dr.textContent = `${repo} (${reposCount} repos)`;\n        } catch {}\n\n        try {\n            const h = await (await fetch(api('/health'))).json();\n            const dh = document.getElementById('dash-health'); if (dh) dh.textContent = `${h.status}${h.graph_loaded? ' (graph ready)':''}`;\n        } catch {}\n\n        try {\n            const a = await (await fetch(api('/api/autotune/status'))).json();\n            const da = document.getElementById('dash-autotune'); if (da) da.textContent = a.enabled ? (a.current_mode || 'enabled') : 'disabled';\n        } catch { const da = document.getElementById('dash-autotune'); if (da) da.textContent = 'Pro required'; }\n\n        try {\n            const cards = await (await fetch(api('/api/cards'))).json();\n            const dc = document.getElementById('dash-cards'); if (dc) dc.textContent = `${cards.count || 0} cards`;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "b9828662f5960f88e55a6991e6974f2d"}
{"id": "3f38f55ecbd8", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 25, "imports": [], "code": "        } catch {}\n\n        try {\n            const env = (state.config && state.config.env) || {};\n            const host = env.MCP_HTTP_HOST || '0.0.0.0';\n            const port = env.MCP_HTTP_PORT || '8013';\n            const path = env.MCP_HTTP_PATH || '/mcp';\n            const dm = document.getElementById('dash-mcp'); if (dm) dm.textContent = `${host}:${port}${path}`;\n        } catch {}\n    }\n\n    // ---------------- Help Tooltips ----------------\n    function addHelpTooltips() {\n        const HELP = {\n            // Generation\n            GEN_MODEL: 'Primary inference model for generation (e.g., gpt-4o-mini or qwen3-coder:14b).',\n            OPENAI_API_KEY: 'API key for OpenAI-compatible endpoints (generation/embeddings).',\n            OPENAI_BASE_URL: 'Optional OpenAI-compatible base URL (vLLM/proxy).',\n            OLLAMA_URL: 'Local model endpoint (Ollama or MLX serve).',\n            ENRICH_MODEL: 'Model used to enrich code chunks before embedding (text summaries).',\n            ENRICH_MODEL_OLLAMA: 'Local enrich model for Ollama/MLX.',\n            GEN_MODEL_HTTP: 'Override GEN_MODEL for HTTP server responses only.',\n            GEN_MODEL_MCP: 'Override GEN_MODEL for MCP tool responses only.',\n            GEN_MODEL_CLI: 'Override GEN_MODEL for CLI chat only.',\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "60880303cd5b3a125812e81879076ded"}
{"id": "f5a3ef96adb2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 21, "imports": [], "code": "            ENRICH_BACKEND: 'Force enrich backend (mlx or ollama).',\n\n            // Embeddings\n            EMBEDDING_TYPE: 'Embedding provider for dense vector search (openai, voyage, mxbai, local).',\n            VOYAGE_API_KEY: 'API key for Voyage embeddings.',\n            VOYAGE_EMBED_DIM: 'Output dimension for Voyage embeddings.',\n            EMBEDDING_DIM: 'Embedding dimension for MXBAI/local models.',\n            SKIP_DENSE: 'If 1, skip building dense vectors/Qdrant (sparse-only).',\n            ENRICH_CODE_CHUNKS: 'If true, store per-chunk summaries/keywords before embedding.',\n\n            // Reranking\n            RERANK_BACKEND: 'Cross-encoder reranking backend: local, hf, cohere, or none.',\n            RERANKER_MODEL: 'Local/HF cross-encoder model (e.g., BAAI/bge-reranker-v2-m3).',\n            COHERE_API_KEY: 'API key for Cohere reranking.',\n            COHERE_RERANK_MODEL: 'Cohere reranker model (e.g., rerank-3.5).',\n            TRANSFORMERS_TRUST_REMOTE_CODE: 'Allow HF models that require remote code.',\n\n            // Retrieval\n            MQ_REWRITES: 'Multi-query expansion count (more rewrites → better recall, more cost).',\n            FINAL_K: 'Final top-K after fusion + rerank (downstream consumers use these).',\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "815f690907d9ffdae8766c14a5d09818"}
{"id": "baf872bd3d76", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 20, "imports": [], "code": "            TOPK_DENSE: 'Number of dense candidates (Qdrant) to fuse.',\n            TOPK_SPARSE: 'Number of sparse candidates (BM25) to fuse.',\n            HYDRATION_MODE: 'lazy: hydrate code snippets on demand; none: skip hydration.',\n            HYDRATION_MAX_CHARS: 'Max characters per hydrated code snippet.',\n            VENDOR_MODE: 'Prefer first-party or vendor paths when scoring files.',\n            project_PATH_BOOSTS: 'CSV of path substrings to boost (e.g., app/,lib/,config/).',\n            CARDS_MAX: 'Limit number of cards used for boosting (0 = all).',\n\n            // Confidence\n            CONF_TOP1: 'Accept answer if top-1 rerank score exceeds this threshold.',\n            CONF_AVG5: 'Accept if average of top-5 rerank scores exceeds this threshold.',\n            CONF_ANY: 'Accept if overall confidence exceeds this fallback threshold.',\n\n            // Infra\n            QDRANT_URL: 'Qdrant endpoint for vector search.',\n            REDIS_URL: 'Redis for LangGraph memory/checkpointer.',\n            REPO: 'Active repository tag for routing and output directories.',\n            COLLECTION_SUFFIX: 'Optional suffix to group collections in Qdrant.',\n            COLLECTION_NAME: 'Override Qdrant collection name.',\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "505efd7e89de1eb827efbeef8f89a8f7"}
{"id": "9c81aa4214d6", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 21, "imports": [], "code": "            REPO_PATH: 'Fallback path when repos.json is absent.',\n            REPOS_FILE: 'Path to repos.json configuration file.',\n            OUT_DIR_BASE: 'Base output directory for per-repo data.',\n            RAG_OUT_BASE: 'Alternate env for OUT_DIR_BASE.',\n            MCP_HTTP_HOST: 'Host for MCP HTTP server.',\n            MCP_HTTP_PORT: 'Port for MCP HTTP server.',\n            MCP_HTTP_PATH: 'Path prefix for MCP HTTP server.',\n\n            // Misc\n            AGRO_EDITION: 'Edition gate (oss, pro, enterprise). Pro/Enterprise unlock Autotune/Compat.',\n            THREAD_ID: 'LangGraph thread id (http or cli-chat).',\n            PORT: 'Uvicorn port for serve entrypoints.',\n            PROJECT_PATH: 'Optional reference path used by some helpers.',\n            LANGCHAIN_TRACING_V2: 'Enable tracing for LangChain-compatible tooling.',\n            LANGCHAIN_PROJECT: 'Tracing project name.',\n            NETLIFY_API_KEY: 'Key for Netlify actions (if used).',\n            NETLIFY_DOMAINS: 'Comma-separated domains for Netlify deploy (if used).',\n        };\n        $$('.settings-section .input-group').forEach(g=>{\n            const label = g.querySelector('label'); const input = g.querySelector('input,select,textarea');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "cc69514b6d42ddfe99ffef9c0e1536c6"}
{"id": "1779ec992371", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 13, "imports": [], "code": "            if (!label || !input) return; const key = input.name || input.id; const help = HELP[key];\n            if (!help) return; if (label.querySelector('.help')) return;\n            const tip = document.createElement('span'); tip.className='help'; tip.title = help; tip.textContent='?';\n            label.appendChild(tip);\n        });\n    }\n\n    // ---------- Numbers formatting + per‑day converters ----------\n    function getNum(id){ const v=document.getElementById(id); if (!v) return 0; return parseInt((v.value||'').toString().replace(/,/g,'').replace(/\\s/g,''),10)||0; }\n    function setNum(id, n){ const el=document.getElementById(id); if (!el) return; el.value = (Number(n)||0).toLocaleString('en-US'); }\n    function attachCommaFormatting(ids){ ids.forEach(id=>{ const el=document.getElementById(id); if(!el) return; el.addEventListener('focus',()=>{ el.value = el.value.replace(/,/g,''); }); el.addEventListener('blur',()=>{ const num=getNum(id); if(num >= 0) el.value = num.toLocaleString('en-US'); }); }); }\n    function wireDayConverters(){ const recalc=()=>{ const rpd=getNum('cost-rpd'); const inDay=getNum('cost-in-day'); const outDay=getNum('cost-out-day'); if(rpd>0){ if(inDay>0) setNum('cost-in', Math.floor(inDay/rpd)); if(outDay>0) setNum('cost-out', Math.floor(outDay/rpd)); } }; ['cost-in-day','cost-out-day','cost-rpd'].forEach(id=>{ const el=document.getElementById(id); if(el) el.addEventListener('input', recalc); }); recalc(); }\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "60cff8292e77fc1f30e93a5519757a99"}
{"id": "fbf8192bbe2a", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 37, "imports": [], "code": "\n    async function setAutotuneEnabled() {\n        try {\n            const enabled = document.getElementById('autotune-enabled').checked;\n            const r = await fetch(api('/api/autotune/status'), {\n                method: 'POST', headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ enabled, current_mode: null })\n            });\n            if (!r.ok) {\n                if (r.status === 403 || r.status === 402) {\n                    alert('Autotune is a Pro feature. Enable it by setting Edition to \"pro\" (Misc section) or PRO_ENABLED=1.');\n                    $('#autotune-enabled').checked = false;\n                    return;\n                }\n                throw new Error('HTTP ' + r.status);\n            }\n            await refreshAutotune();\n        } catch (e) {\n            alert('Failed to set Auto‑Tune: ' + e.message);\n        }\n    }\n\n    // ---------------- Keywords ----------------\n    async function loadKeywords() {\n        try {\n            const r = await fetch(api('/api/keywords'));\n            const d = await r.json();\n            state.keywordsCatalog = d;\n            const list = document.getElementById('keywords-list');\n            if (list) {\n                list.innerHTML = '';\n                (d.keywords || []).forEach(k => {\n                    const opt = document.createElement('option'); opt.value = k; list.appendChild(opt);\n                });\n            }\n            const kc = document.getElementById('keywords-count');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "4907b1339282654cb7998f6b565b155b"}
{"id": "2cd60b2f4474", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 20, "imports": [], "code": "            if (kc) kc.textContent = String((d.keywords||[]).length);\n            // repaint per-repo managers if present\n            ($$('#repos-section > div') || []).forEach(div => {\n                const srcSel = div.querySelector('[id^=\"kw-src-\"]');\n                const filter = div.querySelector('[id^=\"kw-filter-\"]');\n                const allSel = div.querySelector('[id^=\"kw-all-\"]');\n                const fld = div.querySelector('[name^=\"repo_keywords_\"]');\n                if (srcSel && filter && allSel && fld) {\n                    const cat = (srcSel.value||'all');\n                    const catMap = d; let base = cat==='all' ? (d.keywords||[]) : (d[cat]||[]);\n                    const f=(filter.value||'').toLowerCase(); const inRepo=new Set((fld.value||'').split(',').map(s=>s.trim()).filter(Boolean));\n                    allSel.innerHTML=''; base.filter(k=>!inRepo.has(k)&&(!f||k.toLowerCase().includes(f))).slice(0,500).forEach(k=>{const o=document.createElement('option');o.value=k;o.textContent=k;allSel.appendChild(o);});\n                }\n            });\n        } catch (e) { console.warn('keywords load failed', e); }\n    }\n\n    // ---------------- Indexing + Cards ----------------\n    let indexPoll = null;\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "2c9a8293fe58736198cd3ce345029eeb"}
{"id": "6dfe9ec84f1d", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 31, "imports": [], "code": "    function progressFromLog(lines) {\n        const text = (lines||[]).join(' ');\n        let pct = 5;\n        if (/Prepared \\d+ chunks/i.test(text)) pct = 20;\n        if (/BM25 index saved/i.test(text)) pct = 60;\n        if (/Indexed \\d+ chunks to Qdrant/i.test(text)) pct = 100;\n        return pct;\n    }\n\n    async function startIndexing() {\n        try {\n            await fetch(api('/api/index/start'), { method: 'POST' });\n            if (indexPoll) clearInterval(indexPoll);\n            indexPoll = setInterval(pollIndexStatus, 800);\n            await pollIndexStatus();\n        } catch (e) { alert('Failed to start index: ' + e.message); }\n    }\n\n    function formatIndexStatus(lines) {\n        if (!lines || !lines.length) return 'Ready to index...';\n        const text = lines.join('\\n');\n        const parts = [];\n\n        // Extract key info from log lines\n        if (/Prepared (\\d+) chunks/i.test(text)) {\n            const m = text.match(/Prepared (\\d+) chunks/i);\n            parts.push(`<div class=\"section\"><span class=\"key\">Chunks prepared:</span> <span class=\"value\">${m[1]}</span></div>`);\n        }\n        if (/BM25 index saved/i.test(text)) {\n            parts.push(`<div class=\"section\"><span class=\"key\">BM25 index:</span> <span class=\"value\">✓ Saved</span></div>`);\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "6252714a57a7ef947383708f1674cb8f"}
{"id": "400c015a48a2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "        }\n        if (/Indexed (\\d+) chunks to Qdrant/i.test(text)) {\n            const m = text.match(/Indexed (\\d+) chunks to Qdrant/i);\n            parts.push(`<div class=\"section\"><span class=\"key\">Vector index:</span> <span class=\"value\">✓ ${m[1]} chunks</span></div>`);\n        }\n\n        if (parts.length === 0) {\n            // Show last few lines if no structured info\n            return `<div style=\"color:#aaa;\">${text.split('\\n').slice(-3).join('<br>')}</div>`;\n        }\n\n        return parts.join('');\n    }\n\n    async function pollIndexStatus() {\n        try {\n            const r = await fetch(api('/api/index/status'));\n            const d = await r.json();\n            const box1 = document.getElementById('index-status');\n            const bar1 = document.getElementById('index-bar');\n            const box2 = document.getElementById('dash-index-status');\n            const bar2 = document.getElementById('dash-index-bar');\n            const formatted = formatIndexStatus(d.lines);\n            const pct = progressFromLog(d.lines);\n            if (box1) box1.innerHTML = formatted;\n            if (bar1) bar1.style.width = pct + '%';\n            if (box2) box2.innerHTML = formatted;\n            if (bar2) bar2.style.width = pct + '%';\n            if (!d.running && indexPoll) { clearInterval(indexPoll); indexPoll = null; }\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5a7a80617bdf28dd5c8a8b11b850574e"}
{"id": "bdc4bed551e2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 30, "imports": [], "code": "        } catch (e) { /* ignore */ }\n    }\n\n    async function buildCards() {\n        try { await fetch(api('/api/cards/build'), { method: 'POST' }); await refreshCards(); }\n        catch (e) { alert('Failed to build cards: ' + e.message); }\n    }\n\n    async function refreshCards() {\n        try {\n            const r = await fetch(api('/api/cards'));\n            const d = await r.json();\n            const el = document.getElementById('cards-list');\n            if (!el) return;\n            el.innerHTML = '';\n            if (!d.cards || d.cards.length === 0) { el.textContent = 'No cards found.'; return; }\n            d.cards.forEach(c => {\n                const div = document.createElement('div');\n                div.style.cssText = 'border-bottom:1px solid #1a1a1a; padding:6px 2px;';\n                div.innerHTML = `<div style=\"color:#00ff88;\">${c.title || '(untitled)'}<\\/div><div class=\"small\">${c.path || ''}<\\/div><div class=\"mono\" style=\"white-space:pre-wrap;\">${(c.summary||'').slice(0,240)}<\\/div>`;\n                el.appendChild(div);\n            });\n        } catch (e) { console.warn('cards refresh failed', e); }\n    }\n\n    // ---------------- Add Model Flows ----------------\n    async function updateEnv(envUpdates) {\n        try {\n            await fetch(api('/api/config'), {\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "c2e7bf4567b2e9435eb4431b288b3b85"}
{"id": "1609572dd4e7", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 40, "imports": [], "code": "                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ env: envUpdates, repos: [] })\n            });\n        } catch (e) {\n            alert('Failed to update config: ' + e.message);\n        }\n    }\n\n    async function upsertPrice(entry) {\n        try {\n            await fetch(api('/api/prices/upsert'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify(entry)\n            });\n        } catch (e) {\n            console.warn('Price upsert failed:', e);\n        }\n    }\n\n    function promptStr(msg, defVal = '') {\n        const v = window.prompt(msg, defVal);\n        return v === null ? null : v.trim();\n    }\n\n    async function addGenModelFlow() {\n        const provider = promptStr('Provider (openai, anthropic, google, local)', 'openai');\n        if (!provider) return;\n        const model = promptStr('Model ID (e.g., gpt-4o-mini or qwen3-coder:14b)', 'gpt-4o-mini');\n        if (!model) return;\n        const baseUrl = promptStr('Base URL (optional; for proxies or local, e.g., http://127.0.0.1:11434)', '');\n        let apiKey = '';\n        if (provider !== 'local') {\n            apiKey = promptStr('API Key (optional; shown locally only)', '') || '';\n        }\n\n        // Update env\n        const env = { GEN_MODEL: model };\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "ec927390f03ae171cfe75f9c078cb27c"}
{"id": "c9e98a83edd2", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 29, "imports": [], "code": "        if (provider === 'openai') {\n            if (apiKey) env.OPENAI_API_KEY = apiKey;\n            if (baseUrl) env.OPENAI_BASE_URL = baseUrl;\n        } else if (provider === 'anthropic') {\n            if (apiKey) env.ANTHROPIC_API_KEY = apiKey;\n        } else if (provider === 'google') {\n            if (apiKey) env.GOOGLE_API_KEY = apiKey;\n        } else if (provider === 'local') {\n            if (baseUrl) env.OLLAMA_URL = baseUrl;\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        // Price entry (scaffold)\n        const entry = { provider, model, family: 'gen', base_url: baseUrl || undefined };\n        if (provider === 'local') entry.unit = 'request'; else entry.unit = '1k_tokens';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Generation model added.');\n    }\n\n    async function addEmbedModelFlow() {\n        const provider = promptStr('Embedding provider (openai, voyage, local, mxbai)', 'openai');\n        if (!provider) return;\n        const model = promptStr('Embedding model ID (optional; depends on provider)', provider === 'openai' ? 'text-embedding-3-small' : '');\n        const baseUrl = promptStr('Base URL (optional)', '');\n        let apiKey = '';\n        if (provider !== 'local' && provider !== 'mxbai') {\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "d55529b18c1726d5c8775511e4f68631"}
{"id": "b3f505559d16", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 32, "imports": [], "code": "            apiKey = promptStr('API Key (optional)', '') || '';\n        }\n\n        const env = {};\n        if (provider === 'openai') {\n            env.EMBEDDING_TYPE = 'openai';\n            if (apiKey) env.OPENAI_API_KEY = apiKey;\n            if (baseUrl) env.OPENAI_BASE_URL = baseUrl;\n        } else if (provider === 'voyage') {\n            env.EMBEDDING_TYPE = 'voyage';\n            if (apiKey) env.VOYAGE_API_KEY = apiKey;\n        } else if (provider === 'mxbai') {\n            env.EMBEDDING_TYPE = 'mxbai';\n        } else if (provider === 'local') {\n            env.EMBEDDING_TYPE = 'local';\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        const entry = { provider, model: model || provider + '-embed', family: 'embed', base_url: baseUrl || undefined };\n        entry.unit = '1k_tokens';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Embedding model added.');\n    }\n\n    async function addRerankModelFlow() {\n        const provider = promptStr('Rerank provider (cohere, local, hf)', 'cohere');\n        if (!provider) return;\n        let model = promptStr('Rerank model ID (e.g., rerank-3.5 or BAAI/bge-reranker-v2-m3)', provider === 'cohere' ? 'rerank-3.5' : 'BAAI/bge-reranker-v2-m3');\n        const baseUrl = promptStr('Base URL (optional)', '');\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "22b9878a815a20b92f7c5850a361d1c7"}
{"id": "bde13d0f4e03", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 35, "imports": [], "code": "        let apiKey = '';\n        if (provider === 'cohere') {\n            apiKey = promptStr('Cohere API Key (optional)', '') || '';\n        }\n\n        const env = {};\n        if (provider === 'cohere') {\n            env.RERANK_BACKEND = 'cohere';\n            env.COHERE_RERANK_MODEL = model;\n            if (apiKey) env.COHERE_API_KEY = apiKey;\n        } else if (provider === 'local') {\n            env.RERANK_BACKEND = 'local';\n            env.RERANKER_MODEL = model;\n        } else if (provider === 'hf') {\n            env.RERANK_BACKEND = 'hf';\n            env.RERANKER_MODEL = model;\n        }\n        await updateEnv(env);\n        await loadConfig();\n\n        const entry = { provider, model, family: 'rerank', base_url: baseUrl || undefined };\n        entry.unit = provider === 'cohere' ? '1k_tokens' : 'request';\n        await upsertPrice(entry);\n        await loadPrices();\n        alert('Rerank model added.');\n    }\n\n    async function addCostModelFlow() {\n        const provider = promptStr('Provider', 'openai');\n        if (!provider) return;\n        const model = promptStr('Model ID', 'gpt-4o-mini');\n        if (!model) return;\n        const baseUrl = promptStr('Base URL (optional)', '');\n        const unit = promptStr('Unit (1k_tokens or request)', provider === 'local' ? 'request' : '1k_tokens') || '1k_tokens';\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "3cf512cb255f79d5767651a7ae9a59b9"}
{"id": "556ce11d797a", "file_path": "/Users/davidmontgomery/agro/gui/app.js", "language": "javascript", "type": "blob", "name": null, "start_line": 1, "end_line": 6, "imports": [], "code": "        await upsertPrice({ provider, model, family: 'misc', base_url: baseUrl || undefined, unit });\n        await loadPrices();\n        alert('Model added to pricing catalog.');\n    }\n})();\n", "repo": "agro", "layer": "server", "origin": "first_party", "hash": "5a262422effcec990a4ef2d51087f53e"}
