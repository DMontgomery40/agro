{"query": "Where is OAuth token validated?", "positive_text": "    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// SSE proxy for streaming answer\napp.get('/mcp/answer_stream', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer_stream', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.sear", "positive_doc_id": "/Users/davidmontgomery/agro/node_mcp/server.js:1-36", "negative_texts": ["3. **Respect repo boundaries.** Never fuse PROJECT and PROJECT.\n4. **Borderline confidence:** present best citations and ask concise follow-ups.\n5. **Security:** never surface PHI or secrets; redact before emitting.\n\n---\n\n## Evaluation & Quality\n\n### Golden tests (golden.json):\n\n```json\n{ \"q\": \"Where is OAuth token validated?\", \"repo\": \"project\", \"expect_paths\": [\"identity\", \"auth\", \"oauth\", \"token\"] }\n```\n\nSubstring match on `expect_paths` counts as a hit.\n\nExpand golden set when agents miss or", "# Claude Code Alone vs Claude Code + RAG\n\n![Evals](../assets/evals.png)\n\n**Bottom line: RAG saves 91% tokens. That means 11x more queries before hitting your Claude rate limits.**\n\n**📊 [Contributing benchmarks](CONTRIBUTING.md)** - Help us test with different Claude models & tiers!\n\n---\n\n## The Comparison\n\n**Date:** 2025-10-08\n**Query:** \"Where is OAuth processed in this repo, and which plugins must validate with it?\" (large repo of mine, thought it was decent baseline quesstion)\n**Claude:** Son", "  \"citations\": [\n    \"auth/middleware.py:45-67\",\n    \"server/auth.py:120-145\"\n  ],\n  \"repo\": \"agro\",\n  \"confidence\": 0.78,\n  \"retrieval_count\": 5\n}\n```\n\n**Example:**\n```bash\ncurl \"http://127.0.0.1:8012/answer?q=Where%20is%20OAuth%20validated&repo=agro\"\n```\n\n---\n\n### GET `/search`\n\nRetrieval only (no generation). Returns ranked code chunks with rerank scores.\n\n**Query Parameters:**\n- `q` (string, required) - Search query\n- `repo` (string, optional) - Repository name\n- `top_k` (integer, optional) ", "from common.paths import *  # noqa: F401,F403\n\n"], "negative_doc_ids": ["/Users/davidmontgomery/agro/CLAUDE.md:1-41", "/Users/davidmontgomery/agro/docs/PERFORMANCE_AND_COST.md:1-31", "/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-60", "/Users/davidmontgomery/agro/path_config.py:1-3"], "source": "golden.json"}
{"query": "Where is the mcp server?", "positive_text": "    const headers = token ? { Authorization: `Bearer ${token}` } : {};\n    const r = await fetch(u.toString(), { headers });\n    const data = await r.json();\n    res.json(data);\n  } catch (e) {\n    res.status(500).json({ error: String(e) });\n  }\n});\n\n// SSE proxy for streaming answer\napp.get('/mcp/answer_stream', async (req, res) => {\n  try {\n    const { q, repo, token } = req.query;\n    const u = new URL('/answer_stream', RAG_API_URL);\n    if (q) u.searchParams.set('q', q);\n    if (repo) u.sear", "positive_doc_id": "/Users/davidmontgomery/agro/node_mcp/server.js:1-36", "negative_texts": ["\nOutputs: `out/{repo}/chunks.jsonl`, `out/{repo}/bm25_idx/`, optional `out/{repo}/cards.jsonl`.\n\n### Hybrid search (hybrid_search.py)\n\nIntent classification (ui/server/integration/sdk/infra) → per-repo layer bonuses.\n\nMulti-query expansion (defaults enabled; count configurable).\n\nBM25 + vector fusion → cross-encoder rerank → local hydration of code.\n\nReturns top-K with `rerank_score`, `file_path`, `start_line`, `end_line`, `layer`, `repo`.\n\n### LangGraph pipeline (langgraph_app.py)\n\nIterative re", "- Indexer entry is indexer/index_repo.py:1-28.\n- HTTP MCP server is in server/mcp/http.py:1-23.\n\n\n## Architecture\n\n```\n┌────────────────────────────────────────────────────────────────────────────────┐\n│  AI Agents (Codex/Claude)   CLI Chat (local)                 CLI Chat (stream) │\n└────────────┬───────────────────────┬──────────────┬───────────────────────────┘\n             │ MCP stdio            │ MCP HTTP     │ HTTP (SSE)                \n             ▼                       ▼              ▼", "- Wait between repos if hitting limits\n- Consider using local embeddings (see Model Selection)\n\n### MCP Issues\n\n**Codex doesn't see tools:**\n```bash\n# Check registration\ncodex mcp list\n\n# Re-register\ncodex mcp add rag-service -- /path/to/python /path/to/mcp_server.py\n\n# Test manually\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | \\\n  .venv/bin/python mcp_server.py\n```\n\n**Claude Code doesn't see tools:**\n1. Check config file:\n   ```bash\n   cat ~/Library/Application\\ Support/C", "```\n\n### MCP Server Management\n\n```bash\n# List all MCP servers\ncodex mcp list\n\n# Remove a server\ncodex mcp remove rag-service\n\n# Re-add with updated path\ncodex mcp add rag-service -- /path/to/python /path/to/mcp_server.py\n\n# Test manually (stdio mode)\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | \\\n  .venv/bin/python mcp_server.py\n```\n\n---\n\n## Evaluation & Testing\n\n### In GUI \n\n<a href=\"assets/evals.png\" target=\"_blank\">\n  <img src=\"assets/evals.png\" alt=\"Evaluation Interfa"], "negative_doc_ids": ["/Users/davidmontgomery/agro/CLAUDE.md:1-46", "/Users/davidmontgomery/agro/README.md:1-29", "/Users/davidmontgomery/agro/README.md:1-42", "/Users/davidmontgomery/agro/README.md:1-39"], "source": "golden.json"}
{"query": "Where is auto-profile wizard rendered?", "positive_text": "    });\n  }\n  function renderResult(env, reason, scan, budget){\n    const results = document.getElementById('profile-results-content');\n    const placeholder = document.getElementById('profile-placeholder');\n    if (window.ProfileRenderer && results) {\n      try{\n        const html = window.ProfileRenderer.renderProfileResults(env, scan, budget);\n        results.innerHTML = html;\n        if (window.ProfileRenderer.bindTooltips) window.ProfileRenderer.bindTooltips(results);\n        // Append diag", "positive_doc_id": "/Users/davidmontgomery/agro/gui/js/autoprofile_v2.js:1-22", "negative_texts": ["      if (!r.ok){ const txt = await r.text(); throw new Error(txt || 'autoselect failed'); }\n      setPhase('Rendering result...');\n      const data = await r.json();\n      renderResult(data.env, data.reason, scan, payload.objective.monthly_budget_usd || budget);\n\n      // Optional: show an estimated cost banner using current cost panel inputs and selected providers\n      try{\n        const genProvider = (data.env.GEN_MODEL && data.env.GEN_MODEL.includes(':')) ? 'local' : 'openai';\n        const", "    });\n  }\n  function renderResult(env, reason, scan, budget){\n    const results = document.getElementById('profile-results-content');\n    const placeholder = document.getElementById('profile-placeholder');\n    if (window.ProfileRenderer && results) {\n      try{\n        const html = window.ProfileRenderer.renderProfileResults(env, scan, budget);\n        results.innerHTML = html;\n        if (window.ProfileRenderer.bindTooltips) window.ProfileRenderer.bindTooltips(results);\n        // Append diag", "        '</div>'; results.style.display='block'; }\n      if (placeholder) placeholder.style.display='none';\n    }\n  }\n\n  window.AutoProfileV2 = { run };\n})();\n", "    const results = document.getElementById('profile-results-content');\n    if (placeholder) {\n      placeholder.style.display='flex';\n      placeholder.innerHTML = `\n        <div style=\"display:flex;flex-direction:column;align-items:center;justify-content:center;\">\n          <div style=\\\"width:48px;height:48px;border:3px solid #2a2a2a;border-top-color:#00ff88;border-radius:50%;animation:spin 1s linear infinite;margin-bottom:16px;\\\"></div>\n          <p id=\\\"apv2-phase\\\" style=\\\"font-size:14px;co"], "negative_doc_ids": ["/Users/davidmontgomery/agro/public/agro/js/autoprofile_v2.js:1-23", "/Users/davidmontgomery/agro/public/agro/js/autoprofile_v2.js:1-22", "/Users/davidmontgomery/agro/public/agro/js/autoprofile_v2.js:1-8", "/Users/davidmontgomery/agro/public/agro/js/autoprofile_v2.js:1-20"], "source": "golden.json"}
{"query": "Test question from curl", "positive_text": "run_test(question: str, repo: str):\n    \"\"\"Run all three approaches and compare\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"TEST: {question}\")\n    print(f\"REPO: {repo}\")\n    print(f\"{'='*70}\\n\")\n\n    # Method 1: Claude alone\n    print(\"⏳ Measuring: Claude Alone (traditional grep + read files)...\")\n    claude_alone = measure_claude_alone(question, repo)\n\n    # Method 2: RAG Python\n    print(\"⏳ Measuring: RAG via Direct Python...\")\n    rag_python = measure_rag_python(question, repo, top_k=10)\n\n    # M", "positive_doc_id": "/Users/davidmontgomery/agro/scripts/test_token_savings.py:1-133", "negative_texts": ["golden_test(payload: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Test a single golden question and return retrieval results.\"\"\"\n    q = str(payload.get(\"q\") or \"\").strip()\n    if not q:\n        raise HTTPException(status_code=400, detail=\"Question required\")\n\n    repo = str(payload.get(\"repo\") or os.getenv(\"REPO\", \"agro\"))\n    expect_paths = list(payload.get(\"expect_paths\") or [])\n    final_k = int(payload.get(\"final_k\") or os.getenv(\"EVAL_FINAL_K\", \"5\"))\n    use_multi = payload.get(\"use_multi\", o", "#!/usr/bin/env python3\n\"\"\"Mine training triplets from golden.json test questions.\n\nRuns each golden question through retrieval and generates triplets\nbased on expect_paths matches.\n\"\"\"\nimport json\nimport sys\nfrom pathlib import Path\n\n# Add parent dir to path so we can import retrieval\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom retrieval.hybrid_search import search\n\nGOLDEN = Path(\"/agro/golden.json\")\nOUT = Path(\"data/training/triplets.jsonl\")\n", "#!/usr/bin/env python3\nfrom __future__ import annotations\n\n\"\"\"\nMCP server exposing RAG tools for Codex/Claude integration (stdio transport).\n\nTools (sanitized names for OpenAI tool spec):\n  - rag_answer(repo, question) → full LangGraph answer + citations\n  - rag_search(repo, question) → retrieval-only (for debugging)\nCompatibility: accepts legacy names \"rag.answer\" and \"rag.search\" on tools/call.\n\"\"\"\nimport sys\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport urllib.request, urlli", "from retrieval.rerank import *  # noqa: F401,F403\n"], "negative_doc_ids": ["/Users/davidmontgomery/agro/server/app.py:1-57", "/Users/davidmontgomery/agro/scripts/mine_from_golden.py:1-18", "/Users/davidmontgomery/agro/server/mcp/server.py:1-25", "/Users/davidmontgomery/agro/rerank.py:1-2"], "source": "golden.json"}
{"query": "Where is hybrid retrieval implemented?", "positive_text": "import os\nimport json\nimport collections\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom common.config_loader import choose_repo_from_query, get_default_repo, out_dir\nfrom dotenv import load_dotenv, find_dotenv\n\n# Load any existing env ASAP so downstream imports (e.g., rerank backend) see them\ntry:\n    load_dotenv(override=False)\nexcept Exception:\n    pass\n\nfrom qdrant_client import QdrantClient, models\nimport bm25s\nfrom bm25s.tokenization import Tokenizer\nfrom Stemmer import Stemmer", "positive_doc_id": "/Users/davidmontgomery/agro/retrieval/hybrid_search.py:1-23", "negative_texts": ["\"\"\"Retrieval package (hybrid search, reranking, chunking, caches).\n\nModules here are the canonical locations. Root-level shims import from here\nto preserve backward compatibility while we reorganize folders.\n\"\"\"\n\n", "│ langgraph_app   │     │ hybrid_search    │\n│ (LangGraph)     │     │ (Retrieval)      │\n└─────────────────┘     └─────────┬────────┘\n                                  │\n        ┌─────────────────────────┼─────────────────┐\n        ▼                         ▼                 ▼\n┌──────────────┐          ┌──────────────┐  ┌──────────────┐\n│   Qdrant     │          │    BM25S     │  │ Local Chunks │\n│  (vectors)   │          │  (sparse)    │  │   (.jsonl)   │\n└──────────────┘          └───────────", "\t•\tFile Search: https://platform.openai.com/docs/assistants/tools/file-search OpenAI\n\t•\tVector Store API: https://platform.openai.com/docs/api-reference/vector-stores OpenAI\nThis gives you hybrid retrieval and reranking out-of-the-box, but since you already have a working RAG, the MCP bridge above is the lightest, least-bloat path.\n\n10) Troubleshooting (one step at a time)\n\t1\tCodex can’t see MCP tools → run:\n\ncat ~/.codex/config.toml\ncodex mcp --help\nMake sure rag-service is listed, or re-add wi", "  - `indexer/`: indexing + cards\n    - `indexer/index_repo.py`\n    - `indexer/build_cards.py`\n\n- Root shims (keep CLI paths and imports stable)\n- Removed root shims. Use canonical modules:\n  - API app: `uvicorn server.app:app`\n  - `config_loader.py` → re-exports `common/config_loader.py`\n  - `path_config.py` → re-exports `common/paths.py`\n  - `filtering.py` → re-exports `common/filtering.py`\n  - `metadata_enricher.py` → re-exports `common/metadata.py`\n  - `qdrant_recreate_fallback.py` → re-expor"], "negative_doc_ids": ["/Users/davidmontgomery/agro/retrieval/__init__.py:1-7", "/Users/davidmontgomery/agro/internal_docs.md/archive/IMPLEMENTATION_COMPLETE.md:1-43", "/Users/davidmontgomery/agro/internal_docs.md/update_to_codex_agents_sdk.md:1-20", "/Users/davidmontgomery/agro/MIGRATION.md:1-26"], "source": "golden.json"}
{"query": "Where is keyword generation handled server-side?", "positive_text": "generate_keywords(body: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate keywords using either heuristics or an LLM (GUI‑selectable).\n\n    Body: { repo: str, mode?: 'heuristic' | 'llm', max_files?: int }\n    - heuristic: runs scripts/analyze_keywords.py and scripts/analyze_keywords_v2.py\n    - llm: samples files and uses metadata_enricher.enrich to accumulate keywords\n    \"\"\"\n    import subprocess\n    import time\n    from common.config_loader import get_repo_paths\n\n    repo = body.get(\"repo\")\n", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-285", "negative_texts": ["                mode === 'llm' ? `Mode: LLM • Backend: ${backend} • Model: ${model}` : 'Mode: Heuristic • Scanning tokens and file coverage…',\n                max_files || 80,\n                tips\n            );\n\n            // Call the keywords generation endpoint\n            const createResponse = await fetch(api('/api/keywords/generate'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ repo, mode, max_fi", "            ];\n            sim = startSimProgress(\n                mode === 'llm' ? `Mode: LLM • Backend: ${backend} • Model: ${model}` : 'Mode: Heuristic • Scanning tokens and file coverage…',\n                max_files || 80,\n                tips\n            );\n\n            // Call the keywords generation endpoint\n            const createResponse = await fetch(api('/api/keywords/generate'), {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n      ", "        const btn = document.getElementById('btn-generate-keywords');\n        setButtonState(btn, 'loading');\n        showStatus('Generating keywords (this may take 2–5 minutes)...', 'loading');\n        let sim; // progress simulator for keyword generation\n        try {\n            const response = await fetch(api('/api/config'));\n            const data = await response.json();\n            const env = (data && data.env) || (state.config && state.config.env) || {};\n            const repo = env.RE", "        setButtonState(btn, 'loading');\n        showStatus('Generating keywords (this may take 2–5 minutes)...', 'loading');\n        let sim; // progress simulator for keyword generation\n        try {\n            const response = await fetch(api('/api/config'));\n            const data = await response.json();\n            const env = (data && data.env) || (state.config && state.config.env) || {};\n            const repo = env.REPO || data.default_repo || 'agro';\n            const modeSel = documen"], "negative_doc_ids": ["/Users/davidmontgomery/agro/public/agro/app.js:1-30", "/Users/davidmontgomery/agro/gui/app.js:1-31", "/Users/davidmontgomery/agro/gui/app.js:1-22", "/Users/davidmontgomery/agro/public/agro/app.js:1-23"], "source": "golden.json"}
{"query": "Where is the metadata enrichment logic for code/keywords?", "positive_text": "from common.metadata import *  # noqa: F401,F403\n            txt = r.choices[0].message.content or \"{}\"\n        except Exception as e:\n            return {\"summary\": f\"OpenAI error: {str(e)[:100]}\", \"keywords\": []}\n\n    # Parse JSON response\n    # Parse JSON response; if model returned plain text, fallback to capturing tokens\n    try:\n        data = json.loads(txt)\n        if isinstance(data, dict):\n            kws = data.get(\"keywords\") or []\n            if isinstance(kws, str):\n               ", "positive_doc_id": "/Users/davidmontgomery/agro/metadata_enricher.py:1-24", "negative_texts": ["cat > /tmp/index_repo_patch.py << 'PY'\n# --- index_repo.py (snippet) ---\nimport os\nENRICH = os.getenv(\"ENRICH_CODE_CHUNKS\", \"false\").lower() == \"true\"\nif ENRICH:\n    from metadata_enricher import enrich\n\n# inside your chunk loop where you build the doc record:\n#   record = { 'file_path': fp, 'lang': lang, 'code': code_text, ... }\nif ENRICH:\n    meta = enrich(fp, lang, code_text)\n    record['summary'] = meta.get('summary', '')\n    record['keywords'] = meta.get('keywords', [])\n    # Concatenate en", "python index_repo.py\n```\n\n> **Note:** Changing dims creates a new Qdrant collection via `COLLECTION_SUFFIX`, avoiding errors from mismatched vector sizes.\n\n---\n\n## A2 — Enrich code chunks with **Qwen3‑Coder (30B)** via **Ollama**\n\nUse a local code LLM to generate *keywords + function/class summaries* that we append to each chunk prior to embedding. This dramatically improves recall on terse code.\n\n### Start Qwen3‑Coder (one time)\n\n````bash\n# Pull & warm up Qwen3‑Coder (30B). Requires recent Olla", "    \"2) key APIs/classes/functions referenced, 3) inputs/outputs/side-effects, \"\n    \"4) 8-15 retrieval keywords (snake_case). Keep under 120 tokens.\"\n)\n\nPROMPT_TMPL = (\n    \"<system>\" + SYSTEM + \"</system>\n\"\n    \"<analyze file='{file}' lang='{lang}'>\n{code}\n</analyze>\n\"\n    \"<format>JSON with keys: summary, keywords</format>\"\n)\n\ndef enrich(file_path: str, lang: str, code: str) -> dict:\n    prompt = PROMPT_TMPL.format(file=file_path, lang=lang, code=code[:4000])\n    resp = requests.post(OLLAMA_U", "from __future__ import annotations\n\nimport os\nimport json\nimport time\nimport uuid\nimport queue\nimport threading\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Iterator, List\n\nfrom common.config_loader import out_dir\nfrom server.env_model import generate_text\n\n\nQUICK_TIPS = [\n    \"Put repo-specific nouns in Discriminative to improve filename/path hits.\",\n    \"Add Semantic synonyms: auth→oauth,jwt,bearer; events→sse,ws,subscribe.\",\n    \"Sh"], "negative_doc_ids": ["/Users/davidmontgomery/agro/internal_docs.md/rag-improvement-runbook.md:1-37", "/Users/davidmontgomery/agro/internal_docs.md/rag-improvement-runbook.md:1-36", "/Users/davidmontgomery/agro/internal_docs.md/rag-improvement-runbook.md:1-35", "/Users/davidmontgomery/agro/server/cards_builder.py:1-33"], "source": "golden.json"}
{"query": "Where is the indexing pipeline (BM25 and dense) implemented?", "positive_text": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nfrom common.config_loader import get_repo_paths, out_dir\nfrom common.paths import data_dir\nfrom retrieval.ast_chunker import lang_from_path, collect_files, chunk_code\nimport bm25s  # type: ignore\nfrom bm25s.tokenization import Tokenizer  # type: ignore\nfrom Stemmer import Stemmer  # type: ignore\nfrom qdrant_client import QdrantClient, models\nimport uuid\nfrom ope", "positive_doc_id": "/Users/davidmontgomery/agro/indexer/index_repo.py:1-28", "negative_texts": ["\n```\nUser / Agent\n   ↓\nMCP Server (mcp_server.py)  ← tools: rag_answer(repo, question), rag_search(repo, question, top_k)\n   ↓\nLangGraph Orchestrator (langgraph_app.py)\n   ↓\nHybrid Search (hybrid_search.py)\n   ├─ BM25 (bm25s)\n   ├─ Dense vectors (Qdrant; OpenAI embeddings 3072-d)\n   └─ Cross-encoder rerank (e.g., BAAI/bge-reranker-v2-m3)\n   ↓\nLocal Hydration (out/{repo}/chunks.jsonl)\n   ↓\nGeneration (via Responses API; default `gpt-4o-mini-latest` or `GEN_MODEL`)\n   ↓\nAnswer + Citations (must in", "                                    <div style=\"color:#888;margin-bottom:2px;\">BM25 Index</div>\n                                    <div style=\"color:#ff9b5e;font-family:'SF Mono',monospace;font-size:11px;\">${formatBytes(repo.sizes.bm25)}</div>\n                                </div>\n                            ` : ''}\n                            ${repo.paths.cards ? `\n                                <div style=\"background:#0a0a0a;padding:6px 8px;border-radius:4px;border:1px solid #1a1a1a;\">\n    ", "         print(d['file_path'], d['start_line'], d['end_line'])\n     PY\n     ```\n\nKey Components\nIndexing (index_repo.py)\n\nAST-aware chunking (ast_chunker.py), layer tagging (ui/server/integration/infra).\n\nBM25 index build (stemming).\n\nEmbeddings: OpenAI text-embedding-3-large when available; automatic local fallback (BGE-small, 384‑d) → Qdrant \n\nLocal cache to prevent re-embedding unchanged chunks.\n\n\n\nHybrid search (hybrid_search.py)\n\n\n\nMulti-query expansion (defaults enabled; count configurable", "```\n\n### 6) Minimal CLI chat\n```bash\ncd path/to/your/rag-service && . .venv/bin/activate && \\\nexport REPO=project && export THREAD_ID=my-session && \\\npython chat_cli.py\n```\n\n### Cross-Branch Indexing (Shared Profile)\n\n- Goal: One shared index usable from any branch without touching code.\n- Create a fast BM25-only index (no external APIs):\n  - `REPO=agro OUT_DIR_BASE=./out.noindex-shared EMBEDDING_TYPE=local SKIP_DENSE=1 python index_repo.py`\n- Retrieval picks the index from `OUT_DIR_BASE`. Dense"], "negative_doc_ids": ["/Users/davidmontgomery/agro/CLAUDE.md:1-41", "/Users/davidmontgomery/agro/public/agro/app.js:1-20", "/Users/davidmontgomery/agro/AGENTS.md:1-41", "/Users/davidmontgomery/agro/CLAUDE.md:1-26"], "source": "golden.json"}
{"query": "Where is comprehensive index status computed?", "positive_text": "index_status() -> Dict[str, Any]:\n    \"\"\"Return comprehensive indexing status with all metrics.\"\"\"\n    if not _INDEX_METADATA:\n        # Return basic status if no metadata yet\n        return {\n            \"lines\": _INDEX_STATUS,\n            \"running\": len(_INDEX_STATUS) > 0 and not any(\"completed\" in s or \"failed\" in s for s in _INDEX_STATUS),\n            \"metadata\": _get_index_stats()  # Always provide current stats\n        }\n\n    return {\n        \"lines\": _INDEX_STATUS,\n        \"running\": Fals", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-36", "negative_texts": ["// Enterprise-grade indexing status display\n// Matches storage calculator format with comprehensive metrics\nformatBytes(bytes) {\n    if (!bytes || bytes === 0) return '0 B';\n    const k = 1024;\n    const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];\n    const i = Math.floor(Math.log(bytes) / Math.log(k));\n    return Math.round((bytes / Math.pow(k, i)) * 100) / 100 + ' ' + sizes[i];\n}\n", "// Indexing status and controls. Exported via window.IndexStatus\n;(function(){\n  'use strict';\n  const api = (window.CoreUtils && window.CoreUtils.api) ? window.CoreUtils.api : (p=>p);\n  let indexPoll = null;\n\n  function formatBytes(bytes){\n    if (!bytes || bytes === 0) return '0 B';\n    const k = 1024; const sizes = ['B','KB','MB','GB'];\n    const i = Math.floor(Math.log(bytes)/Math.log(k));\n    return Math.round((bytes / Math.pow(k,i))*100)/100 + ' ' + sizes[i];\n  }\n\n  function formatIndexSta", "from retrieval.rerank import *  # noqa: F401,F403\n", "from common.filtering import *  # noqa: F401,F403\n"], "negative_doc_ids": ["/Users/davidmontgomery/agro/public/agro/js/index-display.js:1-10", "/Users/davidmontgomery/agro/public/agro/js/index_status.js:1-24", "/Users/davidmontgomery/agro/rerank.py:1-2", "/Users/davidmontgomery/agro/filtering.py:1-2"], "source": "golden.json"}
{"query": "Where are semantic cards built or listed?", "positive_text": "import os\nimport json\nfrom typing import Dict, Iterator\nfrom dotenv import load_dotenv\nfrom server.env_model import generate_text\nfrom common.config_loader import out_dir\n\nload_dotenv()\nREPO = os.getenv('REPO','project').strip()\nMAX_CHUNKS = int(os.getenv('CARDS_MAX') or '0')\nBASE = out_dir(REPO)\nCHUNKS = os.path.join(BASE, 'chunks.jsonl')\nCARDS = os.path.join(BASE, 'cards.jsonl')\nCARDS_TXT = os.path.join(BASE, 'cards.txt')\nINDEX_DIR = os.path.join(BASE, 'bm25_cards')\n\nPROMPT = (\n    \"Analyze th", "positive_doc_id": "/Users/davidmontgomery/agro/indexer/build_cards.py:1-37", "negative_texts": ["from __future__ import annotations\n\nimport os\nimport json\nimport time\nimport uuid\nimport queue\nimport threading\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Iterator, List\n\nfrom common.config_loader import out_dir\nfrom server.env_model import generate_text\n\n\nQUICK_TIPS = [\n    \"Put repo-specific nouns in Discriminative to improve filename/path hits.\",\n    \"Add Semantic synonyms: auth→oauth,jwt,bearer; events→sse,ws,subscribe.\",\n    \"Sh", "  - `indexer/`: indexing + cards\n    - `indexer/index_repo.py`\n    - `indexer/build_cards.py`\n\n- Root shims (keep CLI paths and imports stable)\n- Removed root shims. Use canonical modules:\n  - API app: `uvicorn server.app:app`\n  - `config_loader.py` → re-exports `common/config_loader.py`\n  - `path_config.py` → re-exports `common/paths.py`\n  - `filtering.py` → re-exports `common/filtering.py`\n  - `metadata_enricher.py` → re-exports `common/metadata.py`\n  - `qdrant_recreate_fallback.py` → re-expor", "      const e2 = document.getElementById('cards-model-enrich'); if (e2 && model && model.enrich) e2.textContent = `enrich: ${model.enrich}`;\n      const e3 = document.getElementById('cards-model-rerank'); if (e3 && model && model.rerank) e3.textContent = `rerank: ${model.rerank}`;\n    } catch {}\n  }\n\n  function stopCardsStreams(){\n    if (cardsJob.timer) { clearInterval(cardsJob.timer); cardsJob.timer = null; }\n    if (cardsJob.sse) { try { cardsJob.sse.close(); } catch{} cardsJob.sse = null; }\n", "\n**Query Parameters:**\n- `repo` (string, optional) - Repository name\n- `enrich` (integer, optional) - Enable enrichment with LLM (1=yes, 0=no, default: 1)\n\n**Response:**\n```json\n{\n  \"job_id\": \"cards-abc123\",\n  \"status\": \"started\",\n  \"repo\": \"agro\",\n  \"stream_url\": \"/api/cards/build/stream/cards-abc123\"\n}\n```\n\n---\n\n### GET `/api/cards/build/stream/{job_id}`\n\nStream card building progress (SSE).\n\n**Response (Server-Sent Events):**\n```\nevent: progress\ndata: {\"files_processed\": 10, \"total\": 100, \"me"], "negative_doc_ids": ["/Users/davidmontgomery/agro/server/cards_builder.py:1-33", "/Users/davidmontgomery/agro/MIGRATION.md:1-26", "/Users/davidmontgomery/agro/public/agro/js/cards_builder.js:1-20", "/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-56"], "source": "golden.json"}
{"query": "Where are golden questions API routes defined?", "positive_text": "golden_list() -> Dict[str, Any]:\n    \"\"\"List all golden questions.\"\"\"\n    gp = _golden_path()\n    if not gp.exists():\n        return {\"questions\": [], \"count\": 0}\n    data = _read_json(gp, [])\n    if not isinstance(data, list):\n        data = []\n    # Filter out comment entries\n    questions = [q for q in data if isinstance(q, dict) and \"q\" in q]\n    return {\"questions\": questions, \"count\": len(questions)}\n\n@app.post(\"/api/golden\")golden_add(payload: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Add", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-35", "negative_texts": ["// Golden Questions Manager\n// Handles CRUD operations for golden questions used in RAG evaluation\n\nlet goldenQuestions = [];\n\n// Recommended questions (baseline for this repo)\nconst RECOMMENDED_GOLDEN = [\n  { q: 'Where is hybrid retrieval implemented?', repo: 'agro', expect_paths: ['retrieval/hybrid_search.py'] },\n  { q: 'Where is keyword generation handled server-side?', repo: 'agro', expect_paths: ['server/app.py','keywords/generate'] },\n  { q: 'Where is the metadata enrichment logic for code", "exportGoldenQuestions() {\n    const dataStr = JSON.stringify(goldenQuestions, null, 2);\n    const blob = new Blob([dataStr], { type: 'application/json' });\n    const url = URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = 'golden_questions_export.json';\n    a.click();\n    URL.revokeObjectURL(url);\n    showToast('Questions exported', 'success');\n}\n\n// Helper: escape HTMLescapeHtml(text) {\n    const div = document.createElement('div');\n    div", "renderGoldenQuestions() {\n    const container = document.getElementById('golden-questions-content');\n\n    if (goldenQuestions.length === 0) {\n        container.innerHTML = `\n            <div style=\"text-align: center; padding: 24px; color: #666;\">\n                <svg width=\"48\" height=\"48\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.5\" style=\"opacity: 0.3; margin-bottom: 12px;\">\n                    <circle cx=\"12\" cy=\"12\" r=\"10\"></circle>\n                    <line x1=\"", "  }\n}\n```\n\n---\n\n### GET `/api/prices`\n\nGet model pricing database.\n\n**Response:**\n```json\n{\n  \"models\": [\n    {\n      \"provider\": \"openai\",\n      \"model\": \"gpt-4o-mini\",\n      \"unit\": \"1k_tokens\",\n      \"input_cost\": 0.000150,\n      \"output_cost\": 0.000600\n    },\n    {\n      \"provider\": \"cohere\",\n      \"model\": \"rerank-3.5\",\n      \"unit\": \"1k_searches\",\n      \"rerank_per_1k\": 2.00\n    }\n  ]\n}\n```\n\n---\n\n### POST `/api/prices/upsert`\n\nAdd or update model pricing.\n\n**Request Body:**\n```json\n{\n  \"pr"], "negative_doc_ids": ["/Users/davidmontgomery/agro/public/agro/js/golden_questions.js:1-36", "/Users/davidmontgomery/agro/public/agro/js/golden_questions.js:1-19", "/Users/davidmontgomery/agro/public/agro/js/golden_questions.js:1-152", "/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-96"], "source": "golden.json"}
{"query": "Where is the endpoint to test a single golden question?", "positive_text": "golden_test(payload: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Test a single golden question and return retrieval results.\"\"\"\n    q = str(payload.get(\"q\") or \"\").strip()\n    if not q:\n        raise HTTPException(status_code=400, detail=\"Question required\")\n\n    repo = str(payload.get(\"repo\") or os.getenv(\"REPO\", \"agro\"))\n    expect_paths = list(payload.get(\"expect_paths\") or [])\n    final_k = int(payload.get(\"final_k\") or os.getenv(\"EVAL_FINAL_K\", \"5\"))\n    use_multi = payload.get(\"use_multi\", o", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-57", "negative_texts": ["  \"repo\": \"agro\",\n  \"expect_paths\": [\"auth\", \"oauth\", \"token\", \"validation\"]\n}\n```\n\n---\n\n### DELETE `/api/golden/{index}`\n\nDelete a golden test by index.\n\n**Response:**\n```json\n{\n  \"ok\": true,\n  \"deleted_index\": 2,\n  \"remaining_count\": 9\n}\n```\n\n---\n\n### POST `/api/golden/test`\n\nTest a single question without adding to golden set.\n\n**Request Body:**\n```json\n{\n  \"q\": \"How does indexing work?\",\n  \"repo\": \"agro\",\n  \"expect_paths\": [\"index\", \"chunk\"]\n}\n```\n\n**Response:**\n```json\n{\n  \"hit\": true,\n  \"r", "  }\n}\n```\n\n---\n\n### GET `/api/prices`\n\nGet model pricing database.\n\n**Response:**\n```json\n{\n  \"models\": [\n    {\n      \"provider\": \"openai\",\n      \"model\": \"gpt-4o-mini\",\n      \"unit\": \"1k_tokens\",\n      \"input_cost\": 0.000150,\n      \"output_cost\": 0.000600\n    },\n    {\n      \"provider\": \"cohere\",\n      \"model\": \"rerank-3.5\",\n      \"unit\": \"1k_searches\",\n      \"rerank_per_1k\": 2.00\n    }\n  ]\n}\n```\n\n---\n\n### POST `/api/prices/upsert`\n\nAdd or update model pricing.\n\n**Request Body:**\n```json\n{\n  \"pr", "// Golden Questions Manager\n// Handles CRUD operations for golden questions used in RAG evaluation\n\nlet goldenQuestions = [];\n\n// Recommended questions (baseline for this repo)\nconst RECOMMENDED_GOLDEN = [\n  { q: 'Where is hybrid retrieval implemented?', repo: 'agro', expect_paths: ['retrieval/hybrid_search.py'] },\n  { q: 'Where is keyword generation handled server-side?', repo: 'agro', expect_paths: ['server/app.py','keywords/generate'] },\n  { q: 'Where is the metadata enrichment logic for code", "renderGoldenQuestions() {\n    const container = document.getElementById('golden-questions-content');\n\n    if (goldenQuestions.length === 0) {\n        container.innerHTML = `\n            <div style=\"text-align: center; padding: 24px; color: #666;\">\n                <svg width=\"48\" height=\"48\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.5\" style=\"opacity: 0.3; margin-bottom: 12px;\">\n                    <circle cx=\"12\" cy=\"12\" r=\"10\"></circle>\n                    <line x1=\""], "negative_doc_ids": ["/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-87", "/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-96", "/Users/davidmontgomery/agro/public/agro/js/golden_questions.js:1-36", "/Users/davidmontgomery/agro/public/agro/js/golden_questions.js:1-152"], "source": "golden.json"}
{"query": "Where are GUI assets mounted and served?", "positive_text": "from fastapi import FastAPI, Query, HTTPException, Request, UploadFile, File, Form\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom pathlib import Path\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse, JSONResponse, RedirectResponse, Response\nfrom starlette.responses import StreamingResponse\nfrom server.langgraph_app import build_graph\nfrom server.tracing import start_trace, end_trace, Trace, latest_trace_path\nfrom retrieval.h", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-42", "negative_texts": ["- Scripts (`scripts/up.sh`, CI, and MCP registrations) still reference root filenames.\n- Once all internal imports and tooling point to canonical packages, shims can be removed in a follow-up change.\n\nWhere to find key functionality\n\n- API/GUI service: `server/app.py` (mounts `/gui`, `/docs`, `/files`, config endpoints).\n- Path resolution: `path_config.py` with `repo_root()`, `files_root()`, `gui_dir()`, `docs_dir()`, `data_dir()`. See: path_config.py:1-40, 42-80.\n  (Now canonical: `common/paths", "```\n\n### MCP Server Management\n\n```bash\n# List all MCP servers\ncodex mcp list\n\n# Remove a server\ncodex mcp remove rag-service\n\n# Re-add with updated path\ncodex mcp add rag-service -- /path/to/python /path/to/mcp_server.py\n\n# Test manually (stdio mode)\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}' | \\\n  .venv/bin/python mcp_server.py\n```\n\n---\n\n## Evaluation & Testing\n\n### In GUI \n\n<a href=\"assets/evals.png\" target=\"_blank\">\n  <img src=\"assets/evals.png\" alt=\"Evaluation Interfa", "# Settings GUI API (Local-Only)\n\nAll feature flags, settings, variables, and parameters are controlled in the GUI. Do not edit code to change configuration. If a knob doesn’t fit a category, it belongs in the GUI “Misc” tab.\n\nThis contract powers the local admin GUI. All routes are localhost-only and unauthenticated.\n\n![Dashboard](../assets/dashboard.png)\n\n### Chat Tab (GUI Chat, not terminal)\n\nThe Chat tab embeds a full chat experience inside the GUI (not a terminal). It shows citations, repo s", "from retrieval.embed_cache import *  # noqa: F401,F403\n"], "negative_doc_ids": ["/Users/davidmontgomery/agro/MIGRATION.md:1-18", "/Users/davidmontgomery/agro/README.md:1-39", "/Users/davidmontgomery/agro/docs/API_GUI.md:1-34", "/Users/davidmontgomery/agro/embed_cache.py:1-2"], "source": "golden.json"}
{"query": "Where is repository configuration (repos.json) loaded?", "positive_text": "list_repos() -> List[str]:\n    cfg = load_repos()\n    return [str(r.get(\"name\")) for r in cfg.get(\"repos\", []) if r.get(\"name\")]\n\nget_default_repo() -> str:\n    cfg = load_repos()\n    if cfg.get(\"default_repo\"):\n        return str(cfg[\"default_repo\"]).strip()\n    repos = cfg.get(\"repos\", [])\n    if repos:\n        return str(repos[0].get(\"name\"))\n    return (os.getenv(\"REPO\") or \"default\").strip()\n\n_find_repo(name: str) -> Optional[Dict[str, Any]]:\n    name_low = (name or \"\").strip().lower()\n    ", "positive_doc_id": "/Users/davidmontgomery/agro/common/config_loader.py:1-34", "negative_texts": ["from fastapi import FastAPI, Query, HTTPException, Request, UploadFile, File, Form\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom pathlib import Path\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse, JSONResponse, RedirectResponse, Response\nfrom starlette.responses import StreamingResponse\nfrom server.langgraph_app import build_graph\nfrom server.tracing import start_trace, end_trace, Trace, latest_trace_path\nfrom retrieval.h", "    async function changeRepo() {\n        showStatus('Loading repositories...', 'loading');\n\n        try {\n            const response = await fetch(api('/api/config'));\n            const data = await response.json();\n            const repos = data.repos || [];\n            const currentRepo = (data.env && data.env.REPO) || data.default_repo || 'agro';\n\n            if (repos.length === 0) {\n                showStatus('No repositories configured', 'error');\n                return;\n            }\n\n  ", "    async function changeRepo() {\n        showStatus('Loading repositories...', 'loading');\n\n        try {\n            const response = await fetch(api('/api/config'));\n            const data = await response.json();\n            const repos = data.repos || [];\n            const currentRepo = (data.env && data.env.REPO) || data.default_repo || 'agro';\n\n            if (repos.length === 0) {\n                showStatus('No repositories configured', 'error');\n                return;\n            }\n\n  ", "  - Open `/` → Tab “Infrastructure” → set `Out Dir Base` to `./out.noindex-shared`, select `Active Repository`, optionally set `Collection Name`.\n  - Click “Apply All Changes” — this writes `.env` and `repos.json` (POST `/api/config`).\n\nMCP “no results” quick fix\n- Symptom: `rag_search` returns `{count: 0}` even though `out.noindex-shared/agro/chunks.jsonl` exists.\n- Fix checklist:\n  1) Confirm index path: `ls -lh out.noindex-shared/agro/chunks.jsonl`\n  2) Ensure env seen by MCP: set `OUT_DIR_BA"], "negative_doc_ids": ["/Users/davidmontgomery/agro/server/app.py:1-42", "/Users/davidmontgomery/agro/gui/app.js:1-42", "/Users/davidmontgomery/agro/public/agro/app.js:1-44", "/Users/davidmontgomery/agro/AGENTS.md:1-17"], "source": "golden.json"}
{"query": "Where are MCP stdio tools implemented (rag_answer, rag_search)?", "positive_text": "#!/usr/bin/env python3\nfrom __future__ import annotations\n\n\"\"\"\nMCP server exposing RAG tools for Codex/Claude integration (stdio transport).\n\nTools (sanitized names for OpenAI tool spec):\n  - rag_answer(repo, question) → full LangGraph answer + citations\n  - rag_search(repo, question) → retrieval-only (for debugging)\nCompatibility: accepts legacy names \"rag.answer\" and \"rag.search\" on tools/call.\n\"\"\"\nimport sys\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport urllib.request, urlli", "positive_doc_id": "/Users/davidmontgomery/agro/server/mcp/server.py:1-25", "negative_texts": ["from __future__ import annotations\nimport os\nimport json\nimport urllib.request\nimport urllib.error\nimport urllib.parse\nfrom typing import Dict, Any\n\nfrom fastmcp import FastMCP\n\n# Canonical imports\nfrom server.langgraph_app import build_graph\nfrom retrieval.hybrid_search import search_routed_multi\nfrom common.config_loader import list_repos\n\n\nmcp = FastMCP(\"rag-service\")\n_graph = None\n\n_get_graph():\n    global _graph\n    if _graph is None:\n        _graph = build_graph()\n    return _graph\n\n\n@mcp.", "\n# Eval to check quality\n. .venv/bin/activate && python eval_loop.py\n\n# MCP quick check (stdio mode)\nprintf '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\",\"params\":{}}\\n' | python mcp_server.py | head -n1\n\n# Use with Codex\ncodex\n# Then type: \"Use rag_answer to explain how authentication works in repo-a\"\n```\n\n---\n\n## ✅ What's Been Implemented\n\n- ✅ **MCP Server (stdio + HTTP modes)**\n  - `rag_answer(repo, question)` → Full pipeline with citations\n  - `rag_search(repo, question)` → Retrieval-only (", "\n#### 2. **HTTP Mode** (for remote agents/platforms)\n- File: `mcp_server_http.py`\n- Protocol: HTTP at `/mcp` endpoint\n- Use for: Remote evals, cloud platforms, web agents\n\n#### 3. **HTTPS Mode** (HTTP + reverse proxy)\n- Setup: Caddy/Nginx in front of HTTP mode\n- Tunneling: ngrok or Cloudflare Tunnel support (coming soon)\n- Use for: Production deployments, secure remote access\n\nSee **[docs/REMOTE_MCP.md](docs/REMOTE_MCP.md)** for HTTP/HTTPS setup.\n\n### Tools Available\n\nThe MCP server exposes 4 to", "echo \"  • Claude Code: Restart app, then use rag_answer or rag_search tools\"\necho \"\"\necho \"Docs:\"\necho \"  • Quick start: docs/QUICKSTART_MCP.md\"\necho \"  • Full guide: README.md\"\n"], "negative_doc_ids": ["/Users/davidmontgomery/agro/server/mcp/http.py:1-27", "/Users/davidmontgomery/agro/START_HERE.md:1-38", "/Users/davidmontgomery/agro/README.md:1-47", "/Users/davidmontgomery/agro/scripts/SETUP_MCP.sh:1-6"], "source": "golden.json"}
{"query": "Where can I list or fetch latest LangGraph traces?", "positive_text": "from fastapi import FastAPI, Query, HTTPException, Request, UploadFile, File, Form\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom pathlib import Path\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse, JSONResponse, RedirectResponse, Response\nfrom starlette.responses import StreamingResponse\nfrom server.langgraph_app import build_graph\nfrom server.tracing import start_trace, end_trace, Trace, latest_trace_path\nfrom retrieval.h", "positive_doc_id": "/Users/davidmontgomery/agro/server/app.py:1-42", "negative_texts": ["\nLangGraph memory/checkpoint.\n\n### Local files\n\n- `out/{repo}/chunks.jsonl` (full code chunks)\n- `out/{repo}/bm25_idx/` (BM25)\n- `out/{repo}/cards.jsonl` (optional code \"cards\" for high-level hits)\n\n---\n\n## Environment\n\n### Required\n\n`OPENAI_API_KEY`\n\n### Infra\n\n- `QDRANT_URL` (default `http://127.0.0.1:6333`)\n- `REDIS_URL` (default `redis://127.0.0.1:6379/0`)\n\n### RAG\n\n- `REPO` (project | project) for indexers/CLIs\n- `RERANKER_MODEL` (default `BAAI/bge-reranker-v2-m3`)\n- `MQ_REWRITES` (multi-qu", "\nOutputs: `out/{repo}/chunks.jsonl`, `out/{repo}/bm25_idx/`, optional `out/{repo}/cards.jsonl`.\n\n### Hybrid search (hybrid_search.py)\n\nIntent classification (ui/server/integration/sdk/infra) → per-repo layer bonuses.\n\nMulti-query expansion (defaults enabled; count configurable).\n\nBM25 + vector fusion → cross-encoder rerank → local hydration of code.\n\nReturns top-K with `rerank_score`, `file_path`, `start_line`, `end_line`, `layer`, `repo`.\n\n### LangGraph pipeline (langgraph_app.py)\n\nIterative re", "  \"key_present\": true,\n  \"can_connect\": true,\n  \"identity\": {\n    \"user_id\": \"abc123\",\n    \"org_id\": \"org-xyz\"\n  }\n}\n```\n\n---\n\n### GET `/api/traces`\n\nList recent retrieval traces.\n\n**Query Parameters:**\n- `repo` (string, optional) - Filter by repository\n- `limit` (integer, optional) - Number of traces (default: 20)\n\n**Response:**\n```json\n{\n  \"traces\": [\n    {\n      \"query\": \"Where is OAuth validated?\",\n      \"repo\": \"agro\",\n      \"timestamp\": \"2025-10-13T12:34:56Z\",\n      \"retrieval_count\": 5,\n ", "#!/usr/bin/env python3\nfrom __future__ import annotations\n\n\"\"\"\nMCP server exposing RAG tools for Codex/Claude integration (stdio transport).\n\nTools (sanitized names for OpenAI tool spec):\n  - rag_answer(repo, question) → full LangGraph answer + citations\n  - rag_search(repo, question) → retrieval-only (for debugging)\nCompatibility: accepts legacy names \"rag.answer\" and \"rag.search\" on tools/call.\n\"\"\"\nimport sys\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport urllib.request, urlli"], "negative_doc_ids": ["/Users/davidmontgomery/agro/CLAUDE.md:1-44", "/Users/davidmontgomery/agro/CLAUDE.md:1-46", "/Users/davidmontgomery/agro/docs/API_REFERENCE.md:1-77", "/Users/davidmontgomery/agro/server/mcp/server.py:1-25"], "source": "golden.json"}
